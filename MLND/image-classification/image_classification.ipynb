{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 6:\n",
      "Image - Min Value: 7 Max Value: 249\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 2 Name: bird\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAH2CAYAAABz4PUxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAHQ9JREFUeJzt3UmP7Pd1HuBfVXVV9Tzd23cmxSuSkqgZloU4CyNKgNiL\nrLPLZ8mnSdbZZWnEQSJAsAI7GkmKIsU7Dz3cHqtrzlbbc9CGg4Pn2b843VX/rrdr9XaWy2UDAOrp\n/kv/AADAPw8lDwBFKXkAKErJA0BRSh4AilLyAFCUkgeAopQ8ABSl5AGgKCUPAEUpeQAoSskDQFFK\nHgCKUvIAUJSSB4CilDwAFKXkAaColX/pH+Cfw3/9x/+4zOT+99+9Dme2Vr+TOdU21rfDmX4n93Zt\nbvRTuds7D8KZvfVHqVu7OzvhzMvDJ6lbX779v6nc9sOLcObWw8vUrf7wKpwZXb5L3VpdHYQzvc5u\n6tZiPkvl5vPzcGZvO/csDofr4cxKi/98rbV2ejZO5Y5exz8Lri/if2OttXY13gxnli31EdxOjl+m\ncldX8dfx7OI0dWvZ4s/wyXH8s6O11v7Lf/55JxX8M77JA0BRSh4AilLyAFCUkgeAopQ8ABSl5AGg\nKCUPAEUpeQAoSskDQFFKHgCKUvIAUJSSB4CilDwAFFVyha43zOU2bseXgn71f36euvXevb8IZ7Y2\n1lK3rie9VG50Hl+SGu3mRpNmnfjq2t6D3OP78Xu53Gg1vlJ4vsgtwy3O4stww/lG6tZyGH+fp/P4\n+9Vaayu9+KJZa63tb98OZ9YHuSW06eVWOHN2eT916/zoLJV78vnX4UxvuEjdav1pOPLs+avUqa3N\n+HPfWmsX5/NwZjbL3WqJhb1F8qW/Cb7JA0BRSh4AilLyAFCUkgeAopQ8ABSl5AGgKCUPAEUpeQAo\nSskDQFFKHgCKUvIAUJSSB4CiSg7UPH9zlMo9eLwXzvR68TGL1lrb3/xmIhUfimittedffZnKffX8\nZTjz8EFuuORyGX8d91ZOUrdm25+mct3N+HM1nvZTt87fzcKZ/ZX11K1BYshleyc3NLO19iiVG0/j\nz/5klht/abP4msjp64PUqZMvcx/Bn//yn8KZjffiz1RrrT386E44s7qRe+7PznPv2fg68bt1cj/j\n4dHbcGYyvU7dugm+yQNAUUoeAIpS8gBQlJIHgKKUPAAUpeQBoCglDwBFKXkAKErJA0BRSh4AilLy\nAFCUkgeAopQ8ABRVcoXu88/PU7kPvhlfknr87fdTt778wxfhzOXVRerWxlZunex8dBrO/OazX6du\nbT74OJy5tTVJ3Zp14ytjrbX27MvEuuEy99rvDR7ET7XcytjqIP7c7+/cTd26OB2kcp/+Pv677W3c\nS93a2o5/95ne6qVuXT7P/YyvXu+GM48f5X7G9c346zFb5J77yXXuM25lEP8ZT45zPXF1GV+U6+Re\n+hvhmzwAFKXkAaAoJQ8ARSl5AChKyQNAUUoeAIpS8gBQlJIHgKKUPAAUpeQBoCglDwBFKXkAKKrk\nQM3TJ/NUbtlG4czZraepW5NufPxlvjJN3drd20/lPv7243Dm9Zv479Vaa5fT+OjDr36bGIxprc26\nuedj93Z8RKctcyMY/WH89djbz73Pm+u3w5nzs07q1uHrcSq3mMQ/qla3t1K3ziZ74cyvr7+ZujXe\nv5XKde98Hc6sr+b+Xk7eHYczL1/knvvZODeyNB3H/14uLs9St2az+M+4Ohimbt0E3+QBoCglDwBF\nKXkAKErJA0BRSh4AilLyAFCUkgeAopQ8ABSl5AGgKCUPAEUpeQAoSskDQFFKHgCKKrlCNxv3U7l3\nbybhzPTqJHVruLEMZ/bu5VbGlsPcstOdjzbDmbPFRerWxSj+2q+13OtxdBRfrGqtta3BTjjz4NFu\n6ta0vQlnThe53+vy+DCcWe3FX4vWWruIDz221lrb2o6veM0Gub/NN5d3wpn//t/iz29rrS2WL1K5\nDwfxn7G37KVuHb6Ir7VNruOfb6211lvJrRteT+MLnctO7tbmVvzZ7yxzt26Cb/IAUJSSB4CilDwA\nFKXkAaAoJQ8ARSl5AChKyQNAUUoeAIpS8gBQlJIHgKKUPAAUpeQBoCglDwBFlVyhG3ZyK3TTUXzF\na+/evdSt569fhzNn189Tt5bdz1O5H33/W+HMv/7b3OuxMdgKZ6ZX8UxrrX3+eW4K7ezkbTizthZf\nT2uttflgHs48O3uSunVrK77g9WBvkLq1tb+Wyg0S30cuZ7kltD8++zqc+fJ/naZuTc7/mMp13ovf\nu3oTX5NrrbX731gPZ9Z2c89H6+aWFLu9+L319VxPTBKLmf1u/DW8Kb7JA0BRSh4AilLyAFCUkgeA\nopQ8ABSl5AGgKCUPAEUpeQAoSskDQFFKHgCKUvIAUJSSB4CiSg7UnJ9cpHLbt+ODFkdnL1O3Vjc7\n4czF5Sx1azqLj5201tqnv/sqnHn5PDeSsrW1Gs7cvfte6tadD3LjGVdfX4YzT9/mBkjWthbhzK2D\n7dStve34KEi3+yx1a2UQf59ba23Q3QlnZpPbqVuLafxvsy1OUrc++UFu2OY7j+O5rfVx6tbeQfxZ\nvLraSN2aTHJ/m+dH8cGv+ST+e7XW2togMTYzz40l3QTf5AGgKCUPAEUpeQAoSskDQFFKHgCKUvIA\nUJSSB4CilDwAFKXkAaAoJQ8ARSl5AChKyQNAUUoeAIoquULXWSRWpFpr3ZXEMtzoXerW3bt3wple\niy9xtdbaixfTVO5sGV8MOzuZpG6trL4NZ44u45nWWtvZ2kvlVjfXwpntW49St9aG8T/Nu3v3k7d6\niVTumZpOc4uI0+lROLPs577DnJ0chDPbuQHA9rN/fyuVG7Y34cz9e5upW4PE8/H5r3MLb8cnV6nc\n9dkonFkm1zl3bsdfx3ny1k3wTR4AilLyAFCUkgeAopQ8ABSl5AGgKCUPAEUpeQAoSskDQFFKHgCK\nUvIAUJSSB4CilDwAFFVyoObi/DyV613G/+fZ6udewulVfIih23LjDWvDcSrX7cQHarb2dlO35r1Z\nODOa5AZqrl7nRnQeP/xeOLOzFh87aa21Nl3GI6e5AZK9jfV4qJ97Da+uL1O5thJ/Pha93N/ml1/0\nw5m9u8PUrb/4SW6gZq19HM5M5xepW9eX8eGu2fR16tZklPvsHvbir//aRu496yX2nDrd3GDPTfBN\nHgCKUvIAUJSSB4CilDwAFKXkAaAoJQ8ARSl5AChKyQNAUUoeAIpS8gBQlJIHgKKUPAAUpeQBoKiS\nK3S9Ye5/l9H1NJy5+Dq3mjQ+HIUzdx7El8laa21jLbe2dDp6F85sreQW7/bvxqed3r5NrkjNc2tt\n83H8Z7y+yC0HDjsb4Uy3l1sAPD6M/4wrG/PUraPz3PMxukgsqK3kXo+nz+Mfi/cfnaZurW6epXIr\n1/EVwNEosTbYWluO46/jo4e5lcKdzCJia+3V1/F1w43N5OvRjf9unfiw4Y3xTR4AilLyAFCUkgeA\nopQ8ABSl5AGgKCUPAEUpeQAoSskDQFFKHgCKUvIAUJSSB4CilDwAFKXkAaCokit0neUslVtex5e1\nDrZvp271RvGfcXaemzJaDHNv8+Q6vrB3eBhfg2qttWW/E85s9ONLba21dnDnQSp351b8vT7YvZO6\n1abxxbt+b5A8FV94O7t8m7r17PVXqdyrZ6/DmeN4pLXW2mz8w3Bmazf3erw6/F0qt9OJL6itD76b\nunXnwbfCmQcPt1K3OrPVVO78k7VwZjJLLBu21uad+Grj1Ti+OnpTfJMHgKKUPAAUpeQBoCglDwBF\nKXkAKErJA0BRSh4AilLyAFCUkgeAopQ8ABSl5AGgKCUPAEWVHKhp0+tUbLASH4DZHAxTt/rz+Es/\nm8QHdFprrTPMvR7rq/Hf7ejNNHVrnvgRP/nme6lbD289TuVWVuIDMNeXuVGhfosPbnR68ZGf1lq7\nmCzDmc++epK69fJdLtedxp/9xbvca7+/jI+JfGsv931pdpX725ysxIdcetPD1K1ON/67DdZyv9fd\n2x+ncre33w9nzi5PUrfG03E4s7FyK3XrJvgmDwBFKXkAKErJA0BRSh4AilLyAFCUkgeAopQ8ABSl\n5AGgKCUPAEUpeQAoSskDQFFKHgCKUvIAUFTJFbrtnfVUbnUjvvy1XMktf23sboYzs3l8/ai11maz\ny1Tu4vQqnOldxBfNWmttuBJ/7dsotzLWRrdTsc7KQTgzn8Xf59ZaG/bjuek8twB4mhjjWp59krq1\nNt3P5Zbx93rYe5i69erdL8OZD1bupG49Wv1+Kjftxt/r0dVF6tbp5GU4szg+Td3qLM5Sud2NeG7R\nzS2Inp/FFxEHG3upWzfBN3kAKErJA0BRSh4AilLyAFCUkgeAopQ8ABSl5AGgKCUPAEUpeQAoSskD\nQFFKHgCKUvIAUFTJgZreODeSMu/MwpnpMjcKcpX4Ea8uckMz/UHu9djuxId+ht1e6tZgth3ObPS+\nkbrVG3+Yyi1Gd8OZtf5u6labx///7szjwxmttXZ/K/463tv9q9St0fw8lbs8HoUzX735OnVrb+W3\n4czOMjeK9f6d3LP4+1d/DGe6ndxISr8T/4ybjHPP4vUolxtt/iKcmQ8So1ittbPr1XDm/F185Ke1\n1toP/kMu92d8kweAopQ8ABSl5AGgKCUPAEUpeQAoSskDQFFKHgCKUvIAUJSSB4CilDwAFKXkAaAo\nJQ8ARSl5ACiq5Ard4k1udW2xtghnJt3r1K3B2iCe6d9K3epO4r9Xa60tZ5NwZjHLPVJ3Hvw4nOnP\nv5269fZFbn2qvxL/3WZr8WXD1lqbT8bhzGgUf79aa211Lb6q1U1+cuzs3k/lBtvxdcPjg9xzP9iI\nL8qdXZ+kbr0e/SaV27wX/362Os+t0I2vN8OZ3vxB6taydVK5V8f/GM4M+1upW/v7PwxnutP4a3hT\nfJMHgKKUPAAUpeQBoCglDwBFKXkAKErJA0BRSh4AilLyAFCUkgeAopQ8ABSl5AGgKCUPAEWVHKj5\n7qOfpHLz9WE80++nbt3fvR3OrO5sp251FrnRh7dvn4Qzx5e5QZbe6kfhzPX1burWaJobFVpdOw1n\nJpPcrdHlVThzeXmZujWfzxOZ3Pu8vZUbBVnbjI8KPX97nLp13YsP1Ly8fJu6tXmUG9Pq7cVfj+nZ\nn1K31rvxMa29tQ9St1YGuc+q2Tj+M24Mc4Nfj+59HM7028PUrZvgmzwAFKXkAaAoJQ8ARSl5AChK\nyQNAUUoeAIpS8gBQlJIHgKKUPAAUpeQBoCglDwBFKXkAKErJA0BRJVfofvijn6Vy3Z34QlZ3cyN1\na3c1vnTVG8ZX8lprrddyS3m//eyX4czRk9epW1+9iq+u9VdyC29rm71UbjA9D2eW0/g6VmutXZ6O\nwpnZcpy6NRjEn4+ri/hr0VprX/7pj6nc5mr8dZwvch9vF9NJOPP2/Ch168PpB6nc8fNpOPPkT79P\n3epP4n8vu5u5z4EHH+ykcqez+OLgYjf+Gdxaa/v9+OLg5jC3vngTfJMHgKKUPAAUpeQBoCglDwBF\nKXkAKErJA0BRSh4AilLyAFCUkgeAopQ8ABSl5AGgKCUPAEUpeQAoquQK3Uc//Gkqt+yvhjPzlfga\nVGutrfQuw5nePP7ztdZaZy23unb1m3k48/xpbo3r+Dqe29rcTN2avcq9Z+vD+L07+3dSt25tx9e4\nLq7iz1RrrU0m8TW/6XV8qa211i7enaVy14tZONNdJH/G66fxTOLna621s0Vuza/TXYYz/c7d1K3f\nfRFfDty5nfu9TlZya239jfjf9EViVbK11o5OLsKZx3f/MnXrJ3f/Uyr353yTB4CilDwAFKXkAaAo\nJQ8ARSl5AChKyQNAUUoeAIpS8gBQlJIHgKKUPAAUpeQBoCglDwBFlRyoWd+Jj3u01tpsEf+fZ95J\nnWqtHx+0WCyvUqdWN3MDNdPLt+HM6z/8LnVrubkRzhzc+17q1hefvUjlRp21cKZzOU7dWnkYHyDp\ntHimtdZePvlTOHN5lRuaubqKj3u01lpvHh9L6ixzgz1t9V04suz3U6eevoqP4bTW2t5O/O/lvfcf\npW6Nx/HnfjTJvc+TcS63tR9//a/Hi9StydlpODNs8ZGf1lpr38/F/pxv8gBQlJIHgKKUPAAUpeQB\noCglDwBFKXkAKErJA0BRSh4AilLyAFCUkgeAopQ8ABSl5AGgKCUPAEWVXKHr5kbX2nIeX4abTiep\nW7P5dTizGOQWzRbn01Suc3EUzswuXqdu7R08DmfGb3O3Lt/klr9mi/jk4PQit9Z2lPjdesPcgz8a\nnScyud/r/Cr+TLXWWq+b+Kjqxf/GWmvt0eP4rTv3t1O31oepWFsu44uDl9NXqVuPP3g/nFmZP0zd\nupr8NpXrrjwLZybz+Lpea61tbMbX/Ba5j+Ab4Zs8ABSl5AGgKCUPAEUpeQAoSskDQFFKHgCKUvIA\nUJSSB4CilDwAFKXkAaAoJQ8ARSl5ACiq5EDNaJIbppiM5uHM9WSUujVfxnOz2XHq1qzlRnSuTuPD\nJd1hfMSltdZWNuKP4rvD3EjK4cv4mEVrrU2W8edqNr9K3drcvR+/dZ0bqFlM4j/j1eht6tb1/E0q\n1xn0w5mVfnzEpbXWbj+Kv/YffSs+sNRaa6+OciNLg8QeTqebuzW5jH/u3Nv7QepW6z5IxZab8c+C\nzz49Sd26f3A3nNkYrqdu3QTf5AGgKCUPAEUpeQAoSskDQFFKHgCKUvIAUJSSB4CilDwAFKXkAaAo\nJQ8ARSl5AChKyQNAUUoeAIoquUI3X+SW0BaJ0arVwVbq1nR8Gc5M3r1M3Tqevkvl1m/thjP/5m/+\nOnXrxVV8Eerp8fPUrYMPh6ncohP/n3g+za3QTdpFOLOxnVvwevM0/lxdT3IrdB//eD+Va2vxP86j\n06PUqd07a/FQJ76S11pro4vcZ9X+wUY4M1vmVtdu390JZw4Oct8fu93bqdy7UXzl7WA39zMOe/Fb\nb17k1kpvgm/yAFCUkgeAopQ8ABSl5AGgKCUPAEUpeQAoSskDQFFKHgCKUvIAUJSSB4CilDwAFKXk\nAaAoJQ8ARZVcoZtMFqlcJ/FydBbJ/5Pm8Vv91dx62upubilv8zKeO//yaerWX37vIJz58Hu91K3W\nvZuKTUbx9/of/mfu9Tg8jK+arW3l3uerUXzxbmc/t7r2w59+I5X76s1n8dBWbuHtwfv3wpm9vfup\nW5sbueXA0ex1OHN+NU7dWizj7/Wzw9+kbu3v5lboxlfxpbydtb3UreloHs6Mr3Ov/U3wTR4AilLy\nAFCUkgeAopQ8ABSl5AGgKCUPAEUpeQAoSskDQFFKHgCKUvIAUJSSB4CilDwAFFVyoGY+iQ8ItNba\n/Po6nFlZWaZudVZG4czW9lrq1nz0LpV7/uT34cwffvNF6tbW6nfCmev9V6lbo+kklbu19n44013E\nn6nWWjvY+1Y4M1zbSN0aT+ODTju3d1O3prPca39+fhjOPHwUHz1qrbXOPP6e/f3f/SJ1q7+eG9O6\n8378M27Qyw1cvXrxNpyZzI9St44vcoM9+6sPw5mdze3UrdlK/LvxbJF7n2+Cb/IAUJSSB4CilDwA\nFKXkAaAoJQ8ARSl5AChKyQNAUUoeAIpS8gBQlJIHgKKUPAAUpeQBoCglDwBFlVyh6/enqdz04iqc\nWRn0Ureu5/FVrRevf5W69ekvf53KbfU2w5mN6Wrq1u//xz+FM8MPOqlbR4m1wdZaW/8wvrz2waP1\n1K1nr8fhzHwyS91aGQzCmbuJFbTWWlssL3K5q/jPuN7Nra599dkfwpmf/+JZ6taj7+Y+ghdb8e9n\n/dmt1K3ZWfy13z/I/V5/+uqPqdynp8fhzN/8279O3br3KL4GejnLrfLdBN/kAaAoJQ8ARSl5AChK\nyQNAUUoeAIpS8gBQlJIHgKKUPAAUpeQBoCglDwBFKXkAKErJA0BRJQdqTqZPU7nJeBTOXMY3bVpr\nrb1+Fx+NeXHy96lbh6/epXL3+t8LZ251coM9Z6P4z9h/tZ26NRjlhlyezT8PZ779776RunW0iL8e\nJy9yf84H9+NjMz/8ae77wepGbsDo8PD9cObt2/hoSWutbWxuhTOffPIodWv7Ue4DZDmPf1bNp7nn\n49Xzy3Dm8jh3azLOjUe9uzgNZ55/cjt1a2PrTjjz8jA3LnYTfJMHgKKUPAAUpeQBoCglDwBFKXkA\nKErJA0BRSh4AilLyAFCUkgeAopQ8ABSl5AGgKCUPAEUpeQAoquYK3cXLVO7y7FU4Mx/FF5paa+3d\nxR/DmcV1fHmqtdZ21pep3NXpF+HMxn5uha67GV+U669upm5tT3dSue7d9XBm7yC3ura90wlnnnyW\nWxvstPh7dvw69/1gPDtM5e7ei6+8PX2eW3g7Ooz/TS/7k9StO7nHow2H8eej04lnWmttPF6EMy8/\nP0vd2ujnXpBv/fhxOHORWK5rrbXDk/jnaX8YX3q8Kb7JA0BRSh4AilLyAFCUkgeAopQ8ABSl5AGg\nKCUPAEUpeQAoSskDQFFKHgCKUvIAUJSSB4CilDwAFFVyhW50Hl+Ta621Tu9tONPfuk7d2lmPL0KN\nv4yvoLXW2tbBNJWb3j4OZzr9/dStB/vfD2eePc+9z6d/yK1Pfffhd8OZzc3cAuB7j+KrZkcv4u9X\na619+bv4zzg6y60N9tZzy3CDtfgC490HuWfx1bP4Ut54kVujbMvc89Fp8WW47d1h6tbjD/fCmbdf\nPE3dmk1zK3Rnx+Nw5tXL3FLeeB5fe7x1ezd16yb4Jg8ARSl5AChKyQNAUUoeAIpS8gBQlJIHgKKU\nPAAUpeQBoCglDwBFKXkAKErJA0BRSh4Aiqo5UHP8aSrXG8ZHDsad+FBEa60NtuJDDPe/9yB1azqd\np3KzYfx/wMXpdurW2Zv4cMnFu9zYyehlfOyktdZ+/Q+fhzO3tnN/Yt3+ZjjzVz/LDRh98PhuOLN/\nEP9baa217Tu5kZS1W/G/l273XurW4fPH4cyb4y9StxbDJ6lcm/YTxwapU4P1eK6Te5vb1mbu83Sx\nOA9nLi5mqVuzbjy3urqWunUTfJMHgKKUPAAUpeQBoCglDwBFKXkAKErJA0BRSh4AilLyAFCUkgeA\nopQ8ABSl5AGgKCUPAEUpeQAoquQK3b213K91NeyEMystvo7VWmvLlfj/V4O93Hra5GQrlbt6E8+c\n/P4odWtwEV9d2x7fSt2a9XP/246Xk3BmMc8tw528vg5nzqfxn6+11r75+HY4M57mFryOn+aej+5F\n/GFc3cy9z48f/yicufswtzJ2cp2ba3v7Nr66tpjkPqt6g/jn4o/+1Qe5W/OTVG7R4ouUo1nu87ST\n+MzvdJepWzfBN3kAKErJA0BRSh4AilLyAFCUkgeAopQ8ABSl5AGgKCUPAEUpeQAoSskDQFFKHgCK\nUvIAUFTJgZrbs71Ubnx/O5x58+xd6tabZ6/Dmdn6OHVrZbKTynWfz8OZ1ePccEnrJoY6ZvH3q7XW\nNj7Kjcbc+jA+MtFLvvbtTfy5evVl/JlqrbX5SXzc487j5DO16KVya+P74czx6WXqVn/+JJy5dfdu\n6ta9/e+mcvPr5+HM0+e552NtM/73sneQG96ZXedGdFb68RGddpgbjRmfxj8Xp9fJz8Ub4Js8ABSl\n5AGgKCUPAEUpeQAoSskDQFFKHgCKUvIAUJSSB4CilDwAFKXkAaAoJQ8ARSl5AChKyQNAUZ3lMrfE\nAwD8/803eQAoSskDQFFKHgCKUvIAUJSSB4CilDwAFKXkAaAoJQ8ARSl5AChKyQNAUUoeAIpS8gBQ\nlJIHgKKUPAAUpeQBoCglDwBFKXkAKErJA0BRSh4AilLyAFCUkgeAopQ8ABSl5AGgKCUPAEUpeQAo\nSskDQFFKHgCKUvIAUJSSB4CilDwAFKXkAaAoJQ8ARSl5AChKyQNAUUoeAIpS8gBQlJIHgKKUPAAU\npeQBoCglDwBFKXkAKErJA0BRSh4AilLyAFCUkgeAopQ8ABSl5AGgKCUPAEX9P3IdH603aAOtAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a3608d0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 251,
       "width": 252
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 6\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    xmax, xmin = x.max(),x.min()\n",
    "    y = (x-xmin)/(xmax-xmin)\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "Look into LabelBinarizer in the preprocessing module of sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "map = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(map)\n",
    "    return lb.transform(x)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = (None,image_shape[0],image_shape[1],image_shape[2])\n",
    "    return tf.placeholder(tf.float32,shape=shape,name=\"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = [None,n_classes]\n",
    "    return tf.placeholder(tf.int16,shape=shape,name=\"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,name=\"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers.\n",
    "\n",
    "** Hint: **\n",
    "\n",
    "When unpacking values as an argument in Python, look into the [unpacking](https://docs.python.org/3/tutorial/controlflow.html#unpacking-argument-lists) operator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    filter_size_width = int(conv_ksize[0])\n",
    "    filter_size_height = int(conv_ksize[1])\n",
    "    input_size = int(x_tensor.get_shape()[3])\n",
    "#     print([filter_size_width,filter_size_height,input_size,conv_num_outputs])\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal(\\\n",
    "                                              [filter_size_width,filter_size_height,\\\n",
    "                                               input_size,conv_num_outputs],stddev=0.005))\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    x = tf.nn.conv2d(input=x_tensor,filter=weights,\\\n",
    "                            strides=[1,conv_strides[0],conv_strides[1],1],\n",
    "                            padding='SAME')\n",
    "    x = tf.nn.bias_add(x,bias)\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    return tf.nn.max_pool(x,ksize=[1,pool_ksize[0],pool_ksize[1],1],\\\n",
    "                          strides=[1,pool_strides[0],pool_strides[1],1],\\\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    batch_size, dim1, dim2, dim3 = x_tensor.get_shape().as_list()\n",
    "    flat_dims = dim1 * dim2 * dim3\n",
    "\n",
    "    return tf.reshape(x_tensor,[-1, flat_dims])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    f_size = x_tensor.get_shape().as_list()[1]\n",
    "    weights = tf.Variable(tf.truncated_normal([f_size,num_outputs],stddev=0.005))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    fc = tf.add(tf.matmul(x_tensor,weights),bias)\n",
    "    \n",
    "    return tf.nn.relu(fc)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    size = x_tensor.get_shape().as_list()[1]\n",
    "    weights = tf.Variable(tf.truncated_normal([size,num_outputs],stddev=0.005))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    out = tf.add(tf.matmul(x_tensor,weights),bias)\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv_ksize = (4,4)\n",
    "    conv_strides = (2,2)\n",
    "    conv_num_outputs = 256\n",
    "    pool_ksize = (4,4)\n",
    "    pool_strides = (2,2)\n",
    "    num_outputs = 10\n",
    "    \n",
    "    x = conv2d_maxpool(x,conv_num_outputs=conv_num_outputs,\\\n",
    "                       conv_ksize=conv_ksize,conv_strides=conv_strides,\\\n",
    "                      pool_ksize=pool_ksize,pool_strides=pool_strides)\n",
    "    x = tf.nn.dropout(x,keep_prob)\n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    x = flatten(x)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    x = fully_conn(x,num_outputs)\n",
    "    x = tf.nn.dropout(x,keep_prob)\n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return output(x,num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer,feed_dict={x:feature_batch,y:label_batch,keep_prob:keep_probability})\n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost,{x:feature_batch,y:label_batch,keep_prob:1.})\n",
    "    valid_acc = session.run(accuracy,{x:valid_features,y:valid_labels,keep_prob:1.})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss,valid_acc))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 888\n",
    "batch_size = 6000000000\n",
    "keep_probability = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.3026 Validation Accuracy: 0.098800\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.3024 Validation Accuracy: 0.105000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.3021 Validation Accuracy: 0.105000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.3015 Validation Accuracy: 0.105000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     2.3006 Validation Accuracy: 0.105000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     2.2990 Validation Accuracy: 0.105000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     2.2971 Validation Accuracy: 0.105000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     2.2946 Validation Accuracy: 0.105000\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     2.2915 Validation Accuracy: 0.105400\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     2.2874 Validation Accuracy: 0.105600\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     2.2823 Validation Accuracy: 0.108600\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     2.2758 Validation Accuracy: 0.112000\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     2.2677 Validation Accuracy: 0.120400\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     2.2582 Validation Accuracy: 0.131400\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     2.2476 Validation Accuracy: 0.137600\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     2.2353 Validation Accuracy: 0.142400\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     2.2223 Validation Accuracy: 0.144800\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     2.2085 Validation Accuracy: 0.148400\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     2.1938 Validation Accuracy: 0.152800\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     2.1788 Validation Accuracy: 0.155400\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     2.1637 Validation Accuracy: 0.155000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     2.1496 Validation Accuracy: 0.163400\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     2.1364 Validation Accuracy: 0.184400\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     2.1241 Validation Accuracy: 0.191400\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     2.1123 Validation Accuracy: 0.201600\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     2.1012 Validation Accuracy: 0.216800\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     2.0907 Validation Accuracy: 0.227800\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     2.0808 Validation Accuracy: 0.232000\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     2.0714 Validation Accuracy: 0.226600\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     2.0634 Validation Accuracy: 0.225800\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     2.0569 Validation Accuracy: 0.228000\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     2.0493 Validation Accuracy: 0.237200\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     2.0396 Validation Accuracy: 0.240800\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     2.0348 Validation Accuracy: 0.247000\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     2.0303 Validation Accuracy: 0.246600\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     2.0224 Validation Accuracy: 0.248400\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     2.0177 Validation Accuracy: 0.251600\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     2.0138 Validation Accuracy: 0.253800\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     2.0069 Validation Accuracy: 0.253200\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     2.0027 Validation Accuracy: 0.252000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.9991 Validation Accuracy: 0.251400\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.9931 Validation Accuracy: 0.255600\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.9890 Validation Accuracy: 0.257400\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.9853 Validation Accuracy: 0.258000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.9797 Validation Accuracy: 0.262200\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.9756 Validation Accuracy: 0.262600\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.9718 Validation Accuracy: 0.262200\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.9664 Validation Accuracy: 0.266000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.9618 Validation Accuracy: 0.267200\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.9577 Validation Accuracy: 0.268400\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.9525 Validation Accuracy: 0.272200\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.9472 Validation Accuracy: 0.271000\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.9426 Validation Accuracy: 0.270400\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.9373 Validation Accuracy: 0.273400\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.9314 Validation Accuracy: 0.278800\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.9259 Validation Accuracy: 0.281200\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.9202 Validation Accuracy: 0.283000\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.9139 Validation Accuracy: 0.279800\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.9075 Validation Accuracy: 0.283800\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.9012 Validation Accuracy: 0.288400\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.8945 Validation Accuracy: 0.287800\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.8874 Validation Accuracy: 0.292600\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.8802 Validation Accuracy: 0.296000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.8731 Validation Accuracy: 0.299400\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.8658 Validation Accuracy: 0.303600\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.8581 Validation Accuracy: 0.307400\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.8503 Validation Accuracy: 0.307800\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.8424 Validation Accuracy: 0.308800\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.8345 Validation Accuracy: 0.309600\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.8266 Validation Accuracy: 0.309000\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.8187 Validation Accuracy: 0.316600\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.8109 Validation Accuracy: 0.314600\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.8032 Validation Accuracy: 0.322800\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     1.7958 Validation Accuracy: 0.322400\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     1.7888 Validation Accuracy: 0.328400\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     1.7825 Validation Accuracy: 0.326000\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     1.7777 Validation Accuracy: 0.334600\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     1.7754 Validation Accuracy: 0.326600\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     1.7714 Validation Accuracy: 0.342000\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     1.7615 Validation Accuracy: 0.338400\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     1.7536 Validation Accuracy: 0.336000\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     1.7528 Validation Accuracy: 0.346800\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     1.7488 Validation Accuracy: 0.341400\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     1.7402 Validation Accuracy: 0.345400\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     1.7376 Validation Accuracy: 0.348200\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     1.7357 Validation Accuracy: 0.345800\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     1.7284 Validation Accuracy: 0.351200\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     1.7244 Validation Accuracy: 0.350800\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     1.7229 Validation Accuracy: 0.350000\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     1.7174 Validation Accuracy: 0.357800\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     1.7127 Validation Accuracy: 0.353200\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     1.7105 Validation Accuracy: 0.354200\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     1.7068 Validation Accuracy: 0.359000\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     1.7021 Validation Accuracy: 0.356400\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     1.6985 Validation Accuracy: 0.360400\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     1.6960 Validation Accuracy: 0.365200\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     1.6921 Validation Accuracy: 0.360400\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     1.6876 Validation Accuracy: 0.367200\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     1.6849 Validation Accuracy: 0.370800\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     1.6820 Validation Accuracy: 0.364600\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:     1.6778 Validation Accuracy: 0.372000\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:     1.6744 Validation Accuracy: 0.370200\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:     1.6711 Validation Accuracy: 0.370400\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:     1.6681 Validation Accuracy: 0.376200\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:     1.6650 Validation Accuracy: 0.371800\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:     1.6611 Validation Accuracy: 0.374600\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:     1.6577 Validation Accuracy: 0.376000\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:     1.6548 Validation Accuracy: 0.378000\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss:     1.6517 Validation Accuracy: 0.378800\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:     1.6487 Validation Accuracy: 0.376400\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:     1.6455 Validation Accuracy: 0.380200\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:     1.6421 Validation Accuracy: 0.381400\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:     1.6389 Validation Accuracy: 0.382200\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:     1.6358 Validation Accuracy: 0.385400\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:     1.6327 Validation Accuracy: 0.384600\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:     1.6298 Validation Accuracy: 0.384800\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:     1.6269 Validation Accuracy: 0.386800\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:     1.6240 Validation Accuracy: 0.389200\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:     1.6212 Validation Accuracy: 0.388000\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:     1.6186 Validation Accuracy: 0.390600\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:     1.6160 Validation Accuracy: 0.389400\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:     1.6137 Validation Accuracy: 0.389400\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:     1.6113 Validation Accuracy: 0.392600\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:     1.6086 Validation Accuracy: 0.392600\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:     1.6052 Validation Accuracy: 0.392400\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:     1.6010 Validation Accuracy: 0.396400\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:     1.5970 Validation Accuracy: 0.399400\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:     1.5940 Validation Accuracy: 0.398800\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:     1.5917 Validation Accuracy: 0.404200\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:     1.5897 Validation Accuracy: 0.401600\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:     1.5872 Validation Accuracy: 0.404600\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:     1.5840 Validation Accuracy: 0.404000\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:     1.5804 Validation Accuracy: 0.407200\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:     1.5771 Validation Accuracy: 0.407400\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:     1.5743 Validation Accuracy: 0.408400\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:     1.5720 Validation Accuracy: 0.412800\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:     1.5704 Validation Accuracy: 0.411200\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:     1.5701 Validation Accuracy: 0.414400\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:     1.5715 Validation Accuracy: 0.410600\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:     1.5732 Validation Accuracy: 0.415000\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:     1.5663 Validation Accuracy: 0.413000\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:     1.5587 Validation Accuracy: 0.417600\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:     1.5606 Validation Accuracy: 0.419800\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:     1.5563 Validation Accuracy: 0.416200\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:     1.5505 Validation Accuracy: 0.422400\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:     1.5523 Validation Accuracy: 0.424600\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:     1.5458 Validation Accuracy: 0.422400\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:     1.5432 Validation Accuracy: 0.423800\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:     1.5438 Validation Accuracy: 0.429200\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:     1.5371 Validation Accuracy: 0.429000\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:     1.5363 Validation Accuracy: 0.425200\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:     1.5356 Validation Accuracy: 0.428400\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:     1.5294 Validation Accuracy: 0.434200\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:     1.5297 Validation Accuracy: 0.431200\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:     1.5274 Validation Accuracy: 0.431200\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:     1.5226 Validation Accuracy: 0.432800\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:     1.5229 Validation Accuracy: 0.432800\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:     1.5194 Validation Accuracy: 0.437600\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:     1.5160 Validation Accuracy: 0.435400\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:     1.5158 Validation Accuracy: 0.434600\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:     1.5120 Validation Accuracy: 0.441200\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:     1.5093 Validation Accuracy: 0.438200\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:     1.5086 Validation Accuracy: 0.436000\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:     1.5051 Validation Accuracy: 0.445200\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:     1.5027 Validation Accuracy: 0.441600\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:     1.5016 Validation Accuracy: 0.436000\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:     1.4985 Validation Accuracy: 0.443200\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:     1.4964 Validation Accuracy: 0.443000\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:     1.4949 Validation Accuracy: 0.438400\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:     1.4921 Validation Accuracy: 0.444600\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:     1.4900 Validation Accuracy: 0.446200\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:     1.4887 Validation Accuracy: 0.441600\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss:     1.4861 Validation Accuracy: 0.447000\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:     1.4840 Validation Accuracy: 0.447600\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:     1.4825 Validation Accuracy: 0.444000\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:     1.4804 Validation Accuracy: 0.449000\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:     1.4782 Validation Accuracy: 0.450000\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:     1.4767 Validation Accuracy: 0.446400\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:     1.4749 Validation Accuracy: 0.450200\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:     1.4727 Validation Accuracy: 0.448800\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:     1.4710 Validation Accuracy: 0.450400\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:     1.4694 Validation Accuracy: 0.451200\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:     1.4675 Validation Accuracy: 0.450200\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:     1.4656 Validation Accuracy: 0.450600\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:     1.4641 Validation Accuracy: 0.453800\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:     1.4624 Validation Accuracy: 0.451600\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:     1.4606 Validation Accuracy: 0.454000\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:     1.4590 Validation Accuracy: 0.454800\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:     1.4574 Validation Accuracy: 0.452200\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:     1.4557 Validation Accuracy: 0.456600\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:     1.4541 Validation Accuracy: 0.455000\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:     1.4527 Validation Accuracy: 0.455000\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:     1.4515 Validation Accuracy: 0.454200\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:     1.4505 Validation Accuracy: 0.456600\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:     1.4505 Validation Accuracy: 0.453000\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:     1.4518 Validation Accuracy: 0.461200\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:     1.4553 Validation Accuracy: 0.448800\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:     1.4547 Validation Accuracy: 0.459600\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:     1.4492 Validation Accuracy: 0.450800\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:     1.4411 Validation Accuracy: 0.457200\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss:     1.4412 Validation Accuracy: 0.460400\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss:     1.4446 Validation Accuracy: 0.452800\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss:     1.4406 Validation Accuracy: 0.464400\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss:     1.4355 Validation Accuracy: 0.458800\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss:     1.4359 Validation Accuracy: 0.460000\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss:     1.4362 Validation Accuracy: 0.461200\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss:     1.4329 Validation Accuracy: 0.460600\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss:     1.4302 Validation Accuracy: 0.463400\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss:     1.4305 Validation Accuracy: 0.462600\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss:     1.4297 Validation Accuracy: 0.462000\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss:     1.4271 Validation Accuracy: 0.464200\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss:     1.4257 Validation Accuracy: 0.463200\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss:     1.4249 Validation Accuracy: 0.465200\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss:     1.4236 Validation Accuracy: 0.463200\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss:     1.4222 Validation Accuracy: 0.466000\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss:     1.4205 Validation Accuracy: 0.469200\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss:     1.4190 Validation Accuracy: 0.465200\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss:     1.4183 Validation Accuracy: 0.467000\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss:     1.4173 Validation Accuracy: 0.469200\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss:     1.4153 Validation Accuracy: 0.466800\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss:     1.4139 Validation Accuracy: 0.468600\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss:     1.4133 Validation Accuracy: 0.469600\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss:     1.4121 Validation Accuracy: 0.470000\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss:     1.4104 Validation Accuracy: 0.468600\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss:     1.4091 Validation Accuracy: 0.470600\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss:     1.4083 Validation Accuracy: 0.470200\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss:     1.4070 Validation Accuracy: 0.472400\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss:     1.4056 Validation Accuracy: 0.472000\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss:     1.4044 Validation Accuracy: 0.470600\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss:     1.4032 Validation Accuracy: 0.469400\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss:     1.4019 Validation Accuracy: 0.471400\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss:     1.4008 Validation Accuracy: 0.472400\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss:     1.3998 Validation Accuracy: 0.471600\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss:     1.3986 Validation Accuracy: 0.472000\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss:     1.3972 Validation Accuracy: 0.471600\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss:     1.3961 Validation Accuracy: 0.473000\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss:     1.3952 Validation Accuracy: 0.471400\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss:     1.3944 Validation Accuracy: 0.474600\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss:     1.3937 Validation Accuracy: 0.472800\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss:     1.3934 Validation Accuracy: 0.473400\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss:     1.3926 Validation Accuracy: 0.472200\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss:     1.3911 Validation Accuracy: 0.474200\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss:     1.3888 Validation Accuracy: 0.473600\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss:     1.3872 Validation Accuracy: 0.473800\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss:     1.3863 Validation Accuracy: 0.474400\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss:     1.3854 Validation Accuracy: 0.472600\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss:     1.3840 Validation Accuracy: 0.477400\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss:     1.3823 Validation Accuracy: 0.474000\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss:     1.3810 Validation Accuracy: 0.479000\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss:     1.3799 Validation Accuracy: 0.476200\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss:     1.3789 Validation Accuracy: 0.473000\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss:     1.3781 Validation Accuracy: 0.479200\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss:     1.3772 Validation Accuracy: 0.474400\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss:     1.3761 Validation Accuracy: 0.478600\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss:     1.3750 Validation Accuracy: 0.476000\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss:     1.3744 Validation Accuracy: 0.478200\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss:     1.3746 Validation Accuracy: 0.477400\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss:     1.3762 Validation Accuracy: 0.477800\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss:     1.3794 Validation Accuracy: 0.474400\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss:     1.3826 Validation Accuracy: 0.472400\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss:     1.3821 Validation Accuracy: 0.470400\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss:     1.3761 Validation Accuracy: 0.478600\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss:     1.3676 Validation Accuracy: 0.476600\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss:     1.3656 Validation Accuracy: 0.482400\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss:     1.3691 Validation Accuracy: 0.479800\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss:     1.3705 Validation Accuracy: 0.477800\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss:     1.3666 Validation Accuracy: 0.480800\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss:     1.3611 Validation Accuracy: 0.479200\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss:     1.3610 Validation Accuracy: 0.479800\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss:     1.3637 Validation Accuracy: 0.482600\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss:     1.3619 Validation Accuracy: 0.479400\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss:     1.3575 Validation Accuracy: 0.483000\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss:     1.3561 Validation Accuracy: 0.482800\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss:     1.3575 Validation Accuracy: 0.480200\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss:     1.3569 Validation Accuracy: 0.483200\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss:     1.3538 Validation Accuracy: 0.482000\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss:     1.3522 Validation Accuracy: 0.482600\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss:     1.3524 Validation Accuracy: 0.485200\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss:     1.3517 Validation Accuracy: 0.481400\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss:     1.3500 Validation Accuracy: 0.485400\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss:     1.3487 Validation Accuracy: 0.484000\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss:     1.3479 Validation Accuracy: 0.483800\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss:     1.3469 Validation Accuracy: 0.485200\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss:     1.3458 Validation Accuracy: 0.483000\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss:     1.3450 Validation Accuracy: 0.486400\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss:     1.3442 Validation Accuracy: 0.485600\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss:     1.3429 Validation Accuracy: 0.486800\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss:     1.3415 Validation Accuracy: 0.486600\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss:     1.3404 Validation Accuracy: 0.485600\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss:     1.3398 Validation Accuracy: 0.488200\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss:     1.3392 Validation Accuracy: 0.487600\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss:     1.3382 Validation Accuracy: 0.488400\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss:     1.3369 Validation Accuracy: 0.487600\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss:     1.3356 Validation Accuracy: 0.488600\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss:     1.3347 Validation Accuracy: 0.486200\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss:     1.3338 Validation Accuracy: 0.489800\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss:     1.3328 Validation Accuracy: 0.489600\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss:     1.3317 Validation Accuracy: 0.488000\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss:     1.3308 Validation Accuracy: 0.490000\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss:     1.3300 Validation Accuracy: 0.488400\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss:     1.3293 Validation Accuracy: 0.491200\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss:     1.3287 Validation Accuracy: 0.487600\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss:     1.3281 Validation Accuracy: 0.490400\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss:     1.3278 Validation Accuracy: 0.487400\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss:     1.3278 Validation Accuracy: 0.490400\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss:     1.3284 Validation Accuracy: 0.487000\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss:     1.3286 Validation Accuracy: 0.485200\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss:     1.3287 Validation Accuracy: 0.486600\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss:     1.3259 Validation Accuracy: 0.489200\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss:     1.3228 Validation Accuracy: 0.488800\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss:     1.3203 Validation Accuracy: 0.493000\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss:     1.3194 Validation Accuracy: 0.490600\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss:     1.3193 Validation Accuracy: 0.494800\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss:     1.3190 Validation Accuracy: 0.490400\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss:     1.3179 Validation Accuracy: 0.492600\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss:     1.3160 Validation Accuracy: 0.493200\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss:     1.3148 Validation Accuracy: 0.490400\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss:     1.3146 Validation Accuracy: 0.494400\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss:     1.3147 Validation Accuracy: 0.488600\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss:     1.3142 Validation Accuracy: 0.496400\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss:     1.3125 Validation Accuracy: 0.491000\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss:     1.3104 Validation Accuracy: 0.495800\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss:     1.3086 Validation Accuracy: 0.494200\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss:     1.3077 Validation Accuracy: 0.495400\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss:     1.3074 Validation Accuracy: 0.494800\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss:     1.3071 Validation Accuracy: 0.492600\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss:     1.3064 Validation Accuracy: 0.495400\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss:     1.3050 Validation Accuracy: 0.493800\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss:     1.3036 Validation Accuracy: 0.498000\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss:     1.3023 Validation Accuracy: 0.496800\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss:     1.3016 Validation Accuracy: 0.498200\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss:     1.3012 Validation Accuracy: 0.495400\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss:     1.3011 Validation Accuracy: 0.499000\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss:     1.3014 Validation Accuracy: 0.497600\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss:     1.3016 Validation Accuracy: 0.495800\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss:     1.3024 Validation Accuracy: 0.494400\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss:     1.3029 Validation Accuracy: 0.495000\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss:     1.3043 Validation Accuracy: 0.488600\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss:     1.3070 Validation Accuracy: 0.494400\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss:     1.3065 Validation Accuracy: 0.486600\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss:     1.3044 Validation Accuracy: 0.494200\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss:     1.2956 Validation Accuracy: 0.492000\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss:     1.2909 Validation Accuracy: 0.499200\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss:     1.2928 Validation Accuracy: 0.501800\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss:     1.2959 Validation Accuracy: 0.489200\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss:     1.2957 Validation Accuracy: 0.499400\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss:     1.2906 Validation Accuracy: 0.495600\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss:     1.2880 Validation Accuracy: 0.500000\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss:     1.2890 Validation Accuracy: 0.502800\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss:     1.2891 Validation Accuracy: 0.494800\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss:     1.2867 Validation Accuracy: 0.503000\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss:     1.2843 Validation Accuracy: 0.499600\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss:     1.2847 Validation Accuracy: 0.499600\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss:     1.2856 Validation Accuracy: 0.502600\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss:     1.2840 Validation Accuracy: 0.498400\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss:     1.2812 Validation Accuracy: 0.502600\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss:     1.2800 Validation Accuracy: 0.503200\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss:     1.2802 Validation Accuracy: 0.500400\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss:     1.2799 Validation Accuracy: 0.504200\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss:     1.2784 Validation Accuracy: 0.502000\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss:     1.2770 Validation Accuracy: 0.503000\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss:     1.2767 Validation Accuracy: 0.506000\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss:     1.2767 Validation Accuracy: 0.500000\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss:     1.2759 Validation Accuracy: 0.504800\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss:     1.2744 Validation Accuracy: 0.499800\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss:     1.2731 Validation Accuracy: 0.504200\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss:     1.2726 Validation Accuracy: 0.504000\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss:     1.2722 Validation Accuracy: 0.503200\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss:     1.2713 Validation Accuracy: 0.504800\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss:     1.2700 Validation Accuracy: 0.503400\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss:     1.2689 Validation Accuracy: 0.504200\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss:     1.2682 Validation Accuracy: 0.506600\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss:     1.2678 Validation Accuracy: 0.504200\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss:     1.2674 Validation Accuracy: 0.506600\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss:     1.2667 Validation Accuracy: 0.504200\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss:     1.2660 Validation Accuracy: 0.508200\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss:     1.2659 Validation Accuracy: 0.505400\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss:     1.2665 Validation Accuracy: 0.506200\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss:     1.2685 Validation Accuracy: 0.503600\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss:     1.2708 Validation Accuracy: 0.503400\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss:     1.2739 Validation Accuracy: 0.498800\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss:     1.2717 Validation Accuracy: 0.503400\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss:     1.2671 Validation Accuracy: 0.501000\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss:     1.2612 Validation Accuracy: 0.509800\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss:     1.2599 Validation Accuracy: 0.504800\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss:     1.2621 Validation Accuracy: 0.507800\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss:     1.2627 Validation Accuracy: 0.506000\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss:     1.2606 Validation Accuracy: 0.504400\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss:     1.2572 Validation Accuracy: 0.510000\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss:     1.2564 Validation Accuracy: 0.505200\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss:     1.2576 Validation Accuracy: 0.511600\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss:     1.2569 Validation Accuracy: 0.506000\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss:     1.2541 Validation Accuracy: 0.509000\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss:     1.2516 Validation Accuracy: 0.511000\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss:     1.2516 Validation Accuracy: 0.507600\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss:     1.2527 Validation Accuracy: 0.511400\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss:     1.2520 Validation Accuracy: 0.507000\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss:     1.2498 Validation Accuracy: 0.509200\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss:     1.2480 Validation Accuracy: 0.508400\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss:     1.2476 Validation Accuracy: 0.510800\n",
      "Epoch 401, CIFAR-10 Batch 1:  Loss:     1.2478 Validation Accuracy: 0.510800\n",
      "Epoch 402, CIFAR-10 Batch 1:  Loss:     1.2473 Validation Accuracy: 0.509000\n",
      "Epoch 403, CIFAR-10 Batch 1:  Loss:     1.2461 Validation Accuracy: 0.510000\n",
      "Epoch 404, CIFAR-10 Batch 1:  Loss:     1.2447 Validation Accuracy: 0.509000\n",
      "Epoch 405, CIFAR-10 Batch 1:  Loss:     1.2440 Validation Accuracy: 0.512800\n",
      "Epoch 406, CIFAR-10 Batch 1:  Loss:     1.2438 Validation Accuracy: 0.510000\n",
      "Epoch 407, CIFAR-10 Batch 1:  Loss:     1.2434 Validation Accuracy: 0.511600\n",
      "Epoch 408, CIFAR-10 Batch 1:  Loss:     1.2425 Validation Accuracy: 0.511000\n",
      "Epoch 409, CIFAR-10 Batch 1:  Loss:     1.2412 Validation Accuracy: 0.513600\n",
      "Epoch 410, CIFAR-10 Batch 1:  Loss:     1.2400 Validation Accuracy: 0.510800\n",
      "Epoch 411, CIFAR-10 Batch 1:  Loss:     1.2393 Validation Accuracy: 0.511800\n",
      "Epoch 412, CIFAR-10 Batch 1:  Loss:     1.2389 Validation Accuracy: 0.512800\n",
      "Epoch 413, CIFAR-10 Batch 1:  Loss:     1.2384 Validation Accuracy: 0.511400\n",
      "Epoch 414, CIFAR-10 Batch 1:  Loss:     1.2377 Validation Accuracy: 0.513200\n",
      "Epoch 415, CIFAR-10 Batch 1:  Loss:     1.2367 Validation Accuracy: 0.514000\n",
      "Epoch 416, CIFAR-10 Batch 1:  Loss:     1.2358 Validation Accuracy: 0.512600\n",
      "Epoch 417, CIFAR-10 Batch 1:  Loss:     1.2349 Validation Accuracy: 0.513400\n",
      "Epoch 418, CIFAR-10 Batch 1:  Loss:     1.2342 Validation Accuracy: 0.513200\n",
      "Epoch 419, CIFAR-10 Batch 1:  Loss:     1.2336 Validation Accuracy: 0.512600\n",
      "Epoch 420, CIFAR-10 Batch 1:  Loss:     1.2330 Validation Accuracy: 0.515600\n",
      "Epoch 421, CIFAR-10 Batch 1:  Loss:     1.2325 Validation Accuracy: 0.512400\n",
      "Epoch 422, CIFAR-10 Batch 1:  Loss:     1.2318 Validation Accuracy: 0.516000\n",
      "Epoch 423, CIFAR-10 Batch 1:  Loss:     1.2312 Validation Accuracy: 0.510800\n",
      "Epoch 424, CIFAR-10 Batch 1:  Loss:     1.2307 Validation Accuracy: 0.514800\n",
      "Epoch 425, CIFAR-10 Batch 1:  Loss:     1.2305 Validation Accuracy: 0.509400\n",
      "Epoch 426, CIFAR-10 Batch 1:  Loss:     1.2312 Validation Accuracy: 0.513800\n",
      "Epoch 427, CIFAR-10 Batch 1:  Loss:     1.2335 Validation Accuracy: 0.506000\n",
      "Epoch 428, CIFAR-10 Batch 1:  Loss:     1.2397 Validation Accuracy: 0.512400\n",
      "Epoch 429, CIFAR-10 Batch 1:  Loss:     1.2486 Validation Accuracy: 0.500800\n",
      "Epoch 430, CIFAR-10 Batch 1:  Loss:     1.2605 Validation Accuracy: 0.508200\n",
      "Epoch 431, CIFAR-10 Batch 1:  Loss:     1.2525 Validation Accuracy: 0.497000\n",
      "Epoch 432, CIFAR-10 Batch 1:  Loss:     1.2367 Validation Accuracy: 0.513600\n",
      "Epoch 433, CIFAR-10 Batch 1:  Loss:     1.2276 Validation Accuracy: 0.509800\n",
      "Epoch 434, CIFAR-10 Batch 1:  Loss:     1.2332 Validation Accuracy: 0.509000\n",
      "Epoch 435, CIFAR-10 Batch 1:  Loss:     1.2404 Validation Accuracy: 0.513000\n",
      "Epoch 436, CIFAR-10 Batch 1:  Loss:     1.2317 Validation Accuracy: 0.503400\n",
      "Epoch 437, CIFAR-10 Batch 1:  Loss:     1.2250 Validation Accuracy: 0.518400\n",
      "Epoch 438, CIFAR-10 Batch 1:  Loss:     1.2276 Validation Accuracy: 0.511800\n",
      "Epoch 439, CIFAR-10 Batch 1:  Loss:     1.2285 Validation Accuracy: 0.510000\n",
      "Epoch 440, CIFAR-10 Batch 1:  Loss:     1.2236 Validation Accuracy: 0.517600\n",
      "Epoch 441, CIFAR-10 Batch 1:  Loss:     1.2204 Validation Accuracy: 0.513200\n",
      "Epoch 442, CIFAR-10 Batch 1:  Loss:     1.2245 Validation Accuracy: 0.511200\n",
      "Epoch 443, CIFAR-10 Batch 1:  Loss:     1.2253 Validation Accuracy: 0.513400\n",
      "Epoch 444, CIFAR-10 Batch 1:  Loss:     1.2184 Validation Accuracy: 0.510800\n",
      "Epoch 445, CIFAR-10 Batch 1:  Loss:     1.2176 Validation Accuracy: 0.513800\n",
      "Epoch 446, CIFAR-10 Batch 1:  Loss:     1.2215 Validation Accuracy: 0.514000\n",
      "Epoch 447, CIFAR-10 Batch 1:  Loss:     1.2188 Validation Accuracy: 0.512200\n",
      "Epoch 448, CIFAR-10 Batch 1:  Loss:     1.2150 Validation Accuracy: 0.516000\n",
      "Epoch 449, CIFAR-10 Batch 1:  Loss:     1.2160 Validation Accuracy: 0.518400\n",
      "Epoch 450, CIFAR-10 Batch 1:  Loss:     1.2164 Validation Accuracy: 0.512400\n",
      "Epoch 451, CIFAR-10 Batch 1:  Loss:     1.2140 Validation Accuracy: 0.517000\n",
      "Epoch 452, CIFAR-10 Batch 1:  Loss:     1.2129 Validation Accuracy: 0.520000\n",
      "Epoch 453, CIFAR-10 Batch 1:  Loss:     1.2136 Validation Accuracy: 0.511800\n",
      "Epoch 454, CIFAR-10 Batch 1:  Loss:     1.2126 Validation Accuracy: 0.519600\n",
      "Epoch 455, CIFAR-10 Batch 1:  Loss:     1.2107 Validation Accuracy: 0.517200\n",
      "Epoch 456, CIFAR-10 Batch 1:  Loss:     1.2106 Validation Accuracy: 0.514400\n",
      "Epoch 457, CIFAR-10 Batch 1:  Loss:     1.2108 Validation Accuracy: 0.520400\n",
      "Epoch 458, CIFAR-10 Batch 1:  Loss:     1.2096 Validation Accuracy: 0.513200\n",
      "Epoch 459, CIFAR-10 Batch 1:  Loss:     1.2083 Validation Accuracy: 0.516600\n",
      "Epoch 460, CIFAR-10 Batch 1:  Loss:     1.2078 Validation Accuracy: 0.518600\n",
      "Epoch 461, CIFAR-10 Batch 1:  Loss:     1.2074 Validation Accuracy: 0.514000\n",
      "Epoch 462, CIFAR-10 Batch 1:  Loss:     1.2067 Validation Accuracy: 0.520200\n",
      "Epoch 463, CIFAR-10 Batch 1:  Loss:     1.2060 Validation Accuracy: 0.515400\n",
      "Epoch 464, CIFAR-10 Batch 1:  Loss:     1.2052 Validation Accuracy: 0.517600\n",
      "Epoch 465, CIFAR-10 Batch 1:  Loss:     1.2047 Validation Accuracy: 0.518600\n",
      "Epoch 466, CIFAR-10 Batch 1:  Loss:     1.2041 Validation Accuracy: 0.519400\n",
      "Epoch 467, CIFAR-10 Batch 1:  Loss:     1.2033 Validation Accuracy: 0.517800\n",
      "Epoch 468, CIFAR-10 Batch 1:  Loss:     1.2024 Validation Accuracy: 0.517600\n",
      "Epoch 469, CIFAR-10 Batch 1:  Loss:     1.2020 Validation Accuracy: 0.519400\n",
      "Epoch 470, CIFAR-10 Batch 1:  Loss:     1.2016 Validation Accuracy: 0.518800\n",
      "Epoch 471, CIFAR-10 Batch 1:  Loss:     1.2009 Validation Accuracy: 0.520800\n",
      "Epoch 472, CIFAR-10 Batch 1:  Loss:     1.2000 Validation Accuracy: 0.516600\n",
      "Epoch 473, CIFAR-10 Batch 1:  Loss:     1.1994 Validation Accuracy: 0.521400\n",
      "Epoch 474, CIFAR-10 Batch 1:  Loss:     1.1990 Validation Accuracy: 0.518400\n",
      "Epoch 475, CIFAR-10 Batch 1:  Loss:     1.1983 Validation Accuracy: 0.519400\n",
      "Epoch 476, CIFAR-10 Batch 1:  Loss:     1.1974 Validation Accuracy: 0.520000\n",
      "Epoch 477, CIFAR-10 Batch 1:  Loss:     1.1967 Validation Accuracy: 0.520600\n",
      "Epoch 478, CIFAR-10 Batch 1:  Loss:     1.1962 Validation Accuracy: 0.519200\n",
      "Epoch 479, CIFAR-10 Batch 1:  Loss:     1.1957 Validation Accuracy: 0.519400\n",
      "Epoch 480, CIFAR-10 Batch 1:  Loss:     1.1950 Validation Accuracy: 0.521000\n",
      "Epoch 481, CIFAR-10 Batch 1:  Loss:     1.1943 Validation Accuracy: 0.518400\n",
      "Epoch 482, CIFAR-10 Batch 1:  Loss:     1.1937 Validation Accuracy: 0.521800\n",
      "Epoch 483, CIFAR-10 Batch 1:  Loss:     1.1931 Validation Accuracy: 0.518600\n",
      "Epoch 484, CIFAR-10 Batch 1:  Loss:     1.1926 Validation Accuracy: 0.522600\n",
      "Epoch 485, CIFAR-10 Batch 1:  Loss:     1.1920 Validation Accuracy: 0.519000\n",
      "Epoch 486, CIFAR-10 Batch 1:  Loss:     1.1915 Validation Accuracy: 0.521400\n",
      "Epoch 487, CIFAR-10 Batch 1:  Loss:     1.1911 Validation Accuracy: 0.517800\n",
      "Epoch 488, CIFAR-10 Batch 1:  Loss:     1.1909 Validation Accuracy: 0.524600\n",
      "Epoch 489, CIFAR-10 Batch 1:  Loss:     1.1912 Validation Accuracy: 0.518200\n",
      "Epoch 490, CIFAR-10 Batch 1:  Loss:     1.1921 Validation Accuracy: 0.525400\n",
      "Epoch 491, CIFAR-10 Batch 1:  Loss:     1.1945 Validation Accuracy: 0.513600\n",
      "Epoch 492, CIFAR-10 Batch 1:  Loss:     1.1981 Validation Accuracy: 0.522800\n",
      "Epoch 493, CIFAR-10 Batch 1:  Loss:     1.2039 Validation Accuracy: 0.511600\n",
      "Epoch 494, CIFAR-10 Batch 1:  Loss:     1.2048 Validation Accuracy: 0.514000\n",
      "Epoch 495, CIFAR-10 Batch 1:  Loss:     1.2012 Validation Accuracy: 0.514800\n",
      "Epoch 496, CIFAR-10 Batch 1:  Loss:     1.1904 Validation Accuracy: 0.522000\n",
      "Epoch 497, CIFAR-10 Batch 1:  Loss:     1.1848 Validation Accuracy: 0.522000\n",
      "Epoch 498, CIFAR-10 Batch 1:  Loss:     1.1878 Validation Accuracy: 0.516000\n",
      "Epoch 499, CIFAR-10 Batch 1:  Loss:     1.1927 Validation Accuracy: 0.522400\n",
      "Epoch 500, CIFAR-10 Batch 1:  Loss:     1.1930 Validation Accuracy: 0.517400\n",
      "Epoch 501, CIFAR-10 Batch 1:  Loss:     1.1864 Validation Accuracy: 0.523400\n",
      "Epoch 502, CIFAR-10 Batch 1:  Loss:     1.1818 Validation Accuracy: 0.520800\n",
      "Epoch 503, CIFAR-10 Batch 1:  Loss:     1.1833 Validation Accuracy: 0.521200\n",
      "Epoch 504, CIFAR-10 Batch 1:  Loss:     1.1861 Validation Accuracy: 0.523200\n",
      "Epoch 505, CIFAR-10 Batch 1:  Loss:     1.1847 Validation Accuracy: 0.520400\n",
      "Epoch 506, CIFAR-10 Batch 1:  Loss:     1.1804 Validation Accuracy: 0.524400\n",
      "Epoch 507, CIFAR-10 Batch 1:  Loss:     1.1791 Validation Accuracy: 0.523600\n",
      "Epoch 508, CIFAR-10 Batch 1:  Loss:     1.1811 Validation Accuracy: 0.522200\n",
      "Epoch 509, CIFAR-10 Batch 1:  Loss:     1.1815 Validation Accuracy: 0.523800\n",
      "Epoch 510, CIFAR-10 Batch 1:  Loss:     1.1790 Validation Accuracy: 0.522600\n",
      "Epoch 511, CIFAR-10 Batch 1:  Loss:     1.1766 Validation Accuracy: 0.522400\n",
      "Epoch 512, CIFAR-10 Batch 1:  Loss:     1.1767 Validation Accuracy: 0.523200\n",
      "Epoch 513, CIFAR-10 Batch 1:  Loss:     1.1777 Validation Accuracy: 0.522800\n",
      "Epoch 514, CIFAR-10 Batch 1:  Loss:     1.1769 Validation Accuracy: 0.524200\n",
      "Epoch 515, CIFAR-10 Batch 1:  Loss:     1.1749 Validation Accuracy: 0.522400\n",
      "Epoch 516, CIFAR-10 Batch 1:  Loss:     1.1737 Validation Accuracy: 0.522800\n",
      "Epoch 517, CIFAR-10 Batch 1:  Loss:     1.1739 Validation Accuracy: 0.525000\n",
      "Epoch 518, CIFAR-10 Batch 1:  Loss:     1.1741 Validation Accuracy: 0.523200\n",
      "Epoch 519, CIFAR-10 Batch 1:  Loss:     1.1731 Validation Accuracy: 0.524400\n",
      "Epoch 520, CIFAR-10 Batch 1:  Loss:     1.1717 Validation Accuracy: 0.522600\n",
      "Epoch 521, CIFAR-10 Batch 1:  Loss:     1.1708 Validation Accuracy: 0.522200\n",
      "Epoch 522, CIFAR-10 Batch 1:  Loss:     1.1707 Validation Accuracy: 0.523400\n",
      "Epoch 523, CIFAR-10 Batch 1:  Loss:     1.1706 Validation Accuracy: 0.522600\n",
      "Epoch 524, CIFAR-10 Batch 1:  Loss:     1.1699 Validation Accuracy: 0.524800\n",
      "Epoch 525, CIFAR-10 Batch 1:  Loss:     1.1688 Validation Accuracy: 0.523400\n",
      "Epoch 526, CIFAR-10 Batch 1:  Loss:     1.1679 Validation Accuracy: 0.523600\n",
      "Epoch 527, CIFAR-10 Batch 1:  Loss:     1.1675 Validation Accuracy: 0.525200\n",
      "Epoch 528, CIFAR-10 Batch 1:  Loss:     1.1673 Validation Accuracy: 0.522600\n",
      "Epoch 529, CIFAR-10 Batch 1:  Loss:     1.1668 Validation Accuracy: 0.523200\n",
      "Epoch 530, CIFAR-10 Batch 1:  Loss:     1.1660 Validation Accuracy: 0.524400\n",
      "Epoch 531, CIFAR-10 Batch 1:  Loss:     1.1651 Validation Accuracy: 0.524800\n",
      "Epoch 532, CIFAR-10 Batch 1:  Loss:     1.1644 Validation Accuracy: 0.524000\n",
      "Epoch 533, CIFAR-10 Batch 1:  Loss:     1.1639 Validation Accuracy: 0.525600\n",
      "Epoch 534, CIFAR-10 Batch 1:  Loss:     1.1635 Validation Accuracy: 0.524600\n",
      "Epoch 535, CIFAR-10 Batch 1:  Loss:     1.1630 Validation Accuracy: 0.525800\n",
      "Epoch 536, CIFAR-10 Batch 1:  Loss:     1.1624 Validation Accuracy: 0.524400\n",
      "Epoch 537, CIFAR-10 Batch 1:  Loss:     1.1617 Validation Accuracy: 0.526200\n",
      "Epoch 538, CIFAR-10 Batch 1:  Loss:     1.1610 Validation Accuracy: 0.524400\n",
      "Epoch 539, CIFAR-10 Batch 1:  Loss:     1.1605 Validation Accuracy: 0.525600\n",
      "Epoch 540, CIFAR-10 Batch 1:  Loss:     1.1601 Validation Accuracy: 0.525400\n",
      "Epoch 541, CIFAR-10 Batch 1:  Loss:     1.1599 Validation Accuracy: 0.527000\n",
      "Epoch 542, CIFAR-10 Batch 1:  Loss:     1.1600 Validation Accuracy: 0.524600\n",
      "Epoch 543, CIFAR-10 Batch 1:  Loss:     1.1607 Validation Accuracy: 0.528200\n",
      "Epoch 544, CIFAR-10 Batch 1:  Loss:     1.1626 Validation Accuracy: 0.519400\n",
      "Epoch 545, CIFAR-10 Batch 1:  Loss:     1.1671 Validation Accuracy: 0.525200\n",
      "Epoch 546, CIFAR-10 Batch 1:  Loss:     1.1738 Validation Accuracy: 0.519200\n",
      "Epoch 547, CIFAR-10 Batch 1:  Loss:     1.1834 Validation Accuracy: 0.524600\n",
      "Epoch 548, CIFAR-10 Batch 1:  Loss:     1.1814 Validation Accuracy: 0.516000\n",
      "Epoch 549, CIFAR-10 Batch 1:  Loss:     1.1711 Validation Accuracy: 0.527600\n",
      "Epoch 550, CIFAR-10 Batch 1:  Loss:     1.1572 Validation Accuracy: 0.521200\n",
      "Epoch 551, CIFAR-10 Batch 1:  Loss:     1.1561 Validation Accuracy: 0.522800\n",
      "Epoch 552, CIFAR-10 Batch 1:  Loss:     1.1647 Validation Accuracy: 0.526400\n",
      "Epoch 553, CIFAR-10 Batch 1:  Loss:     1.1665 Validation Accuracy: 0.518800\n",
      "Epoch 554, CIFAR-10 Batch 1:  Loss:     1.1595 Validation Accuracy: 0.528200\n",
      "Epoch 555, CIFAR-10 Batch 1:  Loss:     1.1520 Validation Accuracy: 0.526200\n",
      "Epoch 556, CIFAR-10 Batch 1:  Loss:     1.1542 Validation Accuracy: 0.522800\n",
      "Epoch 557, CIFAR-10 Batch 1:  Loss:     1.1596 Validation Accuracy: 0.527800\n",
      "Epoch 558, CIFAR-10 Batch 1:  Loss:     1.1564 Validation Accuracy: 0.520800\n",
      "Epoch 559, CIFAR-10 Batch 1:  Loss:     1.1504 Validation Accuracy: 0.529800\n",
      "Epoch 560, CIFAR-10 Batch 1:  Loss:     1.1497 Validation Accuracy: 0.530000\n",
      "Epoch 561, CIFAR-10 Batch 1:  Loss:     1.1530 Validation Accuracy: 0.521200\n",
      "Epoch 562, CIFAR-10 Batch 1:  Loss:     1.1530 Validation Accuracy: 0.529400\n",
      "Epoch 563, CIFAR-10 Batch 1:  Loss:     1.1489 Validation Accuracy: 0.525200\n",
      "Epoch 564, CIFAR-10 Batch 1:  Loss:     1.1470 Validation Accuracy: 0.526400\n",
      "Epoch 565, CIFAR-10 Batch 1:  Loss:     1.1487 Validation Accuracy: 0.527200\n",
      "Epoch 566, CIFAR-10 Batch 1:  Loss:     1.1491 Validation Accuracy: 0.523400\n",
      "Epoch 567, CIFAR-10 Batch 1:  Loss:     1.1465 Validation Accuracy: 0.530200\n",
      "Epoch 568, CIFAR-10 Batch 1:  Loss:     1.1446 Validation Accuracy: 0.528200\n",
      "Epoch 569, CIFAR-10 Batch 1:  Loss:     1.1452 Validation Accuracy: 0.526600\n",
      "Epoch 570, CIFAR-10 Batch 1:  Loss:     1.1459 Validation Accuracy: 0.528400\n",
      "Epoch 571, CIFAR-10 Batch 1:  Loss:     1.1444 Validation Accuracy: 0.525200\n",
      "Epoch 572, CIFAR-10 Batch 1:  Loss:     1.1425 Validation Accuracy: 0.528600\n",
      "Epoch 573, CIFAR-10 Batch 1:  Loss:     1.1423 Validation Accuracy: 0.530400\n",
      "Epoch 574, CIFAR-10 Batch 1:  Loss:     1.1427 Validation Accuracy: 0.525800\n",
      "Epoch 575, CIFAR-10 Batch 1:  Loss:     1.1421 Validation Accuracy: 0.531400\n",
      "Epoch 576, CIFAR-10 Batch 1:  Loss:     1.1405 Validation Accuracy: 0.526000\n",
      "Epoch 577, CIFAR-10 Batch 1:  Loss:     1.1397 Validation Accuracy: 0.529600\n",
      "Epoch 578, CIFAR-10 Batch 1:  Loss:     1.1398 Validation Accuracy: 0.532400\n",
      "Epoch 579, CIFAR-10 Batch 1:  Loss:     1.1396 Validation Accuracy: 0.526200\n",
      "Epoch 580, CIFAR-10 Batch 1:  Loss:     1.1387 Validation Accuracy: 0.532200\n",
      "Epoch 581, CIFAR-10 Batch 1:  Loss:     1.1376 Validation Accuracy: 0.529000\n",
      "Epoch 582, CIFAR-10 Batch 1:  Loss:     1.1371 Validation Accuracy: 0.528200\n",
      "Epoch 583, CIFAR-10 Batch 1:  Loss:     1.1370 Validation Accuracy: 0.529200\n",
      "Epoch 584, CIFAR-10 Batch 1:  Loss:     1.1366 Validation Accuracy: 0.527400\n",
      "Epoch 585, CIFAR-10 Batch 1:  Loss:     1.1358 Validation Accuracy: 0.530200\n",
      "Epoch 586, CIFAR-10 Batch 1:  Loss:     1.1351 Validation Accuracy: 0.528600\n",
      "Epoch 587, CIFAR-10 Batch 1:  Loss:     1.1347 Validation Accuracy: 0.529600\n",
      "Epoch 588, CIFAR-10 Batch 1:  Loss:     1.1347 Validation Accuracy: 0.531200\n",
      "Epoch 589, CIFAR-10 Batch 1:  Loss:     1.1347 Validation Accuracy: 0.528200\n",
      "Epoch 590, CIFAR-10 Batch 1:  Loss:     1.1348 Validation Accuracy: 0.531600\n",
      "Epoch 591, CIFAR-10 Batch 1:  Loss:     1.1355 Validation Accuracy: 0.529000\n",
      "Epoch 592, CIFAR-10 Batch 1:  Loss:     1.1373 Validation Accuracy: 0.530000\n",
      "Epoch 593, CIFAR-10 Batch 1:  Loss:     1.1407 Validation Accuracy: 0.527200\n",
      "Epoch 594, CIFAR-10 Batch 1:  Loss:     1.1449 Validation Accuracy: 0.524200\n",
      "Epoch 595, CIFAR-10 Batch 1:  Loss:     1.1482 Validation Accuracy: 0.523400\n",
      "Epoch 596, CIFAR-10 Batch 1:  Loss:     1.1463 Validation Accuracy: 0.523200\n",
      "Epoch 597, CIFAR-10 Batch 1:  Loss:     1.1389 Validation Accuracy: 0.525400\n",
      "Epoch 598, CIFAR-10 Batch 1:  Loss:     1.1306 Validation Accuracy: 0.529200\n",
      "Epoch 599, CIFAR-10 Batch 1:  Loss:     1.1280 Validation Accuracy: 0.531800\n",
      "Epoch 600, CIFAR-10 Batch 1:  Loss:     1.1314 Validation Accuracy: 0.529200\n",
      "Epoch 601, CIFAR-10 Batch 1:  Loss:     1.1353 Validation Accuracy: 0.527400\n",
      "Epoch 602, CIFAR-10 Batch 1:  Loss:     1.1346 Validation Accuracy: 0.525400\n",
      "Epoch 603, CIFAR-10 Batch 1:  Loss:     1.1295 Validation Accuracy: 0.531000\n",
      "Epoch 604, CIFAR-10 Batch 1:  Loss:     1.1255 Validation Accuracy: 0.533000\n",
      "Epoch 605, CIFAR-10 Batch 1:  Loss:     1.1260 Validation Accuracy: 0.530800\n",
      "Epoch 606, CIFAR-10 Batch 1:  Loss:     1.1284 Validation Accuracy: 0.529600\n",
      "Epoch 607, CIFAR-10 Batch 1:  Loss:     1.1286 Validation Accuracy: 0.530000\n",
      "Epoch 608, CIFAR-10 Batch 1:  Loss:     1.1257 Validation Accuracy: 0.530600\n",
      "Epoch 609, CIFAR-10 Batch 1:  Loss:     1.1231 Validation Accuracy: 0.533400\n",
      "Epoch 610, CIFAR-10 Batch 1:  Loss:     1.1230 Validation Accuracy: 0.531400\n",
      "Epoch 611, CIFAR-10 Batch 1:  Loss:     1.1240 Validation Accuracy: 0.529800\n",
      "Epoch 612, CIFAR-10 Batch 1:  Loss:     1.1240 Validation Accuracy: 0.530600\n",
      "Epoch 613, CIFAR-10 Batch 1:  Loss:     1.1223 Validation Accuracy: 0.531400\n",
      "Epoch 614, CIFAR-10 Batch 1:  Loss:     1.1207 Validation Accuracy: 0.534000\n",
      "Epoch 615, CIFAR-10 Batch 1:  Loss:     1.1202 Validation Accuracy: 0.531400\n",
      "Epoch 616, CIFAR-10 Batch 1:  Loss:     1.1204 Validation Accuracy: 0.531800\n",
      "Epoch 617, CIFAR-10 Batch 1:  Loss:     1.1202 Validation Accuracy: 0.531000\n",
      "Epoch 618, CIFAR-10 Batch 1:  Loss:     1.1191 Validation Accuracy: 0.531000\n",
      "Epoch 619, CIFAR-10 Batch 1:  Loss:     1.1180 Validation Accuracy: 0.533400\n",
      "Epoch 620, CIFAR-10 Batch 1:  Loss:     1.1174 Validation Accuracy: 0.531200\n",
      "Epoch 621, CIFAR-10 Batch 1:  Loss:     1.1173 Validation Accuracy: 0.532400\n",
      "Epoch 622, CIFAR-10 Batch 1:  Loss:     1.1171 Validation Accuracy: 0.532000\n",
      "Epoch 623, CIFAR-10 Batch 1:  Loss:     1.1164 Validation Accuracy: 0.532600\n",
      "Epoch 624, CIFAR-10 Batch 1:  Loss:     1.1153 Validation Accuracy: 0.533000\n",
      "Epoch 625, CIFAR-10 Batch 1:  Loss:     1.1145 Validation Accuracy: 0.532400\n",
      "Epoch 626, CIFAR-10 Batch 1:  Loss:     1.1141 Validation Accuracy: 0.532200\n",
      "Epoch 627, CIFAR-10 Batch 1:  Loss:     1.1139 Validation Accuracy: 0.533800\n",
      "Epoch 628, CIFAR-10 Batch 1:  Loss:     1.1136 Validation Accuracy: 0.532200\n",
      "Epoch 629, CIFAR-10 Batch 1:  Loss:     1.1130 Validation Accuracy: 0.533600\n",
      "Epoch 630, CIFAR-10 Batch 1:  Loss:     1.1121 Validation Accuracy: 0.532400\n",
      "Epoch 631, CIFAR-10 Batch 1:  Loss:     1.1114 Validation Accuracy: 0.532200\n",
      "Epoch 632, CIFAR-10 Batch 1:  Loss:     1.1108 Validation Accuracy: 0.532000\n",
      "Epoch 633, CIFAR-10 Batch 1:  Loss:     1.1104 Validation Accuracy: 0.531800\n",
      "Epoch 634, CIFAR-10 Batch 1:  Loss:     1.1101 Validation Accuracy: 0.532200\n",
      "Epoch 635, CIFAR-10 Batch 1:  Loss:     1.1096 Validation Accuracy: 0.532600\n",
      "Epoch 636, CIFAR-10 Batch 1:  Loss:     1.1091 Validation Accuracy: 0.533000\n",
      "Epoch 637, CIFAR-10 Batch 1:  Loss:     1.1084 Validation Accuracy: 0.532200\n",
      "Epoch 638, CIFAR-10 Batch 1:  Loss:     1.1077 Validation Accuracy: 0.532800\n",
      "Epoch 639, CIFAR-10 Batch 1:  Loss:     1.1072 Validation Accuracy: 0.531200\n",
      "Epoch 640, CIFAR-10 Batch 1:  Loss:     1.1067 Validation Accuracy: 0.531400\n",
      "Epoch 641, CIFAR-10 Batch 1:  Loss:     1.1063 Validation Accuracy: 0.531200\n",
      "Epoch 642, CIFAR-10 Batch 1:  Loss:     1.1061 Validation Accuracy: 0.533000\n",
      "Epoch 643, CIFAR-10 Batch 1:  Loss:     1.1059 Validation Accuracy: 0.533600\n",
      "Epoch 644, CIFAR-10 Batch 1:  Loss:     1.1059 Validation Accuracy: 0.533600\n",
      "Epoch 645, CIFAR-10 Batch 1:  Loss:     1.1063 Validation Accuracy: 0.533200\n",
      "Epoch 646, CIFAR-10 Batch 1:  Loss:     1.1072 Validation Accuracy: 0.535800\n",
      "Epoch 647, CIFAR-10 Batch 1:  Loss:     1.1089 Validation Accuracy: 0.534600\n",
      "Epoch 648, CIFAR-10 Batch 1:  Loss:     1.1105 Validation Accuracy: 0.535000\n",
      "Epoch 649, CIFAR-10 Batch 1:  Loss:     1.1121 Validation Accuracy: 0.530200\n",
      "Epoch 650, CIFAR-10 Batch 1:  Loss:     1.1106 Validation Accuracy: 0.531000\n",
      "Epoch 651, CIFAR-10 Batch 1:  Loss:     1.1098 Validation Accuracy: 0.530400\n",
      "Epoch 652, CIFAR-10 Batch 1:  Loss:     1.1078 Validation Accuracy: 0.531800\n",
      "Epoch 653, CIFAR-10 Batch 1:  Loss:     1.1061 Validation Accuracy: 0.532600\n",
      "Epoch 654, CIFAR-10 Batch 1:  Loss:     1.1037 Validation Accuracy: 0.529600\n",
      "Epoch 655, CIFAR-10 Batch 1:  Loss:     1.1006 Validation Accuracy: 0.534800\n",
      "Epoch 656, CIFAR-10 Batch 1:  Loss:     1.0990 Validation Accuracy: 0.535600\n",
      "Epoch 657, CIFAR-10 Batch 1:  Loss:     1.0999 Validation Accuracy: 0.533600\n",
      "Epoch 658, CIFAR-10 Batch 1:  Loss:     1.1018 Validation Accuracy: 0.533800\n",
      "Epoch 659, CIFAR-10 Batch 1:  Loss:     1.1023 Validation Accuracy: 0.531000\n",
      "Epoch 660, CIFAR-10 Batch 1:  Loss:     1.1004 Validation Accuracy: 0.534200\n",
      "Epoch 661, CIFAR-10 Batch 1:  Loss:     1.0975 Validation Accuracy: 0.535400\n",
      "Epoch 662, CIFAR-10 Batch 1:  Loss:     1.0957 Validation Accuracy: 0.536000\n",
      "Epoch 663, CIFAR-10 Batch 1:  Loss:     1.0954 Validation Accuracy: 0.535400\n",
      "Epoch 664, CIFAR-10 Batch 1:  Loss:     1.0958 Validation Accuracy: 0.533600\n",
      "Epoch 665, CIFAR-10 Batch 1:  Loss:     1.0957 Validation Accuracy: 0.536000\n",
      "Epoch 666, CIFAR-10 Batch 1:  Loss:     1.0950 Validation Accuracy: 0.535400\n",
      "Epoch 667, CIFAR-10 Batch 1:  Loss:     1.0943 Validation Accuracy: 0.537400\n",
      "Epoch 668, CIFAR-10 Batch 1:  Loss:     1.0938 Validation Accuracy: 0.536200\n",
      "Epoch 669, CIFAR-10 Batch 1:  Loss:     1.0933 Validation Accuracy: 0.537200\n",
      "Epoch 670, CIFAR-10 Batch 1:  Loss:     1.0923 Validation Accuracy: 0.534800\n",
      "Epoch 671, CIFAR-10 Batch 1:  Loss:     1.0912 Validation Accuracy: 0.536800\n",
      "Epoch 672, CIFAR-10 Batch 1:  Loss:     1.0904 Validation Accuracy: 0.535600\n",
      "Epoch 673, CIFAR-10 Batch 1:  Loss:     1.0902 Validation Accuracy: 0.536400\n",
      "Epoch 674, CIFAR-10 Batch 1:  Loss:     1.0907 Validation Accuracy: 0.536000\n",
      "Epoch 675, CIFAR-10 Batch 1:  Loss:     1.0914 Validation Accuracy: 0.535200\n",
      "Epoch 676, CIFAR-10 Batch 1:  Loss:     1.0930 Validation Accuracy: 0.536400\n",
      "Epoch 677, CIFAR-10 Batch 1:  Loss:     1.0964 Validation Accuracy: 0.531600\n",
      "Epoch 678, CIFAR-10 Batch 1:  Loss:     1.1051 Validation Accuracy: 0.535800\n",
      "Epoch 679, CIFAR-10 Batch 1:  Loss:     1.1165 Validation Accuracy: 0.525600\n",
      "Epoch 680, CIFAR-10 Batch 1:  Loss:     1.1318 Validation Accuracy: 0.529600\n",
      "Epoch 681, CIFAR-10 Batch 1:  Loss:     1.1228 Validation Accuracy: 0.523200\n",
      "Epoch 682, CIFAR-10 Batch 1:  Loss:     1.1029 Validation Accuracy: 0.531600\n",
      "Epoch 683, CIFAR-10 Batch 1:  Loss:     1.0904 Validation Accuracy: 0.537200\n",
      "Epoch 684, CIFAR-10 Batch 1:  Loss:     1.0972 Validation Accuracy: 0.531400\n",
      "Epoch 685, CIFAR-10 Batch 1:  Loss:     1.1086 Validation Accuracy: 0.531800\n",
      "Epoch 686, CIFAR-10 Batch 1:  Loss:     1.0994 Validation Accuracy: 0.528400\n",
      "Epoch 687, CIFAR-10 Batch 1:  Loss:     1.0867 Validation Accuracy: 0.535800\n",
      "Epoch 688, CIFAR-10 Batch 1:  Loss:     1.0880 Validation Accuracy: 0.537600\n",
      "Epoch 689, CIFAR-10 Batch 1:  Loss:     1.0946 Validation Accuracy: 0.534400\n",
      "Epoch 690, CIFAR-10 Batch 1:  Loss:     1.0921 Validation Accuracy: 0.536200\n",
      "Epoch 691, CIFAR-10 Batch 1:  Loss:     1.0844 Validation Accuracy: 0.539000\n",
      "Epoch 692, CIFAR-10 Batch 1:  Loss:     1.0848 Validation Accuracy: 0.536200\n",
      "Epoch 693, CIFAR-10 Batch 1:  Loss:     1.0887 Validation Accuracy: 0.538800\n",
      "Epoch 694, CIFAR-10 Batch 1:  Loss:     1.0857 Validation Accuracy: 0.536800\n",
      "Epoch 695, CIFAR-10 Batch 1:  Loss:     1.0818 Validation Accuracy: 0.536800\n",
      "Epoch 696, CIFAR-10 Batch 1:  Loss:     1.0829 Validation Accuracy: 0.539200\n",
      "Epoch 697, CIFAR-10 Batch 1:  Loss:     1.0837 Validation Accuracy: 0.537400\n",
      "Epoch 698, CIFAR-10 Batch 1:  Loss:     1.0810 Validation Accuracy: 0.537600\n",
      "Epoch 699, CIFAR-10 Batch 1:  Loss:     1.0792 Validation Accuracy: 0.539600\n",
      "Epoch 700, CIFAR-10 Batch 1:  Loss:     1.0804 Validation Accuracy: 0.536600\n",
      "Epoch 701, CIFAR-10 Batch 1:  Loss:     1.0805 Validation Accuracy: 0.538600\n",
      "Epoch 702, CIFAR-10 Batch 1:  Loss:     1.0779 Validation Accuracy: 0.536800\n",
      "Epoch 703, CIFAR-10 Batch 1:  Loss:     1.0770 Validation Accuracy: 0.539200\n",
      "Epoch 704, CIFAR-10 Batch 1:  Loss:     1.0779 Validation Accuracy: 0.538200\n",
      "Epoch 705, CIFAR-10 Batch 1:  Loss:     1.0771 Validation Accuracy: 0.537400\n",
      "Epoch 706, CIFAR-10 Batch 1:  Loss:     1.0750 Validation Accuracy: 0.539000\n",
      "Epoch 707, CIFAR-10 Batch 1:  Loss:     1.0746 Validation Accuracy: 0.539000\n",
      "Epoch 708, CIFAR-10 Batch 1:  Loss:     1.0754 Validation Accuracy: 0.537000\n",
      "Epoch 709, CIFAR-10 Batch 1:  Loss:     1.0748 Validation Accuracy: 0.539800\n",
      "Epoch 710, CIFAR-10 Batch 1:  Loss:     1.0730 Validation Accuracy: 0.539000\n",
      "Epoch 711, CIFAR-10 Batch 1:  Loss:     1.0725 Validation Accuracy: 0.540200\n",
      "Epoch 712, CIFAR-10 Batch 1:  Loss:     1.0730 Validation Accuracy: 0.541200\n",
      "Epoch 713, CIFAR-10 Batch 1:  Loss:     1.0724 Validation Accuracy: 0.537200\n",
      "Epoch 714, CIFAR-10 Batch 1:  Loss:     1.0710 Validation Accuracy: 0.540200\n",
      "Epoch 715, CIFAR-10 Batch 1:  Loss:     1.0704 Validation Accuracy: 0.540400\n",
      "Epoch 716, CIFAR-10 Batch 1:  Loss:     1.0705 Validation Accuracy: 0.538600\n",
      "Epoch 717, CIFAR-10 Batch 1:  Loss:     1.0703 Validation Accuracy: 0.540000\n",
      "Epoch 718, CIFAR-10 Batch 1:  Loss:     1.0693 Validation Accuracy: 0.541000\n",
      "Epoch 719, CIFAR-10 Batch 1:  Loss:     1.0684 Validation Accuracy: 0.542800\n",
      "Epoch 720, CIFAR-10 Batch 1:  Loss:     1.0682 Validation Accuracy: 0.541400\n",
      "Epoch 721, CIFAR-10 Batch 1:  Loss:     1.0681 Validation Accuracy: 0.540200\n",
      "Epoch 722, CIFAR-10 Batch 1:  Loss:     1.0674 Validation Accuracy: 0.542000\n",
      "Epoch 723, CIFAR-10 Batch 1:  Loss:     1.0666 Validation Accuracy: 0.541800\n",
      "Epoch 724, CIFAR-10 Batch 1:  Loss:     1.0662 Validation Accuracy: 0.542200\n",
      "Epoch 725, CIFAR-10 Batch 1:  Loss:     1.0659 Validation Accuracy: 0.541000\n",
      "Epoch 726, CIFAR-10 Batch 1:  Loss:     1.0655 Validation Accuracy: 0.541800\n",
      "Epoch 727, CIFAR-10 Batch 1:  Loss:     1.0649 Validation Accuracy: 0.541600\n",
      "Epoch 728, CIFAR-10 Batch 1:  Loss:     1.0644 Validation Accuracy: 0.542600\n",
      "Epoch 729, CIFAR-10 Batch 1:  Loss:     1.0641 Validation Accuracy: 0.541000\n",
      "Epoch 730, CIFAR-10 Batch 1:  Loss:     1.0640 Validation Accuracy: 0.539800\n",
      "Epoch 731, CIFAR-10 Batch 1:  Loss:     1.0640 Validation Accuracy: 0.537600\n",
      "Epoch 732, CIFAR-10 Batch 1:  Loss:     1.0645 Validation Accuracy: 0.540200\n",
      "Epoch 733, CIFAR-10 Batch 1:  Loss:     1.0660 Validation Accuracy: 0.537600\n",
      "Epoch 734, CIFAR-10 Batch 1:  Loss:     1.0699 Validation Accuracy: 0.538800\n",
      "Epoch 735, CIFAR-10 Batch 1:  Loss:     1.0758 Validation Accuracy: 0.538400\n",
      "Epoch 736, CIFAR-10 Batch 1:  Loss:     1.0866 Validation Accuracy: 0.531200\n",
      "Epoch 737, CIFAR-10 Batch 1:  Loss:     1.0911 Validation Accuracy: 0.531800\n",
      "Epoch 738, CIFAR-10 Batch 1:  Loss:     1.0918 Validation Accuracy: 0.530600\n",
      "Epoch 739, CIFAR-10 Batch 1:  Loss:     1.0745 Validation Accuracy: 0.536400\n",
      "Epoch 740, CIFAR-10 Batch 1:  Loss:     1.0613 Validation Accuracy: 0.540600\n",
      "Epoch 741, CIFAR-10 Batch 1:  Loss:     1.0610 Validation Accuracy: 0.542000\n",
      "Epoch 742, CIFAR-10 Batch 1:  Loss:     1.0690 Validation Accuracy: 0.537200\n",
      "Epoch 743, CIFAR-10 Batch 1:  Loss:     1.0738 Validation Accuracy: 0.534800\n",
      "Epoch 744, CIFAR-10 Batch 1:  Loss:     1.0657 Validation Accuracy: 0.540000\n",
      "Epoch 745, CIFAR-10 Batch 1:  Loss:     1.0580 Validation Accuracy: 0.540000\n",
      "Epoch 746, CIFAR-10 Batch 1:  Loss:     1.0592 Validation Accuracy: 0.542400\n",
      "Epoch 747, CIFAR-10 Batch 1:  Loss:     1.0634 Validation Accuracy: 0.537800\n",
      "Epoch 748, CIFAR-10 Batch 1:  Loss:     1.0627 Validation Accuracy: 0.538800\n",
      "Epoch 749, CIFAR-10 Batch 1:  Loss:     1.0573 Validation Accuracy: 0.539800\n",
      "Epoch 750, CIFAR-10 Batch 1:  Loss:     1.0557 Validation Accuracy: 0.542600\n",
      "Epoch 751, CIFAR-10 Batch 1:  Loss:     1.0582 Validation Accuracy: 0.542600\n",
      "Epoch 752, CIFAR-10 Batch 1:  Loss:     1.0579 Validation Accuracy: 0.543000\n",
      "Epoch 753, CIFAR-10 Batch 1:  Loss:     1.0554 Validation Accuracy: 0.542200\n",
      "Epoch 754, CIFAR-10 Batch 1:  Loss:     1.0537 Validation Accuracy: 0.544000\n",
      "Epoch 755, CIFAR-10 Batch 1:  Loss:     1.0541 Validation Accuracy: 0.543200\n",
      "Epoch 756, CIFAR-10 Batch 1:  Loss:     1.0545 Validation Accuracy: 0.541600\n",
      "Epoch 757, CIFAR-10 Batch 1:  Loss:     1.0532 Validation Accuracy: 0.541600\n",
      "Epoch 758, CIFAR-10 Batch 1:  Loss:     1.0518 Validation Accuracy: 0.541600\n",
      "Epoch 759, CIFAR-10 Batch 1:  Loss:     1.0514 Validation Accuracy: 0.542000\n",
      "Epoch 760, CIFAR-10 Batch 1:  Loss:     1.0514 Validation Accuracy: 0.542200\n",
      "Epoch 761, CIFAR-10 Batch 1:  Loss:     1.0511 Validation Accuracy: 0.541000\n",
      "Epoch 762, CIFAR-10 Batch 1:  Loss:     1.0500 Validation Accuracy: 0.541600\n",
      "Epoch 763, CIFAR-10 Batch 1:  Loss:     1.0489 Validation Accuracy: 0.543400\n",
      "Epoch 764, CIFAR-10 Batch 1:  Loss:     1.0487 Validation Accuracy: 0.542800\n",
      "Epoch 765, CIFAR-10 Batch 1:  Loss:     1.0488 Validation Accuracy: 0.542000\n",
      "Epoch 766, CIFAR-10 Batch 1:  Loss:     1.0483 Validation Accuracy: 0.543200\n",
      "Epoch 767, CIFAR-10 Batch 1:  Loss:     1.0472 Validation Accuracy: 0.543600\n",
      "Epoch 768, CIFAR-10 Batch 1:  Loss:     1.0463 Validation Accuracy: 0.542400\n",
      "Epoch 769, CIFAR-10 Batch 1:  Loss:     1.0462 Validation Accuracy: 0.542000\n",
      "Epoch 770, CIFAR-10 Batch 1:  Loss:     1.0463 Validation Accuracy: 0.541200\n",
      "Epoch 771, CIFAR-10 Batch 1:  Loss:     1.0458 Validation Accuracy: 0.543800\n",
      "Epoch 772, CIFAR-10 Batch 1:  Loss:     1.0448 Validation Accuracy: 0.545000\n",
      "Epoch 773, CIFAR-10 Batch 1:  Loss:     1.0440 Validation Accuracy: 0.542600\n",
      "Epoch 774, CIFAR-10 Batch 1:  Loss:     1.0437 Validation Accuracy: 0.541800\n",
      "Epoch 775, CIFAR-10 Batch 1:  Loss:     1.0435 Validation Accuracy: 0.544000\n",
      "Epoch 776, CIFAR-10 Batch 1:  Loss:     1.0432 Validation Accuracy: 0.544400\n",
      "Epoch 777, CIFAR-10 Batch 1:  Loss:     1.0427 Validation Accuracy: 0.545000\n",
      "Epoch 778, CIFAR-10 Batch 1:  Loss:     1.0420 Validation Accuracy: 0.544200\n",
      "Epoch 779, CIFAR-10 Batch 1:  Loss:     1.0413 Validation Accuracy: 0.543400\n",
      "Epoch 780, CIFAR-10 Batch 1:  Loss:     1.0408 Validation Accuracy: 0.543600\n",
      "Epoch 781, CIFAR-10 Batch 1:  Loss:     1.0405 Validation Accuracy: 0.543200\n",
      "Epoch 782, CIFAR-10 Batch 1:  Loss:     1.0402 Validation Accuracy: 0.543400\n",
      "Epoch 783, CIFAR-10 Batch 1:  Loss:     1.0399 Validation Accuracy: 0.544000\n",
      "Epoch 784, CIFAR-10 Batch 1:  Loss:     1.0394 Validation Accuracy: 0.543800\n",
      "Epoch 785, CIFAR-10 Batch 1:  Loss:     1.0388 Validation Accuracy: 0.542600\n",
      "Epoch 786, CIFAR-10 Batch 1:  Loss:     1.0382 Validation Accuracy: 0.544200\n",
      "Epoch 787, CIFAR-10 Batch 1:  Loss:     1.0377 Validation Accuracy: 0.543600\n",
      "Epoch 788, CIFAR-10 Batch 1:  Loss:     1.0373 Validation Accuracy: 0.543600\n",
      "Epoch 789, CIFAR-10 Batch 1:  Loss:     1.0369 Validation Accuracy: 0.543600\n",
      "Epoch 790, CIFAR-10 Batch 1:  Loss:     1.0365 Validation Accuracy: 0.544000\n",
      "Epoch 791, CIFAR-10 Batch 1:  Loss:     1.0361 Validation Accuracy: 0.544800\n",
      "Epoch 792, CIFAR-10 Batch 1:  Loss:     1.0356 Validation Accuracy: 0.544000\n",
      "Epoch 793, CIFAR-10 Batch 1:  Loss:     1.0352 Validation Accuracy: 0.545000\n",
      "Epoch 794, CIFAR-10 Batch 1:  Loss:     1.0347 Validation Accuracy: 0.543800\n",
      "Epoch 795, CIFAR-10 Batch 1:  Loss:     1.0342 Validation Accuracy: 0.544800\n",
      "Epoch 796, CIFAR-10 Batch 1:  Loss:     1.0337 Validation Accuracy: 0.543800\n",
      "Epoch 797, CIFAR-10 Batch 1:  Loss:     1.0333 Validation Accuracy: 0.544800\n",
      "Epoch 798, CIFAR-10 Batch 1:  Loss:     1.0328 Validation Accuracy: 0.543800\n",
      "Epoch 799, CIFAR-10 Batch 1:  Loss:     1.0324 Validation Accuracy: 0.544000\n",
      "Epoch 800, CIFAR-10 Batch 1:  Loss:     1.0319 Validation Accuracy: 0.543800\n",
      "Epoch 801, CIFAR-10 Batch 1:  Loss:     1.0315 Validation Accuracy: 0.543600\n",
      "Epoch 802, CIFAR-10 Batch 1:  Loss:     1.0312 Validation Accuracy: 0.543000\n",
      "Epoch 803, CIFAR-10 Batch 1:  Loss:     1.0309 Validation Accuracy: 0.542000\n",
      "Epoch 804, CIFAR-10 Batch 1:  Loss:     1.0307 Validation Accuracy: 0.543400\n",
      "Epoch 805, CIFAR-10 Batch 1:  Loss:     1.0307 Validation Accuracy: 0.542200\n",
      "Epoch 806, CIFAR-10 Batch 1:  Loss:     1.0311 Validation Accuracy: 0.543000\n",
      "Epoch 807, CIFAR-10 Batch 1:  Loss:     1.0321 Validation Accuracy: 0.542000\n",
      "Epoch 808, CIFAR-10 Batch 1:  Loss:     1.0342 Validation Accuracy: 0.545000\n",
      "Epoch 809, CIFAR-10 Batch 1:  Loss:     1.0379 Validation Accuracy: 0.538800\n",
      "Epoch 810, CIFAR-10 Batch 1:  Loss:     1.0440 Validation Accuracy: 0.540600\n",
      "Epoch 811, CIFAR-10 Batch 1:  Loss:     1.0507 Validation Accuracy: 0.536400\n",
      "Epoch 812, CIFAR-10 Batch 1:  Loss:     1.0564 Validation Accuracy: 0.538600\n",
      "Epoch 813, CIFAR-10 Batch 1:  Loss:     1.0529 Validation Accuracy: 0.533600\n",
      "Epoch 814, CIFAR-10 Batch 1:  Loss:     1.0428 Validation Accuracy: 0.540600\n",
      "Epoch 815, CIFAR-10 Batch 1:  Loss:     1.0328 Validation Accuracy: 0.542200\n",
      "Epoch 816, CIFAR-10 Batch 1:  Loss:     1.0319 Validation Accuracy: 0.543800\n",
      "Epoch 817, CIFAR-10 Batch 1:  Loss:     1.0411 Validation Accuracy: 0.542200\n",
      "Epoch 818, CIFAR-10 Batch 1:  Loss:     1.0501 Validation Accuracy: 0.533200\n",
      "Epoch 819, CIFAR-10 Batch 1:  Loss:     1.0519 Validation Accuracy: 0.535800\n",
      "Epoch 820, CIFAR-10 Batch 1:  Loss:     1.0388 Validation Accuracy: 0.539200\n",
      "Epoch 821, CIFAR-10 Batch 1:  Loss:     1.0292 Validation Accuracy: 0.542400\n",
      "Epoch 822, CIFAR-10 Batch 1:  Loss:     1.0287 Validation Accuracy: 0.546400\n",
      "Epoch 823, CIFAR-10 Batch 1:  Loss:     1.0330 Validation Accuracy: 0.541400\n",
      "Epoch 824, CIFAR-10 Batch 1:  Loss:     1.0315 Validation Accuracy: 0.542600\n",
      "Epoch 825, CIFAR-10 Batch 1:  Loss:     1.0258 Validation Accuracy: 0.545200\n",
      "Epoch 826, CIFAR-10 Batch 1:  Loss:     1.0252 Validation Accuracy: 0.545000\n",
      "Epoch 827, CIFAR-10 Batch 1:  Loss:     1.0286 Validation Accuracy: 0.543200\n",
      "Epoch 828, CIFAR-10 Batch 1:  Loss:     1.0285 Validation Accuracy: 0.543600\n",
      "Epoch 829, CIFAR-10 Batch 1:  Loss:     1.0233 Validation Accuracy: 0.545200\n",
      "Epoch 830, CIFAR-10 Batch 1:  Loss:     1.0192 Validation Accuracy: 0.546400\n",
      "Epoch 831, CIFAR-10 Batch 1:  Loss:     1.0209 Validation Accuracy: 0.545200\n",
      "Epoch 832, CIFAR-10 Batch 1:  Loss:     1.0242 Validation Accuracy: 0.544600\n",
      "Epoch 833, CIFAR-10 Batch 1:  Loss:     1.0238 Validation Accuracy: 0.545600\n",
      "Epoch 834, CIFAR-10 Batch 1:  Loss:     1.0204 Validation Accuracy: 0.545800\n",
      "Epoch 835, CIFAR-10 Batch 1:  Loss:     1.0185 Validation Accuracy: 0.545600\n",
      "Epoch 836, CIFAR-10 Batch 1:  Loss:     1.0189 Validation Accuracy: 0.545400\n",
      "Epoch 837, CIFAR-10 Batch 1:  Loss:     1.0192 Validation Accuracy: 0.544200\n",
      "Epoch 838, CIFAR-10 Batch 1:  Loss:     1.0176 Validation Accuracy: 0.544400\n",
      "Epoch 839, CIFAR-10 Batch 1:  Loss:     1.0159 Validation Accuracy: 0.546400\n",
      "Epoch 840, CIFAR-10 Batch 1:  Loss:     1.0162 Validation Accuracy: 0.544400\n",
      "Epoch 841, CIFAR-10 Batch 1:  Loss:     1.0171 Validation Accuracy: 0.547600\n",
      "Epoch 842, CIFAR-10 Batch 1:  Loss:     1.0167 Validation Accuracy: 0.545400\n",
      "Epoch 843, CIFAR-10 Batch 1:  Loss:     1.0150 Validation Accuracy: 0.546600\n",
      "Epoch 844, CIFAR-10 Batch 1:  Loss:     1.0136 Validation Accuracy: 0.545600\n",
      "Epoch 845, CIFAR-10 Batch 1:  Loss:     1.0134 Validation Accuracy: 0.545400\n",
      "Epoch 846, CIFAR-10 Batch 1:  Loss:     1.0135 Validation Accuracy: 0.545800\n",
      "Epoch 847, CIFAR-10 Batch 1:  Loss:     1.0131 Validation Accuracy: 0.545200\n",
      "Epoch 848, CIFAR-10 Batch 1:  Loss:     1.0121 Validation Accuracy: 0.546800\n",
      "Epoch 849, CIFAR-10 Batch 1:  Loss:     1.0115 Validation Accuracy: 0.547000\n",
      "Epoch 850, CIFAR-10 Batch 1:  Loss:     1.0114 Validation Accuracy: 0.546200\n",
      "Epoch 851, CIFAR-10 Batch 1:  Loss:     1.0116 Validation Accuracy: 0.546000\n",
      "Epoch 852, CIFAR-10 Batch 1:  Loss:     1.0113 Validation Accuracy: 0.548000\n",
      "Epoch 853, CIFAR-10 Batch 1:  Loss:     1.0107 Validation Accuracy: 0.546000\n",
      "Epoch 854, CIFAR-10 Batch 1:  Loss:     1.0100 Validation Accuracy: 0.547400\n",
      "Epoch 855, CIFAR-10 Batch 1:  Loss:     1.0098 Validation Accuracy: 0.546200\n",
      "Epoch 856, CIFAR-10 Batch 1:  Loss:     1.0098 Validation Accuracy: 0.550600\n",
      "Epoch 857, CIFAR-10 Batch 1:  Loss:     1.0098 Validation Accuracy: 0.545400\n",
      "Epoch 858, CIFAR-10 Batch 1:  Loss:     1.0096 Validation Accuracy: 0.550200\n",
      "Epoch 859, CIFAR-10 Batch 1:  Loss:     1.0095 Validation Accuracy: 0.545800\n",
      "Epoch 860, CIFAR-10 Batch 1:  Loss:     1.0095 Validation Accuracy: 0.549400\n",
      "Epoch 861, CIFAR-10 Batch 1:  Loss:     1.0104 Validation Accuracy: 0.546000\n",
      "Epoch 862, CIFAR-10 Batch 1:  Loss:     1.0112 Validation Accuracy: 0.548200\n",
      "Epoch 863, CIFAR-10 Batch 1:  Loss:     1.0130 Validation Accuracy: 0.544400\n",
      "Epoch 864, CIFAR-10 Batch 1:  Loss:     1.0138 Validation Accuracy: 0.546400\n",
      "Epoch 865, CIFAR-10 Batch 1:  Loss:     1.0159 Validation Accuracy: 0.541000\n",
      "Epoch 866, CIFAR-10 Batch 1:  Loss:     1.0148 Validation Accuracy: 0.545200\n",
      "Epoch 867, CIFAR-10 Batch 1:  Loss:     1.0147 Validation Accuracy: 0.541800\n",
      "Epoch 868, CIFAR-10 Batch 1:  Loss:     1.0107 Validation Accuracy: 0.549600\n",
      "Epoch 869, CIFAR-10 Batch 1:  Loss:     1.0075 Validation Accuracy: 0.546800\n",
      "Epoch 870, CIFAR-10 Batch 1:  Loss:     1.0040 Validation Accuracy: 0.550000\n",
      "Epoch 871, CIFAR-10 Batch 1:  Loss:     1.0022 Validation Accuracy: 0.545800\n",
      "Epoch 872, CIFAR-10 Batch 1:  Loss:     1.0020 Validation Accuracy: 0.547000\n",
      "Epoch 873, CIFAR-10 Batch 1:  Loss:     1.0030 Validation Accuracy: 0.550400\n",
      "Epoch 874, CIFAR-10 Batch 1:  Loss:     1.0045 Validation Accuracy: 0.546000\n",
      "Epoch 875, CIFAR-10 Batch 1:  Loss:     1.0050 Validation Accuracy: 0.550400\n",
      "Epoch 876, CIFAR-10 Batch 1:  Loss:     1.0051 Validation Accuracy: 0.546600\n",
      "Epoch 877, CIFAR-10 Batch 1:  Loss:     1.0034 Validation Accuracy: 0.550000\n",
      "Epoch 878, CIFAR-10 Batch 1:  Loss:     1.0017 Validation Accuracy: 0.547000\n",
      "Epoch 879, CIFAR-10 Batch 1:  Loss:     0.9997 Validation Accuracy: 0.548400\n",
      "Epoch 880, CIFAR-10 Batch 1:  Loss:     0.9985 Validation Accuracy: 0.545800\n",
      "Epoch 881, CIFAR-10 Batch 1:  Loss:     0.9979 Validation Accuracy: 0.546600\n",
      "Epoch 882, CIFAR-10 Batch 1:  Loss:     0.9979 Validation Accuracy: 0.548600\n",
      "Epoch 883, CIFAR-10 Batch 1:  Loss:     0.9982 Validation Accuracy: 0.548400\n",
      "Epoch 884, CIFAR-10 Batch 1:  Loss:     0.9985 Validation Accuracy: 0.550600\n",
      "Epoch 885, CIFAR-10 Batch 1:  Loss:     0.9988 Validation Accuracy: 0.546200\n",
      "Epoch 886, CIFAR-10 Batch 1:  Loss:     0.9986 Validation Accuracy: 0.551800\n",
      "Epoch 887, CIFAR-10 Batch 1:  Loss:     0.9984 Validation Accuracy: 0.545600\n",
      "Epoch 888, CIFAR-10 Batch 1:  Loss:     0.9976 Validation Accuracy: 0.551600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.3025 Validation Accuracy: 0.104000\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.3023 Validation Accuracy: 0.099800\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     2.3016 Validation Accuracy: 0.099800\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     2.3010 Validation Accuracy: 0.121800\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     2.2991 Validation Accuracy: 0.103000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.2976 Validation Accuracy: 0.103000\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     2.2963 Validation Accuracy: 0.105400\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     2.2918 Validation Accuracy: 0.104200\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     2.2896 Validation Accuracy: 0.105800\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     2.2824 Validation Accuracy: 0.112200\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.2769 Validation Accuracy: 0.122000\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     2.2714 Validation Accuracy: 0.139200\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     2.2603 Validation Accuracy: 0.142200\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     2.2516 Validation Accuracy: 0.138800\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     2.2382 Validation Accuracy: 0.134600\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.2255 Validation Accuracy: 0.139800\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     2.2153 Validation Accuracy: 0.144400\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     2.1967 Validation Accuracy: 0.149800\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     2.1849 Validation Accuracy: 0.152400\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     2.1681 Validation Accuracy: 0.160400\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     2.1526 Validation Accuracy: 0.167800\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     2.1435 Validation Accuracy: 0.175600\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     2.1229 Validation Accuracy: 0.179000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     2.1223 Validation Accuracy: 0.184000\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     2.1189 Validation Accuracy: 0.180000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     2.1043 Validation Accuracy: 0.183000\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     2.1117 Validation Accuracy: 0.180400\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     2.0883 Validation Accuracy: 0.179800\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     2.0906 Validation Accuracy: 0.197600\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     2.0934 Validation Accuracy: 0.213000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     2.0787 Validation Accuracy: 0.213000\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     2.0885 Validation Accuracy: 0.210800\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     2.0659 Validation Accuracy: 0.220800\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     2.0705 Validation Accuracy: 0.228600\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     2.0714 Validation Accuracy: 0.234200\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     2.0645 Validation Accuracy: 0.227600\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     2.0688 Validation Accuracy: 0.236800\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     2.0513 Validation Accuracy: 0.237600\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     2.0486 Validation Accuracy: 0.236400\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     2.0565 Validation Accuracy: 0.227800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     2.0404 Validation Accuracy: 0.232000\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     2.0538 Validation Accuracy: 0.235800\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     2.0285 Validation Accuracy: 0.231800\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     2.0315 Validation Accuracy: 0.235200\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     2.0367 Validation Accuracy: 0.242800\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     2.0216 Validation Accuracy: 0.245400\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     2.0347 Validation Accuracy: 0.249000\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     2.0079 Validation Accuracy: 0.250200\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     2.0103 Validation Accuracy: 0.253000\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     2.0160 Validation Accuracy: 0.254200\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     2.0008 Validation Accuracy: 0.259000\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     2.0134 Validation Accuracy: 0.258000\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     1.9850 Validation Accuracy: 0.256200\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     1.9865 Validation Accuracy: 0.259600\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     1.9925 Validation Accuracy: 0.262800\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.9734 Validation Accuracy: 0.264600\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     1.9913 Validation Accuracy: 0.264600\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     1.9574 Validation Accuracy: 0.269600\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     1.9610 Validation Accuracy: 0.276000\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     1.9665 Validation Accuracy: 0.273800\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.9483 Validation Accuracy: 0.272000\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     1.9666 Validation Accuracy: 0.276400\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     1.9301 Validation Accuracy: 0.282600\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     1.9350 Validation Accuracy: 0.283600\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     1.9377 Validation Accuracy: 0.284200\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.9186 Validation Accuracy: 0.282600\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     1.9387 Validation Accuracy: 0.291400\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     1.9007 Validation Accuracy: 0.294200\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     1.9060 Validation Accuracy: 0.298600\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     1.9060 Validation Accuracy: 0.293000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.8894 Validation Accuracy: 0.295400\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     1.9065 Validation Accuracy: 0.309600\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     1.8684 Validation Accuracy: 0.313000\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     1.8740 Validation Accuracy: 0.315000\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     1.8720 Validation Accuracy: 0.311000\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.8543 Validation Accuracy: 0.310600\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     1.8696 Validation Accuracy: 0.324400\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     1.8349 Validation Accuracy: 0.325600\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     1.8404 Validation Accuracy: 0.332400\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     1.8372 Validation Accuracy: 0.321200\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.8198 Validation Accuracy: 0.325400\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     1.8355 Validation Accuracy: 0.340200\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     1.8017 Validation Accuracy: 0.342600\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     1.8086 Validation Accuracy: 0.344000\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     1.8065 Validation Accuracy: 0.333400\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.7866 Validation Accuracy: 0.343000\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     1.8065 Validation Accuracy: 0.352600\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     1.7701 Validation Accuracy: 0.354400\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     1.7835 Validation Accuracy: 0.349200\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     1.7791 Validation Accuracy: 0.343000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.7584 Validation Accuracy: 0.357800\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     1.7841 Validation Accuracy: 0.358400\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     1.7424 Validation Accuracy: 0.358800\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     1.7655 Validation Accuracy: 0.352200\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     1.7546 Validation Accuracy: 0.351800\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.7387 Validation Accuracy: 0.362600\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     1.7642 Validation Accuracy: 0.363200\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     1.7196 Validation Accuracy: 0.363600\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     1.7502 Validation Accuracy: 0.352600\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     1.7337 Validation Accuracy: 0.357400\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.7230 Validation Accuracy: 0.366200\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     1.7456 Validation Accuracy: 0.368800\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     1.7018 Validation Accuracy: 0.369400\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     1.7360 Validation Accuracy: 0.360000\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     1.7165 Validation Accuracy: 0.366400\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.7089 Validation Accuracy: 0.373600\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     1.7295 Validation Accuracy: 0.376000\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     1.6870 Validation Accuracy: 0.374200\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     1.7215 Validation Accuracy: 0.365400\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     1.7021 Validation Accuracy: 0.370800\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.6957 Validation Accuracy: 0.378600\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     1.7151 Validation Accuracy: 0.379800\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     1.6733 Validation Accuracy: 0.379800\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     1.7075 Validation Accuracy: 0.369800\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     1.6892 Validation Accuracy: 0.375600\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.6823 Validation Accuracy: 0.385800\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     1.7018 Validation Accuracy: 0.383200\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     1.6604 Validation Accuracy: 0.384800\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     1.6948 Validation Accuracy: 0.375000\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     1.6772 Validation Accuracy: 0.380800\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.6695 Validation Accuracy: 0.389800\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     1.6897 Validation Accuracy: 0.388400\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     1.6485 Validation Accuracy: 0.388600\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     1.6826 Validation Accuracy: 0.380600\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     1.6659 Validation Accuracy: 0.385400\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.6574 Validation Accuracy: 0.394200\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     1.6784 Validation Accuracy: 0.390000\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     1.6368 Validation Accuracy: 0.394200\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     1.6702 Validation Accuracy: 0.387200\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     1.6554 Validation Accuracy: 0.386400\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     1.6453 Validation Accuracy: 0.397200\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     1.6673 Validation Accuracy: 0.396200\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     1.6255 Validation Accuracy: 0.394800\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     1.6586 Validation Accuracy: 0.392200\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     1.6454 Validation Accuracy: 0.393000\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.6335 Validation Accuracy: 0.400600\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     1.6567 Validation Accuracy: 0.401400\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     1.6154 Validation Accuracy: 0.398800\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     1.6475 Validation Accuracy: 0.395000\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     1.6359 Validation Accuracy: 0.394800\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     1.6226 Validation Accuracy: 0.401800\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     1.6464 Validation Accuracy: 0.403000\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     1.6058 Validation Accuracy: 0.407200\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     1.6363 Validation Accuracy: 0.397800\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     1.6268 Validation Accuracy: 0.398200\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     1.6121 Validation Accuracy: 0.405200\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     1.6359 Validation Accuracy: 0.408800\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     1.5973 Validation Accuracy: 0.411800\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     1.6260 Validation Accuracy: 0.405400\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     1.6181 Validation Accuracy: 0.404000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     1.6026 Validation Accuracy: 0.410600\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     1.6255 Validation Accuracy: 0.413400\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     1.5897 Validation Accuracy: 0.413000\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     1.6158 Validation Accuracy: 0.411000\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     1.6092 Validation Accuracy: 0.407400\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     1.5943 Validation Accuracy: 0.410200\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     1.6148 Validation Accuracy: 0.414400\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     1.5819 Validation Accuracy: 0.415600\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     1.6067 Validation Accuracy: 0.415600\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     1.5991 Validation Accuracy: 0.410400\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     1.5870 Validation Accuracy: 0.415800\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     1.6047 Validation Accuracy: 0.418600\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     1.5733 Validation Accuracy: 0.416400\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     1.5991 Validation Accuracy: 0.417600\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     1.5882 Validation Accuracy: 0.416600\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     1.5796 Validation Accuracy: 0.415600\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     1.5958 Validation Accuracy: 0.419800\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     1.5633 Validation Accuracy: 0.421000\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     1.5922 Validation Accuracy: 0.421400\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     1.5776 Validation Accuracy: 0.418600\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     1.5712 Validation Accuracy: 0.416200\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     1.5881 Validation Accuracy: 0.421000\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     1.5532 Validation Accuracy: 0.426400\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     1.5852 Validation Accuracy: 0.425400\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     1.5686 Validation Accuracy: 0.422000\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     1.5622 Validation Accuracy: 0.419400\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     1.5811 Validation Accuracy: 0.423200\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     1.5437 Validation Accuracy: 0.431600\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     1.5776 Validation Accuracy: 0.426600\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     1.5609 Validation Accuracy: 0.424400\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     1.5532 Validation Accuracy: 0.426000\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     1.5740 Validation Accuracy: 0.425400\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     1.5356 Validation Accuracy: 0.431000\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     1.5702 Validation Accuracy: 0.430800\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     1.5538 Validation Accuracy: 0.427600\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     1.5452 Validation Accuracy: 0.427200\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     1.5671 Validation Accuracy: 0.425200\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     1.5287 Validation Accuracy: 0.433000\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     1.5630 Validation Accuracy: 0.431600\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     1.5475 Validation Accuracy: 0.431000\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     1.5381 Validation Accuracy: 0.430600\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     1.5605 Validation Accuracy: 0.428000\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     1.5224 Validation Accuracy: 0.435800\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     1.5565 Validation Accuracy: 0.433400\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     1.5416 Validation Accuracy: 0.434000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     1.5315 Validation Accuracy: 0.433600\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     1.5546 Validation Accuracy: 0.430400\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     1.5169 Validation Accuracy: 0.435400\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     1.5508 Validation Accuracy: 0.434600\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     1.5364 Validation Accuracy: 0.435200\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.5257 Validation Accuracy: 0.436800\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     1.5493 Validation Accuracy: 0.434800\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     1.5118 Validation Accuracy: 0.436600\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     1.5455 Validation Accuracy: 0.436000\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     1.5315 Validation Accuracy: 0.436200\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.5205 Validation Accuracy: 0.435600\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     1.5444 Validation Accuracy: 0.438000\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     1.5071 Validation Accuracy: 0.439000\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     1.5406 Validation Accuracy: 0.438800\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     1.5269 Validation Accuracy: 0.438200\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.5156 Validation Accuracy: 0.438200\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     1.5398 Validation Accuracy: 0.440800\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     1.5027 Validation Accuracy: 0.441000\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     1.5363 Validation Accuracy: 0.440800\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     1.5224 Validation Accuracy: 0.440400\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.5111 Validation Accuracy: 0.436600\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     1.5356 Validation Accuracy: 0.442400\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     1.4985 Validation Accuracy: 0.441200\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     1.5321 Validation Accuracy: 0.443200\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     1.5181 Validation Accuracy: 0.442000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.5070 Validation Accuracy: 0.437800\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     1.5316 Validation Accuracy: 0.442400\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     1.4944 Validation Accuracy: 0.443000\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     1.5283 Validation Accuracy: 0.443800\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     1.5140 Validation Accuracy: 0.445200\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.5030 Validation Accuracy: 0.440200\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     1.5276 Validation Accuracy: 0.444200\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     1.4902 Validation Accuracy: 0.444200\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     1.5245 Validation Accuracy: 0.446600\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     1.5099 Validation Accuracy: 0.445400\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.4989 Validation Accuracy: 0.442400\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     1.5239 Validation Accuracy: 0.446000\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     1.4860 Validation Accuracy: 0.446600\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     1.5210 Validation Accuracy: 0.446600\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     1.5060 Validation Accuracy: 0.448200\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.4949 Validation Accuracy: 0.444400\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     1.5206 Validation Accuracy: 0.445800\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     1.4819 Validation Accuracy: 0.448200\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     1.5174 Validation Accuracy: 0.446800\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     1.5025 Validation Accuracy: 0.449600\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.4909 Validation Accuracy: 0.444400\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     1.5174 Validation Accuracy: 0.447800\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     1.4779 Validation Accuracy: 0.447200\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     1.5139 Validation Accuracy: 0.446200\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     1.4993 Validation Accuracy: 0.450400\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.4868 Validation Accuracy: 0.446200\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     1.5143 Validation Accuracy: 0.449000\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     1.4741 Validation Accuracy: 0.449800\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     1.5104 Validation Accuracy: 0.451000\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     1.4962 Validation Accuracy: 0.450200\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.4827 Validation Accuracy: 0.448400\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     1.5112 Validation Accuracy: 0.449200\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     1.4705 Validation Accuracy: 0.449800\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     1.5067 Validation Accuracy: 0.452200\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     1.4934 Validation Accuracy: 0.452000\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.4788 Validation Accuracy: 0.451000\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     1.5081 Validation Accuracy: 0.451200\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     1.4672 Validation Accuracy: 0.452800\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     1.5030 Validation Accuracy: 0.451800\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     1.4909 Validation Accuracy: 0.452200\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.4751 Validation Accuracy: 0.452400\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     1.5049 Validation Accuracy: 0.452400\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     1.4642 Validation Accuracy: 0.452600\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     1.4994 Validation Accuracy: 0.452600\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     1.4883 Validation Accuracy: 0.454200\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.4716 Validation Accuracy: 0.454000\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     1.5016 Validation Accuracy: 0.454400\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     1.4615 Validation Accuracy: 0.453400\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     1.4957 Validation Accuracy: 0.454000\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     1.4858 Validation Accuracy: 0.454600\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.4683 Validation Accuracy: 0.454800\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     1.4981 Validation Accuracy: 0.456400\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     1.4590 Validation Accuracy: 0.455200\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     1.4920 Validation Accuracy: 0.455400\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     1.4832 Validation Accuracy: 0.454800\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.4652 Validation Accuracy: 0.455600\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     1.4945 Validation Accuracy: 0.457800\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     1.4567 Validation Accuracy: 0.456000\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     1.4883 Validation Accuracy: 0.458000\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     1.4803 Validation Accuracy: 0.456600\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.4624 Validation Accuracy: 0.455200\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     1.4906 Validation Accuracy: 0.459400\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     1.4545 Validation Accuracy: 0.456800\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     1.4848 Validation Accuracy: 0.459200\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     1.4772 Validation Accuracy: 0.457800\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.4599 Validation Accuracy: 0.456400\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     1.4865 Validation Accuracy: 0.459600\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     1.4523 Validation Accuracy: 0.458000\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     1.4815 Validation Accuracy: 0.460200\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     1.4737 Validation Accuracy: 0.461800\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.4575 Validation Accuracy: 0.458600\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     1.4825 Validation Accuracy: 0.460000\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     1.4497 Validation Accuracy: 0.459000\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     1.4785 Validation Accuracy: 0.461200\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     1.4698 Validation Accuracy: 0.463200\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.4552 Validation Accuracy: 0.461800\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     1.4787 Validation Accuracy: 0.462000\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     1.4468 Validation Accuracy: 0.461200\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     1.4757 Validation Accuracy: 0.462800\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     1.4660 Validation Accuracy: 0.466000\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.4526 Validation Accuracy: 0.464200\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     1.4752 Validation Accuracy: 0.464000\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     1.4435 Validation Accuracy: 0.463400\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     1.4729 Validation Accuracy: 0.463000\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     1.4621 Validation Accuracy: 0.466000\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.4497 Validation Accuracy: 0.465400\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     1.4719 Validation Accuracy: 0.463200\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     1.4400 Validation Accuracy: 0.464000\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     1.4700 Validation Accuracy: 0.463000\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     1.4584 Validation Accuracy: 0.465600\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.4466 Validation Accuracy: 0.466600\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     1.4687 Validation Accuracy: 0.464400\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     1.4363 Validation Accuracy: 0.464600\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     1.4671 Validation Accuracy: 0.464000\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     1.4549 Validation Accuracy: 0.466400\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.4432 Validation Accuracy: 0.468400\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     1.4656 Validation Accuracy: 0.467000\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     1.4329 Validation Accuracy: 0.466000\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     1.4639 Validation Accuracy: 0.462800\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     1.4518 Validation Accuracy: 0.466000\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.4398 Validation Accuracy: 0.469800\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:     1.4625 Validation Accuracy: 0.468400\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:     1.4296 Validation Accuracy: 0.467600\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:     1.4607 Validation Accuracy: 0.464000\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:     1.4488 Validation Accuracy: 0.467800\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.4365 Validation Accuracy: 0.471000\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:     1.4594 Validation Accuracy: 0.468400\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:     1.4265 Validation Accuracy: 0.468800\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:     1.4574 Validation Accuracy: 0.466600\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:     1.4461 Validation Accuracy: 0.468200\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.4333 Validation Accuracy: 0.471800\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:     1.4564 Validation Accuracy: 0.469200\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:     1.4235 Validation Accuracy: 0.470200\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:     1.4542 Validation Accuracy: 0.468600\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:     1.4435 Validation Accuracy: 0.471200\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.4301 Validation Accuracy: 0.474000\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:     1.4535 Validation Accuracy: 0.471200\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:     1.4206 Validation Accuracy: 0.470600\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:     1.4511 Validation Accuracy: 0.470400\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:     1.4409 Validation Accuracy: 0.472200\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.4270 Validation Accuracy: 0.477000\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:     1.4506 Validation Accuracy: 0.471200\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:     1.4178 Validation Accuracy: 0.472200\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:     1.4481 Validation Accuracy: 0.471600\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:     1.4384 Validation Accuracy: 0.474000\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.4239 Validation Accuracy: 0.477200\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:     1.4478 Validation Accuracy: 0.474800\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:     1.4151 Validation Accuracy: 0.472800\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:     1.4450 Validation Accuracy: 0.472800\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:     1.4359 Validation Accuracy: 0.476000\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.4209 Validation Accuracy: 0.478000\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:     1.4450 Validation Accuracy: 0.476600\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:     1.4122 Validation Accuracy: 0.474600\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:     1.4421 Validation Accuracy: 0.473800\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:     1.4332 Validation Accuracy: 0.475600\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.4179 Validation Accuracy: 0.478600\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:     1.4421 Validation Accuracy: 0.478000\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:     1.4093 Validation Accuracy: 0.476600\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:     1.4391 Validation Accuracy: 0.474600\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:     1.4304 Validation Accuracy: 0.477200\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.4150 Validation Accuracy: 0.478800\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:     1.4392 Validation Accuracy: 0.478800\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:     1.4066 Validation Accuracy: 0.477400\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:     1.4363 Validation Accuracy: 0.475800\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:     1.4276 Validation Accuracy: 0.478200\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     1.4122 Validation Accuracy: 0.480600\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:     1.4363 Validation Accuracy: 0.479200\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:     1.4037 Validation Accuracy: 0.477800\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:     1.4334 Validation Accuracy: 0.477400\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:     1.4246 Validation Accuracy: 0.479000\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     1.4093 Validation Accuracy: 0.482000\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:     1.4332 Validation Accuracy: 0.478600\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:     1.4007 Validation Accuracy: 0.479000\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:     1.4305 Validation Accuracy: 0.478000\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:     1.4214 Validation Accuracy: 0.480000\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     1.4066 Validation Accuracy: 0.483400\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:     1.4301 Validation Accuracy: 0.479000\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:     1.3977 Validation Accuracy: 0.480400\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:     1.4276 Validation Accuracy: 0.478800\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:     1.4181 Validation Accuracy: 0.481800\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     1.4038 Validation Accuracy: 0.484000\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:     1.4269 Validation Accuracy: 0.480000\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:     1.3945 Validation Accuracy: 0.480400\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:     1.4248 Validation Accuracy: 0.480000\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:     1.4148 Validation Accuracy: 0.481600\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     1.4009 Validation Accuracy: 0.484800\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:     1.4238 Validation Accuracy: 0.481400\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:     1.3913 Validation Accuracy: 0.482400\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:     1.4219 Validation Accuracy: 0.480600\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:     1.4112 Validation Accuracy: 0.484200\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     1.3980 Validation Accuracy: 0.486200\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:     1.4206 Validation Accuracy: 0.482600\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:     1.3880 Validation Accuracy: 0.483600\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:     1.4190 Validation Accuracy: 0.481000\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:     1.4077 Validation Accuracy: 0.484400\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     1.3951 Validation Accuracy: 0.487400\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:     1.4174 Validation Accuracy: 0.483600\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:     1.3846 Validation Accuracy: 0.484600\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:     1.4161 Validation Accuracy: 0.481400\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:     1.4042 Validation Accuracy: 0.485800\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     1.3921 Validation Accuracy: 0.488600\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:     1.4142 Validation Accuracy: 0.482800\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:     1.3812 Validation Accuracy: 0.485800\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:     1.4132 Validation Accuracy: 0.483400\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:     1.4007 Validation Accuracy: 0.487800\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     1.3891 Validation Accuracy: 0.489000\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:     1.4109 Validation Accuracy: 0.484000\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:     1.3779 Validation Accuracy: 0.487200\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:     1.4102 Validation Accuracy: 0.483600\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:     1.3972 Validation Accuracy: 0.487200\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     1.3860 Validation Accuracy: 0.490200\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:     1.4076 Validation Accuracy: 0.486400\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:     1.3745 Validation Accuracy: 0.489000\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:     1.4071 Validation Accuracy: 0.483800\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:     1.3937 Validation Accuracy: 0.489200\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     1.3828 Validation Accuracy: 0.490200\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:     1.4043 Validation Accuracy: 0.487400\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:     1.3713 Validation Accuracy: 0.489400\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:     1.4038 Validation Accuracy: 0.485800\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:     1.3903 Validation Accuracy: 0.490800\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     1.3796 Validation Accuracy: 0.489600\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:     1.4010 Validation Accuracy: 0.486600\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:     1.3680 Validation Accuracy: 0.488800\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:     1.4005 Validation Accuracy: 0.486600\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:     1.3870 Validation Accuracy: 0.490600\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     1.3762 Validation Accuracy: 0.491600\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:     1.3977 Validation Accuracy: 0.489200\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:     1.3647 Validation Accuracy: 0.489000\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:     1.3971 Validation Accuracy: 0.487600\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:     1.3837 Validation Accuracy: 0.491000\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     1.3728 Validation Accuracy: 0.494000\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:     1.3943 Validation Accuracy: 0.490400\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:     1.3614 Validation Accuracy: 0.491200\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:     1.3936 Validation Accuracy: 0.489200\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:     1.3806 Validation Accuracy: 0.492400\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     1.3692 Validation Accuracy: 0.494200\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:     1.3911 Validation Accuracy: 0.493400\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:     1.3581 Validation Accuracy: 0.494200\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:     1.3901 Validation Accuracy: 0.489800\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:     1.3775 Validation Accuracy: 0.493600\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     1.3657 Validation Accuracy: 0.494600\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:     1.3879 Validation Accuracy: 0.494000\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:     1.3549 Validation Accuracy: 0.495800\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:     1.3866 Validation Accuracy: 0.492200\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:     1.3744 Validation Accuracy: 0.494600\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     1.3622 Validation Accuracy: 0.494400\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:     1.3848 Validation Accuracy: 0.496400\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:     1.3517 Validation Accuracy: 0.495800\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:     1.3833 Validation Accuracy: 0.493200\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:     1.3715 Validation Accuracy: 0.494400\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     1.3588 Validation Accuracy: 0.495600\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:     1.3818 Validation Accuracy: 0.496400\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:     1.3486 Validation Accuracy: 0.496600\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:     1.3800 Validation Accuracy: 0.493000\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:     1.3686 Validation Accuracy: 0.495000\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     1.3554 Validation Accuracy: 0.496400\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:     1.3789 Validation Accuracy: 0.496600\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:     1.3455 Validation Accuracy: 0.496400\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:     1.3768 Validation Accuracy: 0.493600\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:     1.3658 Validation Accuracy: 0.494600\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     1.3521 Validation Accuracy: 0.497400\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:     1.3761 Validation Accuracy: 0.497200\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:     1.3426 Validation Accuracy: 0.496800\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:     1.3738 Validation Accuracy: 0.494600\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:     1.3630 Validation Accuracy: 0.493800\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     1.3489 Validation Accuracy: 0.498400\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:     1.3734 Validation Accuracy: 0.499400\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:     1.3396 Validation Accuracy: 0.496600\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:     1.3707 Validation Accuracy: 0.494800\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:     1.3602 Validation Accuracy: 0.495200\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     1.3459 Validation Accuracy: 0.498600\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:     1.3706 Validation Accuracy: 0.500000\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:     1.3364 Validation Accuracy: 0.498000\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:     1.3676 Validation Accuracy: 0.497200\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:     1.3573 Validation Accuracy: 0.497000\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     1.3427 Validation Accuracy: 0.499400\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:     1.3676 Validation Accuracy: 0.501400\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:     1.3333 Validation Accuracy: 0.499400\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:     1.3646 Validation Accuracy: 0.498200\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:     1.3546 Validation Accuracy: 0.498200\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     1.3396 Validation Accuracy: 0.498000\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:     1.3647 Validation Accuracy: 0.501000\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:     1.3303 Validation Accuracy: 0.499800\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:     1.3616 Validation Accuracy: 0.499000\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:     1.3518 Validation Accuracy: 0.499000\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     1.3365 Validation Accuracy: 0.499400\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:     1.3618 Validation Accuracy: 0.503200\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:     1.3274 Validation Accuracy: 0.501600\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:     1.3586 Validation Accuracy: 0.499200\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:     1.3489 Validation Accuracy: 0.500200\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     1.3334 Validation Accuracy: 0.499400\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:     1.3589 Validation Accuracy: 0.503600\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:     1.3245 Validation Accuracy: 0.503000\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:     1.3557 Validation Accuracy: 0.500200\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:     1.3461 Validation Accuracy: 0.500800\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     1.3304 Validation Accuracy: 0.499400\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:     1.3560 Validation Accuracy: 0.503800\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:     1.3216 Validation Accuracy: 0.505400\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:     1.3526 Validation Accuracy: 0.501200\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:     1.3432 Validation Accuracy: 0.501600\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:     1.3275 Validation Accuracy: 0.501400\n",
      "Epoch 101, CIFAR-10 Batch 2:  Loss:     1.3530 Validation Accuracy: 0.504000\n",
      "Epoch 101, CIFAR-10 Batch 3:  Loss:     1.3187 Validation Accuracy: 0.507200\n",
      "Epoch 101, CIFAR-10 Batch 4:  Loss:     1.3497 Validation Accuracy: 0.500200\n",
      "Epoch 101, CIFAR-10 Batch 5:  Loss:     1.3403 Validation Accuracy: 0.502000\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:     1.3245 Validation Accuracy: 0.502800\n",
      "Epoch 102, CIFAR-10 Batch 2:  Loss:     1.3499 Validation Accuracy: 0.504200\n",
      "Epoch 102, CIFAR-10 Batch 3:  Loss:     1.3159 Validation Accuracy: 0.508800\n",
      "Epoch 102, CIFAR-10 Batch 4:  Loss:     1.3466 Validation Accuracy: 0.501400\n",
      "Epoch 102, CIFAR-10 Batch 5:  Loss:     1.3374 Validation Accuracy: 0.501600\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:     1.3216 Validation Accuracy: 0.504800\n",
      "Epoch 103, CIFAR-10 Batch 2:  Loss:     1.3468 Validation Accuracy: 0.505200\n",
      "Epoch 103, CIFAR-10 Batch 3:  Loss:     1.3131 Validation Accuracy: 0.511200\n",
      "Epoch 103, CIFAR-10 Batch 4:  Loss:     1.3437 Validation Accuracy: 0.503600\n",
      "Epoch 103, CIFAR-10 Batch 5:  Loss:     1.3345 Validation Accuracy: 0.502000\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:     1.3188 Validation Accuracy: 0.504800\n",
      "Epoch 104, CIFAR-10 Batch 2:  Loss:     1.3438 Validation Accuracy: 0.506800\n",
      "Epoch 104, CIFAR-10 Batch 3:  Loss:     1.3103 Validation Accuracy: 0.511200\n",
      "Epoch 104, CIFAR-10 Batch 4:  Loss:     1.3407 Validation Accuracy: 0.505400\n",
      "Epoch 104, CIFAR-10 Batch 5:  Loss:     1.3316 Validation Accuracy: 0.502600\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:     1.3160 Validation Accuracy: 0.504800\n",
      "Epoch 105, CIFAR-10 Batch 2:  Loss:     1.3408 Validation Accuracy: 0.508800\n",
      "Epoch 105, CIFAR-10 Batch 3:  Loss:     1.3076 Validation Accuracy: 0.512200\n",
      "Epoch 105, CIFAR-10 Batch 4:  Loss:     1.3378 Validation Accuracy: 0.505600\n",
      "Epoch 105, CIFAR-10 Batch 5:  Loss:     1.3288 Validation Accuracy: 0.503400\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:     1.3132 Validation Accuracy: 0.506200\n",
      "Epoch 106, CIFAR-10 Batch 2:  Loss:     1.3378 Validation Accuracy: 0.509200\n",
      "Epoch 106, CIFAR-10 Batch 3:  Loss:     1.3048 Validation Accuracy: 0.512400\n",
      "Epoch 106, CIFAR-10 Batch 4:  Loss:     1.3349 Validation Accuracy: 0.506800\n",
      "Epoch 106, CIFAR-10 Batch 5:  Loss:     1.3260 Validation Accuracy: 0.503800\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:     1.3104 Validation Accuracy: 0.506200\n",
      "Epoch 107, CIFAR-10 Batch 2:  Loss:     1.3349 Validation Accuracy: 0.509400\n",
      "Epoch 107, CIFAR-10 Batch 3:  Loss:     1.3022 Validation Accuracy: 0.512600\n",
      "Epoch 107, CIFAR-10 Batch 4:  Loss:     1.3320 Validation Accuracy: 0.507000\n",
      "Epoch 107, CIFAR-10 Batch 5:  Loss:     1.3231 Validation Accuracy: 0.505400\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:     1.3077 Validation Accuracy: 0.507400\n",
      "Epoch 108, CIFAR-10 Batch 2:  Loss:     1.3319 Validation Accuracy: 0.510400\n",
      "Epoch 108, CIFAR-10 Batch 3:  Loss:     1.2995 Validation Accuracy: 0.512400\n",
      "Epoch 108, CIFAR-10 Batch 4:  Loss:     1.3291 Validation Accuracy: 0.508400\n",
      "Epoch 108, CIFAR-10 Batch 5:  Loss:     1.3203 Validation Accuracy: 0.506600\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss:     1.3051 Validation Accuracy: 0.507200\n",
      "Epoch 109, CIFAR-10 Batch 2:  Loss:     1.3290 Validation Accuracy: 0.511600\n",
      "Epoch 109, CIFAR-10 Batch 3:  Loss:     1.2969 Validation Accuracy: 0.513800\n",
      "Epoch 109, CIFAR-10 Batch 4:  Loss:     1.3263 Validation Accuracy: 0.509000\n",
      "Epoch 109, CIFAR-10 Batch 5:  Loss:     1.3174 Validation Accuracy: 0.507400\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:     1.3024 Validation Accuracy: 0.507200\n",
      "Epoch 110, CIFAR-10 Batch 2:  Loss:     1.3262 Validation Accuracy: 0.513800\n",
      "Epoch 110, CIFAR-10 Batch 3:  Loss:     1.2942 Validation Accuracy: 0.515600\n",
      "Epoch 110, CIFAR-10 Batch 4:  Loss:     1.3236 Validation Accuracy: 0.511000\n",
      "Epoch 110, CIFAR-10 Batch 5:  Loss:     1.3146 Validation Accuracy: 0.508600\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:     1.2997 Validation Accuracy: 0.507400\n",
      "Epoch 111, CIFAR-10 Batch 2:  Loss:     1.3234 Validation Accuracy: 0.515200\n",
      "Epoch 111, CIFAR-10 Batch 3:  Loss:     1.2916 Validation Accuracy: 0.514800\n",
      "Epoch 111, CIFAR-10 Batch 4:  Loss:     1.3208 Validation Accuracy: 0.513200\n",
      "Epoch 111, CIFAR-10 Batch 5:  Loss:     1.3117 Validation Accuracy: 0.509200\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:     1.2971 Validation Accuracy: 0.508800\n",
      "Epoch 112, CIFAR-10 Batch 2:  Loss:     1.3207 Validation Accuracy: 0.516200\n",
      "Epoch 112, CIFAR-10 Batch 3:  Loss:     1.2889 Validation Accuracy: 0.516800\n",
      "Epoch 112, CIFAR-10 Batch 4:  Loss:     1.3181 Validation Accuracy: 0.513000\n",
      "Epoch 112, CIFAR-10 Batch 5:  Loss:     1.3089 Validation Accuracy: 0.509600\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:     1.2945 Validation Accuracy: 0.510400\n",
      "Epoch 113, CIFAR-10 Batch 2:  Loss:     1.3180 Validation Accuracy: 0.517000\n",
      "Epoch 113, CIFAR-10 Batch 3:  Loss:     1.2862 Validation Accuracy: 0.517000\n",
      "Epoch 113, CIFAR-10 Batch 4:  Loss:     1.3154 Validation Accuracy: 0.512200\n",
      "Epoch 113, CIFAR-10 Batch 5:  Loss:     1.3062 Validation Accuracy: 0.510000\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:     1.2919 Validation Accuracy: 0.511200\n",
      "Epoch 114, CIFAR-10 Batch 2:  Loss:     1.3154 Validation Accuracy: 0.518200\n",
      "Epoch 114, CIFAR-10 Batch 3:  Loss:     1.2836 Validation Accuracy: 0.517800\n",
      "Epoch 114, CIFAR-10 Batch 4:  Loss:     1.3128 Validation Accuracy: 0.513600\n",
      "Epoch 114, CIFAR-10 Batch 5:  Loss:     1.3035 Validation Accuracy: 0.510800\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:     1.2894 Validation Accuracy: 0.512200\n",
      "Epoch 115, CIFAR-10 Batch 2:  Loss:     1.3127 Validation Accuracy: 0.519600\n",
      "Epoch 115, CIFAR-10 Batch 3:  Loss:     1.2810 Validation Accuracy: 0.518200\n",
      "Epoch 115, CIFAR-10 Batch 4:  Loss:     1.3102 Validation Accuracy: 0.514800\n",
      "Epoch 115, CIFAR-10 Batch 5:  Loss:     1.3009 Validation Accuracy: 0.510800\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:     1.2868 Validation Accuracy: 0.513200\n",
      "Epoch 116, CIFAR-10 Batch 2:  Loss:     1.3102 Validation Accuracy: 0.520800\n",
      "Epoch 116, CIFAR-10 Batch 3:  Loss:     1.2784 Validation Accuracy: 0.519400\n",
      "Epoch 116, CIFAR-10 Batch 4:  Loss:     1.3076 Validation Accuracy: 0.515600\n",
      "Epoch 116, CIFAR-10 Batch 5:  Loss:     1.2983 Validation Accuracy: 0.512800\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:     1.2843 Validation Accuracy: 0.514400\n",
      "Epoch 117, CIFAR-10 Batch 2:  Loss:     1.3077 Validation Accuracy: 0.521600\n",
      "Epoch 117, CIFAR-10 Batch 3:  Loss:     1.2759 Validation Accuracy: 0.519400\n",
      "Epoch 117, CIFAR-10 Batch 4:  Loss:     1.3050 Validation Accuracy: 0.516600\n",
      "Epoch 117, CIFAR-10 Batch 5:  Loss:     1.2958 Validation Accuracy: 0.514600\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:     1.2818 Validation Accuracy: 0.514000\n",
      "Epoch 118, CIFAR-10 Batch 2:  Loss:     1.3052 Validation Accuracy: 0.523000\n",
      "Epoch 118, CIFAR-10 Batch 3:  Loss:     1.2734 Validation Accuracy: 0.520800\n",
      "Epoch 118, CIFAR-10 Batch 4:  Loss:     1.3025 Validation Accuracy: 0.518000\n",
      "Epoch 118, CIFAR-10 Batch 5:  Loss:     1.2934 Validation Accuracy: 0.515400\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:     1.2793 Validation Accuracy: 0.513800\n",
      "Epoch 119, CIFAR-10 Batch 2:  Loss:     1.3028 Validation Accuracy: 0.523400\n",
      "Epoch 119, CIFAR-10 Batch 3:  Loss:     1.2709 Validation Accuracy: 0.521800\n",
      "Epoch 119, CIFAR-10 Batch 4:  Loss:     1.3000 Validation Accuracy: 0.519000\n",
      "Epoch 119, CIFAR-10 Batch 5:  Loss:     1.2909 Validation Accuracy: 0.516800\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:     1.2768 Validation Accuracy: 0.514200\n",
      "Epoch 120, CIFAR-10 Batch 2:  Loss:     1.3003 Validation Accuracy: 0.523400\n",
      "Epoch 120, CIFAR-10 Batch 3:  Loss:     1.2685 Validation Accuracy: 0.522200\n",
      "Epoch 120, CIFAR-10 Batch 4:  Loss:     1.2975 Validation Accuracy: 0.519400\n",
      "Epoch 120, CIFAR-10 Batch 5:  Loss:     1.2885 Validation Accuracy: 0.519600\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:     1.2744 Validation Accuracy: 0.515600\n",
      "Epoch 121, CIFAR-10 Batch 2:  Loss:     1.2979 Validation Accuracy: 0.523000\n",
      "Epoch 121, CIFAR-10 Batch 3:  Loss:     1.2661 Validation Accuracy: 0.524000\n",
      "Epoch 121, CIFAR-10 Batch 4:  Loss:     1.2950 Validation Accuracy: 0.520400\n",
      "Epoch 121, CIFAR-10 Batch 5:  Loss:     1.2860 Validation Accuracy: 0.521000\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:     1.2720 Validation Accuracy: 0.515800\n",
      "Epoch 122, CIFAR-10 Batch 2:  Loss:     1.2955 Validation Accuracy: 0.523600\n",
      "Epoch 122, CIFAR-10 Batch 3:  Loss:     1.2637 Validation Accuracy: 0.523800\n",
      "Epoch 122, CIFAR-10 Batch 4:  Loss:     1.2926 Validation Accuracy: 0.521200\n",
      "Epoch 122, CIFAR-10 Batch 5:  Loss:     1.2836 Validation Accuracy: 0.521200\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:     1.2696 Validation Accuracy: 0.516400\n",
      "Epoch 123, CIFAR-10 Batch 2:  Loss:     1.2931 Validation Accuracy: 0.524000\n",
      "Epoch 123, CIFAR-10 Batch 3:  Loss:     1.2614 Validation Accuracy: 0.524600\n",
      "Epoch 123, CIFAR-10 Batch 4:  Loss:     1.2902 Validation Accuracy: 0.523200\n",
      "Epoch 123, CIFAR-10 Batch 5:  Loss:     1.2812 Validation Accuracy: 0.522800\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:     1.2673 Validation Accuracy: 0.517000\n",
      "Epoch 124, CIFAR-10 Batch 2:  Loss:     1.2907 Validation Accuracy: 0.524400\n",
      "Epoch 124, CIFAR-10 Batch 3:  Loss:     1.2591 Validation Accuracy: 0.525000\n",
      "Epoch 124, CIFAR-10 Batch 4:  Loss:     1.2878 Validation Accuracy: 0.524200\n",
      "Epoch 124, CIFAR-10 Batch 5:  Loss:     1.2788 Validation Accuracy: 0.523800\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:     1.2650 Validation Accuracy: 0.517800\n",
      "Epoch 125, CIFAR-10 Batch 2:  Loss:     1.2883 Validation Accuracy: 0.526200\n",
      "Epoch 125, CIFAR-10 Batch 3:  Loss:     1.2567 Validation Accuracy: 0.526000\n",
      "Epoch 125, CIFAR-10 Batch 4:  Loss:     1.2854 Validation Accuracy: 0.525200\n",
      "Epoch 125, CIFAR-10 Batch 5:  Loss:     1.2764 Validation Accuracy: 0.525200\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:     1.2627 Validation Accuracy: 0.519600\n",
      "Epoch 126, CIFAR-10 Batch 2:  Loss:     1.2859 Validation Accuracy: 0.527200\n",
      "Epoch 126, CIFAR-10 Batch 3:  Loss:     1.2544 Validation Accuracy: 0.526000\n",
      "Epoch 126, CIFAR-10 Batch 4:  Loss:     1.2830 Validation Accuracy: 0.526200\n",
      "Epoch 126, CIFAR-10 Batch 5:  Loss:     1.2741 Validation Accuracy: 0.526000\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:     1.2604 Validation Accuracy: 0.520400\n",
      "Epoch 127, CIFAR-10 Batch 2:  Loss:     1.2836 Validation Accuracy: 0.529000\n",
      "Epoch 127, CIFAR-10 Batch 3:  Loss:     1.2520 Validation Accuracy: 0.525600\n",
      "Epoch 127, CIFAR-10 Batch 4:  Loss:     1.2807 Validation Accuracy: 0.527200\n",
      "Epoch 127, CIFAR-10 Batch 5:  Loss:     1.2718 Validation Accuracy: 0.527200\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:     1.2581 Validation Accuracy: 0.520800\n",
      "Epoch 128, CIFAR-10 Batch 2:  Loss:     1.2813 Validation Accuracy: 0.530000\n",
      "Epoch 128, CIFAR-10 Batch 3:  Loss:     1.2498 Validation Accuracy: 0.526400\n",
      "Epoch 128, CIFAR-10 Batch 4:  Loss:     1.2784 Validation Accuracy: 0.526400\n",
      "Epoch 128, CIFAR-10 Batch 5:  Loss:     1.2696 Validation Accuracy: 0.528200\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:     1.2559 Validation Accuracy: 0.521600\n",
      "Epoch 129, CIFAR-10 Batch 2:  Loss:     1.2790 Validation Accuracy: 0.530400\n",
      "Epoch 129, CIFAR-10 Batch 3:  Loss:     1.2477 Validation Accuracy: 0.527800\n",
      "Epoch 129, CIFAR-10 Batch 4:  Loss:     1.2762 Validation Accuracy: 0.527000\n",
      "Epoch 129, CIFAR-10 Batch 5:  Loss:     1.2674 Validation Accuracy: 0.528800\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:     1.2538 Validation Accuracy: 0.522000\n",
      "Epoch 130, CIFAR-10 Batch 2:  Loss:     1.2768 Validation Accuracy: 0.530800\n",
      "Epoch 130, CIFAR-10 Batch 3:  Loss:     1.2456 Validation Accuracy: 0.529600\n",
      "Epoch 130, CIFAR-10 Batch 4:  Loss:     1.2739 Validation Accuracy: 0.527200\n",
      "Epoch 130, CIFAR-10 Batch 5:  Loss:     1.2652 Validation Accuracy: 0.529000\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:     1.2516 Validation Accuracy: 0.523800\n",
      "Epoch 131, CIFAR-10 Batch 2:  Loss:     1.2747 Validation Accuracy: 0.531000\n",
      "Epoch 131, CIFAR-10 Batch 3:  Loss:     1.2435 Validation Accuracy: 0.530000\n",
      "Epoch 131, CIFAR-10 Batch 4:  Loss:     1.2717 Validation Accuracy: 0.528600\n",
      "Epoch 131, CIFAR-10 Batch 5:  Loss:     1.2631 Validation Accuracy: 0.529400\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:     1.2495 Validation Accuracy: 0.525000\n",
      "Epoch 132, CIFAR-10 Batch 2:  Loss:     1.2726 Validation Accuracy: 0.531000\n",
      "Epoch 132, CIFAR-10 Batch 3:  Loss:     1.2414 Validation Accuracy: 0.531200\n",
      "Epoch 132, CIFAR-10 Batch 4:  Loss:     1.2695 Validation Accuracy: 0.530400\n",
      "Epoch 132, CIFAR-10 Batch 5:  Loss:     1.2610 Validation Accuracy: 0.529600\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:     1.2474 Validation Accuracy: 0.526600\n",
      "Epoch 133, CIFAR-10 Batch 2:  Loss:     1.2705 Validation Accuracy: 0.532000\n",
      "Epoch 133, CIFAR-10 Batch 3:  Loss:     1.2392 Validation Accuracy: 0.532000\n",
      "Epoch 133, CIFAR-10 Batch 4:  Loss:     1.2674 Validation Accuracy: 0.530600\n",
      "Epoch 133, CIFAR-10 Batch 5:  Loss:     1.2589 Validation Accuracy: 0.529600\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:     1.2453 Validation Accuracy: 0.528600\n",
      "Epoch 134, CIFAR-10 Batch 2:  Loss:     1.2684 Validation Accuracy: 0.531800\n",
      "Epoch 134, CIFAR-10 Batch 3:  Loss:     1.2370 Validation Accuracy: 0.533200\n",
      "Epoch 134, CIFAR-10 Batch 4:  Loss:     1.2652 Validation Accuracy: 0.530600\n",
      "Epoch 134, CIFAR-10 Batch 5:  Loss:     1.2569 Validation Accuracy: 0.530800\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:     1.2432 Validation Accuracy: 0.528400\n",
      "Epoch 135, CIFAR-10 Batch 2:  Loss:     1.2661 Validation Accuracy: 0.532600\n",
      "Epoch 135, CIFAR-10 Batch 3:  Loss:     1.2349 Validation Accuracy: 0.533200\n",
      "Epoch 135, CIFAR-10 Batch 4:  Loss:     1.2631 Validation Accuracy: 0.531200\n",
      "Epoch 135, CIFAR-10 Batch 5:  Loss:     1.2548 Validation Accuracy: 0.531800\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:     1.2411 Validation Accuracy: 0.528400\n",
      "Epoch 136, CIFAR-10 Batch 2:  Loss:     1.2640 Validation Accuracy: 0.533200\n",
      "Epoch 136, CIFAR-10 Batch 3:  Loss:     1.2329 Validation Accuracy: 0.534000\n",
      "Epoch 136, CIFAR-10 Batch 4:  Loss:     1.2610 Validation Accuracy: 0.532200\n",
      "Epoch 136, CIFAR-10 Batch 5:  Loss:     1.2528 Validation Accuracy: 0.532200\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:     1.2390 Validation Accuracy: 0.529000\n",
      "Epoch 137, CIFAR-10 Batch 2:  Loss:     1.2620 Validation Accuracy: 0.533600\n",
      "Epoch 137, CIFAR-10 Batch 3:  Loss:     1.2310 Validation Accuracy: 0.535000\n",
      "Epoch 137, CIFAR-10 Batch 4:  Loss:     1.2589 Validation Accuracy: 0.533200\n",
      "Epoch 137, CIFAR-10 Batch 5:  Loss:     1.2507 Validation Accuracy: 0.532800\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:     1.2370 Validation Accuracy: 0.529400\n",
      "Epoch 138, CIFAR-10 Batch 2:  Loss:     1.2600 Validation Accuracy: 0.534200\n",
      "Epoch 138, CIFAR-10 Batch 3:  Loss:     1.2291 Validation Accuracy: 0.535800\n",
      "Epoch 138, CIFAR-10 Batch 4:  Loss:     1.2569 Validation Accuracy: 0.535200\n",
      "Epoch 138, CIFAR-10 Batch 5:  Loss:     1.2486 Validation Accuracy: 0.533200\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:     1.2351 Validation Accuracy: 0.530800\n",
      "Epoch 139, CIFAR-10 Batch 2:  Loss:     1.2580 Validation Accuracy: 0.535400\n",
      "Epoch 139, CIFAR-10 Batch 3:  Loss:     1.2273 Validation Accuracy: 0.536400\n",
      "Epoch 139, CIFAR-10 Batch 4:  Loss:     1.2548 Validation Accuracy: 0.535800\n",
      "Epoch 139, CIFAR-10 Batch 5:  Loss:     1.2467 Validation Accuracy: 0.533800\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:     1.2332 Validation Accuracy: 0.532400\n",
      "Epoch 140, CIFAR-10 Batch 2:  Loss:     1.2560 Validation Accuracy: 0.536400\n",
      "Epoch 140, CIFAR-10 Batch 3:  Loss:     1.2254 Validation Accuracy: 0.537600\n",
      "Epoch 140, CIFAR-10 Batch 4:  Loss:     1.2528 Validation Accuracy: 0.536000\n",
      "Epoch 140, CIFAR-10 Batch 5:  Loss:     1.2447 Validation Accuracy: 0.535200\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:     1.2314 Validation Accuracy: 0.533400\n",
      "Epoch 141, CIFAR-10 Batch 2:  Loss:     1.2540 Validation Accuracy: 0.536800\n",
      "Epoch 141, CIFAR-10 Batch 3:  Loss:     1.2234 Validation Accuracy: 0.538200\n",
      "Epoch 141, CIFAR-10 Batch 4:  Loss:     1.2508 Validation Accuracy: 0.535800\n",
      "Epoch 141, CIFAR-10 Batch 5:  Loss:     1.2428 Validation Accuracy: 0.535600\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:     1.2295 Validation Accuracy: 0.534600\n",
      "Epoch 142, CIFAR-10 Batch 2:  Loss:     1.2519 Validation Accuracy: 0.537800\n",
      "Epoch 142, CIFAR-10 Batch 3:  Loss:     1.2214 Validation Accuracy: 0.538800\n",
      "Epoch 142, CIFAR-10 Batch 4:  Loss:     1.2488 Validation Accuracy: 0.535800\n",
      "Epoch 142, CIFAR-10 Batch 5:  Loss:     1.2409 Validation Accuracy: 0.536600\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:     1.2275 Validation Accuracy: 0.535600\n",
      "Epoch 143, CIFAR-10 Batch 2:  Loss:     1.2498 Validation Accuracy: 0.537600\n",
      "Epoch 143, CIFAR-10 Batch 3:  Loss:     1.2195 Validation Accuracy: 0.539600\n",
      "Epoch 143, CIFAR-10 Batch 4:  Loss:     1.2468 Validation Accuracy: 0.537000\n",
      "Epoch 143, CIFAR-10 Batch 5:  Loss:     1.2389 Validation Accuracy: 0.536800\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:     1.2257 Validation Accuracy: 0.536600\n",
      "Epoch 144, CIFAR-10 Batch 2:  Loss:     1.2478 Validation Accuracy: 0.539000\n",
      "Epoch 144, CIFAR-10 Batch 3:  Loss:     1.2177 Validation Accuracy: 0.540200\n",
      "Epoch 144, CIFAR-10 Batch 4:  Loss:     1.2449 Validation Accuracy: 0.536800\n",
      "Epoch 144, CIFAR-10 Batch 5:  Loss:     1.2370 Validation Accuracy: 0.537200\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:     1.2238 Validation Accuracy: 0.537400\n",
      "Epoch 145, CIFAR-10 Batch 2:  Loss:     1.2459 Validation Accuracy: 0.539800\n",
      "Epoch 145, CIFAR-10 Batch 3:  Loss:     1.2160 Validation Accuracy: 0.540400\n",
      "Epoch 145, CIFAR-10 Batch 4:  Loss:     1.2430 Validation Accuracy: 0.537400\n",
      "Epoch 145, CIFAR-10 Batch 5:  Loss:     1.2351 Validation Accuracy: 0.537600\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:     1.2220 Validation Accuracy: 0.537400\n",
      "Epoch 146, CIFAR-10 Batch 2:  Loss:     1.2441 Validation Accuracy: 0.539800\n",
      "Epoch 146, CIFAR-10 Batch 3:  Loss:     1.2144 Validation Accuracy: 0.540600\n",
      "Epoch 146, CIFAR-10 Batch 4:  Loss:     1.2412 Validation Accuracy: 0.538000\n",
      "Epoch 146, CIFAR-10 Batch 5:  Loss:     1.2332 Validation Accuracy: 0.538600\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:     1.2203 Validation Accuracy: 0.538400\n",
      "Epoch 147, CIFAR-10 Batch 2:  Loss:     1.2425 Validation Accuracy: 0.541200\n",
      "Epoch 147, CIFAR-10 Batch 3:  Loss:     1.2129 Validation Accuracy: 0.541000\n",
      "Epoch 147, CIFAR-10 Batch 4:  Loss:     1.2394 Validation Accuracy: 0.538200\n",
      "Epoch 147, CIFAR-10 Batch 5:  Loss:     1.2313 Validation Accuracy: 0.539000\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:     1.2187 Validation Accuracy: 0.539000\n",
      "Epoch 148, CIFAR-10 Batch 2:  Loss:     1.2407 Validation Accuracy: 0.541400\n",
      "Epoch 148, CIFAR-10 Batch 3:  Loss:     1.2112 Validation Accuracy: 0.542200\n",
      "Epoch 148, CIFAR-10 Batch 4:  Loss:     1.2376 Validation Accuracy: 0.538600\n",
      "Epoch 148, CIFAR-10 Batch 5:  Loss:     1.2295 Validation Accuracy: 0.539800\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:     1.2170 Validation Accuracy: 0.540000\n",
      "Epoch 149, CIFAR-10 Batch 2:  Loss:     1.2389 Validation Accuracy: 0.541800\n",
      "Epoch 149, CIFAR-10 Batch 3:  Loss:     1.2093 Validation Accuracy: 0.542400\n",
      "Epoch 149, CIFAR-10 Batch 4:  Loss:     1.2357 Validation Accuracy: 0.539600\n",
      "Epoch 149, CIFAR-10 Batch 5:  Loss:     1.2278 Validation Accuracy: 0.540600\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:     1.2154 Validation Accuracy: 0.540400\n",
      "Epoch 150, CIFAR-10 Batch 2:  Loss:     1.2369 Validation Accuracy: 0.543400\n",
      "Epoch 150, CIFAR-10 Batch 3:  Loss:     1.2072 Validation Accuracy: 0.544400\n",
      "Epoch 150, CIFAR-10 Batch 4:  Loss:     1.2338 Validation Accuracy: 0.540000\n",
      "Epoch 150, CIFAR-10 Batch 5:  Loss:     1.2260 Validation Accuracy: 0.540400\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:     1.2134 Validation Accuracy: 0.541600\n",
      "Epoch 151, CIFAR-10 Batch 2:  Loss:     1.2348 Validation Accuracy: 0.544400\n",
      "Epoch 151, CIFAR-10 Batch 3:  Loss:     1.2052 Validation Accuracy: 0.544200\n",
      "Epoch 151, CIFAR-10 Batch 4:  Loss:     1.2320 Validation Accuracy: 0.539600\n",
      "Epoch 151, CIFAR-10 Batch 5:  Loss:     1.2243 Validation Accuracy: 0.541000\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:     1.2116 Validation Accuracy: 0.541800\n",
      "Epoch 152, CIFAR-10 Batch 2:  Loss:     1.2330 Validation Accuracy: 0.545800\n",
      "Epoch 152, CIFAR-10 Batch 3:  Loss:     1.2035 Validation Accuracy: 0.545400\n",
      "Epoch 152, CIFAR-10 Batch 4:  Loss:     1.2302 Validation Accuracy: 0.541400\n",
      "Epoch 152, CIFAR-10 Batch 5:  Loss:     1.2225 Validation Accuracy: 0.540800\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:     1.2099 Validation Accuracy: 0.542600\n",
      "Epoch 153, CIFAR-10 Batch 2:  Loss:     1.2312 Validation Accuracy: 0.546800\n",
      "Epoch 153, CIFAR-10 Batch 3:  Loss:     1.2020 Validation Accuracy: 0.547200\n",
      "Epoch 153, CIFAR-10 Batch 4:  Loss:     1.2286 Validation Accuracy: 0.543000\n",
      "Epoch 153, CIFAR-10 Batch 5:  Loss:     1.2208 Validation Accuracy: 0.541400\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:     1.2082 Validation Accuracy: 0.543200\n",
      "Epoch 154, CIFAR-10 Batch 2:  Loss:     1.2296 Validation Accuracy: 0.547800\n",
      "Epoch 154, CIFAR-10 Batch 3:  Loss:     1.2007 Validation Accuracy: 0.548200\n",
      "Epoch 154, CIFAR-10 Batch 4:  Loss:     1.2270 Validation Accuracy: 0.543600\n",
      "Epoch 154, CIFAR-10 Batch 5:  Loss:     1.2190 Validation Accuracy: 0.542000\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:     1.2067 Validation Accuracy: 0.544000\n",
      "Epoch 155, CIFAR-10 Batch 2:  Loss:     1.2280 Validation Accuracy: 0.549200\n",
      "Epoch 155, CIFAR-10 Batch 3:  Loss:     1.1992 Validation Accuracy: 0.549000\n",
      "Epoch 155, CIFAR-10 Batch 4:  Loss:     1.2253 Validation Accuracy: 0.544600\n",
      "Epoch 155, CIFAR-10 Batch 5:  Loss:     1.2174 Validation Accuracy: 0.542200\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:     1.2052 Validation Accuracy: 0.543600\n",
      "Epoch 156, CIFAR-10 Batch 2:  Loss:     1.2265 Validation Accuracy: 0.549800\n",
      "Epoch 156, CIFAR-10 Batch 3:  Loss:     1.1976 Validation Accuracy: 0.549400\n",
      "Epoch 156, CIFAR-10 Batch 4:  Loss:     1.2236 Validation Accuracy: 0.545400\n",
      "Epoch 156, CIFAR-10 Batch 5:  Loss:     1.2159 Validation Accuracy: 0.543600\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:     1.2038 Validation Accuracy: 0.544800\n",
      "Epoch 157, CIFAR-10 Batch 2:  Loss:     1.2248 Validation Accuracy: 0.550200\n",
      "Epoch 157, CIFAR-10 Batch 3:  Loss:     1.1960 Validation Accuracy: 0.550000\n",
      "Epoch 157, CIFAR-10 Batch 4:  Loss:     1.2218 Validation Accuracy: 0.546800\n",
      "Epoch 157, CIFAR-10 Batch 5:  Loss:     1.2144 Validation Accuracy: 0.544800\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:     1.2022 Validation Accuracy: 0.544400\n",
      "Epoch 158, CIFAR-10 Batch 2:  Loss:     1.2229 Validation Accuracy: 0.550200\n",
      "Epoch 158, CIFAR-10 Batch 3:  Loss:     1.1942 Validation Accuracy: 0.550600\n",
      "Epoch 158, CIFAR-10 Batch 4:  Loss:     1.2201 Validation Accuracy: 0.546800\n",
      "Epoch 158, CIFAR-10 Batch 5:  Loss:     1.2127 Validation Accuracy: 0.545400\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:     1.2005 Validation Accuracy: 0.544800\n",
      "Epoch 159, CIFAR-10 Batch 2:  Loss:     1.2210 Validation Accuracy: 0.551200\n",
      "Epoch 159, CIFAR-10 Batch 3:  Loss:     1.1924 Validation Accuracy: 0.551200\n",
      "Epoch 159, CIFAR-10 Batch 4:  Loss:     1.2184 Validation Accuracy: 0.547400\n",
      "Epoch 159, CIFAR-10 Batch 5:  Loss:     1.2111 Validation Accuracy: 0.545600\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:     1.1989 Validation Accuracy: 0.545600\n",
      "Epoch 160, CIFAR-10 Batch 2:  Loss:     1.2192 Validation Accuracy: 0.552400\n",
      "Epoch 160, CIFAR-10 Batch 3:  Loss:     1.1909 Validation Accuracy: 0.551400\n",
      "Epoch 160, CIFAR-10 Batch 4:  Loss:     1.2168 Validation Accuracy: 0.548400\n",
      "Epoch 160, CIFAR-10 Batch 5:  Loss:     1.2095 Validation Accuracy: 0.547000\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:     1.1972 Validation Accuracy: 0.546400\n",
      "Epoch 161, CIFAR-10 Batch 2:  Loss:     1.2176 Validation Accuracy: 0.552600\n",
      "Epoch 161, CIFAR-10 Batch 3:  Loss:     1.1895 Validation Accuracy: 0.551000\n",
      "Epoch 161, CIFAR-10 Batch 4:  Loss:     1.2153 Validation Accuracy: 0.548600\n",
      "Epoch 161, CIFAR-10 Batch 5:  Loss:     1.2079 Validation Accuracy: 0.547600\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:     1.1958 Validation Accuracy: 0.547000\n",
      "Epoch 162, CIFAR-10 Batch 2:  Loss:     1.2161 Validation Accuracy: 0.553000\n",
      "Epoch 162, CIFAR-10 Batch 3:  Loss:     1.1882 Validation Accuracy: 0.552200\n",
      "Epoch 162, CIFAR-10 Batch 4:  Loss:     1.2137 Validation Accuracy: 0.547800\n",
      "Epoch 162, CIFAR-10 Batch 5:  Loss:     1.2063 Validation Accuracy: 0.548000\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:     1.1944 Validation Accuracy: 0.546600\n",
      "Epoch 163, CIFAR-10 Batch 2:  Loss:     1.2146 Validation Accuracy: 0.554000\n",
      "Epoch 163, CIFAR-10 Batch 3:  Loss:     1.1869 Validation Accuracy: 0.552600\n",
      "Epoch 163, CIFAR-10 Batch 4:  Loss:     1.2122 Validation Accuracy: 0.548400\n",
      "Epoch 163, CIFAR-10 Batch 5:  Loss:     1.2049 Validation Accuracy: 0.549200\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:     1.1931 Validation Accuracy: 0.546400\n",
      "Epoch 164, CIFAR-10 Batch 2:  Loss:     1.2130 Validation Accuracy: 0.554200\n",
      "Epoch 164, CIFAR-10 Batch 3:  Loss:     1.1853 Validation Accuracy: 0.552600\n",
      "Epoch 164, CIFAR-10 Batch 4:  Loss:     1.2106 Validation Accuracy: 0.549800\n",
      "Epoch 164, CIFAR-10 Batch 5:  Loss:     1.2034 Validation Accuracy: 0.549800\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:     1.1916 Validation Accuracy: 0.547600\n",
      "Epoch 165, CIFAR-10 Batch 2:  Loss:     1.2113 Validation Accuracy: 0.554000\n",
      "Epoch 165, CIFAR-10 Batch 3:  Loss:     1.1837 Validation Accuracy: 0.553400\n",
      "Epoch 165, CIFAR-10 Batch 4:  Loss:     1.2090 Validation Accuracy: 0.550800\n",
      "Epoch 165, CIFAR-10 Batch 5:  Loss:     1.2019 Validation Accuracy: 0.549200\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:     1.1901 Validation Accuracy: 0.548600\n",
      "Epoch 166, CIFAR-10 Batch 2:  Loss:     1.2096 Validation Accuracy: 0.554600\n",
      "Epoch 166, CIFAR-10 Batch 3:  Loss:     1.1822 Validation Accuracy: 0.553000\n",
      "Epoch 166, CIFAR-10 Batch 4:  Loss:     1.2074 Validation Accuracy: 0.551400\n",
      "Epoch 166, CIFAR-10 Batch 5:  Loss:     1.2004 Validation Accuracy: 0.549200\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:     1.1886 Validation Accuracy: 0.551000\n",
      "Epoch 167, CIFAR-10 Batch 2:  Loss:     1.2079 Validation Accuracy: 0.555000\n",
      "Epoch 167, CIFAR-10 Batch 3:  Loss:     1.1807 Validation Accuracy: 0.553600\n",
      "Epoch 167, CIFAR-10 Batch 4:  Loss:     1.2059 Validation Accuracy: 0.551200\n",
      "Epoch 167, CIFAR-10 Batch 5:  Loss:     1.1989 Validation Accuracy: 0.549600\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:     1.1872 Validation Accuracy: 0.551800\n",
      "Epoch 168, CIFAR-10 Batch 2:  Loss:     1.2064 Validation Accuracy: 0.555000\n",
      "Epoch 168, CIFAR-10 Batch 3:  Loss:     1.1793 Validation Accuracy: 0.553000\n",
      "Epoch 168, CIFAR-10 Batch 4:  Loss:     1.2044 Validation Accuracy: 0.551600\n",
      "Epoch 168, CIFAR-10 Batch 5:  Loss:     1.1974 Validation Accuracy: 0.549800\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:     1.1858 Validation Accuracy: 0.551400\n",
      "Epoch 169, CIFAR-10 Batch 2:  Loss:     1.2050 Validation Accuracy: 0.554600\n",
      "Epoch 169, CIFAR-10 Batch 3:  Loss:     1.1779 Validation Accuracy: 0.554400\n",
      "Epoch 169, CIFAR-10 Batch 4:  Loss:     1.2030 Validation Accuracy: 0.551400\n",
      "Epoch 169, CIFAR-10 Batch 5:  Loss:     1.1960 Validation Accuracy: 0.550800\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:     1.1845 Validation Accuracy: 0.551200\n",
      "Epoch 170, CIFAR-10 Batch 2:  Loss:     1.2036 Validation Accuracy: 0.555400\n",
      "Epoch 170, CIFAR-10 Batch 3:  Loss:     1.1766 Validation Accuracy: 0.555000\n",
      "Epoch 170, CIFAR-10 Batch 4:  Loss:     1.2015 Validation Accuracy: 0.551800\n",
      "Epoch 170, CIFAR-10 Batch 5:  Loss:     1.1946 Validation Accuracy: 0.551400\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:     1.1832 Validation Accuracy: 0.551000\n",
      "Epoch 171, CIFAR-10 Batch 2:  Loss:     1.2021 Validation Accuracy: 0.556000\n",
      "Epoch 171, CIFAR-10 Batch 3:  Loss:     1.1752 Validation Accuracy: 0.555400\n",
      "Epoch 171, CIFAR-10 Batch 4:  Loss:     1.2001 Validation Accuracy: 0.551800\n",
      "Epoch 171, CIFAR-10 Batch 5:  Loss:     1.1932 Validation Accuracy: 0.551600\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:     1.1819 Validation Accuracy: 0.551600\n",
      "Epoch 172, CIFAR-10 Batch 2:  Loss:     1.2007 Validation Accuracy: 0.555800\n",
      "Epoch 172, CIFAR-10 Batch 3:  Loss:     1.1737 Validation Accuracy: 0.555400\n",
      "Epoch 172, CIFAR-10 Batch 4:  Loss:     1.1986 Validation Accuracy: 0.552200\n",
      "Epoch 172, CIFAR-10 Batch 5:  Loss:     1.1918 Validation Accuracy: 0.551400\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss:     1.1805 Validation Accuracy: 0.552000\n",
      "Epoch 173, CIFAR-10 Batch 2:  Loss:     1.1992 Validation Accuracy: 0.555400\n",
      "Epoch 173, CIFAR-10 Batch 3:  Loss:     1.1723 Validation Accuracy: 0.555000\n",
      "Epoch 173, CIFAR-10 Batch 4:  Loss:     1.1972 Validation Accuracy: 0.551600\n",
      "Epoch 173, CIFAR-10 Batch 5:  Loss:     1.1905 Validation Accuracy: 0.551000\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:     1.1792 Validation Accuracy: 0.553000\n",
      "Epoch 174, CIFAR-10 Batch 2:  Loss:     1.1977 Validation Accuracy: 0.556600\n",
      "Epoch 174, CIFAR-10 Batch 3:  Loss:     1.1710 Validation Accuracy: 0.555200\n",
      "Epoch 174, CIFAR-10 Batch 4:  Loss:     1.1957 Validation Accuracy: 0.552200\n",
      "Epoch 174, CIFAR-10 Batch 5:  Loss:     1.1891 Validation Accuracy: 0.551800\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:     1.1778 Validation Accuracy: 0.553800\n",
      "Epoch 175, CIFAR-10 Batch 2:  Loss:     1.1963 Validation Accuracy: 0.557000\n",
      "Epoch 175, CIFAR-10 Batch 3:  Loss:     1.1697 Validation Accuracy: 0.555200\n",
      "Epoch 175, CIFAR-10 Batch 4:  Loss:     1.1943 Validation Accuracy: 0.552600\n",
      "Epoch 175, CIFAR-10 Batch 5:  Loss:     1.1878 Validation Accuracy: 0.552400\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:     1.1765 Validation Accuracy: 0.553600\n",
      "Epoch 176, CIFAR-10 Batch 2:  Loss:     1.1949 Validation Accuracy: 0.557000\n",
      "Epoch 176, CIFAR-10 Batch 3:  Loss:     1.1684 Validation Accuracy: 0.555400\n",
      "Epoch 176, CIFAR-10 Batch 4:  Loss:     1.1930 Validation Accuracy: 0.552800\n",
      "Epoch 176, CIFAR-10 Batch 5:  Loss:     1.1864 Validation Accuracy: 0.552600\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:     1.1752 Validation Accuracy: 0.554000\n",
      "Epoch 177, CIFAR-10 Batch 2:  Loss:     1.1936 Validation Accuracy: 0.557200\n",
      "Epoch 177, CIFAR-10 Batch 3:  Loss:     1.1672 Validation Accuracy: 0.556600\n",
      "Epoch 177, CIFAR-10 Batch 4:  Loss:     1.1916 Validation Accuracy: 0.553400\n",
      "Epoch 177, CIFAR-10 Batch 5:  Loss:     1.1851 Validation Accuracy: 0.552800\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:     1.1740 Validation Accuracy: 0.554200\n",
      "Epoch 178, CIFAR-10 Batch 2:  Loss:     1.1923 Validation Accuracy: 0.557200\n",
      "Epoch 178, CIFAR-10 Batch 3:  Loss:     1.1659 Validation Accuracy: 0.556400\n",
      "Epoch 178, CIFAR-10 Batch 4:  Loss:     1.1902 Validation Accuracy: 0.554000\n",
      "Epoch 178, CIFAR-10 Batch 5:  Loss:     1.1838 Validation Accuracy: 0.553400\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:     1.1727 Validation Accuracy: 0.555000\n",
      "Epoch 179, CIFAR-10 Batch 2:  Loss:     1.1909 Validation Accuracy: 0.557200\n",
      "Epoch 179, CIFAR-10 Batch 3:  Loss:     1.1646 Validation Accuracy: 0.557800\n",
      "Epoch 179, CIFAR-10 Batch 4:  Loss:     1.1889 Validation Accuracy: 0.554400\n",
      "Epoch 179, CIFAR-10 Batch 5:  Loss:     1.1826 Validation Accuracy: 0.553400\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:     1.1714 Validation Accuracy: 0.555000\n",
      "Epoch 180, CIFAR-10 Batch 2:  Loss:     1.1895 Validation Accuracy: 0.557000\n",
      "Epoch 180, CIFAR-10 Batch 3:  Loss:     1.1633 Validation Accuracy: 0.558400\n",
      "Epoch 180, CIFAR-10 Batch 4:  Loss:     1.1875 Validation Accuracy: 0.554600\n",
      "Epoch 180, CIFAR-10 Batch 5:  Loss:     1.1813 Validation Accuracy: 0.554400\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:     1.1702 Validation Accuracy: 0.555600\n",
      "Epoch 181, CIFAR-10 Batch 2:  Loss:     1.1882 Validation Accuracy: 0.557600\n",
      "Epoch 181, CIFAR-10 Batch 3:  Loss:     1.1621 Validation Accuracy: 0.558600\n",
      "Epoch 181, CIFAR-10 Batch 4:  Loss:     1.1863 Validation Accuracy: 0.555000\n",
      "Epoch 181, CIFAR-10 Batch 5:  Loss:     1.1801 Validation Accuracy: 0.555200\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:     1.1689 Validation Accuracy: 0.556600\n",
      "Epoch 182, CIFAR-10 Batch 2:  Loss:     1.1869 Validation Accuracy: 0.557800\n",
      "Epoch 182, CIFAR-10 Batch 3:  Loss:     1.1609 Validation Accuracy: 0.558600\n",
      "Epoch 182, CIFAR-10 Batch 4:  Loss:     1.1850 Validation Accuracy: 0.555200\n",
      "Epoch 182, CIFAR-10 Batch 5:  Loss:     1.1788 Validation Accuracy: 0.555200\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:     1.1677 Validation Accuracy: 0.557000\n",
      "Epoch 183, CIFAR-10 Batch 2:  Loss:     1.1857 Validation Accuracy: 0.557800\n",
      "Epoch 183, CIFAR-10 Batch 3:  Loss:     1.1598 Validation Accuracy: 0.559200\n",
      "Epoch 183, CIFAR-10 Batch 4:  Loss:     1.1837 Validation Accuracy: 0.555400\n",
      "Epoch 183, CIFAR-10 Batch 5:  Loss:     1.1777 Validation Accuracy: 0.555800\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:     1.1666 Validation Accuracy: 0.557200\n",
      "Epoch 184, CIFAR-10 Batch 2:  Loss:     1.1845 Validation Accuracy: 0.558600\n",
      "Epoch 184, CIFAR-10 Batch 3:  Loss:     1.1586 Validation Accuracy: 0.559600\n",
      "Epoch 184, CIFAR-10 Batch 4:  Loss:     1.1823 Validation Accuracy: 0.555600\n",
      "Epoch 184, CIFAR-10 Batch 5:  Loss:     1.1765 Validation Accuracy: 0.556000\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:     1.1654 Validation Accuracy: 0.556800\n",
      "Epoch 185, CIFAR-10 Batch 2:  Loss:     1.1832 Validation Accuracy: 0.559400\n",
      "Epoch 185, CIFAR-10 Batch 3:  Loss:     1.1573 Validation Accuracy: 0.560200\n",
      "Epoch 185, CIFAR-10 Batch 4:  Loss:     1.1810 Validation Accuracy: 0.555600\n",
      "Epoch 185, CIFAR-10 Batch 5:  Loss:     1.1754 Validation Accuracy: 0.556800\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:     1.1642 Validation Accuracy: 0.557600\n",
      "Epoch 186, CIFAR-10 Batch 2:  Loss:     1.1818 Validation Accuracy: 0.560000\n",
      "Epoch 186, CIFAR-10 Batch 3:  Loss:     1.1560 Validation Accuracy: 0.560400\n",
      "Epoch 186, CIFAR-10 Batch 4:  Loss:     1.1798 Validation Accuracy: 0.555600\n",
      "Epoch 186, CIFAR-10 Batch 5:  Loss:     1.1742 Validation Accuracy: 0.557200\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:     1.1629 Validation Accuracy: 0.558000\n",
      "Epoch 187, CIFAR-10 Batch 2:  Loss:     1.1804 Validation Accuracy: 0.560200\n",
      "Epoch 187, CIFAR-10 Batch 3:  Loss:     1.1549 Validation Accuracy: 0.560800\n",
      "Epoch 187, CIFAR-10 Batch 4:  Loss:     1.1785 Validation Accuracy: 0.556800\n",
      "Epoch 187, CIFAR-10 Batch 5:  Loss:     1.1729 Validation Accuracy: 0.557400\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:     1.1617 Validation Accuracy: 0.558200\n",
      "Epoch 188, CIFAR-10 Batch 2:  Loss:     1.1791 Validation Accuracy: 0.560400\n",
      "Epoch 188, CIFAR-10 Batch 3:  Loss:     1.1537 Validation Accuracy: 0.561600\n",
      "Epoch 188, CIFAR-10 Batch 4:  Loss:     1.1773 Validation Accuracy: 0.557600\n",
      "Epoch 188, CIFAR-10 Batch 5:  Loss:     1.1717 Validation Accuracy: 0.557400\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:     1.1605 Validation Accuracy: 0.558600\n",
      "Epoch 189, CIFAR-10 Batch 2:  Loss:     1.1779 Validation Accuracy: 0.561000\n",
      "Epoch 189, CIFAR-10 Batch 3:  Loss:     1.1526 Validation Accuracy: 0.561400\n",
      "Epoch 189, CIFAR-10 Batch 4:  Loss:     1.1760 Validation Accuracy: 0.557800\n",
      "Epoch 189, CIFAR-10 Batch 5:  Loss:     1.1705 Validation Accuracy: 0.558200\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:     1.1594 Validation Accuracy: 0.559000\n",
      "Epoch 190, CIFAR-10 Batch 2:  Loss:     1.1767 Validation Accuracy: 0.561400\n",
      "Epoch 190, CIFAR-10 Batch 3:  Loss:     1.1515 Validation Accuracy: 0.561000\n",
      "Epoch 190, CIFAR-10 Batch 4:  Loss:     1.1748 Validation Accuracy: 0.558600\n",
      "Epoch 190, CIFAR-10 Batch 5:  Loss:     1.1694 Validation Accuracy: 0.558400\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:     1.1583 Validation Accuracy: 0.560600\n",
      "Epoch 191, CIFAR-10 Batch 2:  Loss:     1.1755 Validation Accuracy: 0.562600\n",
      "Epoch 191, CIFAR-10 Batch 3:  Loss:     1.1504 Validation Accuracy: 0.561000\n",
      "Epoch 191, CIFAR-10 Batch 4:  Loss:     1.1736 Validation Accuracy: 0.559600\n",
      "Epoch 191, CIFAR-10 Batch 5:  Loss:     1.1683 Validation Accuracy: 0.560200\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:     1.1572 Validation Accuracy: 0.560600\n",
      "Epoch 192, CIFAR-10 Batch 2:  Loss:     1.1742 Validation Accuracy: 0.563200\n",
      "Epoch 192, CIFAR-10 Batch 3:  Loss:     1.1492 Validation Accuracy: 0.561800\n",
      "Epoch 192, CIFAR-10 Batch 4:  Loss:     1.1724 Validation Accuracy: 0.559200\n",
      "Epoch 192, CIFAR-10 Batch 5:  Loss:     1.1671 Validation Accuracy: 0.560000\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:     1.1560 Validation Accuracy: 0.561000\n",
      "Epoch 193, CIFAR-10 Batch 2:  Loss:     1.1730 Validation Accuracy: 0.562800\n",
      "Epoch 193, CIFAR-10 Batch 3:  Loss:     1.1481 Validation Accuracy: 0.563200\n",
      "Epoch 193, CIFAR-10 Batch 4:  Loss:     1.1712 Validation Accuracy: 0.559800\n",
      "Epoch 193, CIFAR-10 Batch 5:  Loss:     1.1659 Validation Accuracy: 0.560200\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:     1.1549 Validation Accuracy: 0.561200\n",
      "Epoch 194, CIFAR-10 Batch 2:  Loss:     1.1718 Validation Accuracy: 0.562800\n",
      "Epoch 194, CIFAR-10 Batch 3:  Loss:     1.1470 Validation Accuracy: 0.563200\n",
      "Epoch 194, CIFAR-10 Batch 4:  Loss:     1.1700 Validation Accuracy: 0.560000\n",
      "Epoch 194, CIFAR-10 Batch 5:  Loss:     1.1648 Validation Accuracy: 0.560400\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:     1.1538 Validation Accuracy: 0.561800\n",
      "Epoch 195, CIFAR-10 Batch 2:  Loss:     1.1707 Validation Accuracy: 0.563200\n",
      "Epoch 195, CIFAR-10 Batch 3:  Loss:     1.1459 Validation Accuracy: 0.562800\n",
      "Epoch 195, CIFAR-10 Batch 4:  Loss:     1.1688 Validation Accuracy: 0.561200\n",
      "Epoch 195, CIFAR-10 Batch 5:  Loss:     1.1637 Validation Accuracy: 0.561600\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:     1.1527 Validation Accuracy: 0.562200\n",
      "Epoch 196, CIFAR-10 Batch 2:  Loss:     1.1695 Validation Accuracy: 0.563200\n",
      "Epoch 196, CIFAR-10 Batch 3:  Loss:     1.1449 Validation Accuracy: 0.563400\n",
      "Epoch 196, CIFAR-10 Batch 4:  Loss:     1.1677 Validation Accuracy: 0.561600\n",
      "Epoch 196, CIFAR-10 Batch 5:  Loss:     1.1627 Validation Accuracy: 0.562200\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:     1.1517 Validation Accuracy: 0.562000\n",
      "Epoch 197, CIFAR-10 Batch 2:  Loss:     1.1684 Validation Accuracy: 0.563400\n",
      "Epoch 197, CIFAR-10 Batch 3:  Loss:     1.1437 Validation Accuracy: 0.563600\n",
      "Epoch 197, CIFAR-10 Batch 4:  Loss:     1.1665 Validation Accuracy: 0.561600\n",
      "Epoch 197, CIFAR-10 Batch 5:  Loss:     1.1616 Validation Accuracy: 0.561600\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:     1.1506 Validation Accuracy: 0.562400\n",
      "Epoch 198, CIFAR-10 Batch 2:  Loss:     1.1672 Validation Accuracy: 0.564400\n",
      "Epoch 198, CIFAR-10 Batch 3:  Loss:     1.1426 Validation Accuracy: 0.564000\n",
      "Epoch 198, CIFAR-10 Batch 4:  Loss:     1.1654 Validation Accuracy: 0.562400\n",
      "Epoch 198, CIFAR-10 Batch 5:  Loss:     1.1604 Validation Accuracy: 0.563200\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:     1.1494 Validation Accuracy: 0.563000\n",
      "Epoch 199, CIFAR-10 Batch 2:  Loss:     1.1661 Validation Accuracy: 0.564600\n",
      "Epoch 199, CIFAR-10 Batch 3:  Loss:     1.1416 Validation Accuracy: 0.564800\n",
      "Epoch 199, CIFAR-10 Batch 4:  Loss:     1.1642 Validation Accuracy: 0.563000\n",
      "Epoch 199, CIFAR-10 Batch 5:  Loss:     1.1593 Validation Accuracy: 0.562800\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:     1.1484 Validation Accuracy: 0.563400\n",
      "Epoch 200, CIFAR-10 Batch 2:  Loss:     1.1649 Validation Accuracy: 0.566000\n",
      "Epoch 200, CIFAR-10 Batch 3:  Loss:     1.1405 Validation Accuracy: 0.566200\n",
      "Epoch 200, CIFAR-10 Batch 4:  Loss:     1.1631 Validation Accuracy: 0.562600\n",
      "Epoch 200, CIFAR-10 Batch 5:  Loss:     1.1583 Validation Accuracy: 0.562400\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss:     1.1474 Validation Accuracy: 0.563200\n",
      "Epoch 201, CIFAR-10 Batch 2:  Loss:     1.1639 Validation Accuracy: 0.566600\n",
      "Epoch 201, CIFAR-10 Batch 3:  Loss:     1.1395 Validation Accuracy: 0.566000\n",
      "Epoch 201, CIFAR-10 Batch 4:  Loss:     1.1620 Validation Accuracy: 0.563000\n",
      "Epoch 201, CIFAR-10 Batch 5:  Loss:     1.1573 Validation Accuracy: 0.563200\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss:     1.1464 Validation Accuracy: 0.563000\n",
      "Epoch 202, CIFAR-10 Batch 2:  Loss:     1.1628 Validation Accuracy: 0.566200\n",
      "Epoch 202, CIFAR-10 Batch 3:  Loss:     1.1384 Validation Accuracy: 0.566600\n",
      "Epoch 202, CIFAR-10 Batch 4:  Loss:     1.1608 Validation Accuracy: 0.562200\n",
      "Epoch 202, CIFAR-10 Batch 5:  Loss:     1.1563 Validation Accuracy: 0.563600\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss:     1.1453 Validation Accuracy: 0.563600\n",
      "Epoch 203, CIFAR-10 Batch 2:  Loss:     1.1617 Validation Accuracy: 0.565600\n",
      "Epoch 203, CIFAR-10 Batch 3:  Loss:     1.1373 Validation Accuracy: 0.566800\n",
      "Epoch 203, CIFAR-10 Batch 4:  Loss:     1.1597 Validation Accuracy: 0.563000\n",
      "Epoch 203, CIFAR-10 Batch 5:  Loss:     1.1553 Validation Accuracy: 0.564000\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss:     1.1442 Validation Accuracy: 0.563600\n",
      "Epoch 204, CIFAR-10 Batch 2:  Loss:     1.1605 Validation Accuracy: 0.565800\n",
      "Epoch 204, CIFAR-10 Batch 3:  Loss:     1.1362 Validation Accuracy: 0.566800\n",
      "Epoch 204, CIFAR-10 Batch 4:  Loss:     1.1586 Validation Accuracy: 0.563400\n",
      "Epoch 204, CIFAR-10 Batch 5:  Loss:     1.1542 Validation Accuracy: 0.563400\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss:     1.1431 Validation Accuracy: 0.565000\n",
      "Epoch 205, CIFAR-10 Batch 2:  Loss:     1.1594 Validation Accuracy: 0.565800\n",
      "Epoch 205, CIFAR-10 Batch 3:  Loss:     1.1351 Validation Accuracy: 0.567600\n",
      "Epoch 205, CIFAR-10 Batch 4:  Loss:     1.1575 Validation Accuracy: 0.564600\n",
      "Epoch 205, CIFAR-10 Batch 5:  Loss:     1.1532 Validation Accuracy: 0.563600\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss:     1.1420 Validation Accuracy: 0.565800\n",
      "Epoch 206, CIFAR-10 Batch 2:  Loss:     1.1584 Validation Accuracy: 0.565200\n",
      "Epoch 206, CIFAR-10 Batch 3:  Loss:     1.1342 Validation Accuracy: 0.567800\n",
      "Epoch 206, CIFAR-10 Batch 4:  Loss:     1.1564 Validation Accuracy: 0.564800\n",
      "Epoch 206, CIFAR-10 Batch 5:  Loss:     1.1522 Validation Accuracy: 0.564400\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss:     1.1410 Validation Accuracy: 0.566600\n",
      "Epoch 207, CIFAR-10 Batch 2:  Loss:     1.1574 Validation Accuracy: 0.565600\n",
      "Epoch 207, CIFAR-10 Batch 3:  Loss:     1.1333 Validation Accuracy: 0.568000\n",
      "Epoch 207, CIFAR-10 Batch 4:  Loss:     1.1554 Validation Accuracy: 0.564400\n",
      "Epoch 207, CIFAR-10 Batch 5:  Loss:     1.1512 Validation Accuracy: 0.564200\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss:     1.1401 Validation Accuracy: 0.567400\n",
      "Epoch 208, CIFAR-10 Batch 2:  Loss:     1.1565 Validation Accuracy: 0.565800\n",
      "Epoch 208, CIFAR-10 Batch 3:  Loss:     1.1323 Validation Accuracy: 0.568000\n",
      "Epoch 208, CIFAR-10 Batch 4:  Loss:     1.1543 Validation Accuracy: 0.565200\n",
      "Epoch 208, CIFAR-10 Batch 5:  Loss:     1.1503 Validation Accuracy: 0.565000\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss:     1.1391 Validation Accuracy: 0.567400\n",
      "Epoch 209, CIFAR-10 Batch 2:  Loss:     1.1554 Validation Accuracy: 0.566600\n",
      "Epoch 209, CIFAR-10 Batch 3:  Loss:     1.1312 Validation Accuracy: 0.568600\n",
      "Epoch 209, CIFAR-10 Batch 4:  Loss:     1.1532 Validation Accuracy: 0.565200\n",
      "Epoch 209, CIFAR-10 Batch 5:  Loss:     1.1493 Validation Accuracy: 0.565400\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss:     1.1380 Validation Accuracy: 0.567000\n",
      "Epoch 210, CIFAR-10 Batch 2:  Loss:     1.1543 Validation Accuracy: 0.566000\n",
      "Epoch 210, CIFAR-10 Batch 3:  Loss:     1.1302 Validation Accuracy: 0.569000\n",
      "Epoch 210, CIFAR-10 Batch 4:  Loss:     1.1521 Validation Accuracy: 0.565600\n",
      "Epoch 210, CIFAR-10 Batch 5:  Loss:     1.1484 Validation Accuracy: 0.565400\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss:     1.1370 Validation Accuracy: 0.566800\n",
      "Epoch 211, CIFAR-10 Batch 2:  Loss:     1.1531 Validation Accuracy: 0.565600\n",
      "Epoch 211, CIFAR-10 Batch 3:  Loss:     1.1291 Validation Accuracy: 0.569200\n",
      "Epoch 211, CIFAR-10 Batch 4:  Loss:     1.1510 Validation Accuracy: 0.566200\n",
      "Epoch 211, CIFAR-10 Batch 5:  Loss:     1.1474 Validation Accuracy: 0.565800\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss:     1.1359 Validation Accuracy: 0.566800\n",
      "Epoch 212, CIFAR-10 Batch 2:  Loss:     1.1520 Validation Accuracy: 0.565800\n",
      "Epoch 212, CIFAR-10 Batch 3:  Loss:     1.1282 Validation Accuracy: 0.569000\n",
      "Epoch 212, CIFAR-10 Batch 4:  Loss:     1.1500 Validation Accuracy: 0.566200\n",
      "Epoch 212, CIFAR-10 Batch 5:  Loss:     1.1464 Validation Accuracy: 0.566400\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss:     1.1349 Validation Accuracy: 0.567200\n",
      "Epoch 213, CIFAR-10 Batch 2:  Loss:     1.1510 Validation Accuracy: 0.567000\n",
      "Epoch 213, CIFAR-10 Batch 3:  Loss:     1.1273 Validation Accuracy: 0.568800\n",
      "Epoch 213, CIFAR-10 Batch 4:  Loss:     1.1489 Validation Accuracy: 0.566200\n",
      "Epoch 213, CIFAR-10 Batch 5:  Loss:     1.1454 Validation Accuracy: 0.566400\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss:     1.1340 Validation Accuracy: 0.568200\n",
      "Epoch 214, CIFAR-10 Batch 2:  Loss:     1.1501 Validation Accuracy: 0.566600\n",
      "Epoch 214, CIFAR-10 Batch 3:  Loss:     1.1264 Validation Accuracy: 0.569200\n",
      "Epoch 214, CIFAR-10 Batch 4:  Loss:     1.1479 Validation Accuracy: 0.566200\n",
      "Epoch 214, CIFAR-10 Batch 5:  Loss:     1.1444 Validation Accuracy: 0.566400\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss:     1.1331 Validation Accuracy: 0.569000\n",
      "Epoch 215, CIFAR-10 Batch 2:  Loss:     1.1492 Validation Accuracy: 0.567200\n",
      "Epoch 215, CIFAR-10 Batch 3:  Loss:     1.1255 Validation Accuracy: 0.569000\n",
      "Epoch 215, CIFAR-10 Batch 4:  Loss:     1.1468 Validation Accuracy: 0.566200\n",
      "Epoch 215, CIFAR-10 Batch 5:  Loss:     1.1435 Validation Accuracy: 0.567000\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss:     1.1322 Validation Accuracy: 0.569800\n",
      "Epoch 216, CIFAR-10 Batch 2:  Loss:     1.1481 Validation Accuracy: 0.567400\n",
      "Epoch 216, CIFAR-10 Batch 3:  Loss:     1.1245 Validation Accuracy: 0.569600\n",
      "Epoch 216, CIFAR-10 Batch 4:  Loss:     1.1458 Validation Accuracy: 0.566200\n",
      "Epoch 216, CIFAR-10 Batch 5:  Loss:     1.1427 Validation Accuracy: 0.567200\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss:     1.1312 Validation Accuracy: 0.570400\n",
      "Epoch 217, CIFAR-10 Batch 2:  Loss:     1.1470 Validation Accuracy: 0.567600\n",
      "Epoch 217, CIFAR-10 Batch 3:  Loss:     1.1234 Validation Accuracy: 0.569800\n",
      "Epoch 217, CIFAR-10 Batch 4:  Loss:     1.1448 Validation Accuracy: 0.567200\n",
      "Epoch 217, CIFAR-10 Batch 5:  Loss:     1.1417 Validation Accuracy: 0.567600\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss:     1.1302 Validation Accuracy: 0.570000\n",
      "Epoch 218, CIFAR-10 Batch 2:  Loss:     1.1459 Validation Accuracy: 0.567600\n",
      "Epoch 218, CIFAR-10 Batch 3:  Loss:     1.1224 Validation Accuracy: 0.570400\n",
      "Epoch 218, CIFAR-10 Batch 4:  Loss:     1.1438 Validation Accuracy: 0.567400\n",
      "Epoch 218, CIFAR-10 Batch 5:  Loss:     1.1407 Validation Accuracy: 0.568400\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss:     1.1291 Validation Accuracy: 0.570200\n",
      "Epoch 219, CIFAR-10 Batch 2:  Loss:     1.1448 Validation Accuracy: 0.568600\n",
      "Epoch 219, CIFAR-10 Batch 3:  Loss:     1.1215 Validation Accuracy: 0.570200\n",
      "Epoch 219, CIFAR-10 Batch 4:  Loss:     1.1428 Validation Accuracy: 0.566800\n",
      "Epoch 219, CIFAR-10 Batch 5:  Loss:     1.1397 Validation Accuracy: 0.568800\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss:     1.1281 Validation Accuracy: 0.570600\n",
      "Epoch 220, CIFAR-10 Batch 2:  Loss:     1.1439 Validation Accuracy: 0.568400\n",
      "Epoch 220, CIFAR-10 Batch 3:  Loss:     1.1207 Validation Accuracy: 0.569800\n",
      "Epoch 220, CIFAR-10 Batch 4:  Loss:     1.1418 Validation Accuracy: 0.567000\n",
      "Epoch 220, CIFAR-10 Batch 5:  Loss:     1.1388 Validation Accuracy: 0.568400\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss:     1.1273 Validation Accuracy: 0.571200\n",
      "Epoch 221, CIFAR-10 Batch 2:  Loss:     1.1429 Validation Accuracy: 0.569000\n",
      "Epoch 221, CIFAR-10 Batch 3:  Loss:     1.1198 Validation Accuracy: 0.570600\n",
      "Epoch 221, CIFAR-10 Batch 4:  Loss:     1.1408 Validation Accuracy: 0.567600\n",
      "Epoch 221, CIFAR-10 Batch 5:  Loss:     1.1379 Validation Accuracy: 0.568600\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss:     1.1264 Validation Accuracy: 0.571600\n",
      "Epoch 222, CIFAR-10 Batch 2:  Loss:     1.1420 Validation Accuracy: 0.569000\n",
      "Epoch 222, CIFAR-10 Batch 3:  Loss:     1.1189 Validation Accuracy: 0.571200\n",
      "Epoch 222, CIFAR-10 Batch 4:  Loss:     1.1398 Validation Accuracy: 0.568200\n",
      "Epoch 222, CIFAR-10 Batch 5:  Loss:     1.1371 Validation Accuracy: 0.569400\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss:     1.1255 Validation Accuracy: 0.572000\n",
      "Epoch 223, CIFAR-10 Batch 2:  Loss:     1.1410 Validation Accuracy: 0.569600\n",
      "Epoch 223, CIFAR-10 Batch 3:  Loss:     1.1180 Validation Accuracy: 0.571000\n",
      "Epoch 223, CIFAR-10 Batch 4:  Loss:     1.1389 Validation Accuracy: 0.568800\n",
      "Epoch 223, CIFAR-10 Batch 5:  Loss:     1.1362 Validation Accuracy: 0.570400\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss:     1.1246 Validation Accuracy: 0.572600\n",
      "Epoch 224, CIFAR-10 Batch 2:  Loss:     1.1401 Validation Accuracy: 0.569400\n",
      "Epoch 224, CIFAR-10 Batch 3:  Loss:     1.1172 Validation Accuracy: 0.571600\n",
      "Epoch 224, CIFAR-10 Batch 4:  Loss:     1.1379 Validation Accuracy: 0.569200\n",
      "Epoch 224, CIFAR-10 Batch 5:  Loss:     1.1354 Validation Accuracy: 0.571600\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss:     1.1237 Validation Accuracy: 0.571600\n",
      "Epoch 225, CIFAR-10 Batch 2:  Loss:     1.1392 Validation Accuracy: 0.569800\n",
      "Epoch 225, CIFAR-10 Batch 3:  Loss:     1.1162 Validation Accuracy: 0.573400\n",
      "Epoch 225, CIFAR-10 Batch 4:  Loss:     1.1370 Validation Accuracy: 0.569400\n",
      "Epoch 225, CIFAR-10 Batch 5:  Loss:     1.1345 Validation Accuracy: 0.572200\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss:     1.1227 Validation Accuracy: 0.571800\n",
      "Epoch 226, CIFAR-10 Batch 2:  Loss:     1.1382 Validation Accuracy: 0.570200\n",
      "Epoch 226, CIFAR-10 Batch 3:  Loss:     1.1153 Validation Accuracy: 0.573400\n",
      "Epoch 226, CIFAR-10 Batch 4:  Loss:     1.1360 Validation Accuracy: 0.569800\n",
      "Epoch 226, CIFAR-10 Batch 5:  Loss:     1.1336 Validation Accuracy: 0.572200\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss:     1.1218 Validation Accuracy: 0.572000\n",
      "Epoch 227, CIFAR-10 Batch 2:  Loss:     1.1373 Validation Accuracy: 0.570200\n",
      "Epoch 227, CIFAR-10 Batch 3:  Loss:     1.1144 Validation Accuracy: 0.573600\n",
      "Epoch 227, CIFAR-10 Batch 4:  Loss:     1.1350 Validation Accuracy: 0.570400\n",
      "Epoch 227, CIFAR-10 Batch 5:  Loss:     1.1327 Validation Accuracy: 0.572600\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss:     1.1208 Validation Accuracy: 0.572400\n",
      "Epoch 228, CIFAR-10 Batch 2:  Loss:     1.1364 Validation Accuracy: 0.571000\n",
      "Epoch 228, CIFAR-10 Batch 3:  Loss:     1.1135 Validation Accuracy: 0.574200\n",
      "Epoch 228, CIFAR-10 Batch 4:  Loss:     1.1341 Validation Accuracy: 0.570400\n",
      "Epoch 228, CIFAR-10 Batch 5:  Loss:     1.1318 Validation Accuracy: 0.573000\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss:     1.1200 Validation Accuracy: 0.572800\n",
      "Epoch 229, CIFAR-10 Batch 2:  Loss:     1.1355 Validation Accuracy: 0.571400\n",
      "Epoch 229, CIFAR-10 Batch 3:  Loss:     1.1126 Validation Accuracy: 0.574600\n",
      "Epoch 229, CIFAR-10 Batch 4:  Loss:     1.1331 Validation Accuracy: 0.571000\n",
      "Epoch 229, CIFAR-10 Batch 5:  Loss:     1.1309 Validation Accuracy: 0.573200\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss:     1.1191 Validation Accuracy: 0.572800\n",
      "Epoch 230, CIFAR-10 Batch 2:  Loss:     1.1347 Validation Accuracy: 0.572200\n",
      "Epoch 230, CIFAR-10 Batch 3:  Loss:     1.1117 Validation Accuracy: 0.574600\n",
      "Epoch 230, CIFAR-10 Batch 4:  Loss:     1.1322 Validation Accuracy: 0.571400\n",
      "Epoch 230, CIFAR-10 Batch 5:  Loss:     1.1301 Validation Accuracy: 0.573400\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss:     1.1182 Validation Accuracy: 0.572800\n",
      "Epoch 231, CIFAR-10 Batch 2:  Loss:     1.1338 Validation Accuracy: 0.573000\n",
      "Epoch 231, CIFAR-10 Batch 3:  Loss:     1.1107 Validation Accuracy: 0.574400\n",
      "Epoch 231, CIFAR-10 Batch 4:  Loss:     1.1313 Validation Accuracy: 0.571800\n",
      "Epoch 231, CIFAR-10 Batch 5:  Loss:     1.1293 Validation Accuracy: 0.574200\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss:     1.1173 Validation Accuracy: 0.573000\n",
      "Epoch 232, CIFAR-10 Batch 2:  Loss:     1.1328 Validation Accuracy: 0.572600\n",
      "Epoch 232, CIFAR-10 Batch 3:  Loss:     1.1097 Validation Accuracy: 0.574600\n",
      "Epoch 232, CIFAR-10 Batch 4:  Loss:     1.1303 Validation Accuracy: 0.571800\n",
      "Epoch 232, CIFAR-10 Batch 5:  Loss:     1.1284 Validation Accuracy: 0.574600\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss:     1.1163 Validation Accuracy: 0.572400\n",
      "Epoch 233, CIFAR-10 Batch 2:  Loss:     1.1319 Validation Accuracy: 0.573200\n",
      "Epoch 233, CIFAR-10 Batch 3:  Loss:     1.1089 Validation Accuracy: 0.574600\n",
      "Epoch 233, CIFAR-10 Batch 4:  Loss:     1.1295 Validation Accuracy: 0.572000\n",
      "Epoch 233, CIFAR-10 Batch 5:  Loss:     1.1275 Validation Accuracy: 0.574000\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss:     1.1154 Validation Accuracy: 0.573600\n",
      "Epoch 234, CIFAR-10 Batch 2:  Loss:     1.1310 Validation Accuracy: 0.573200\n",
      "Epoch 234, CIFAR-10 Batch 3:  Loss:     1.1080 Validation Accuracy: 0.575000\n",
      "Epoch 234, CIFAR-10 Batch 4:  Loss:     1.1286 Validation Accuracy: 0.572600\n",
      "Epoch 234, CIFAR-10 Batch 5:  Loss:     1.1267 Validation Accuracy: 0.574400\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss:     1.1145 Validation Accuracy: 0.573400\n",
      "Epoch 235, CIFAR-10 Batch 2:  Loss:     1.1302 Validation Accuracy: 0.574000\n",
      "Epoch 235, CIFAR-10 Batch 3:  Loss:     1.1073 Validation Accuracy: 0.575400\n",
      "Epoch 235, CIFAR-10 Batch 4:  Loss:     1.1277 Validation Accuracy: 0.573000\n",
      "Epoch 235, CIFAR-10 Batch 5:  Loss:     1.1259 Validation Accuracy: 0.574600\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss:     1.1137 Validation Accuracy: 0.573600\n",
      "Epoch 236, CIFAR-10 Batch 2:  Loss:     1.1294 Validation Accuracy: 0.575200\n",
      "Epoch 236, CIFAR-10 Batch 3:  Loss:     1.1065 Validation Accuracy: 0.575000\n",
      "Epoch 236, CIFAR-10 Batch 4:  Loss:     1.1267 Validation Accuracy: 0.573400\n",
      "Epoch 236, CIFAR-10 Batch 5:  Loss:     1.1250 Validation Accuracy: 0.574800\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss:     1.1128 Validation Accuracy: 0.574000\n",
      "Epoch 237, CIFAR-10 Batch 2:  Loss:     1.1285 Validation Accuracy: 0.576400\n",
      "Epoch 237, CIFAR-10 Batch 3:  Loss:     1.1056 Validation Accuracy: 0.575000\n",
      "Epoch 237, CIFAR-10 Batch 4:  Loss:     1.1258 Validation Accuracy: 0.574200\n",
      "Epoch 237, CIFAR-10 Batch 5:  Loss:     1.1242 Validation Accuracy: 0.574800\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss:     1.1120 Validation Accuracy: 0.573800\n",
      "Epoch 238, CIFAR-10 Batch 2:  Loss:     1.1276 Validation Accuracy: 0.576200\n",
      "Epoch 238, CIFAR-10 Batch 3:  Loss:     1.1047 Validation Accuracy: 0.575400\n",
      "Epoch 238, CIFAR-10 Batch 4:  Loss:     1.1248 Validation Accuracy: 0.574400\n",
      "Epoch 238, CIFAR-10 Batch 5:  Loss:     1.1234 Validation Accuracy: 0.575400\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss:     1.1111 Validation Accuracy: 0.574000\n",
      "Epoch 239, CIFAR-10 Batch 2:  Loss:     1.1266 Validation Accuracy: 0.576600\n",
      "Epoch 239, CIFAR-10 Batch 3:  Loss:     1.1038 Validation Accuracy: 0.575800\n",
      "Epoch 239, CIFAR-10 Batch 4:  Loss:     1.1239 Validation Accuracy: 0.574600\n",
      "Epoch 239, CIFAR-10 Batch 5:  Loss:     1.1226 Validation Accuracy: 0.575600\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss:     1.1102 Validation Accuracy: 0.574400\n",
      "Epoch 240, CIFAR-10 Batch 2:  Loss:     1.1258 Validation Accuracy: 0.577400\n",
      "Epoch 240, CIFAR-10 Batch 3:  Loss:     1.1030 Validation Accuracy: 0.575800\n",
      "Epoch 240, CIFAR-10 Batch 4:  Loss:     1.1231 Validation Accuracy: 0.575000\n",
      "Epoch 240, CIFAR-10 Batch 5:  Loss:     1.1218 Validation Accuracy: 0.575400\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss:     1.1093 Validation Accuracy: 0.575400\n",
      "Epoch 241, CIFAR-10 Batch 2:  Loss:     1.1249 Validation Accuracy: 0.577200\n",
      "Epoch 241, CIFAR-10 Batch 3:  Loss:     1.1022 Validation Accuracy: 0.575600\n",
      "Epoch 241, CIFAR-10 Batch 4:  Loss:     1.1222 Validation Accuracy: 0.575000\n",
      "Epoch 241, CIFAR-10 Batch 5:  Loss:     1.1210 Validation Accuracy: 0.575000\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss:     1.1085 Validation Accuracy: 0.575600\n",
      "Epoch 242, CIFAR-10 Batch 2:  Loss:     1.1242 Validation Accuracy: 0.577400\n",
      "Epoch 242, CIFAR-10 Batch 3:  Loss:     1.1014 Validation Accuracy: 0.575600\n",
      "Epoch 242, CIFAR-10 Batch 4:  Loss:     1.1214 Validation Accuracy: 0.575200\n",
      "Epoch 242, CIFAR-10 Batch 5:  Loss:     1.1202 Validation Accuracy: 0.574800\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss:     1.1077 Validation Accuracy: 0.576600\n",
      "Epoch 243, CIFAR-10 Batch 2:  Loss:     1.1233 Validation Accuracy: 0.578000\n",
      "Epoch 243, CIFAR-10 Batch 3:  Loss:     1.1006 Validation Accuracy: 0.575800\n",
      "Epoch 243, CIFAR-10 Batch 4:  Loss:     1.1205 Validation Accuracy: 0.575600\n",
      "Epoch 243, CIFAR-10 Batch 5:  Loss:     1.1194 Validation Accuracy: 0.575200\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss:     1.1069 Validation Accuracy: 0.576400\n",
      "Epoch 244, CIFAR-10 Batch 2:  Loss:     1.1224 Validation Accuracy: 0.578400\n",
      "Epoch 244, CIFAR-10 Batch 3:  Loss:     1.0997 Validation Accuracy: 0.576200\n",
      "Epoch 244, CIFAR-10 Batch 4:  Loss:     1.1196 Validation Accuracy: 0.575400\n",
      "Epoch 244, CIFAR-10 Batch 5:  Loss:     1.1186 Validation Accuracy: 0.575400\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss:     1.1060 Validation Accuracy: 0.577000\n",
      "Epoch 245, CIFAR-10 Batch 2:  Loss:     1.1216 Validation Accuracy: 0.578800\n",
      "Epoch 245, CIFAR-10 Batch 3:  Loss:     1.0988 Validation Accuracy: 0.576400\n",
      "Epoch 245, CIFAR-10 Batch 4:  Loss:     1.1187 Validation Accuracy: 0.575200\n",
      "Epoch 245, CIFAR-10 Batch 5:  Loss:     1.1177 Validation Accuracy: 0.576000\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss:     1.1051 Validation Accuracy: 0.577600\n",
      "Epoch 246, CIFAR-10 Batch 2:  Loss:     1.1207 Validation Accuracy: 0.578600\n",
      "Epoch 246, CIFAR-10 Batch 3:  Loss:     1.0980 Validation Accuracy: 0.576600\n",
      "Epoch 246, CIFAR-10 Batch 4:  Loss:     1.1179 Validation Accuracy: 0.575200\n",
      "Epoch 246, CIFAR-10 Batch 5:  Loss:     1.1169 Validation Accuracy: 0.575800\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss:     1.1043 Validation Accuracy: 0.577200\n",
      "Epoch 247, CIFAR-10 Batch 2:  Loss:     1.1200 Validation Accuracy: 0.579200\n",
      "Epoch 247, CIFAR-10 Batch 3:  Loss:     1.0972 Validation Accuracy: 0.576000\n",
      "Epoch 247, CIFAR-10 Batch 4:  Loss:     1.1171 Validation Accuracy: 0.575600\n",
      "Epoch 247, CIFAR-10 Batch 5:  Loss:     1.1161 Validation Accuracy: 0.576000\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss:     1.1034 Validation Accuracy: 0.577800\n",
      "Epoch 248, CIFAR-10 Batch 2:  Loss:     1.1192 Validation Accuracy: 0.579400\n",
      "Epoch 248, CIFAR-10 Batch 3:  Loss:     1.0964 Validation Accuracy: 0.575800\n",
      "Epoch 248, CIFAR-10 Batch 4:  Loss:     1.1162 Validation Accuracy: 0.576000\n",
      "Epoch 248, CIFAR-10 Batch 5:  Loss:     1.1153 Validation Accuracy: 0.576000\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss:     1.1027 Validation Accuracy: 0.578200\n",
      "Epoch 249, CIFAR-10 Batch 2:  Loss:     1.1184 Validation Accuracy: 0.579600\n",
      "Epoch 249, CIFAR-10 Batch 3:  Loss:     1.0955 Validation Accuracy: 0.576400\n",
      "Epoch 249, CIFAR-10 Batch 4:  Loss:     1.1154 Validation Accuracy: 0.576000\n",
      "Epoch 249, CIFAR-10 Batch 5:  Loss:     1.1145 Validation Accuracy: 0.576200\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss:     1.1019 Validation Accuracy: 0.578800\n",
      "Epoch 250, CIFAR-10 Batch 2:  Loss:     1.1176 Validation Accuracy: 0.579800\n",
      "Epoch 250, CIFAR-10 Batch 3:  Loss:     1.0946 Validation Accuracy: 0.576200\n",
      "Epoch 250, CIFAR-10 Batch 4:  Loss:     1.1145 Validation Accuracy: 0.576200\n",
      "Epoch 250, CIFAR-10 Batch 5:  Loss:     1.1137 Validation Accuracy: 0.576400\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss:     1.1010 Validation Accuracy: 0.579000\n",
      "Epoch 251, CIFAR-10 Batch 2:  Loss:     1.1167 Validation Accuracy: 0.579800\n",
      "Epoch 251, CIFAR-10 Batch 3:  Loss:     1.0937 Validation Accuracy: 0.577800\n",
      "Epoch 251, CIFAR-10 Batch 4:  Loss:     1.1137 Validation Accuracy: 0.576600\n",
      "Epoch 251, CIFAR-10 Batch 5:  Loss:     1.1129 Validation Accuracy: 0.576600\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss:     1.1002 Validation Accuracy: 0.579400\n",
      "Epoch 252, CIFAR-10 Batch 2:  Loss:     1.1160 Validation Accuracy: 0.580400\n",
      "Epoch 252, CIFAR-10 Batch 3:  Loss:     1.0929 Validation Accuracy: 0.577800\n",
      "Epoch 252, CIFAR-10 Batch 4:  Loss:     1.1129 Validation Accuracy: 0.576600\n",
      "Epoch 252, CIFAR-10 Batch 5:  Loss:     1.1122 Validation Accuracy: 0.577200\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss:     1.0993 Validation Accuracy: 0.579400\n",
      "Epoch 253, CIFAR-10 Batch 2:  Loss:     1.1152 Validation Accuracy: 0.580600\n",
      "Epoch 253, CIFAR-10 Batch 3:  Loss:     1.0921 Validation Accuracy: 0.577800\n",
      "Epoch 253, CIFAR-10 Batch 4:  Loss:     1.1121 Validation Accuracy: 0.576800\n",
      "Epoch 253, CIFAR-10 Batch 5:  Loss:     1.1114 Validation Accuracy: 0.577200\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss:     1.0985 Validation Accuracy: 0.580000\n",
      "Epoch 254, CIFAR-10 Batch 2:  Loss:     1.1145 Validation Accuracy: 0.581000\n",
      "Epoch 254, CIFAR-10 Batch 3:  Loss:     1.0913 Validation Accuracy: 0.578000\n",
      "Epoch 254, CIFAR-10 Batch 4:  Loss:     1.1113 Validation Accuracy: 0.577000\n",
      "Epoch 254, CIFAR-10 Batch 5:  Loss:     1.1106 Validation Accuracy: 0.577400\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss:     1.0977 Validation Accuracy: 0.580400\n",
      "Epoch 255, CIFAR-10 Batch 2:  Loss:     1.1137 Validation Accuracy: 0.581400\n",
      "Epoch 255, CIFAR-10 Batch 3:  Loss:     1.0905 Validation Accuracy: 0.578200\n",
      "Epoch 255, CIFAR-10 Batch 4:  Loss:     1.1105 Validation Accuracy: 0.576600\n",
      "Epoch 255, CIFAR-10 Batch 5:  Loss:     1.1098 Validation Accuracy: 0.578000\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss:     1.0969 Validation Accuracy: 0.580800\n",
      "Epoch 256, CIFAR-10 Batch 2:  Loss:     1.1129 Validation Accuracy: 0.581400\n",
      "Epoch 256, CIFAR-10 Batch 3:  Loss:     1.0897 Validation Accuracy: 0.578200\n",
      "Epoch 256, CIFAR-10 Batch 4:  Loss:     1.1097 Validation Accuracy: 0.576800\n",
      "Epoch 256, CIFAR-10 Batch 5:  Loss:     1.1091 Validation Accuracy: 0.578400\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss:     1.0961 Validation Accuracy: 0.581400\n",
      "Epoch 257, CIFAR-10 Batch 2:  Loss:     1.1121 Validation Accuracy: 0.581400\n",
      "Epoch 257, CIFAR-10 Batch 3:  Loss:     1.0888 Validation Accuracy: 0.578400\n",
      "Epoch 257, CIFAR-10 Batch 4:  Loss:     1.1089 Validation Accuracy: 0.577600\n",
      "Epoch 257, CIFAR-10 Batch 5:  Loss:     1.1083 Validation Accuracy: 0.578600\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss:     1.0953 Validation Accuracy: 0.581400\n",
      "Epoch 258, CIFAR-10 Batch 2:  Loss:     1.1114 Validation Accuracy: 0.581800\n",
      "Epoch 258, CIFAR-10 Batch 3:  Loss:     1.0881 Validation Accuracy: 0.578400\n",
      "Epoch 258, CIFAR-10 Batch 4:  Loss:     1.1081 Validation Accuracy: 0.577400\n",
      "Epoch 258, CIFAR-10 Batch 5:  Loss:     1.1075 Validation Accuracy: 0.579200\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss:     1.0945 Validation Accuracy: 0.581600\n",
      "Epoch 259, CIFAR-10 Batch 2:  Loss:     1.1106 Validation Accuracy: 0.582200\n",
      "Epoch 259, CIFAR-10 Batch 3:  Loss:     1.0872 Validation Accuracy: 0.578800\n",
      "Epoch 259, CIFAR-10 Batch 4:  Loss:     1.1073 Validation Accuracy: 0.578000\n",
      "Epoch 259, CIFAR-10 Batch 5:  Loss:     1.1067 Validation Accuracy: 0.578800\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss:     1.0937 Validation Accuracy: 0.581600\n",
      "Epoch 260, CIFAR-10 Batch 2:  Loss:     1.1098 Validation Accuracy: 0.582200\n",
      "Epoch 260, CIFAR-10 Batch 3:  Loss:     1.0864 Validation Accuracy: 0.579000\n",
      "Epoch 260, CIFAR-10 Batch 4:  Loss:     1.1065 Validation Accuracy: 0.578200\n",
      "Epoch 260, CIFAR-10 Batch 5:  Loss:     1.1060 Validation Accuracy: 0.579200\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss:     1.0929 Validation Accuracy: 0.582000\n",
      "Epoch 261, CIFAR-10 Batch 2:  Loss:     1.1090 Validation Accuracy: 0.581800\n",
      "Epoch 261, CIFAR-10 Batch 3:  Loss:     1.0856 Validation Accuracy: 0.579600\n",
      "Epoch 261, CIFAR-10 Batch 4:  Loss:     1.1057 Validation Accuracy: 0.578800\n",
      "Epoch 261, CIFAR-10 Batch 5:  Loss:     1.1052 Validation Accuracy: 0.579200\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss:     1.0921 Validation Accuracy: 0.582000\n",
      "Epoch 262, CIFAR-10 Batch 2:  Loss:     1.1082 Validation Accuracy: 0.581800\n",
      "Epoch 262, CIFAR-10 Batch 3:  Loss:     1.0848 Validation Accuracy: 0.579600\n",
      "Epoch 262, CIFAR-10 Batch 4:  Loss:     1.1050 Validation Accuracy: 0.579000\n",
      "Epoch 262, CIFAR-10 Batch 5:  Loss:     1.1045 Validation Accuracy: 0.579000\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss:     1.0913 Validation Accuracy: 0.581800\n",
      "Epoch 263, CIFAR-10 Batch 2:  Loss:     1.1075 Validation Accuracy: 0.582000\n",
      "Epoch 263, CIFAR-10 Batch 3:  Loss:     1.0841 Validation Accuracy: 0.580600\n",
      "Epoch 263, CIFAR-10 Batch 4:  Loss:     1.1042 Validation Accuracy: 0.579000\n",
      "Epoch 263, CIFAR-10 Batch 5:  Loss:     1.1037 Validation Accuracy: 0.579400\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss:     1.0905 Validation Accuracy: 0.581800\n",
      "Epoch 264, CIFAR-10 Batch 2:  Loss:     1.1067 Validation Accuracy: 0.582000\n",
      "Epoch 264, CIFAR-10 Batch 3:  Loss:     1.0833 Validation Accuracy: 0.581200\n",
      "Epoch 264, CIFAR-10 Batch 4:  Loss:     1.1034 Validation Accuracy: 0.579200\n",
      "Epoch 264, CIFAR-10 Batch 5:  Loss:     1.1030 Validation Accuracy: 0.579800\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss:     1.0897 Validation Accuracy: 0.581600\n",
      "Epoch 265, CIFAR-10 Batch 2:  Loss:     1.1059 Validation Accuracy: 0.582400\n",
      "Epoch 265, CIFAR-10 Batch 3:  Loss:     1.0825 Validation Accuracy: 0.581600\n",
      "Epoch 265, CIFAR-10 Batch 4:  Loss:     1.1026 Validation Accuracy: 0.579400\n",
      "Epoch 265, CIFAR-10 Batch 5:  Loss:     1.1022 Validation Accuracy: 0.580200\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss:     1.0890 Validation Accuracy: 0.581600\n",
      "Epoch 266, CIFAR-10 Batch 2:  Loss:     1.1052 Validation Accuracy: 0.582400\n",
      "Epoch 266, CIFAR-10 Batch 3:  Loss:     1.0817 Validation Accuracy: 0.582400\n",
      "Epoch 266, CIFAR-10 Batch 4:  Loss:     1.1019 Validation Accuracy: 0.579400\n",
      "Epoch 266, CIFAR-10 Batch 5:  Loss:     1.1015 Validation Accuracy: 0.580400\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss:     1.0882 Validation Accuracy: 0.581800\n",
      "Epoch 267, CIFAR-10 Batch 2:  Loss:     1.1044 Validation Accuracy: 0.582800\n",
      "Epoch 267, CIFAR-10 Batch 3:  Loss:     1.0809 Validation Accuracy: 0.582800\n",
      "Epoch 267, CIFAR-10 Batch 4:  Loss:     1.1011 Validation Accuracy: 0.579400\n",
      "Epoch 267, CIFAR-10 Batch 5:  Loss:     1.1007 Validation Accuracy: 0.580400\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss:     1.0874 Validation Accuracy: 0.581400\n",
      "Epoch 268, CIFAR-10 Batch 2:  Loss:     1.1036 Validation Accuracy: 0.583000\n",
      "Epoch 268, CIFAR-10 Batch 3:  Loss:     1.0801 Validation Accuracy: 0.583000\n",
      "Epoch 268, CIFAR-10 Batch 4:  Loss:     1.1004 Validation Accuracy: 0.579600\n",
      "Epoch 268, CIFAR-10 Batch 5:  Loss:     1.1000 Validation Accuracy: 0.580600\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss:     1.0867 Validation Accuracy: 0.581200\n",
      "Epoch 269, CIFAR-10 Batch 2:  Loss:     1.1029 Validation Accuracy: 0.582800\n",
      "Epoch 269, CIFAR-10 Batch 3:  Loss:     1.0794 Validation Accuracy: 0.583000\n",
      "Epoch 269, CIFAR-10 Batch 4:  Loss:     1.0996 Validation Accuracy: 0.580400\n",
      "Epoch 269, CIFAR-10 Batch 5:  Loss:     1.0993 Validation Accuracy: 0.580800\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss:     1.0860 Validation Accuracy: 0.581800\n",
      "Epoch 270, CIFAR-10 Batch 2:  Loss:     1.1022 Validation Accuracy: 0.583000\n",
      "Epoch 270, CIFAR-10 Batch 3:  Loss:     1.0786 Validation Accuracy: 0.584400\n",
      "Epoch 270, CIFAR-10 Batch 4:  Loss:     1.0989 Validation Accuracy: 0.580600\n",
      "Epoch 270, CIFAR-10 Batch 5:  Loss:     1.0985 Validation Accuracy: 0.581000\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss:     1.0852 Validation Accuracy: 0.581600\n",
      "Epoch 271, CIFAR-10 Batch 2:  Loss:     1.1014 Validation Accuracy: 0.582800\n",
      "Epoch 271, CIFAR-10 Batch 3:  Loss:     1.0778 Validation Accuracy: 0.584200\n",
      "Epoch 271, CIFAR-10 Batch 4:  Loss:     1.0981 Validation Accuracy: 0.580800\n",
      "Epoch 271, CIFAR-10 Batch 5:  Loss:     1.0978 Validation Accuracy: 0.581600\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss:     1.0845 Validation Accuracy: 0.582200\n",
      "Epoch 272, CIFAR-10 Batch 2:  Loss:     1.1007 Validation Accuracy: 0.583200\n",
      "Epoch 272, CIFAR-10 Batch 3:  Loss:     1.0771 Validation Accuracy: 0.584400\n",
      "Epoch 272, CIFAR-10 Batch 4:  Loss:     1.0975 Validation Accuracy: 0.581200\n",
      "Epoch 272, CIFAR-10 Batch 5:  Loss:     1.0971 Validation Accuracy: 0.581800\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss:     1.0837 Validation Accuracy: 0.583400\n",
      "Epoch 273, CIFAR-10 Batch 2:  Loss:     1.1001 Validation Accuracy: 0.583200\n",
      "Epoch 273, CIFAR-10 Batch 3:  Loss:     1.0764 Validation Accuracy: 0.584800\n",
      "Epoch 273, CIFAR-10 Batch 4:  Loss:     1.0968 Validation Accuracy: 0.580800\n",
      "Epoch 273, CIFAR-10 Batch 5:  Loss:     1.0964 Validation Accuracy: 0.581600\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss:     1.0830 Validation Accuracy: 0.584600\n",
      "Epoch 274, CIFAR-10 Batch 2:  Loss:     1.0994 Validation Accuracy: 0.583200\n",
      "Epoch 274, CIFAR-10 Batch 3:  Loss:     1.0757 Validation Accuracy: 0.584200\n",
      "Epoch 274, CIFAR-10 Batch 4:  Loss:     1.0961 Validation Accuracy: 0.580200\n",
      "Epoch 274, CIFAR-10 Batch 5:  Loss:     1.0957 Validation Accuracy: 0.582200\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss:     1.0823 Validation Accuracy: 0.584800\n",
      "Epoch 275, CIFAR-10 Batch 2:  Loss:     1.0988 Validation Accuracy: 0.583200\n",
      "Epoch 275, CIFAR-10 Batch 3:  Loss:     1.0749 Validation Accuracy: 0.584400\n",
      "Epoch 275, CIFAR-10 Batch 4:  Loss:     1.0955 Validation Accuracy: 0.580200\n",
      "Epoch 275, CIFAR-10 Batch 5:  Loss:     1.0950 Validation Accuracy: 0.582000\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss:     1.0816 Validation Accuracy: 0.584800\n",
      "Epoch 276, CIFAR-10 Batch 2:  Loss:     1.0980 Validation Accuracy: 0.583600\n",
      "Epoch 276, CIFAR-10 Batch 3:  Loss:     1.0741 Validation Accuracy: 0.585400\n",
      "Epoch 276, CIFAR-10 Batch 4:  Loss:     1.0947 Validation Accuracy: 0.580800\n",
      "Epoch 276, CIFAR-10 Batch 5:  Loss:     1.0942 Validation Accuracy: 0.582400\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss:     1.0808 Validation Accuracy: 0.584000\n",
      "Epoch 277, CIFAR-10 Batch 2:  Loss:     1.0973 Validation Accuracy: 0.583200\n",
      "Epoch 277, CIFAR-10 Batch 3:  Loss:     1.0733 Validation Accuracy: 0.585600\n",
      "Epoch 277, CIFAR-10 Batch 4:  Loss:     1.0940 Validation Accuracy: 0.580800\n",
      "Epoch 277, CIFAR-10 Batch 5:  Loss:     1.0934 Validation Accuracy: 0.582400\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss:     1.0801 Validation Accuracy: 0.584400\n",
      "Epoch 278, CIFAR-10 Batch 2:  Loss:     1.0966 Validation Accuracy: 0.583400\n",
      "Epoch 278, CIFAR-10 Batch 3:  Loss:     1.0725 Validation Accuracy: 0.585000\n",
      "Epoch 278, CIFAR-10 Batch 4:  Loss:     1.0933 Validation Accuracy: 0.581600\n",
      "Epoch 278, CIFAR-10 Batch 5:  Loss:     1.0926 Validation Accuracy: 0.583000\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss:     1.0793 Validation Accuracy: 0.584400\n",
      "Epoch 279, CIFAR-10 Batch 2:  Loss:     1.0958 Validation Accuracy: 0.584000\n",
      "Epoch 279, CIFAR-10 Batch 3:  Loss:     1.0718 Validation Accuracy: 0.584800\n",
      "Epoch 279, CIFAR-10 Batch 4:  Loss:     1.0926 Validation Accuracy: 0.581600\n",
      "Epoch 279, CIFAR-10 Batch 5:  Loss:     1.0919 Validation Accuracy: 0.584200\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss:     1.0786 Validation Accuracy: 0.584200\n",
      "Epoch 280, CIFAR-10 Batch 2:  Loss:     1.0952 Validation Accuracy: 0.584400\n",
      "Epoch 280, CIFAR-10 Batch 3:  Loss:     1.0710 Validation Accuracy: 0.584800\n",
      "Epoch 280, CIFAR-10 Batch 4:  Loss:     1.0918 Validation Accuracy: 0.582800\n",
      "Epoch 280, CIFAR-10 Batch 5:  Loss:     1.0912 Validation Accuracy: 0.584600\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss:     1.0780 Validation Accuracy: 0.583600\n",
      "Epoch 281, CIFAR-10 Batch 2:  Loss:     1.0944 Validation Accuracy: 0.584200\n",
      "Epoch 281, CIFAR-10 Batch 3:  Loss:     1.0702 Validation Accuracy: 0.584600\n",
      "Epoch 281, CIFAR-10 Batch 4:  Loss:     1.0911 Validation Accuracy: 0.582800\n",
      "Epoch 281, CIFAR-10 Batch 5:  Loss:     1.0905 Validation Accuracy: 0.584600\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss:     1.0773 Validation Accuracy: 0.583000\n",
      "Epoch 282, CIFAR-10 Batch 2:  Loss:     1.0936 Validation Accuracy: 0.584200\n",
      "Epoch 282, CIFAR-10 Batch 3:  Loss:     1.0695 Validation Accuracy: 0.584600\n",
      "Epoch 282, CIFAR-10 Batch 4:  Loss:     1.0904 Validation Accuracy: 0.583400\n",
      "Epoch 282, CIFAR-10 Batch 5:  Loss:     1.0897 Validation Accuracy: 0.584800\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss:     1.0765 Validation Accuracy: 0.583000\n",
      "Epoch 283, CIFAR-10 Batch 2:  Loss:     1.0929 Validation Accuracy: 0.584200\n",
      "Epoch 283, CIFAR-10 Batch 3:  Loss:     1.0687 Validation Accuracy: 0.584800\n",
      "Epoch 283, CIFAR-10 Batch 4:  Loss:     1.0898 Validation Accuracy: 0.583600\n",
      "Epoch 283, CIFAR-10 Batch 5:  Loss:     1.0890 Validation Accuracy: 0.585400\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss:     1.0758 Validation Accuracy: 0.583200\n",
      "Epoch 284, CIFAR-10 Batch 2:  Loss:     1.0922 Validation Accuracy: 0.585000\n",
      "Epoch 284, CIFAR-10 Batch 3:  Loss:     1.0681 Validation Accuracy: 0.584400\n",
      "Epoch 284, CIFAR-10 Batch 4:  Loss:     1.0891 Validation Accuracy: 0.583600\n",
      "Epoch 284, CIFAR-10 Batch 5:  Loss:     1.0882 Validation Accuracy: 0.586400\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss:     1.0751 Validation Accuracy: 0.583200\n",
      "Epoch 285, CIFAR-10 Batch 2:  Loss:     1.0915 Validation Accuracy: 0.585600\n",
      "Epoch 285, CIFAR-10 Batch 3:  Loss:     1.0673 Validation Accuracy: 0.584400\n",
      "Epoch 285, CIFAR-10 Batch 4:  Loss:     1.0884 Validation Accuracy: 0.583800\n",
      "Epoch 285, CIFAR-10 Batch 5:  Loss:     1.0875 Validation Accuracy: 0.586600\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss:     1.0744 Validation Accuracy: 0.583400\n",
      "Epoch 286, CIFAR-10 Batch 2:  Loss:     1.0908 Validation Accuracy: 0.585800\n",
      "Epoch 286, CIFAR-10 Batch 3:  Loss:     1.0667 Validation Accuracy: 0.584800\n",
      "Epoch 286, CIFAR-10 Batch 4:  Loss:     1.0878 Validation Accuracy: 0.583800\n",
      "Epoch 286, CIFAR-10 Batch 5:  Loss:     1.0868 Validation Accuracy: 0.586800\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss:     1.0737 Validation Accuracy: 0.584400\n",
      "Epoch 287, CIFAR-10 Batch 2:  Loss:     1.0901 Validation Accuracy: 0.585600\n",
      "Epoch 287, CIFAR-10 Batch 3:  Loss:     1.0660 Validation Accuracy: 0.584800\n",
      "Epoch 287, CIFAR-10 Batch 4:  Loss:     1.0871 Validation Accuracy: 0.584800\n",
      "Epoch 287, CIFAR-10 Batch 5:  Loss:     1.0861 Validation Accuracy: 0.586800\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss:     1.0731 Validation Accuracy: 0.585000\n",
      "Epoch 288, CIFAR-10 Batch 2:  Loss:     1.0894 Validation Accuracy: 0.586000\n",
      "Epoch 288, CIFAR-10 Batch 3:  Loss:     1.0653 Validation Accuracy: 0.585200\n",
      "Epoch 288, CIFAR-10 Batch 4:  Loss:     1.0864 Validation Accuracy: 0.585200\n",
      "Epoch 288, CIFAR-10 Batch 5:  Loss:     1.0854 Validation Accuracy: 0.586800\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss:     1.0724 Validation Accuracy: 0.585400\n",
      "Epoch 289, CIFAR-10 Batch 2:  Loss:     1.0886 Validation Accuracy: 0.586000\n",
      "Epoch 289, CIFAR-10 Batch 3:  Loss:     1.0645 Validation Accuracy: 0.585800\n",
      "Epoch 289, CIFAR-10 Batch 4:  Loss:     1.0858 Validation Accuracy: 0.586000\n",
      "Epoch 289, CIFAR-10 Batch 5:  Loss:     1.0847 Validation Accuracy: 0.587000\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss:     1.0717 Validation Accuracy: 0.585400\n",
      "Epoch 290, CIFAR-10 Batch 2:  Loss:     1.0879 Validation Accuracy: 0.585600\n",
      "Epoch 290, CIFAR-10 Batch 3:  Loss:     1.0638 Validation Accuracy: 0.586400\n",
      "Epoch 290, CIFAR-10 Batch 4:  Loss:     1.0851 Validation Accuracy: 0.586400\n",
      "Epoch 290, CIFAR-10 Batch 5:  Loss:     1.0839 Validation Accuracy: 0.587200\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss:     1.0710 Validation Accuracy: 0.585000\n",
      "Epoch 291, CIFAR-10 Batch 2:  Loss:     1.0871 Validation Accuracy: 0.585800\n",
      "Epoch 291, CIFAR-10 Batch 3:  Loss:     1.0631 Validation Accuracy: 0.586800\n",
      "Epoch 291, CIFAR-10 Batch 4:  Loss:     1.0844 Validation Accuracy: 0.586200\n",
      "Epoch 291, CIFAR-10 Batch 5:  Loss:     1.0831 Validation Accuracy: 0.587600\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss:     1.0703 Validation Accuracy: 0.585200\n",
      "Epoch 292, CIFAR-10 Batch 2:  Loss:     1.0865 Validation Accuracy: 0.586000\n",
      "Epoch 292, CIFAR-10 Batch 3:  Loss:     1.0624 Validation Accuracy: 0.586800\n",
      "Epoch 292, CIFAR-10 Batch 4:  Loss:     1.0837 Validation Accuracy: 0.586000\n",
      "Epoch 292, CIFAR-10 Batch 5:  Loss:     1.0824 Validation Accuracy: 0.588200\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss:     1.0697 Validation Accuracy: 0.586400\n",
      "Epoch 293, CIFAR-10 Batch 2:  Loss:     1.0858 Validation Accuracy: 0.586000\n",
      "Epoch 293, CIFAR-10 Batch 3:  Loss:     1.0617 Validation Accuracy: 0.587200\n",
      "Epoch 293, CIFAR-10 Batch 4:  Loss:     1.0830 Validation Accuracy: 0.585800\n",
      "Epoch 293, CIFAR-10 Batch 5:  Loss:     1.0817 Validation Accuracy: 0.588200\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss:     1.0691 Validation Accuracy: 0.587000\n",
      "Epoch 294, CIFAR-10 Batch 2:  Loss:     1.0851 Validation Accuracy: 0.586400\n",
      "Epoch 294, CIFAR-10 Batch 3:  Loss:     1.0610 Validation Accuracy: 0.587000\n",
      "Epoch 294, CIFAR-10 Batch 4:  Loss:     1.0824 Validation Accuracy: 0.586400\n",
      "Epoch 294, CIFAR-10 Batch 5:  Loss:     1.0810 Validation Accuracy: 0.588400\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss:     1.0684 Validation Accuracy: 0.587000\n",
      "Epoch 295, CIFAR-10 Batch 2:  Loss:     1.0844 Validation Accuracy: 0.586400\n",
      "Epoch 295, CIFAR-10 Batch 3:  Loss:     1.0603 Validation Accuracy: 0.586800\n",
      "Epoch 295, CIFAR-10 Batch 4:  Loss:     1.0817 Validation Accuracy: 0.586400\n",
      "Epoch 295, CIFAR-10 Batch 5:  Loss:     1.0803 Validation Accuracy: 0.588400\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss:     1.0678 Validation Accuracy: 0.587000\n",
      "Epoch 296, CIFAR-10 Batch 2:  Loss:     1.0836 Validation Accuracy: 0.586400\n",
      "Epoch 296, CIFAR-10 Batch 3:  Loss:     1.0596 Validation Accuracy: 0.587400\n",
      "Epoch 296, CIFAR-10 Batch 4:  Loss:     1.0811 Validation Accuracy: 0.586000\n",
      "Epoch 296, CIFAR-10 Batch 5:  Loss:     1.0795 Validation Accuracy: 0.588400\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss:     1.0671 Validation Accuracy: 0.587800\n",
      "Epoch 297, CIFAR-10 Batch 2:  Loss:     1.0829 Validation Accuracy: 0.587200\n",
      "Epoch 297, CIFAR-10 Batch 3:  Loss:     1.0589 Validation Accuracy: 0.587600\n",
      "Epoch 297, CIFAR-10 Batch 4:  Loss:     1.0804 Validation Accuracy: 0.586200\n",
      "Epoch 297, CIFAR-10 Batch 5:  Loss:     1.0788 Validation Accuracy: 0.588000\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss:     1.0665 Validation Accuracy: 0.587400\n",
      "Epoch 298, CIFAR-10 Batch 2:  Loss:     1.0822 Validation Accuracy: 0.587400\n",
      "Epoch 298, CIFAR-10 Batch 3:  Loss:     1.0582 Validation Accuracy: 0.588200\n",
      "Epoch 298, CIFAR-10 Batch 4:  Loss:     1.0798 Validation Accuracy: 0.586600\n",
      "Epoch 298, CIFAR-10 Batch 5:  Loss:     1.0781 Validation Accuracy: 0.587600\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss:     1.0658 Validation Accuracy: 0.587800\n",
      "Epoch 299, CIFAR-10 Batch 2:  Loss:     1.0815 Validation Accuracy: 0.587600\n",
      "Epoch 299, CIFAR-10 Batch 3:  Loss:     1.0575 Validation Accuracy: 0.588400\n",
      "Epoch 299, CIFAR-10 Batch 4:  Loss:     1.0792 Validation Accuracy: 0.586800\n",
      "Epoch 299, CIFAR-10 Batch 5:  Loss:     1.0774 Validation Accuracy: 0.588000\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss:     1.0652 Validation Accuracy: 0.587800\n",
      "Epoch 300, CIFAR-10 Batch 2:  Loss:     1.0808 Validation Accuracy: 0.587400\n",
      "Epoch 300, CIFAR-10 Batch 3:  Loss:     1.0569 Validation Accuracy: 0.588200\n",
      "Epoch 300, CIFAR-10 Batch 4:  Loss:     1.0785 Validation Accuracy: 0.587000\n",
      "Epoch 300, CIFAR-10 Batch 5:  Loss:     1.0767 Validation Accuracy: 0.587400\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss:     1.0646 Validation Accuracy: 0.588200\n",
      "Epoch 301, CIFAR-10 Batch 2:  Loss:     1.0801 Validation Accuracy: 0.587000\n",
      "Epoch 301, CIFAR-10 Batch 3:  Loss:     1.0562 Validation Accuracy: 0.588600\n",
      "Epoch 301, CIFAR-10 Batch 4:  Loss:     1.0778 Validation Accuracy: 0.587400\n",
      "Epoch 301, CIFAR-10 Batch 5:  Loss:     1.0760 Validation Accuracy: 0.588000\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss:     1.0639 Validation Accuracy: 0.587600\n",
      "Epoch 302, CIFAR-10 Batch 2:  Loss:     1.0794 Validation Accuracy: 0.587400\n",
      "Epoch 302, CIFAR-10 Batch 3:  Loss:     1.0555 Validation Accuracy: 0.588600\n",
      "Epoch 302, CIFAR-10 Batch 4:  Loss:     1.0772 Validation Accuracy: 0.587600\n",
      "Epoch 302, CIFAR-10 Batch 5:  Loss:     1.0753 Validation Accuracy: 0.588400\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss:     1.0632 Validation Accuracy: 0.588600\n",
      "Epoch 303, CIFAR-10 Batch 2:  Loss:     1.0786 Validation Accuracy: 0.587400\n",
      "Epoch 303, CIFAR-10 Batch 3:  Loss:     1.0548 Validation Accuracy: 0.588800\n",
      "Epoch 303, CIFAR-10 Batch 4:  Loss:     1.0765 Validation Accuracy: 0.587800\n",
      "Epoch 303, CIFAR-10 Batch 5:  Loss:     1.0745 Validation Accuracy: 0.588800\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss:     1.0625 Validation Accuracy: 0.588800\n",
      "Epoch 304, CIFAR-10 Batch 2:  Loss:     1.0779 Validation Accuracy: 0.587000\n",
      "Epoch 304, CIFAR-10 Batch 3:  Loss:     1.0541 Validation Accuracy: 0.589000\n",
      "Epoch 304, CIFAR-10 Batch 4:  Loss:     1.0758 Validation Accuracy: 0.588800\n",
      "Epoch 304, CIFAR-10 Batch 5:  Loss:     1.0738 Validation Accuracy: 0.589000\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss:     1.0618 Validation Accuracy: 0.588600\n",
      "Epoch 305, CIFAR-10 Batch 2:  Loss:     1.0772 Validation Accuracy: 0.587000\n",
      "Epoch 305, CIFAR-10 Batch 3:  Loss:     1.0534 Validation Accuracy: 0.589200\n",
      "Epoch 305, CIFAR-10 Batch 4:  Loss:     1.0751 Validation Accuracy: 0.589000\n",
      "Epoch 305, CIFAR-10 Batch 5:  Loss:     1.0731 Validation Accuracy: 0.588800\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss:     1.0612 Validation Accuracy: 0.588600\n",
      "Epoch 306, CIFAR-10 Batch 2:  Loss:     1.0764 Validation Accuracy: 0.587800\n",
      "Epoch 306, CIFAR-10 Batch 3:  Loss:     1.0527 Validation Accuracy: 0.589000\n",
      "Epoch 306, CIFAR-10 Batch 4:  Loss:     1.0744 Validation Accuracy: 0.589200\n",
      "Epoch 306, CIFAR-10 Batch 5:  Loss:     1.0724 Validation Accuracy: 0.588600\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss:     1.0606 Validation Accuracy: 0.588800\n",
      "Epoch 307, CIFAR-10 Batch 2:  Loss:     1.0757 Validation Accuracy: 0.587600\n",
      "Epoch 307, CIFAR-10 Batch 3:  Loss:     1.0521 Validation Accuracy: 0.588800\n",
      "Epoch 307, CIFAR-10 Batch 4:  Loss:     1.0737 Validation Accuracy: 0.589000\n",
      "Epoch 307, CIFAR-10 Batch 5:  Loss:     1.0717 Validation Accuracy: 0.588600\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss:     1.0600 Validation Accuracy: 0.589000\n",
      "Epoch 308, CIFAR-10 Batch 2:  Loss:     1.0749 Validation Accuracy: 0.588200\n",
      "Epoch 308, CIFAR-10 Batch 3:  Loss:     1.0514 Validation Accuracy: 0.588600\n",
      "Epoch 308, CIFAR-10 Batch 4:  Loss:     1.0730 Validation Accuracy: 0.589000\n",
      "Epoch 308, CIFAR-10 Batch 5:  Loss:     1.0711 Validation Accuracy: 0.588400\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss:     1.0594 Validation Accuracy: 0.589000\n",
      "Epoch 309, CIFAR-10 Batch 2:  Loss:     1.0742 Validation Accuracy: 0.588000\n",
      "Epoch 309, CIFAR-10 Batch 3:  Loss:     1.0508 Validation Accuracy: 0.588400\n",
      "Epoch 309, CIFAR-10 Batch 4:  Loss:     1.0723 Validation Accuracy: 0.589200\n",
      "Epoch 309, CIFAR-10 Batch 5:  Loss:     1.0705 Validation Accuracy: 0.588000\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss:     1.0587 Validation Accuracy: 0.589200\n",
      "Epoch 310, CIFAR-10 Batch 2:  Loss:     1.0734 Validation Accuracy: 0.588200\n",
      "Epoch 310, CIFAR-10 Batch 3:  Loss:     1.0501 Validation Accuracy: 0.588600\n",
      "Epoch 310, CIFAR-10 Batch 4:  Loss:     1.0716 Validation Accuracy: 0.589600\n",
      "Epoch 310, CIFAR-10 Batch 5:  Loss:     1.0698 Validation Accuracy: 0.587800\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss:     1.0580 Validation Accuracy: 0.589200\n",
      "Epoch 311, CIFAR-10 Batch 2:  Loss:     1.0726 Validation Accuracy: 0.588400\n",
      "Epoch 311, CIFAR-10 Batch 3:  Loss:     1.0495 Validation Accuracy: 0.588600\n",
      "Epoch 311, CIFAR-10 Batch 4:  Loss:     1.0709 Validation Accuracy: 0.590200\n",
      "Epoch 311, CIFAR-10 Batch 5:  Loss:     1.0692 Validation Accuracy: 0.588400\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss:     1.0573 Validation Accuracy: 0.589400\n",
      "Epoch 312, CIFAR-10 Batch 2:  Loss:     1.0719 Validation Accuracy: 0.588600\n",
      "Epoch 312, CIFAR-10 Batch 3:  Loss:     1.0489 Validation Accuracy: 0.587800\n",
      "Epoch 312, CIFAR-10 Batch 4:  Loss:     1.0703 Validation Accuracy: 0.590200\n",
      "Epoch 312, CIFAR-10 Batch 5:  Loss:     1.0685 Validation Accuracy: 0.588600\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss:     1.0566 Validation Accuracy: 0.589600\n",
      "Epoch 313, CIFAR-10 Batch 2:  Loss:     1.0712 Validation Accuracy: 0.588800\n",
      "Epoch 313, CIFAR-10 Batch 3:  Loss:     1.0483 Validation Accuracy: 0.587600\n",
      "Epoch 313, CIFAR-10 Batch 4:  Loss:     1.0696 Validation Accuracy: 0.590600\n",
      "Epoch 313, CIFAR-10 Batch 5:  Loss:     1.0679 Validation Accuracy: 0.589000\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss:     1.0560 Validation Accuracy: 0.589600\n",
      "Epoch 314, CIFAR-10 Batch 2:  Loss:     1.0704 Validation Accuracy: 0.589200\n",
      "Epoch 314, CIFAR-10 Batch 3:  Loss:     1.0476 Validation Accuracy: 0.587600\n",
      "Epoch 314, CIFAR-10 Batch 4:  Loss:     1.0689 Validation Accuracy: 0.590800\n",
      "Epoch 314, CIFAR-10 Batch 5:  Loss:     1.0672 Validation Accuracy: 0.589200\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss:     1.0553 Validation Accuracy: 0.589800\n",
      "Epoch 315, CIFAR-10 Batch 2:  Loss:     1.0697 Validation Accuracy: 0.589800\n",
      "Epoch 315, CIFAR-10 Batch 3:  Loss:     1.0470 Validation Accuracy: 0.587400\n",
      "Epoch 315, CIFAR-10 Batch 4:  Loss:     1.0682 Validation Accuracy: 0.591600\n",
      "Epoch 315, CIFAR-10 Batch 5:  Loss:     1.0666 Validation Accuracy: 0.588800\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss:     1.0546 Validation Accuracy: 0.590200\n",
      "Epoch 316, CIFAR-10 Batch 2:  Loss:     1.0690 Validation Accuracy: 0.589800\n",
      "Epoch 316, CIFAR-10 Batch 3:  Loss:     1.0464 Validation Accuracy: 0.587400\n",
      "Epoch 316, CIFAR-10 Batch 4:  Loss:     1.0675 Validation Accuracy: 0.591400\n",
      "Epoch 316, CIFAR-10 Batch 5:  Loss:     1.0659 Validation Accuracy: 0.588800\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss:     1.0540 Validation Accuracy: 0.590000\n",
      "Epoch 317, CIFAR-10 Batch 2:  Loss:     1.0682 Validation Accuracy: 0.590400\n",
      "Epoch 317, CIFAR-10 Batch 3:  Loss:     1.0458 Validation Accuracy: 0.587800\n",
      "Epoch 317, CIFAR-10 Batch 4:  Loss:     1.0668 Validation Accuracy: 0.591800\n",
      "Epoch 317, CIFAR-10 Batch 5:  Loss:     1.0653 Validation Accuracy: 0.588600\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss:     1.0532 Validation Accuracy: 0.589800\n",
      "Epoch 318, CIFAR-10 Batch 2:  Loss:     1.0675 Validation Accuracy: 0.590400\n",
      "Epoch 318, CIFAR-10 Batch 3:  Loss:     1.0452 Validation Accuracy: 0.588200\n",
      "Epoch 318, CIFAR-10 Batch 4:  Loss:     1.0662 Validation Accuracy: 0.592200\n",
      "Epoch 318, CIFAR-10 Batch 5:  Loss:     1.0646 Validation Accuracy: 0.589400\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss:     1.0525 Validation Accuracy: 0.590200\n",
      "Epoch 319, CIFAR-10 Batch 2:  Loss:     1.0668 Validation Accuracy: 0.589800\n",
      "Epoch 319, CIFAR-10 Batch 3:  Loss:     1.0446 Validation Accuracy: 0.588800\n",
      "Epoch 319, CIFAR-10 Batch 4:  Loss:     1.0654 Validation Accuracy: 0.592600\n",
      "Epoch 319, CIFAR-10 Batch 5:  Loss:     1.0639 Validation Accuracy: 0.590200\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss:     1.0518 Validation Accuracy: 0.590200\n",
      "Epoch 320, CIFAR-10 Batch 2:  Loss:     1.0661 Validation Accuracy: 0.589800\n",
      "Epoch 320, CIFAR-10 Batch 3:  Loss:     1.0440 Validation Accuracy: 0.589000\n",
      "Epoch 320, CIFAR-10 Batch 4:  Loss:     1.0648 Validation Accuracy: 0.593000\n",
      "Epoch 320, CIFAR-10 Batch 5:  Loss:     1.0633 Validation Accuracy: 0.590800\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss:     1.0512 Validation Accuracy: 0.590400\n",
      "Epoch 321, CIFAR-10 Batch 2:  Loss:     1.0654 Validation Accuracy: 0.589400\n",
      "Epoch 321, CIFAR-10 Batch 3:  Loss:     1.0434 Validation Accuracy: 0.588400\n",
      "Epoch 321, CIFAR-10 Batch 4:  Loss:     1.0641 Validation Accuracy: 0.593000\n",
      "Epoch 321, CIFAR-10 Batch 5:  Loss:     1.0626 Validation Accuracy: 0.590600\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss:     1.0505 Validation Accuracy: 0.590400\n",
      "Epoch 322, CIFAR-10 Batch 2:  Loss:     1.0648 Validation Accuracy: 0.589600\n",
      "Epoch 322, CIFAR-10 Batch 3:  Loss:     1.0428 Validation Accuracy: 0.589000\n",
      "Epoch 322, CIFAR-10 Batch 4:  Loss:     1.0634 Validation Accuracy: 0.593600\n",
      "Epoch 322, CIFAR-10 Batch 5:  Loss:     1.0620 Validation Accuracy: 0.590600\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss:     1.0499 Validation Accuracy: 0.590200\n",
      "Epoch 323, CIFAR-10 Batch 2:  Loss:     1.0641 Validation Accuracy: 0.590200\n",
      "Epoch 323, CIFAR-10 Batch 3:  Loss:     1.0422 Validation Accuracy: 0.589200\n",
      "Epoch 323, CIFAR-10 Batch 4:  Loss:     1.0627 Validation Accuracy: 0.593800\n",
      "Epoch 323, CIFAR-10 Batch 5:  Loss:     1.0613 Validation Accuracy: 0.590600\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss:     1.0492 Validation Accuracy: 0.590400\n",
      "Epoch 324, CIFAR-10 Batch 2:  Loss:     1.0634 Validation Accuracy: 0.590400\n",
      "Epoch 324, CIFAR-10 Batch 3:  Loss:     1.0416 Validation Accuracy: 0.589400\n",
      "Epoch 324, CIFAR-10 Batch 4:  Loss:     1.0619 Validation Accuracy: 0.594000\n",
      "Epoch 324, CIFAR-10 Batch 5:  Loss:     1.0606 Validation Accuracy: 0.590600\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss:     1.0485 Validation Accuracy: 0.590400\n",
      "Epoch 325, CIFAR-10 Batch 2:  Loss:     1.0627 Validation Accuracy: 0.590600\n",
      "Epoch 325, CIFAR-10 Batch 3:  Loss:     1.0409 Validation Accuracy: 0.589400\n",
      "Epoch 325, CIFAR-10 Batch 4:  Loss:     1.0611 Validation Accuracy: 0.593800\n",
      "Epoch 325, CIFAR-10 Batch 5:  Loss:     1.0599 Validation Accuracy: 0.590800\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss:     1.0479 Validation Accuracy: 0.590400\n",
      "Epoch 326, CIFAR-10 Batch 2:  Loss:     1.0620 Validation Accuracy: 0.590800\n",
      "Epoch 326, CIFAR-10 Batch 3:  Loss:     1.0403 Validation Accuracy: 0.590000\n",
      "Epoch 326, CIFAR-10 Batch 4:  Loss:     1.0603 Validation Accuracy: 0.594400\n",
      "Epoch 326, CIFAR-10 Batch 5:  Loss:     1.0593 Validation Accuracy: 0.591000\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss:     1.0473 Validation Accuracy: 0.590200\n",
      "Epoch 327, CIFAR-10 Batch 2:  Loss:     1.0613 Validation Accuracy: 0.590600\n",
      "Epoch 327, CIFAR-10 Batch 3:  Loss:     1.0397 Validation Accuracy: 0.589800\n",
      "Epoch 327, CIFAR-10 Batch 4:  Loss:     1.0596 Validation Accuracy: 0.594800\n",
      "Epoch 327, CIFAR-10 Batch 5:  Loss:     1.0586 Validation Accuracy: 0.591000\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss:     1.0467 Validation Accuracy: 0.591000\n",
      "Epoch 328, CIFAR-10 Batch 2:  Loss:     1.0606 Validation Accuracy: 0.590400\n",
      "Epoch 328, CIFAR-10 Batch 3:  Loss:     1.0390 Validation Accuracy: 0.590200\n",
      "Epoch 328, CIFAR-10 Batch 4:  Loss:     1.0588 Validation Accuracy: 0.595200\n",
      "Epoch 328, CIFAR-10 Batch 5:  Loss:     1.0580 Validation Accuracy: 0.591800\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss:     1.0460 Validation Accuracy: 0.591400\n",
      "Epoch 329, CIFAR-10 Batch 2:  Loss:     1.0599 Validation Accuracy: 0.590000\n",
      "Epoch 329, CIFAR-10 Batch 3:  Loss:     1.0384 Validation Accuracy: 0.590600\n",
      "Epoch 329, CIFAR-10 Batch 4:  Loss:     1.0581 Validation Accuracy: 0.595000\n",
      "Epoch 329, CIFAR-10 Batch 5:  Loss:     1.0574 Validation Accuracy: 0.591600\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss:     1.0454 Validation Accuracy: 0.591600\n",
      "Epoch 330, CIFAR-10 Batch 2:  Loss:     1.0593 Validation Accuracy: 0.591000\n",
      "Epoch 330, CIFAR-10 Batch 3:  Loss:     1.0377 Validation Accuracy: 0.591000\n",
      "Epoch 330, CIFAR-10 Batch 4:  Loss:     1.0574 Validation Accuracy: 0.594600\n",
      "Epoch 330, CIFAR-10 Batch 5:  Loss:     1.0568 Validation Accuracy: 0.591200\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss:     1.0448 Validation Accuracy: 0.591600\n",
      "Epoch 331, CIFAR-10 Batch 2:  Loss:     1.0586 Validation Accuracy: 0.591200\n",
      "Epoch 331, CIFAR-10 Batch 3:  Loss:     1.0371 Validation Accuracy: 0.591400\n",
      "Epoch 331, CIFAR-10 Batch 4:  Loss:     1.0566 Validation Accuracy: 0.595400\n",
      "Epoch 331, CIFAR-10 Batch 5:  Loss:     1.0562 Validation Accuracy: 0.590800\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss:     1.0441 Validation Accuracy: 0.592000\n",
      "Epoch 332, CIFAR-10 Batch 2:  Loss:     1.0580 Validation Accuracy: 0.592400\n",
      "Epoch 332, CIFAR-10 Batch 3:  Loss:     1.0365 Validation Accuracy: 0.591800\n",
      "Epoch 332, CIFAR-10 Batch 4:  Loss:     1.0559 Validation Accuracy: 0.596000\n",
      "Epoch 332, CIFAR-10 Batch 5:  Loss:     1.0557 Validation Accuracy: 0.590200\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss:     1.0435 Validation Accuracy: 0.592000\n",
      "Epoch 333, CIFAR-10 Batch 2:  Loss:     1.0573 Validation Accuracy: 0.592800\n",
      "Epoch 333, CIFAR-10 Batch 3:  Loss:     1.0359 Validation Accuracy: 0.591800\n",
      "Epoch 333, CIFAR-10 Batch 4:  Loss:     1.0553 Validation Accuracy: 0.596200\n",
      "Epoch 333, CIFAR-10 Batch 5:  Loss:     1.0551 Validation Accuracy: 0.590200\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss:     1.0429 Validation Accuracy: 0.592800\n",
      "Epoch 334, CIFAR-10 Batch 2:  Loss:     1.0567 Validation Accuracy: 0.592400\n",
      "Epoch 334, CIFAR-10 Batch 3:  Loss:     1.0354 Validation Accuracy: 0.591600\n",
      "Epoch 334, CIFAR-10 Batch 4:  Loss:     1.0547 Validation Accuracy: 0.596200\n",
      "Epoch 334, CIFAR-10 Batch 5:  Loss:     1.0547 Validation Accuracy: 0.590400\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss:     1.0424 Validation Accuracy: 0.592800\n",
      "Epoch 335, CIFAR-10 Batch 2:  Loss:     1.0561 Validation Accuracy: 0.592200\n",
      "Epoch 335, CIFAR-10 Batch 3:  Loss:     1.0348 Validation Accuracy: 0.591400\n",
      "Epoch 335, CIFAR-10 Batch 4:  Loss:     1.0541 Validation Accuracy: 0.596400\n",
      "Epoch 335, CIFAR-10 Batch 5:  Loss:     1.0542 Validation Accuracy: 0.590200\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss:     1.0417 Validation Accuracy: 0.592800\n",
      "Epoch 336, CIFAR-10 Batch 2:  Loss:     1.0553 Validation Accuracy: 0.592600\n",
      "Epoch 336, CIFAR-10 Batch 3:  Loss:     1.0342 Validation Accuracy: 0.591600\n",
      "Epoch 336, CIFAR-10 Batch 4:  Loss:     1.0536 Validation Accuracy: 0.596000\n",
      "Epoch 336, CIFAR-10 Batch 5:  Loss:     1.0537 Validation Accuracy: 0.591200\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss:     1.0410 Validation Accuracy: 0.592800\n",
      "Epoch 337, CIFAR-10 Batch 2:  Loss:     1.0546 Validation Accuracy: 0.592600\n",
      "Epoch 337, CIFAR-10 Batch 3:  Loss:     1.0336 Validation Accuracy: 0.591600\n",
      "Epoch 337, CIFAR-10 Batch 4:  Loss:     1.0532 Validation Accuracy: 0.596000\n",
      "Epoch 337, CIFAR-10 Batch 5:  Loss:     1.0532 Validation Accuracy: 0.591000\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss:     1.0403 Validation Accuracy: 0.592600\n",
      "Epoch 338, CIFAR-10 Batch 2:  Loss:     1.0540 Validation Accuracy: 0.593200\n",
      "Epoch 338, CIFAR-10 Batch 3:  Loss:     1.0331 Validation Accuracy: 0.592600\n",
      "Epoch 338, CIFAR-10 Batch 4:  Loss:     1.0527 Validation Accuracy: 0.596400\n",
      "Epoch 338, CIFAR-10 Batch 5:  Loss:     1.0528 Validation Accuracy: 0.591000\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss:     1.0397 Validation Accuracy: 0.592800\n",
      "Epoch 339, CIFAR-10 Batch 2:  Loss:     1.0533 Validation Accuracy: 0.594000\n",
      "Epoch 339, CIFAR-10 Batch 3:  Loss:     1.0326 Validation Accuracy: 0.592000\n",
      "Epoch 339, CIFAR-10 Batch 4:  Loss:     1.0524 Validation Accuracy: 0.596800\n",
      "Epoch 339, CIFAR-10 Batch 5:  Loss:     1.0523 Validation Accuracy: 0.591000\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss:     1.0390 Validation Accuracy: 0.593000\n",
      "Epoch 340, CIFAR-10 Batch 2:  Loss:     1.0526 Validation Accuracy: 0.593400\n",
      "Epoch 340, CIFAR-10 Batch 3:  Loss:     1.0322 Validation Accuracy: 0.591600\n",
      "Epoch 340, CIFAR-10 Batch 4:  Loss:     1.0523 Validation Accuracy: 0.597000\n",
      "Epoch 340, CIFAR-10 Batch 5:  Loss:     1.0519 Validation Accuracy: 0.591600\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss:     1.0383 Validation Accuracy: 0.593800\n",
      "Epoch 341, CIFAR-10 Batch 2:  Loss:     1.0520 Validation Accuracy: 0.593200\n",
      "Epoch 341, CIFAR-10 Batch 3:  Loss:     1.0318 Validation Accuracy: 0.591800\n",
      "Epoch 341, CIFAR-10 Batch 4:  Loss:     1.0522 Validation Accuracy: 0.595400\n",
      "Epoch 341, CIFAR-10 Batch 5:  Loss:     1.0513 Validation Accuracy: 0.592200\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss:     1.0376 Validation Accuracy: 0.594200\n",
      "Epoch 342, CIFAR-10 Batch 2:  Loss:     1.0515 Validation Accuracy: 0.594000\n",
      "Epoch 342, CIFAR-10 Batch 3:  Loss:     1.0317 Validation Accuracy: 0.592400\n",
      "Epoch 342, CIFAR-10 Batch 4:  Loss:     1.0522 Validation Accuracy: 0.594800\n",
      "Epoch 342, CIFAR-10 Batch 5:  Loss:     1.0507 Validation Accuracy: 0.592000\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss:     1.0368 Validation Accuracy: 0.595400\n",
      "Epoch 343, CIFAR-10 Batch 2:  Loss:     1.0511 Validation Accuracy: 0.595800\n",
      "Epoch 343, CIFAR-10 Batch 3:  Loss:     1.0317 Validation Accuracy: 0.592800\n",
      "Epoch 343, CIFAR-10 Batch 4:  Loss:     1.0522 Validation Accuracy: 0.594200\n",
      "Epoch 343, CIFAR-10 Batch 5:  Loss:     1.0499 Validation Accuracy: 0.592000\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss:     1.0362 Validation Accuracy: 0.595400\n",
      "Epoch 344, CIFAR-10 Batch 2:  Loss:     1.0509 Validation Accuracy: 0.596000\n",
      "Epoch 344, CIFAR-10 Batch 3:  Loss:     1.0319 Validation Accuracy: 0.592200\n",
      "Epoch 344, CIFAR-10 Batch 4:  Loss:     1.0520 Validation Accuracy: 0.593800\n",
      "Epoch 344, CIFAR-10 Batch 5:  Loss:     1.0490 Validation Accuracy: 0.592000\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss:     1.0358 Validation Accuracy: 0.596000\n",
      "Epoch 345, CIFAR-10 Batch 2:  Loss:     1.0510 Validation Accuracy: 0.595400\n",
      "Epoch 345, CIFAR-10 Batch 3:  Loss:     1.0320 Validation Accuracy: 0.591200\n",
      "Epoch 345, CIFAR-10 Batch 4:  Loss:     1.0513 Validation Accuracy: 0.594400\n",
      "Epoch 345, CIFAR-10 Batch 5:  Loss:     1.0479 Validation Accuracy: 0.592800\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss:     1.0357 Validation Accuracy: 0.595400\n",
      "Epoch 346, CIFAR-10 Batch 2:  Loss:     1.0513 Validation Accuracy: 0.594800\n",
      "Epoch 346, CIFAR-10 Batch 3:  Loss:     1.0318 Validation Accuracy: 0.591000\n",
      "Epoch 346, CIFAR-10 Batch 4:  Loss:     1.0498 Validation Accuracy: 0.595800\n",
      "Epoch 346, CIFAR-10 Batch 5:  Loss:     1.0468 Validation Accuracy: 0.593600\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss:     1.0358 Validation Accuracy: 0.597200\n",
      "Epoch 347, CIFAR-10 Batch 2:  Loss:     1.0514 Validation Accuracy: 0.593800\n",
      "Epoch 347, CIFAR-10 Batch 3:  Loss:     1.0307 Validation Accuracy: 0.592000\n",
      "Epoch 347, CIFAR-10 Batch 4:  Loss:     1.0477 Validation Accuracy: 0.597600\n",
      "Epoch 347, CIFAR-10 Batch 5:  Loss:     1.0459 Validation Accuracy: 0.594200\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss:     1.0360 Validation Accuracy: 0.595800\n",
      "Epoch 348, CIFAR-10 Batch 2:  Loss:     1.0508 Validation Accuracy: 0.593800\n",
      "Epoch 348, CIFAR-10 Batch 3:  Loss:     1.0288 Validation Accuracy: 0.592800\n",
      "Epoch 348, CIFAR-10 Batch 4:  Loss:     1.0455 Validation Accuracy: 0.598400\n",
      "Epoch 348, CIFAR-10 Batch 5:  Loss:     1.0455 Validation Accuracy: 0.595400\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss:     1.0354 Validation Accuracy: 0.596000\n",
      "Epoch 349, CIFAR-10 Batch 2:  Loss:     1.0490 Validation Accuracy: 0.596800\n",
      "Epoch 349, CIFAR-10 Batch 3:  Loss:     1.0266 Validation Accuracy: 0.593600\n",
      "Epoch 349, CIFAR-10 Batch 4:  Loss:     1.0440 Validation Accuracy: 0.596600\n",
      "Epoch 349, CIFAR-10 Batch 5:  Loss:     1.0451 Validation Accuracy: 0.595000\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss:     1.0339 Validation Accuracy: 0.596600\n",
      "Epoch 350, CIFAR-10 Batch 2:  Loss:     1.0468 Validation Accuracy: 0.596000\n",
      "Epoch 350, CIFAR-10 Batch 3:  Loss:     1.0252 Validation Accuracy: 0.593400\n",
      "Epoch 350, CIFAR-10 Batch 4:  Loss:     1.0433 Validation Accuracy: 0.597200\n",
      "Epoch 350, CIFAR-10 Batch 5:  Loss:     1.0444 Validation Accuracy: 0.595200\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss:     1.0321 Validation Accuracy: 0.596600\n",
      "Epoch 351, CIFAR-10 Batch 2:  Loss:     1.0455 Validation Accuracy: 0.595600\n",
      "Epoch 351, CIFAR-10 Batch 3:  Loss:     1.0248 Validation Accuracy: 0.596200\n",
      "Epoch 351, CIFAR-10 Batch 4:  Loss:     1.0429 Validation Accuracy: 0.595600\n",
      "Epoch 351, CIFAR-10 Batch 5:  Loss:     1.0435 Validation Accuracy: 0.595800\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss:     1.0308 Validation Accuracy: 0.597400\n",
      "Epoch 352, CIFAR-10 Batch 2:  Loss:     1.0450 Validation Accuracy: 0.594200\n",
      "Epoch 352, CIFAR-10 Batch 3:  Loss:     1.0249 Validation Accuracy: 0.596400\n",
      "Epoch 352, CIFAR-10 Batch 4:  Loss:     1.0425 Validation Accuracy: 0.595400\n",
      "Epoch 352, CIFAR-10 Batch 5:  Loss:     1.0428 Validation Accuracy: 0.595800\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss:     1.0302 Validation Accuracy: 0.597200\n",
      "Epoch 353, CIFAR-10 Batch 2:  Loss:     1.0450 Validation Accuracy: 0.596400\n",
      "Epoch 353, CIFAR-10 Batch 3:  Loss:     1.0252 Validation Accuracy: 0.596200\n",
      "Epoch 353, CIFAR-10 Batch 4:  Loss:     1.0421 Validation Accuracy: 0.595000\n",
      "Epoch 353, CIFAR-10 Batch 5:  Loss:     1.0422 Validation Accuracy: 0.594400\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss:     1.0301 Validation Accuracy: 0.596200\n",
      "Epoch 354, CIFAR-10 Batch 2:  Loss:     1.0451 Validation Accuracy: 0.595800\n",
      "Epoch 354, CIFAR-10 Batch 3:  Loss:     1.0251 Validation Accuracy: 0.595000\n",
      "Epoch 354, CIFAR-10 Batch 4:  Loss:     1.0415 Validation Accuracy: 0.595400\n",
      "Epoch 354, CIFAR-10 Batch 5:  Loss:     1.0419 Validation Accuracy: 0.595000\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss:     1.0299 Validation Accuracy: 0.596400\n",
      "Epoch 355, CIFAR-10 Batch 2:  Loss:     1.0449 Validation Accuracy: 0.595200\n",
      "Epoch 355, CIFAR-10 Batch 3:  Loss:     1.0246 Validation Accuracy: 0.594800\n",
      "Epoch 355, CIFAR-10 Batch 4:  Loss:     1.0406 Validation Accuracy: 0.595600\n",
      "Epoch 355, CIFAR-10 Batch 5:  Loss:     1.0415 Validation Accuracy: 0.594200\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss:     1.0295 Validation Accuracy: 0.596400\n",
      "Epoch 356, CIFAR-10 Batch 2:  Loss:     1.0442 Validation Accuracy: 0.594600\n",
      "Epoch 356, CIFAR-10 Batch 3:  Loss:     1.0238 Validation Accuracy: 0.594800\n",
      "Epoch 356, CIFAR-10 Batch 4:  Loss:     1.0398 Validation Accuracy: 0.598200\n",
      "Epoch 356, CIFAR-10 Batch 5:  Loss:     1.0411 Validation Accuracy: 0.594000\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss:     1.0289 Validation Accuracy: 0.596600\n",
      "Epoch 357, CIFAR-10 Batch 2:  Loss:     1.0433 Validation Accuracy: 0.595600\n",
      "Epoch 357, CIFAR-10 Batch 3:  Loss:     1.0229 Validation Accuracy: 0.596400\n",
      "Epoch 357, CIFAR-10 Batch 4:  Loss:     1.0392 Validation Accuracy: 0.599200\n",
      "Epoch 357, CIFAR-10 Batch 5:  Loss:     1.0408 Validation Accuracy: 0.596200\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss:     1.0283 Validation Accuracy: 0.596600\n",
      "Epoch 358, CIFAR-10 Batch 2:  Loss:     1.0423 Validation Accuracy: 0.596400\n",
      "Epoch 358, CIFAR-10 Batch 3:  Loss:     1.0219 Validation Accuracy: 0.597400\n",
      "Epoch 358, CIFAR-10 Batch 4:  Loss:     1.0387 Validation Accuracy: 0.598600\n",
      "Epoch 358, CIFAR-10 Batch 5:  Loss:     1.0404 Validation Accuracy: 0.596400\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss:     1.0275 Validation Accuracy: 0.596200\n",
      "Epoch 359, CIFAR-10 Batch 2:  Loss:     1.0413 Validation Accuracy: 0.596600\n",
      "Epoch 359, CIFAR-10 Batch 3:  Loss:     1.0210 Validation Accuracy: 0.597800\n",
      "Epoch 359, CIFAR-10 Batch 4:  Loss:     1.0385 Validation Accuracy: 0.599400\n",
      "Epoch 359, CIFAR-10 Batch 5:  Loss:     1.0400 Validation Accuracy: 0.596400\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss:     1.0267 Validation Accuracy: 0.596800\n",
      "Epoch 360, CIFAR-10 Batch 2:  Loss:     1.0404 Validation Accuracy: 0.596600\n",
      "Epoch 360, CIFAR-10 Batch 3:  Loss:     1.0204 Validation Accuracy: 0.597200\n",
      "Epoch 360, CIFAR-10 Batch 4:  Loss:     1.0385 Validation Accuracy: 0.598600\n",
      "Epoch 360, CIFAR-10 Batch 5:  Loss:     1.0396 Validation Accuracy: 0.596200\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss:     1.0260 Validation Accuracy: 0.597400\n",
      "Epoch 361, CIFAR-10 Batch 2:  Loss:     1.0396 Validation Accuracy: 0.596800\n",
      "Epoch 361, CIFAR-10 Batch 3:  Loss:     1.0200 Validation Accuracy: 0.596200\n",
      "Epoch 361, CIFAR-10 Batch 4:  Loss:     1.0385 Validation Accuracy: 0.599400\n",
      "Epoch 361, CIFAR-10 Batch 5:  Loss:     1.0391 Validation Accuracy: 0.596800\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss:     1.0252 Validation Accuracy: 0.597000\n",
      "Epoch 362, CIFAR-10 Batch 2:  Loss:     1.0390 Validation Accuracy: 0.596800\n",
      "Epoch 362, CIFAR-10 Batch 3:  Loss:     1.0198 Validation Accuracy: 0.596000\n",
      "Epoch 362, CIFAR-10 Batch 4:  Loss:     1.0385 Validation Accuracy: 0.600400\n",
      "Epoch 362, CIFAR-10 Batch 5:  Loss:     1.0384 Validation Accuracy: 0.596800\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss:     1.0245 Validation Accuracy: 0.597200\n",
      "Epoch 363, CIFAR-10 Batch 2:  Loss:     1.0386 Validation Accuracy: 0.597400\n",
      "Epoch 363, CIFAR-10 Batch 3:  Loss:     1.0196 Validation Accuracy: 0.596200\n",
      "Epoch 363, CIFAR-10 Batch 4:  Loss:     1.0384 Validation Accuracy: 0.599800\n",
      "Epoch 363, CIFAR-10 Batch 5:  Loss:     1.0377 Validation Accuracy: 0.597800\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss:     1.0239 Validation Accuracy: 0.596400\n",
      "Epoch 364, CIFAR-10 Batch 2:  Loss:     1.0383 Validation Accuracy: 0.599600\n",
      "Epoch 364, CIFAR-10 Batch 3:  Loss:     1.0195 Validation Accuracy: 0.596600\n",
      "Epoch 364, CIFAR-10 Batch 4:  Loss:     1.0381 Validation Accuracy: 0.600400\n",
      "Epoch 364, CIFAR-10 Batch 5:  Loss:     1.0368 Validation Accuracy: 0.597000\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss:     1.0234 Validation Accuracy: 0.598000\n",
      "Epoch 365, CIFAR-10 Batch 2:  Loss:     1.0382 Validation Accuracy: 0.599800\n",
      "Epoch 365, CIFAR-10 Batch 3:  Loss:     1.0192 Validation Accuracy: 0.595200\n",
      "Epoch 365, CIFAR-10 Batch 4:  Loss:     1.0374 Validation Accuracy: 0.600000\n",
      "Epoch 365, CIFAR-10 Batch 5:  Loss:     1.0359 Validation Accuracy: 0.597200\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss:     1.0230 Validation Accuracy: 0.598800\n",
      "Epoch 366, CIFAR-10 Batch 2:  Loss:     1.0380 Validation Accuracy: 0.600400\n",
      "Epoch 366, CIFAR-10 Batch 3:  Loss:     1.0187 Validation Accuracy: 0.595000\n",
      "Epoch 366, CIFAR-10 Batch 4:  Loss:     1.0364 Validation Accuracy: 0.599600\n",
      "Epoch 366, CIFAR-10 Batch 5:  Loss:     1.0350 Validation Accuracy: 0.597000\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss:     1.0227 Validation Accuracy: 0.599000\n",
      "Epoch 367, CIFAR-10 Batch 2:  Loss:     1.0376 Validation Accuracy: 0.600400\n",
      "Epoch 367, CIFAR-10 Batch 3:  Loss:     1.0178 Validation Accuracy: 0.595600\n",
      "Epoch 367, CIFAR-10 Batch 4:  Loss:     1.0351 Validation Accuracy: 0.600200\n",
      "Epoch 367, CIFAR-10 Batch 5:  Loss:     1.0342 Validation Accuracy: 0.596200\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss:     1.0222 Validation Accuracy: 0.600800\n",
      "Epoch 368, CIFAR-10 Batch 2:  Loss:     1.0369 Validation Accuracy: 0.600600\n",
      "Epoch 368, CIFAR-10 Batch 3:  Loss:     1.0166 Validation Accuracy: 0.596200\n",
      "Epoch 368, CIFAR-10 Batch 4:  Loss:     1.0338 Validation Accuracy: 0.599200\n",
      "Epoch 368, CIFAR-10 Batch 5:  Loss:     1.0334 Validation Accuracy: 0.598000\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss:     1.0216 Validation Accuracy: 0.600400\n",
      "Epoch 369, CIFAR-10 Batch 2:  Loss:     1.0361 Validation Accuracy: 0.600200\n",
      "Epoch 369, CIFAR-10 Batch 3:  Loss:     1.0155 Validation Accuracy: 0.597400\n",
      "Epoch 369, CIFAR-10 Batch 4:  Loss:     1.0326 Validation Accuracy: 0.598800\n",
      "Epoch 369, CIFAR-10 Batch 5:  Loss:     1.0327 Validation Accuracy: 0.598800\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss:     1.0208 Validation Accuracy: 0.599800\n",
      "Epoch 370, CIFAR-10 Batch 2:  Loss:     1.0351 Validation Accuracy: 0.600000\n",
      "Epoch 370, CIFAR-10 Batch 3:  Loss:     1.0145 Validation Accuracy: 0.598200\n",
      "Epoch 370, CIFAR-10 Batch 4:  Loss:     1.0317 Validation Accuracy: 0.599600\n",
      "Epoch 370, CIFAR-10 Batch 5:  Loss:     1.0321 Validation Accuracy: 0.598200\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss:     1.0200 Validation Accuracy: 0.600600\n",
      "Epoch 371, CIFAR-10 Batch 2:  Loss:     1.0342 Validation Accuracy: 0.599400\n",
      "Epoch 371, CIFAR-10 Batch 3:  Loss:     1.0137 Validation Accuracy: 0.597600\n",
      "Epoch 371, CIFAR-10 Batch 4:  Loss:     1.0309 Validation Accuracy: 0.598400\n",
      "Epoch 371, CIFAR-10 Batch 5:  Loss:     1.0316 Validation Accuracy: 0.599200\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss:     1.0194 Validation Accuracy: 0.600400\n",
      "Epoch 372, CIFAR-10 Batch 2:  Loss:     1.0335 Validation Accuracy: 0.599800\n",
      "Epoch 372, CIFAR-10 Batch 3:  Loss:     1.0131 Validation Accuracy: 0.597800\n",
      "Epoch 372, CIFAR-10 Batch 4:  Loss:     1.0302 Validation Accuracy: 0.599600\n",
      "Epoch 372, CIFAR-10 Batch 5:  Loss:     1.0311 Validation Accuracy: 0.599600\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss:     1.0187 Validation Accuracy: 0.600200\n",
      "Epoch 373, CIFAR-10 Batch 2:  Loss:     1.0329 Validation Accuracy: 0.598600\n",
      "Epoch 373, CIFAR-10 Batch 3:  Loss:     1.0127 Validation Accuracy: 0.599000\n",
      "Epoch 373, CIFAR-10 Batch 4:  Loss:     1.0297 Validation Accuracy: 0.598600\n",
      "Epoch 373, CIFAR-10 Batch 5:  Loss:     1.0307 Validation Accuracy: 0.599800\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss:     1.0181 Validation Accuracy: 0.600400\n",
      "Epoch 374, CIFAR-10 Batch 2:  Loss:     1.0324 Validation Accuracy: 0.598400\n",
      "Epoch 374, CIFAR-10 Batch 3:  Loss:     1.0124 Validation Accuracy: 0.599800\n",
      "Epoch 374, CIFAR-10 Batch 4:  Loss:     1.0292 Validation Accuracy: 0.598000\n",
      "Epoch 374, CIFAR-10 Batch 5:  Loss:     1.0302 Validation Accuracy: 0.599800\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss:     1.0175 Validation Accuracy: 0.600600\n",
      "Epoch 375, CIFAR-10 Batch 2:  Loss:     1.0320 Validation Accuracy: 0.598800\n",
      "Epoch 375, CIFAR-10 Batch 3:  Loss:     1.0121 Validation Accuracy: 0.600000\n",
      "Epoch 375, CIFAR-10 Batch 4:  Loss:     1.0287 Validation Accuracy: 0.598000\n",
      "Epoch 375, CIFAR-10 Batch 5:  Loss:     1.0297 Validation Accuracy: 0.599400\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss:     1.0169 Validation Accuracy: 0.600400\n",
      "Epoch 376, CIFAR-10 Batch 2:  Loss:     1.0316 Validation Accuracy: 0.599000\n",
      "Epoch 376, CIFAR-10 Batch 3:  Loss:     1.0119 Validation Accuracy: 0.600200\n",
      "Epoch 376, CIFAR-10 Batch 4:  Loss:     1.0283 Validation Accuracy: 0.598000\n",
      "Epoch 376, CIFAR-10 Batch 5:  Loss:     1.0292 Validation Accuracy: 0.598800\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss:     1.0163 Validation Accuracy: 0.599600\n",
      "Epoch 377, CIFAR-10 Batch 2:  Loss:     1.0312 Validation Accuracy: 0.598600\n",
      "Epoch 377, CIFAR-10 Batch 3:  Loss:     1.0117 Validation Accuracy: 0.600400\n",
      "Epoch 377, CIFAR-10 Batch 4:  Loss:     1.0277 Validation Accuracy: 0.598200\n",
      "Epoch 377, CIFAR-10 Batch 5:  Loss:     1.0287 Validation Accuracy: 0.599200\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss:     1.0158 Validation Accuracy: 0.599400\n",
      "Epoch 378, CIFAR-10 Batch 2:  Loss:     1.0308 Validation Accuracy: 0.599800\n",
      "Epoch 378, CIFAR-10 Batch 3:  Loss:     1.0114 Validation Accuracy: 0.601200\n",
      "Epoch 378, CIFAR-10 Batch 4:  Loss:     1.0271 Validation Accuracy: 0.598000\n",
      "Epoch 378, CIFAR-10 Batch 5:  Loss:     1.0282 Validation Accuracy: 0.599600\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss:     1.0152 Validation Accuracy: 0.600200\n",
      "Epoch 379, CIFAR-10 Batch 2:  Loss:     1.0304 Validation Accuracy: 0.599800\n",
      "Epoch 379, CIFAR-10 Batch 3:  Loss:     1.0110 Validation Accuracy: 0.601800\n",
      "Epoch 379, CIFAR-10 Batch 4:  Loss:     1.0264 Validation Accuracy: 0.597600\n",
      "Epoch 379, CIFAR-10 Batch 5:  Loss:     1.0277 Validation Accuracy: 0.599600\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss:     1.0146 Validation Accuracy: 0.600400\n",
      "Epoch 380, CIFAR-10 Batch 2:  Loss:     1.0298 Validation Accuracy: 0.601000\n",
      "Epoch 380, CIFAR-10 Batch 3:  Loss:     1.0105 Validation Accuracy: 0.602400\n",
      "Epoch 380, CIFAR-10 Batch 4:  Loss:     1.0258 Validation Accuracy: 0.598200\n",
      "Epoch 380, CIFAR-10 Batch 5:  Loss:     1.0272 Validation Accuracy: 0.600000\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss:     1.0140 Validation Accuracy: 0.598800\n",
      "Epoch 381, CIFAR-10 Batch 2:  Loss:     1.0292 Validation Accuracy: 0.601000\n",
      "Epoch 381, CIFAR-10 Batch 3:  Loss:     1.0099 Validation Accuracy: 0.602400\n",
      "Epoch 381, CIFAR-10 Batch 4:  Loss:     1.0252 Validation Accuracy: 0.597600\n",
      "Epoch 381, CIFAR-10 Batch 5:  Loss:     1.0266 Validation Accuracy: 0.600000\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss:     1.0135 Validation Accuracy: 0.599200\n",
      "Epoch 382, CIFAR-10 Batch 2:  Loss:     1.0287 Validation Accuracy: 0.601600\n",
      "Epoch 382, CIFAR-10 Batch 3:  Loss:     1.0094 Validation Accuracy: 0.602600\n",
      "Epoch 382, CIFAR-10 Batch 4:  Loss:     1.0245 Validation Accuracy: 0.598200\n",
      "Epoch 382, CIFAR-10 Batch 5:  Loss:     1.0262 Validation Accuracy: 0.601200\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss:     1.0130 Validation Accuracy: 0.599000\n",
      "Epoch 383, CIFAR-10 Batch 2:  Loss:     1.0281 Validation Accuracy: 0.601400\n",
      "Epoch 383, CIFAR-10 Batch 3:  Loss:     1.0088 Validation Accuracy: 0.603200\n",
      "Epoch 383, CIFAR-10 Batch 4:  Loss:     1.0239 Validation Accuracy: 0.599000\n",
      "Epoch 383, CIFAR-10 Batch 5:  Loss:     1.0258 Validation Accuracy: 0.601000\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss:     1.0125 Validation Accuracy: 0.598600\n",
      "Epoch 384, CIFAR-10 Batch 2:  Loss:     1.0275 Validation Accuracy: 0.601800\n",
      "Epoch 384, CIFAR-10 Batch 3:  Loss:     1.0081 Validation Accuracy: 0.603400\n",
      "Epoch 384, CIFAR-10 Batch 4:  Loss:     1.0234 Validation Accuracy: 0.599400\n",
      "Epoch 384, CIFAR-10 Batch 5:  Loss:     1.0254 Validation Accuracy: 0.601800\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss:     1.0120 Validation Accuracy: 0.597600\n",
      "Epoch 385, CIFAR-10 Batch 2:  Loss:     1.0269 Validation Accuracy: 0.602800\n",
      "Epoch 385, CIFAR-10 Batch 3:  Loss:     1.0075 Validation Accuracy: 0.603600\n",
      "Epoch 385, CIFAR-10 Batch 4:  Loss:     1.0229 Validation Accuracy: 0.599400\n",
      "Epoch 385, CIFAR-10 Batch 5:  Loss:     1.0251 Validation Accuracy: 0.600200\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss:     1.0116 Validation Accuracy: 0.597000\n",
      "Epoch 386, CIFAR-10 Batch 2:  Loss:     1.0263 Validation Accuracy: 0.602800\n",
      "Epoch 386, CIFAR-10 Batch 3:  Loss:     1.0069 Validation Accuracy: 0.604200\n",
      "Epoch 386, CIFAR-10 Batch 4:  Loss:     1.0225 Validation Accuracy: 0.598600\n",
      "Epoch 386, CIFAR-10 Batch 5:  Loss:     1.0249 Validation Accuracy: 0.600600\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss:     1.0112 Validation Accuracy: 0.598400\n",
      "Epoch 387, CIFAR-10 Batch 2:  Loss:     1.0256 Validation Accuracy: 0.603000\n",
      "Epoch 387, CIFAR-10 Batch 3:  Loss:     1.0062 Validation Accuracy: 0.602400\n",
      "Epoch 387, CIFAR-10 Batch 4:  Loss:     1.0221 Validation Accuracy: 0.599200\n",
      "Epoch 387, CIFAR-10 Batch 5:  Loss:     1.0247 Validation Accuracy: 0.600400\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss:     1.0108 Validation Accuracy: 0.598600\n",
      "Epoch 388, CIFAR-10 Batch 2:  Loss:     1.0249 Validation Accuracy: 0.603200\n",
      "Epoch 388, CIFAR-10 Batch 3:  Loss:     1.0056 Validation Accuracy: 0.602000\n",
      "Epoch 388, CIFAR-10 Batch 4:  Loss:     1.0219 Validation Accuracy: 0.601000\n",
      "Epoch 388, CIFAR-10 Batch 5:  Loss:     1.0246 Validation Accuracy: 0.598600\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss:     1.0103 Validation Accuracy: 0.598400\n",
      "Epoch 389, CIFAR-10 Batch 2:  Loss:     1.0241 Validation Accuracy: 0.603000\n",
      "Epoch 389, CIFAR-10 Batch 3:  Loss:     1.0050 Validation Accuracy: 0.601200\n",
      "Epoch 389, CIFAR-10 Batch 4:  Loss:     1.0220 Validation Accuracy: 0.600600\n",
      "Epoch 389, CIFAR-10 Batch 5:  Loss:     1.0245 Validation Accuracy: 0.598800\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss:     1.0099 Validation Accuracy: 0.598600\n",
      "Epoch 390, CIFAR-10 Batch 2:  Loss:     1.0233 Validation Accuracy: 0.602800\n",
      "Epoch 390, CIFAR-10 Batch 3:  Loss:     1.0045 Validation Accuracy: 0.600400\n",
      "Epoch 390, CIFAR-10 Batch 4:  Loss:     1.0223 Validation Accuracy: 0.601000\n",
      "Epoch 390, CIFAR-10 Batch 5:  Loss:     1.0246 Validation Accuracy: 0.599000\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss:     1.0093 Validation Accuracy: 0.599000\n",
      "Epoch 391, CIFAR-10 Batch 2:  Loss:     1.0224 Validation Accuracy: 0.604200\n",
      "Epoch 391, CIFAR-10 Batch 3:  Loss:     1.0040 Validation Accuracy: 0.599600\n",
      "Epoch 391, CIFAR-10 Batch 4:  Loss:     1.0230 Validation Accuracy: 0.603600\n",
      "Epoch 391, CIFAR-10 Batch 5:  Loss:     1.0246 Validation Accuracy: 0.599000\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss:     1.0086 Validation Accuracy: 0.599200\n",
      "Epoch 392, CIFAR-10 Batch 2:  Loss:     1.0214 Validation Accuracy: 0.603200\n",
      "Epoch 392, CIFAR-10 Batch 3:  Loss:     1.0040 Validation Accuracy: 0.599200\n",
      "Epoch 392, CIFAR-10 Batch 4:  Loss:     1.0243 Validation Accuracy: 0.603000\n",
      "Epoch 392, CIFAR-10 Batch 5:  Loss:     1.0245 Validation Accuracy: 0.599000\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss:     1.0075 Validation Accuracy: 0.600000\n",
      "Epoch 393, CIFAR-10 Batch 2:  Loss:     1.0206 Validation Accuracy: 0.602600\n",
      "Epoch 393, CIFAR-10 Batch 3:  Loss:     1.0047 Validation Accuracy: 0.601000\n",
      "Epoch 393, CIFAR-10 Batch 4:  Loss:     1.0263 Validation Accuracy: 0.598800\n",
      "Epoch 393, CIFAR-10 Batch 5:  Loss:     1.0239 Validation Accuracy: 0.598800\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss:     1.0062 Validation Accuracy: 0.600200\n",
      "Epoch 394, CIFAR-10 Batch 2:  Loss:     1.0205 Validation Accuracy: 0.604400\n",
      "Epoch 394, CIFAR-10 Batch 3:  Loss:     1.0064 Validation Accuracy: 0.600600\n",
      "Epoch 394, CIFAR-10 Batch 4:  Loss:     1.0284 Validation Accuracy: 0.599000\n",
      "Epoch 394, CIFAR-10 Batch 5:  Loss:     1.0224 Validation Accuracy: 0.600000\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss:     1.0052 Validation Accuracy: 0.599200\n",
      "Epoch 395, CIFAR-10 Batch 2:  Loss:     1.0221 Validation Accuracy: 0.603400\n",
      "Epoch 395, CIFAR-10 Batch 3:  Loss:     1.0089 Validation Accuracy: 0.598800\n",
      "Epoch 395, CIFAR-10 Batch 4:  Loss:     1.0285 Validation Accuracy: 0.599200\n",
      "Epoch 395, CIFAR-10 Batch 5:  Loss:     1.0194 Validation Accuracy: 0.600800\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss:     1.0059 Validation Accuracy: 0.602400\n",
      "Epoch 396, CIFAR-10 Batch 2:  Loss:     1.0255 Validation Accuracy: 0.599400\n",
      "Epoch 396, CIFAR-10 Batch 3:  Loss:     1.0097 Validation Accuracy: 0.598400\n",
      "Epoch 396, CIFAR-10 Batch 4:  Loss:     1.0239 Validation Accuracy: 0.600800\n",
      "Epoch 396, CIFAR-10 Batch 5:  Loss:     1.0168 Validation Accuracy: 0.603400\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss:     1.0092 Validation Accuracy: 0.602200\n",
      "Epoch 397, CIFAR-10 Batch 2:  Loss:     1.0279 Validation Accuracy: 0.600400\n",
      "Epoch 397, CIFAR-10 Batch 3:  Loss:     1.0056 Validation Accuracy: 0.600800\n",
      "Epoch 397, CIFAR-10 Batch 4:  Loss:     1.0173 Validation Accuracy: 0.604400\n",
      "Epoch 397, CIFAR-10 Batch 5:  Loss:     1.0175 Validation Accuracy: 0.605000\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss:     1.0111 Validation Accuracy: 0.600400\n",
      "Epoch 398, CIFAR-10 Batch 2:  Loss:     1.0237 Validation Accuracy: 0.603400\n",
      "Epoch 398, CIFAR-10 Batch 3:  Loss:     0.9990 Validation Accuracy: 0.601400\n",
      "Epoch 398, CIFAR-10 Batch 4:  Loss:     1.0155 Validation Accuracy: 0.599400\n",
      "Epoch 398, CIFAR-10 Batch 5:  Loss:     1.0190 Validation Accuracy: 0.603400\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss:     1.0072 Validation Accuracy: 0.599800\n",
      "Epoch 399, CIFAR-10 Batch 2:  Loss:     1.0173 Validation Accuracy: 0.605600\n",
      "Epoch 399, CIFAR-10 Batch 3:  Loss:     0.9975 Validation Accuracy: 0.602200\n",
      "Epoch 399, CIFAR-10 Batch 4:  Loss:     1.0165 Validation Accuracy: 0.598000\n",
      "Epoch 399, CIFAR-10 Batch 5:  Loss:     1.0168 Validation Accuracy: 0.604800\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss:     1.0018 Validation Accuracy: 0.602000\n",
      "Epoch 400, CIFAR-10 Batch 2:  Loss:     1.0162 Validation Accuracy: 0.603800\n",
      "Epoch 400, CIFAR-10 Batch 3:  Loss:     0.9986 Validation Accuracy: 0.604000\n",
      "Epoch 400, CIFAR-10 Batch 4:  Loss:     1.0156 Validation Accuracy: 0.598600\n",
      "Epoch 400, CIFAR-10 Batch 5:  Loss:     1.0138 Validation Accuracy: 0.604200\n",
      "Epoch 401, CIFAR-10 Batch 1:  Loss:     1.0007 Validation Accuracy: 0.602800\n",
      "Epoch 401, CIFAR-10 Batch 2:  Loss:     1.0168 Validation Accuracy: 0.604000\n",
      "Epoch 401, CIFAR-10 Batch 3:  Loss:     0.9981 Validation Accuracy: 0.603800\n",
      "Epoch 401, CIFAR-10 Batch 4:  Loss:     1.0141 Validation Accuracy: 0.600400\n",
      "Epoch 401, CIFAR-10 Batch 5:  Loss:     1.0135 Validation Accuracy: 0.603200\n",
      "Epoch 402, CIFAR-10 Batch 1:  Loss:     1.0014 Validation Accuracy: 0.601600\n",
      "Epoch 402, CIFAR-10 Batch 2:  Loss:     1.0164 Validation Accuracy: 0.605400\n",
      "Epoch 402, CIFAR-10 Batch 3:  Loss:     0.9971 Validation Accuracy: 0.604000\n",
      "Epoch 402, CIFAR-10 Batch 4:  Loss:     1.0135 Validation Accuracy: 0.601200\n",
      "Epoch 402, CIFAR-10 Batch 5:  Loss:     1.0143 Validation Accuracy: 0.603600\n",
      "Epoch 403, CIFAR-10 Batch 1:  Loss:     1.0013 Validation Accuracy: 0.601400\n",
      "Epoch 403, CIFAR-10 Batch 2:  Loss:     1.0156 Validation Accuracy: 0.606000\n",
      "Epoch 403, CIFAR-10 Batch 3:  Loss:     0.9963 Validation Accuracy: 0.600200\n",
      "Epoch 403, CIFAR-10 Batch 4:  Loss:     1.0138 Validation Accuracy: 0.603600\n",
      "Epoch 403, CIFAR-10 Batch 5:  Loss:     1.0142 Validation Accuracy: 0.603600\n",
      "Epoch 404, CIFAR-10 Batch 1:  Loss:     1.0007 Validation Accuracy: 0.601000\n",
      "Epoch 404, CIFAR-10 Batch 2:  Loss:     1.0148 Validation Accuracy: 0.606400\n",
      "Epoch 404, CIFAR-10 Batch 3:  Loss:     0.9960 Validation Accuracy: 0.602800\n",
      "Epoch 404, CIFAR-10 Batch 4:  Loss:     1.0136 Validation Accuracy: 0.603400\n",
      "Epoch 404, CIFAR-10 Batch 5:  Loss:     1.0130 Validation Accuracy: 0.605000\n",
      "Epoch 405, CIFAR-10 Batch 1:  Loss:     0.9998 Validation Accuracy: 0.601600\n",
      "Epoch 405, CIFAR-10 Batch 2:  Loss:     1.0146 Validation Accuracy: 0.606000\n",
      "Epoch 405, CIFAR-10 Batch 3:  Loss:     0.9957 Validation Accuracy: 0.602200\n",
      "Epoch 405, CIFAR-10 Batch 4:  Loss:     1.0128 Validation Accuracy: 0.603200\n",
      "Epoch 405, CIFAR-10 Batch 5:  Loss:     1.0118 Validation Accuracy: 0.605600\n",
      "Epoch 406, CIFAR-10 Batch 1:  Loss:     0.9994 Validation Accuracy: 0.602400\n",
      "Epoch 406, CIFAR-10 Batch 2:  Loss:     1.0143 Validation Accuracy: 0.607000\n",
      "Epoch 406, CIFAR-10 Batch 3:  Loss:     0.9952 Validation Accuracy: 0.604000\n",
      "Epoch 406, CIFAR-10 Batch 4:  Loss:     1.0117 Validation Accuracy: 0.602000\n",
      "Epoch 406, CIFAR-10 Batch 5:  Loss:     1.0111 Validation Accuracy: 0.606800\n",
      "Epoch 407, CIFAR-10 Batch 1:  Loss:     0.9992 Validation Accuracy: 0.602400\n",
      "Epoch 407, CIFAR-10 Batch 2:  Loss:     1.0139 Validation Accuracy: 0.607000\n",
      "Epoch 407, CIFAR-10 Batch 3:  Loss:     0.9945 Validation Accuracy: 0.602600\n",
      "Epoch 407, CIFAR-10 Batch 4:  Loss:     1.0108 Validation Accuracy: 0.601000\n",
      "Epoch 407, CIFAR-10 Batch 5:  Loss:     1.0108 Validation Accuracy: 0.606400\n",
      "Epoch 408, CIFAR-10 Batch 1:  Loss:     0.9988 Validation Accuracy: 0.602800\n",
      "Epoch 408, CIFAR-10 Batch 2:  Loss:     1.0133 Validation Accuracy: 0.607200\n",
      "Epoch 408, CIFAR-10 Batch 3:  Loss:     0.9938 Validation Accuracy: 0.604400\n",
      "Epoch 408, CIFAR-10 Batch 4:  Loss:     1.0101 Validation Accuracy: 0.601400\n",
      "Epoch 408, CIFAR-10 Batch 5:  Loss:     1.0105 Validation Accuracy: 0.606000\n",
      "Epoch 409, CIFAR-10 Batch 1:  Loss:     0.9982 Validation Accuracy: 0.603800\n",
      "Epoch 409, CIFAR-10 Batch 2:  Loss:     1.0125 Validation Accuracy: 0.606800\n",
      "Epoch 409, CIFAR-10 Batch 3:  Loss:     0.9932 Validation Accuracy: 0.604800\n",
      "Epoch 409, CIFAR-10 Batch 4:  Loss:     1.0097 Validation Accuracy: 0.601200\n",
      "Epoch 409, CIFAR-10 Batch 5:  Loss:     1.0099 Validation Accuracy: 0.605600\n",
      "Epoch 410, CIFAR-10 Batch 1:  Loss:     0.9973 Validation Accuracy: 0.603600\n",
      "Epoch 410, CIFAR-10 Batch 2:  Loss:     1.0119 Validation Accuracy: 0.607000\n",
      "Epoch 410, CIFAR-10 Batch 3:  Loss:     0.9929 Validation Accuracy: 0.603200\n",
      "Epoch 410, CIFAR-10 Batch 4:  Loss:     1.0092 Validation Accuracy: 0.601200\n",
      "Epoch 410, CIFAR-10 Batch 5:  Loss:     1.0093 Validation Accuracy: 0.606800\n",
      "Epoch 411, CIFAR-10 Batch 1:  Loss:     0.9966 Validation Accuracy: 0.602200\n",
      "Epoch 411, CIFAR-10 Batch 2:  Loss:     1.0115 Validation Accuracy: 0.606000\n",
      "Epoch 411, CIFAR-10 Batch 3:  Loss:     0.9925 Validation Accuracy: 0.603000\n",
      "Epoch 411, CIFAR-10 Batch 4:  Loss:     1.0086 Validation Accuracy: 0.601400\n",
      "Epoch 411, CIFAR-10 Batch 5:  Loss:     1.0088 Validation Accuracy: 0.607000\n",
      "Epoch 412, CIFAR-10 Batch 1:  Loss:     0.9962 Validation Accuracy: 0.602600\n",
      "Epoch 412, CIFAR-10 Batch 2:  Loss:     1.0111 Validation Accuracy: 0.608200\n",
      "Epoch 412, CIFAR-10 Batch 3:  Loss:     0.9921 Validation Accuracy: 0.604000\n",
      "Epoch 412, CIFAR-10 Batch 4:  Loss:     1.0080 Validation Accuracy: 0.601400\n",
      "Epoch 412, CIFAR-10 Batch 5:  Loss:     1.0084 Validation Accuracy: 0.607000\n",
      "Epoch 413, CIFAR-10 Batch 1:  Loss:     0.9957 Validation Accuracy: 0.602000\n",
      "Epoch 413, CIFAR-10 Batch 2:  Loss:     1.0107 Validation Accuracy: 0.608400\n",
      "Epoch 413, CIFAR-10 Batch 3:  Loss:     0.9917 Validation Accuracy: 0.603800\n",
      "Epoch 413, CIFAR-10 Batch 4:  Loss:     1.0076 Validation Accuracy: 0.601600\n",
      "Epoch 413, CIFAR-10 Batch 5:  Loss:     1.0081 Validation Accuracy: 0.606600\n",
      "Epoch 414, CIFAR-10 Batch 1:  Loss:     0.9953 Validation Accuracy: 0.602800\n",
      "Epoch 414, CIFAR-10 Batch 2:  Loss:     1.0103 Validation Accuracy: 0.608400\n",
      "Epoch 414, CIFAR-10 Batch 3:  Loss:     0.9914 Validation Accuracy: 0.604600\n",
      "Epoch 414, CIFAR-10 Batch 4:  Loss:     1.0072 Validation Accuracy: 0.601000\n",
      "Epoch 414, CIFAR-10 Batch 5:  Loss:     1.0077 Validation Accuracy: 0.605800\n",
      "Epoch 415, CIFAR-10 Batch 1:  Loss:     0.9948 Validation Accuracy: 0.603000\n",
      "Epoch 415, CIFAR-10 Batch 2:  Loss:     1.0098 Validation Accuracy: 0.608400\n",
      "Epoch 415, CIFAR-10 Batch 3:  Loss:     0.9909 Validation Accuracy: 0.604000\n",
      "Epoch 415, CIFAR-10 Batch 4:  Loss:     1.0066 Validation Accuracy: 0.601000\n",
      "Epoch 415, CIFAR-10 Batch 5:  Loss:     1.0073 Validation Accuracy: 0.605600\n",
      "Epoch 416, CIFAR-10 Batch 1:  Loss:     0.9943 Validation Accuracy: 0.602400\n",
      "Epoch 416, CIFAR-10 Batch 2:  Loss:     1.0092 Validation Accuracy: 0.609000\n",
      "Epoch 416, CIFAR-10 Batch 3:  Loss:     0.9904 Validation Accuracy: 0.603800\n",
      "Epoch 416, CIFAR-10 Batch 4:  Loss:     1.0061 Validation Accuracy: 0.601600\n",
      "Epoch 416, CIFAR-10 Batch 5:  Loss:     1.0068 Validation Accuracy: 0.605800\n",
      "Epoch 417, CIFAR-10 Batch 1:  Loss:     0.9937 Validation Accuracy: 0.602200\n",
      "Epoch 417, CIFAR-10 Batch 2:  Loss:     1.0086 Validation Accuracy: 0.609600\n",
      "Epoch 417, CIFAR-10 Batch 3:  Loss:     0.9899 Validation Accuracy: 0.604000\n",
      "Epoch 417, CIFAR-10 Batch 4:  Loss:     1.0056 Validation Accuracy: 0.601400\n",
      "Epoch 417, CIFAR-10 Batch 5:  Loss:     1.0063 Validation Accuracy: 0.606800\n",
      "Epoch 418, CIFAR-10 Batch 1:  Loss:     0.9931 Validation Accuracy: 0.602000\n",
      "Epoch 418, CIFAR-10 Batch 2:  Loss:     1.0080 Validation Accuracy: 0.609800\n",
      "Epoch 418, CIFAR-10 Batch 3:  Loss:     0.9894 Validation Accuracy: 0.604200\n",
      "Epoch 418, CIFAR-10 Batch 4:  Loss:     1.0052 Validation Accuracy: 0.602600\n",
      "Epoch 418, CIFAR-10 Batch 5:  Loss:     1.0058 Validation Accuracy: 0.606600\n",
      "Epoch 419, CIFAR-10 Batch 1:  Loss:     0.9927 Validation Accuracy: 0.603000\n",
      "Epoch 419, CIFAR-10 Batch 2:  Loss:     1.0076 Validation Accuracy: 0.610000\n",
      "Epoch 419, CIFAR-10 Batch 3:  Loss:     0.9890 Validation Accuracy: 0.604000\n",
      "Epoch 419, CIFAR-10 Batch 4:  Loss:     1.0047 Validation Accuracy: 0.603600\n",
      "Epoch 419, CIFAR-10 Batch 5:  Loss:     1.0053 Validation Accuracy: 0.606800\n",
      "Epoch 420, CIFAR-10 Batch 1:  Loss:     0.9923 Validation Accuracy: 0.602800\n",
      "Epoch 420, CIFAR-10 Batch 2:  Loss:     1.0070 Validation Accuracy: 0.610000\n",
      "Epoch 420, CIFAR-10 Batch 3:  Loss:     0.9885 Validation Accuracy: 0.604600\n",
      "Epoch 420, CIFAR-10 Batch 4:  Loss:     1.0042 Validation Accuracy: 0.604000\n",
      "Epoch 420, CIFAR-10 Batch 5:  Loss:     1.0049 Validation Accuracy: 0.606800\n",
      "Epoch 421, CIFAR-10 Batch 1:  Loss:     0.9918 Validation Accuracy: 0.603200\n",
      "Epoch 421, CIFAR-10 Batch 2:  Loss:     1.0065 Validation Accuracy: 0.609600\n",
      "Epoch 421, CIFAR-10 Batch 3:  Loss:     0.9880 Validation Accuracy: 0.604400\n",
      "Epoch 421, CIFAR-10 Batch 4:  Loss:     1.0037 Validation Accuracy: 0.604000\n",
      "Epoch 421, CIFAR-10 Batch 5:  Loss:     1.0044 Validation Accuracy: 0.606800\n",
      "Epoch 422, CIFAR-10 Batch 1:  Loss:     0.9912 Validation Accuracy: 0.604000\n",
      "Epoch 422, CIFAR-10 Batch 2:  Loss:     1.0059 Validation Accuracy: 0.609200\n",
      "Epoch 422, CIFAR-10 Batch 3:  Loss:     0.9875 Validation Accuracy: 0.604000\n",
      "Epoch 422, CIFAR-10 Batch 4:  Loss:     1.0033 Validation Accuracy: 0.603800\n",
      "Epoch 422, CIFAR-10 Batch 5:  Loss:     1.0039 Validation Accuracy: 0.606800\n",
      "Epoch 423, CIFAR-10 Batch 1:  Loss:     0.9907 Validation Accuracy: 0.604600\n",
      "Epoch 423, CIFAR-10 Batch 2:  Loss:     1.0054 Validation Accuracy: 0.609400\n",
      "Epoch 423, CIFAR-10 Batch 3:  Loss:     0.9870 Validation Accuracy: 0.604200\n",
      "Epoch 423, CIFAR-10 Batch 4:  Loss:     1.0028 Validation Accuracy: 0.604000\n",
      "Epoch 423, CIFAR-10 Batch 5:  Loss:     1.0034 Validation Accuracy: 0.607400\n",
      "Epoch 424, CIFAR-10 Batch 1:  Loss:     0.9901 Validation Accuracy: 0.605200\n",
      "Epoch 424, CIFAR-10 Batch 2:  Loss:     1.0049 Validation Accuracy: 0.609400\n",
      "Epoch 424, CIFAR-10 Batch 3:  Loss:     0.9866 Validation Accuracy: 0.604000\n",
      "Epoch 424, CIFAR-10 Batch 4:  Loss:     1.0023 Validation Accuracy: 0.604400\n",
      "Epoch 424, CIFAR-10 Batch 5:  Loss:     1.0029 Validation Accuracy: 0.607400\n",
      "Epoch 425, CIFAR-10 Batch 1:  Loss:     0.9896 Validation Accuracy: 0.605400\n",
      "Epoch 425, CIFAR-10 Batch 2:  Loss:     1.0043 Validation Accuracy: 0.609400\n",
      "Epoch 425, CIFAR-10 Batch 3:  Loss:     0.9861 Validation Accuracy: 0.604000\n",
      "Epoch 425, CIFAR-10 Batch 4:  Loss:     1.0018 Validation Accuracy: 0.605200\n",
      "Epoch 425, CIFAR-10 Batch 5:  Loss:     1.0024 Validation Accuracy: 0.607400\n",
      "Epoch 426, CIFAR-10 Batch 1:  Loss:     0.9891 Validation Accuracy: 0.605800\n",
      "Epoch 426, CIFAR-10 Batch 2:  Loss:     1.0038 Validation Accuracy: 0.609400\n",
      "Epoch 426, CIFAR-10 Batch 3:  Loss:     0.9856 Validation Accuracy: 0.604400\n",
      "Epoch 426, CIFAR-10 Batch 4:  Loss:     1.0013 Validation Accuracy: 0.605200\n",
      "Epoch 426, CIFAR-10 Batch 5:  Loss:     1.0019 Validation Accuracy: 0.606600\n",
      "Epoch 427, CIFAR-10 Batch 1:  Loss:     0.9886 Validation Accuracy: 0.605800\n",
      "Epoch 427, CIFAR-10 Batch 2:  Loss:     1.0033 Validation Accuracy: 0.609400\n",
      "Epoch 427, CIFAR-10 Batch 3:  Loss:     0.9851 Validation Accuracy: 0.604200\n",
      "Epoch 427, CIFAR-10 Batch 4:  Loss:     1.0008 Validation Accuracy: 0.605200\n",
      "Epoch 427, CIFAR-10 Batch 5:  Loss:     1.0014 Validation Accuracy: 0.606800\n",
      "Epoch 428, CIFAR-10 Batch 1:  Loss:     0.9881 Validation Accuracy: 0.605400\n",
      "Epoch 428, CIFAR-10 Batch 2:  Loss:     1.0028 Validation Accuracy: 0.609800\n",
      "Epoch 428, CIFAR-10 Batch 3:  Loss:     0.9846 Validation Accuracy: 0.604400\n",
      "Epoch 428, CIFAR-10 Batch 4:  Loss:     1.0003 Validation Accuracy: 0.605200\n",
      "Epoch 428, CIFAR-10 Batch 5:  Loss:     1.0010 Validation Accuracy: 0.606600\n",
      "Epoch 429, CIFAR-10 Batch 1:  Loss:     0.9876 Validation Accuracy: 0.605400\n",
      "Epoch 429, CIFAR-10 Batch 2:  Loss:     1.0022 Validation Accuracy: 0.609800\n",
      "Epoch 429, CIFAR-10 Batch 3:  Loss:     0.9841 Validation Accuracy: 0.604800\n",
      "Epoch 429, CIFAR-10 Batch 4:  Loss:     0.9999 Validation Accuracy: 0.605600\n",
      "Epoch 429, CIFAR-10 Batch 5:  Loss:     1.0005 Validation Accuracy: 0.606800\n",
      "Epoch 430, CIFAR-10 Batch 1:  Loss:     0.9870 Validation Accuracy: 0.605800\n",
      "Epoch 430, CIFAR-10 Batch 2:  Loss:     1.0016 Validation Accuracy: 0.609400\n",
      "Epoch 430, CIFAR-10 Batch 3:  Loss:     0.9836 Validation Accuracy: 0.605000\n",
      "Epoch 430, CIFAR-10 Batch 4:  Loss:     0.9994 Validation Accuracy: 0.605200\n",
      "Epoch 430, CIFAR-10 Batch 5:  Loss:     1.0000 Validation Accuracy: 0.607400\n",
      "Epoch 431, CIFAR-10 Batch 1:  Loss:     0.9864 Validation Accuracy: 0.605400\n",
      "Epoch 431, CIFAR-10 Batch 2:  Loss:     1.0011 Validation Accuracy: 0.609400\n",
      "Epoch 431, CIFAR-10 Batch 3:  Loss:     0.9831 Validation Accuracy: 0.605400\n",
      "Epoch 431, CIFAR-10 Batch 4:  Loss:     0.9990 Validation Accuracy: 0.605200\n",
      "Epoch 431, CIFAR-10 Batch 5:  Loss:     0.9995 Validation Accuracy: 0.607600\n",
      "Epoch 432, CIFAR-10 Batch 1:  Loss:     0.9859 Validation Accuracy: 0.605400\n",
      "Epoch 432, CIFAR-10 Batch 2:  Loss:     1.0006 Validation Accuracy: 0.609600\n",
      "Epoch 432, CIFAR-10 Batch 3:  Loss:     0.9827 Validation Accuracy: 0.605600\n",
      "Epoch 432, CIFAR-10 Batch 4:  Loss:     0.9985 Validation Accuracy: 0.605400\n",
      "Epoch 432, CIFAR-10 Batch 5:  Loss:     0.9990 Validation Accuracy: 0.607600\n",
      "Epoch 433, CIFAR-10 Batch 1:  Loss:     0.9854 Validation Accuracy: 0.605400\n",
      "Epoch 433, CIFAR-10 Batch 2:  Loss:     1.0001 Validation Accuracy: 0.610200\n",
      "Epoch 433, CIFAR-10 Batch 3:  Loss:     0.9822 Validation Accuracy: 0.605200\n",
      "Epoch 433, CIFAR-10 Batch 4:  Loss:     0.9980 Validation Accuracy: 0.606000\n",
      "Epoch 433, CIFAR-10 Batch 5:  Loss:     0.9986 Validation Accuracy: 0.608200\n",
      "Epoch 434, CIFAR-10 Batch 1:  Loss:     0.9850 Validation Accuracy: 0.605400\n",
      "Epoch 434, CIFAR-10 Batch 2:  Loss:     0.9995 Validation Accuracy: 0.610200\n",
      "Epoch 434, CIFAR-10 Batch 3:  Loss:     0.9817 Validation Accuracy: 0.605200\n",
      "Epoch 434, CIFAR-10 Batch 4:  Loss:     0.9975 Validation Accuracy: 0.606200\n",
      "Epoch 434, CIFAR-10 Batch 5:  Loss:     0.9981 Validation Accuracy: 0.608400\n",
      "Epoch 435, CIFAR-10 Batch 1:  Loss:     0.9844 Validation Accuracy: 0.605200\n",
      "Epoch 435, CIFAR-10 Batch 2:  Loss:     0.9989 Validation Accuracy: 0.610000\n",
      "Epoch 435, CIFAR-10 Batch 3:  Loss:     0.9812 Validation Accuracy: 0.606000\n",
      "Epoch 435, CIFAR-10 Batch 4:  Loss:     0.9970 Validation Accuracy: 0.606600\n",
      "Epoch 435, CIFAR-10 Batch 5:  Loss:     0.9977 Validation Accuracy: 0.608400\n",
      "Epoch 436, CIFAR-10 Batch 1:  Loss:     0.9839 Validation Accuracy: 0.605400\n",
      "Epoch 436, CIFAR-10 Batch 2:  Loss:     0.9983 Validation Accuracy: 0.610600\n",
      "Epoch 436, CIFAR-10 Batch 3:  Loss:     0.9807 Validation Accuracy: 0.605800\n",
      "Epoch 436, CIFAR-10 Batch 4:  Loss:     0.9966 Validation Accuracy: 0.606200\n",
      "Epoch 436, CIFAR-10 Batch 5:  Loss:     0.9972 Validation Accuracy: 0.608600\n",
      "Epoch 437, CIFAR-10 Batch 1:  Loss:     0.9834 Validation Accuracy: 0.605000\n",
      "Epoch 437, CIFAR-10 Batch 2:  Loss:     0.9978 Validation Accuracy: 0.610600\n",
      "Epoch 437, CIFAR-10 Batch 3:  Loss:     0.9802 Validation Accuracy: 0.606000\n",
      "Epoch 437, CIFAR-10 Batch 4:  Loss:     0.9962 Validation Accuracy: 0.606800\n",
      "Epoch 437, CIFAR-10 Batch 5:  Loss:     0.9968 Validation Accuracy: 0.608800\n",
      "Epoch 438, CIFAR-10 Batch 1:  Loss:     0.9829 Validation Accuracy: 0.605400\n",
      "Epoch 438, CIFAR-10 Batch 2:  Loss:     0.9972 Validation Accuracy: 0.610400\n",
      "Epoch 438, CIFAR-10 Batch 3:  Loss:     0.9798 Validation Accuracy: 0.606200\n",
      "Epoch 438, CIFAR-10 Batch 4:  Loss:     0.9959 Validation Accuracy: 0.607400\n",
      "Epoch 438, CIFAR-10 Batch 5:  Loss:     0.9964 Validation Accuracy: 0.607800\n",
      "Epoch 439, CIFAR-10 Batch 1:  Loss:     0.9824 Validation Accuracy: 0.605400\n",
      "Epoch 439, CIFAR-10 Batch 2:  Loss:     0.9967 Validation Accuracy: 0.610600\n",
      "Epoch 439, CIFAR-10 Batch 3:  Loss:     0.9793 Validation Accuracy: 0.606200\n",
      "Epoch 439, CIFAR-10 Batch 4:  Loss:     0.9956 Validation Accuracy: 0.607800\n",
      "Epoch 439, CIFAR-10 Batch 5:  Loss:     0.9960 Validation Accuracy: 0.608400\n",
      "Epoch 440, CIFAR-10 Batch 1:  Loss:     0.9820 Validation Accuracy: 0.605000\n",
      "Epoch 440, CIFAR-10 Batch 2:  Loss:     0.9962 Validation Accuracy: 0.610600\n",
      "Epoch 440, CIFAR-10 Batch 3:  Loss:     0.9789 Validation Accuracy: 0.606400\n",
      "Epoch 440, CIFAR-10 Batch 4:  Loss:     0.9952 Validation Accuracy: 0.607600\n",
      "Epoch 440, CIFAR-10 Batch 5:  Loss:     0.9956 Validation Accuracy: 0.607800\n",
      "Epoch 441, CIFAR-10 Batch 1:  Loss:     0.9815 Validation Accuracy: 0.605000\n",
      "Epoch 441, CIFAR-10 Batch 2:  Loss:     0.9956 Validation Accuracy: 0.610600\n",
      "Epoch 441, CIFAR-10 Batch 3:  Loss:     0.9784 Validation Accuracy: 0.607800\n",
      "Epoch 441, CIFAR-10 Batch 4:  Loss:     0.9950 Validation Accuracy: 0.608200\n",
      "Epoch 441, CIFAR-10 Batch 5:  Loss:     0.9953 Validation Accuracy: 0.607800\n",
      "Epoch 442, CIFAR-10 Batch 1:  Loss:     0.9810 Validation Accuracy: 0.605600\n",
      "Epoch 442, CIFAR-10 Batch 2:  Loss:     0.9949 Validation Accuracy: 0.611000\n",
      "Epoch 442, CIFAR-10 Batch 3:  Loss:     0.9779 Validation Accuracy: 0.608400\n",
      "Epoch 442, CIFAR-10 Batch 4:  Loss:     0.9948 Validation Accuracy: 0.608400\n",
      "Epoch 442, CIFAR-10 Batch 5:  Loss:     0.9949 Validation Accuracy: 0.607600\n",
      "Epoch 443, CIFAR-10 Batch 1:  Loss:     0.9805 Validation Accuracy: 0.605600\n",
      "Epoch 443, CIFAR-10 Batch 2:  Loss:     0.9943 Validation Accuracy: 0.611000\n",
      "Epoch 443, CIFAR-10 Batch 3:  Loss:     0.9776 Validation Accuracy: 0.609400\n",
      "Epoch 443, CIFAR-10 Batch 4:  Loss:     0.9948 Validation Accuracy: 0.608400\n",
      "Epoch 443, CIFAR-10 Batch 5:  Loss:     0.9946 Validation Accuracy: 0.607400\n",
      "Epoch 444, CIFAR-10 Batch 1:  Loss:     0.9800 Validation Accuracy: 0.605200\n",
      "Epoch 444, CIFAR-10 Batch 2:  Loss:     0.9937 Validation Accuracy: 0.611400\n",
      "Epoch 444, CIFAR-10 Batch 3:  Loss:     0.9772 Validation Accuracy: 0.608600\n",
      "Epoch 444, CIFAR-10 Batch 4:  Loss:     0.9949 Validation Accuracy: 0.608400\n",
      "Epoch 444, CIFAR-10 Batch 5:  Loss:     0.9943 Validation Accuracy: 0.607400\n",
      "Epoch 445, CIFAR-10 Batch 1:  Loss:     0.9794 Validation Accuracy: 0.605200\n",
      "Epoch 445, CIFAR-10 Batch 2:  Loss:     0.9931 Validation Accuracy: 0.610800\n",
      "Epoch 445, CIFAR-10 Batch 3:  Loss:     0.9770 Validation Accuracy: 0.609600\n",
      "Epoch 445, CIFAR-10 Batch 4:  Loss:     0.9951 Validation Accuracy: 0.609000\n",
      "Epoch 445, CIFAR-10 Batch 5:  Loss:     0.9939 Validation Accuracy: 0.607400\n",
      "Epoch 446, CIFAR-10 Batch 1:  Loss:     0.9789 Validation Accuracy: 0.606000\n",
      "Epoch 446, CIFAR-10 Batch 2:  Loss:     0.9924 Validation Accuracy: 0.610800\n",
      "Epoch 446, CIFAR-10 Batch 3:  Loss:     0.9769 Validation Accuracy: 0.610200\n",
      "Epoch 446, CIFAR-10 Batch 4:  Loss:     0.9955 Validation Accuracy: 0.607400\n",
      "Epoch 446, CIFAR-10 Batch 5:  Loss:     0.9935 Validation Accuracy: 0.607400\n",
      "Epoch 447, CIFAR-10 Batch 1:  Loss:     0.9782 Validation Accuracy: 0.606200\n",
      "Epoch 447, CIFAR-10 Batch 2:  Loss:     0.9919 Validation Accuracy: 0.610200\n",
      "Epoch 447, CIFAR-10 Batch 3:  Loss:     0.9769 Validation Accuracy: 0.608000\n",
      "Epoch 447, CIFAR-10 Batch 4:  Loss:     0.9961 Validation Accuracy: 0.606600\n",
      "Epoch 447, CIFAR-10 Batch 5:  Loss:     0.9930 Validation Accuracy: 0.606800\n",
      "Epoch 448, CIFAR-10 Batch 1:  Loss:     0.9774 Validation Accuracy: 0.606800\n",
      "Epoch 448, CIFAR-10 Batch 2:  Loss:     0.9915 Validation Accuracy: 0.611400\n",
      "Epoch 448, CIFAR-10 Batch 3:  Loss:     0.9773 Validation Accuracy: 0.608400\n",
      "Epoch 448, CIFAR-10 Batch 4:  Loss:     0.9967 Validation Accuracy: 0.607200\n",
      "Epoch 448, CIFAR-10 Batch 5:  Loss:     0.9922 Validation Accuracy: 0.607200\n",
      "Epoch 449, CIFAR-10 Batch 1:  Loss:     0.9766 Validation Accuracy: 0.608800\n",
      "Epoch 449, CIFAR-10 Batch 2:  Loss:     0.9915 Validation Accuracy: 0.610400\n",
      "Epoch 449, CIFAR-10 Batch 3:  Loss:     0.9780 Validation Accuracy: 0.606600\n",
      "Epoch 449, CIFAR-10 Batch 4:  Loss:     0.9970 Validation Accuracy: 0.607600\n",
      "Epoch 449, CIFAR-10 Batch 5:  Loss:     0.9909 Validation Accuracy: 0.607400\n",
      "Epoch 450, CIFAR-10 Batch 1:  Loss:     0.9760 Validation Accuracy: 0.609400\n",
      "Epoch 450, CIFAR-10 Batch 2:  Loss:     0.9920 Validation Accuracy: 0.610400\n",
      "Epoch 450, CIFAR-10 Batch 3:  Loss:     0.9786 Validation Accuracy: 0.607400\n",
      "Epoch 450, CIFAR-10 Batch 4:  Loss:     0.9963 Validation Accuracy: 0.607400\n",
      "Epoch 450, CIFAR-10 Batch 5:  Loss:     0.9892 Validation Accuracy: 0.608800\n",
      "Epoch 451, CIFAR-10 Batch 1:  Loss:     0.9758 Validation Accuracy: 0.607800\n",
      "Epoch 451, CIFAR-10 Batch 2:  Loss:     0.9929 Validation Accuracy: 0.610800\n",
      "Epoch 451, CIFAR-10 Batch 3:  Loss:     0.9785 Validation Accuracy: 0.607400\n",
      "Epoch 451, CIFAR-10 Batch 4:  Loss:     0.9941 Validation Accuracy: 0.607800\n",
      "Epoch 451, CIFAR-10 Batch 5:  Loss:     0.9873 Validation Accuracy: 0.612400\n",
      "Epoch 452, CIFAR-10 Batch 1:  Loss:     0.9762 Validation Accuracy: 0.606400\n",
      "Epoch 452, CIFAR-10 Batch 2:  Loss:     0.9938 Validation Accuracy: 0.608200\n",
      "Epoch 452, CIFAR-10 Batch 3:  Loss:     0.9771 Validation Accuracy: 0.608600\n",
      "Epoch 452, CIFAR-10 Batch 4:  Loss:     0.9907 Validation Accuracy: 0.610000\n",
      "Epoch 452, CIFAR-10 Batch 5:  Loss:     0.9861 Validation Accuracy: 0.611200\n",
      "Epoch 453, CIFAR-10 Batch 1:  Loss:     0.9774 Validation Accuracy: 0.606200\n",
      "Epoch 453, CIFAR-10 Batch 2:  Loss:     0.9938 Validation Accuracy: 0.608800\n",
      "Epoch 453, CIFAR-10 Batch 3:  Loss:     0.9742 Validation Accuracy: 0.609200\n",
      "Epoch 453, CIFAR-10 Batch 4:  Loss:     0.9876 Validation Accuracy: 0.610600\n",
      "Epoch 453, CIFAR-10 Batch 5:  Loss:     0.9862 Validation Accuracy: 0.610200\n",
      "Epoch 454, CIFAR-10 Batch 1:  Loss:     0.9784 Validation Accuracy: 0.604600\n",
      "Epoch 454, CIFAR-10 Batch 2:  Loss:     0.9922 Validation Accuracy: 0.608600\n",
      "Epoch 454, CIFAR-10 Batch 3:  Loss:     0.9710 Validation Accuracy: 0.610200\n",
      "Epoch 454, CIFAR-10 Batch 4:  Loss:     0.9862 Validation Accuracy: 0.609600\n",
      "Epoch 454, CIFAR-10 Batch 5:  Loss:     0.9874 Validation Accuracy: 0.607600\n",
      "Epoch 455, CIFAR-10 Batch 1:  Loss:     0.9780 Validation Accuracy: 0.605400\n",
      "Epoch 455, CIFAR-10 Batch 2:  Loss:     0.9894 Validation Accuracy: 0.610000\n",
      "Epoch 455, CIFAR-10 Batch 3:  Loss:     0.9690 Validation Accuracy: 0.612400\n",
      "Epoch 455, CIFAR-10 Batch 4:  Loss:     0.9868 Validation Accuracy: 0.608400\n",
      "Epoch 455, CIFAR-10 Batch 5:  Loss:     0.9883 Validation Accuracy: 0.610000\n",
      "Epoch 456, CIFAR-10 Batch 1:  Loss:     0.9758 Validation Accuracy: 0.606600\n",
      "Epoch 456, CIFAR-10 Batch 2:  Loss:     0.9871 Validation Accuracy: 0.611600\n",
      "Epoch 456, CIFAR-10 Batch 3:  Loss:     0.9690 Validation Accuracy: 0.612600\n",
      "Epoch 456, CIFAR-10 Batch 4:  Loss:     0.9880 Validation Accuracy: 0.606000\n",
      "Epoch 456, CIFAR-10 Batch 5:  Loss:     0.9879 Validation Accuracy: 0.609200\n",
      "Epoch 457, CIFAR-10 Batch 1:  Loss:     0.9733 Validation Accuracy: 0.607600\n",
      "Epoch 457, CIFAR-10 Batch 2:  Loss:     0.9862 Validation Accuracy: 0.610600\n",
      "Epoch 457, CIFAR-10 Batch 3:  Loss:     0.9702 Validation Accuracy: 0.610800\n",
      "Epoch 457, CIFAR-10 Batch 4:  Loss:     0.9885 Validation Accuracy: 0.606600\n",
      "Epoch 457, CIFAR-10 Batch 5:  Loss:     0.9862 Validation Accuracy: 0.609800\n",
      "Epoch 458, CIFAR-10 Batch 1:  Loss:     0.9715 Validation Accuracy: 0.608200\n",
      "Epoch 458, CIFAR-10 Batch 2:  Loss:     0.9865 Validation Accuracy: 0.609800\n",
      "Epoch 458, CIFAR-10 Batch 3:  Loss:     0.9713 Validation Accuracy: 0.610200\n",
      "Epoch 458, CIFAR-10 Batch 4:  Loss:     0.9876 Validation Accuracy: 0.606000\n",
      "Epoch 458, CIFAR-10 Batch 5:  Loss:     0.9842 Validation Accuracy: 0.610000\n",
      "Epoch 459, CIFAR-10 Batch 1:  Loss:     0.9707 Validation Accuracy: 0.610600\n",
      "Epoch 459, CIFAR-10 Batch 2:  Loss:     0.9871 Validation Accuracy: 0.609200\n",
      "Epoch 459, CIFAR-10 Batch 3:  Loss:     0.9714 Validation Accuracy: 0.610600\n",
      "Epoch 459, CIFAR-10 Batch 4:  Loss:     0.9859 Validation Accuracy: 0.606200\n",
      "Epoch 459, CIFAR-10 Batch 5:  Loss:     0.9828 Validation Accuracy: 0.610600\n",
      "Epoch 460, CIFAR-10 Batch 1:  Loss:     0.9706 Validation Accuracy: 0.610200\n",
      "Epoch 460, CIFAR-10 Batch 2:  Loss:     0.9873 Validation Accuracy: 0.608800\n",
      "Epoch 460, CIFAR-10 Batch 3:  Loss:     0.9705 Validation Accuracy: 0.610800\n",
      "Epoch 460, CIFAR-10 Batch 4:  Loss:     0.9841 Validation Accuracy: 0.607800\n",
      "Epoch 460, CIFAR-10 Batch 5:  Loss:     0.9823 Validation Accuracy: 0.611200\n",
      "Epoch 461, CIFAR-10 Batch 1:  Loss:     0.9706 Validation Accuracy: 0.610200\n",
      "Epoch 461, CIFAR-10 Batch 2:  Loss:     0.9866 Validation Accuracy: 0.608600\n",
      "Epoch 461, CIFAR-10 Batch 3:  Loss:     0.9691 Validation Accuracy: 0.611200\n",
      "Epoch 461, CIFAR-10 Batch 4:  Loss:     0.9829 Validation Accuracy: 0.609400\n",
      "Epoch 461, CIFAR-10 Batch 5:  Loss:     0.9823 Validation Accuracy: 0.611600\n",
      "Epoch 462, CIFAR-10 Batch 1:  Loss:     0.9703 Validation Accuracy: 0.609200\n",
      "Epoch 462, CIFAR-10 Batch 2:  Loss:     0.9854 Validation Accuracy: 0.609600\n",
      "Epoch 462, CIFAR-10 Batch 3:  Loss:     0.9678 Validation Accuracy: 0.611200\n",
      "Epoch 462, CIFAR-10 Batch 4:  Loss:     0.9823 Validation Accuracy: 0.609600\n",
      "Epoch 462, CIFAR-10 Batch 5:  Loss:     0.9822 Validation Accuracy: 0.612000\n",
      "Epoch 463, CIFAR-10 Batch 1:  Loss:     0.9697 Validation Accuracy: 0.609400\n",
      "Epoch 463, CIFAR-10 Batch 2:  Loss:     0.9843 Validation Accuracy: 0.609600\n",
      "Epoch 463, CIFAR-10 Batch 3:  Loss:     0.9670 Validation Accuracy: 0.612000\n",
      "Epoch 463, CIFAR-10 Batch 4:  Loss:     0.9821 Validation Accuracy: 0.610200\n",
      "Epoch 463, CIFAR-10 Batch 5:  Loss:     0.9818 Validation Accuracy: 0.611800\n",
      "Epoch 464, CIFAR-10 Batch 1:  Loss:     0.9689 Validation Accuracy: 0.609400\n",
      "Epoch 464, CIFAR-10 Batch 2:  Loss:     0.9834 Validation Accuracy: 0.610200\n",
      "Epoch 464, CIFAR-10 Batch 3:  Loss:     0.9664 Validation Accuracy: 0.610200\n",
      "Epoch 464, CIFAR-10 Batch 4:  Loss:     0.9818 Validation Accuracy: 0.611200\n",
      "Epoch 464, CIFAR-10 Batch 5:  Loss:     0.9811 Validation Accuracy: 0.612400\n",
      "Epoch 465, CIFAR-10 Batch 1:  Loss:     0.9683 Validation Accuracy: 0.608800\n",
      "Epoch 465, CIFAR-10 Batch 2:  Loss:     0.9828 Validation Accuracy: 0.611200\n",
      "Epoch 465, CIFAR-10 Batch 3:  Loss:     0.9660 Validation Accuracy: 0.611000\n",
      "Epoch 465, CIFAR-10 Batch 4:  Loss:     0.9814 Validation Accuracy: 0.611200\n",
      "Epoch 465, CIFAR-10 Batch 5:  Loss:     0.9804 Validation Accuracy: 0.612600\n",
      "Epoch 466, CIFAR-10 Batch 1:  Loss:     0.9679 Validation Accuracy: 0.608600\n",
      "Epoch 466, CIFAR-10 Batch 2:  Loss:     0.9824 Validation Accuracy: 0.611800\n",
      "Epoch 466, CIFAR-10 Batch 3:  Loss:     0.9656 Validation Accuracy: 0.610600\n",
      "Epoch 466, CIFAR-10 Batch 4:  Loss:     0.9810 Validation Accuracy: 0.612200\n",
      "Epoch 466, CIFAR-10 Batch 5:  Loss:     0.9797 Validation Accuracy: 0.613000\n",
      "Epoch 467, CIFAR-10 Batch 1:  Loss:     0.9676 Validation Accuracy: 0.609600\n",
      "Epoch 467, CIFAR-10 Batch 2:  Loss:     0.9821 Validation Accuracy: 0.613200\n",
      "Epoch 467, CIFAR-10 Batch 3:  Loss:     0.9651 Validation Accuracy: 0.611800\n",
      "Epoch 467, CIFAR-10 Batch 4:  Loss:     0.9804 Validation Accuracy: 0.612400\n",
      "Epoch 467, CIFAR-10 Batch 5:  Loss:     0.9792 Validation Accuracy: 0.612200\n",
      "Epoch 468, CIFAR-10 Batch 1:  Loss:     0.9672 Validation Accuracy: 0.611200\n",
      "Epoch 468, CIFAR-10 Batch 2:  Loss:     0.9816 Validation Accuracy: 0.612600\n",
      "Epoch 468, CIFAR-10 Batch 3:  Loss:     0.9646 Validation Accuracy: 0.612000\n",
      "Epoch 468, CIFAR-10 Batch 4:  Loss:     0.9799 Validation Accuracy: 0.613000\n",
      "Epoch 468, CIFAR-10 Batch 5:  Loss:     0.9787 Validation Accuracy: 0.612200\n",
      "Epoch 469, CIFAR-10 Batch 1:  Loss:     0.9668 Validation Accuracy: 0.611200\n",
      "Epoch 469, CIFAR-10 Batch 2:  Loss:     0.9811 Validation Accuracy: 0.612800\n",
      "Epoch 469, CIFAR-10 Batch 3:  Loss:     0.9640 Validation Accuracy: 0.612000\n",
      "Epoch 469, CIFAR-10 Batch 4:  Loss:     0.9794 Validation Accuracy: 0.612600\n",
      "Epoch 469, CIFAR-10 Batch 5:  Loss:     0.9782 Validation Accuracy: 0.613000\n",
      "Epoch 470, CIFAR-10 Batch 1:  Loss:     0.9662 Validation Accuracy: 0.611000\n",
      "Epoch 470, CIFAR-10 Batch 2:  Loss:     0.9807 Validation Accuracy: 0.613000\n",
      "Epoch 470, CIFAR-10 Batch 3:  Loss:     0.9636 Validation Accuracy: 0.612600\n",
      "Epoch 470, CIFAR-10 Batch 4:  Loss:     0.9790 Validation Accuracy: 0.611800\n",
      "Epoch 470, CIFAR-10 Batch 5:  Loss:     0.9777 Validation Accuracy: 0.612800\n",
      "Epoch 471, CIFAR-10 Batch 1:  Loss:     0.9657 Validation Accuracy: 0.611000\n",
      "Epoch 471, CIFAR-10 Batch 2:  Loss:     0.9803 Validation Accuracy: 0.613400\n",
      "Epoch 471, CIFAR-10 Batch 3:  Loss:     0.9632 Validation Accuracy: 0.612800\n",
      "Epoch 471, CIFAR-10 Batch 4:  Loss:     0.9784 Validation Accuracy: 0.611200\n",
      "Epoch 471, CIFAR-10 Batch 5:  Loss:     0.9771 Validation Accuracy: 0.612400\n",
      "Epoch 472, CIFAR-10 Batch 1:  Loss:     0.9652 Validation Accuracy: 0.610800\n",
      "Epoch 472, CIFAR-10 Batch 2:  Loss:     0.9798 Validation Accuracy: 0.613800\n",
      "Epoch 472, CIFAR-10 Batch 3:  Loss:     0.9627 Validation Accuracy: 0.613200\n",
      "Epoch 472, CIFAR-10 Batch 4:  Loss:     0.9779 Validation Accuracy: 0.611000\n",
      "Epoch 472, CIFAR-10 Batch 5:  Loss:     0.9766 Validation Accuracy: 0.612000\n",
      "Epoch 473, CIFAR-10 Batch 1:  Loss:     0.9647 Validation Accuracy: 0.611000\n",
      "Epoch 473, CIFAR-10 Batch 2:  Loss:     0.9794 Validation Accuracy: 0.613400\n",
      "Epoch 473, CIFAR-10 Batch 3:  Loss:     0.9623 Validation Accuracy: 0.613000\n",
      "Epoch 473, CIFAR-10 Batch 4:  Loss:     0.9774 Validation Accuracy: 0.611200\n",
      "Epoch 473, CIFAR-10 Batch 5:  Loss:     0.9762 Validation Accuracy: 0.611200\n",
      "Epoch 474, CIFAR-10 Batch 1:  Loss:     0.9642 Validation Accuracy: 0.610800\n",
      "Epoch 474, CIFAR-10 Batch 2:  Loss:     0.9789 Validation Accuracy: 0.613400\n",
      "Epoch 474, CIFAR-10 Batch 3:  Loss:     0.9619 Validation Accuracy: 0.613400\n",
      "Epoch 474, CIFAR-10 Batch 4:  Loss:     0.9769 Validation Accuracy: 0.610000\n",
      "Epoch 474, CIFAR-10 Batch 5:  Loss:     0.9758 Validation Accuracy: 0.611200\n",
      "Epoch 475, CIFAR-10 Batch 1:  Loss:     0.9638 Validation Accuracy: 0.610600\n",
      "Epoch 475, CIFAR-10 Batch 2:  Loss:     0.9785 Validation Accuracy: 0.613200\n",
      "Epoch 475, CIFAR-10 Batch 3:  Loss:     0.9615 Validation Accuracy: 0.613000\n",
      "Epoch 475, CIFAR-10 Batch 4:  Loss:     0.9765 Validation Accuracy: 0.611000\n",
      "Epoch 475, CIFAR-10 Batch 5:  Loss:     0.9753 Validation Accuracy: 0.612000\n",
      "Epoch 476, CIFAR-10 Batch 1:  Loss:     0.9633 Validation Accuracy: 0.610600\n",
      "Epoch 476, CIFAR-10 Batch 2:  Loss:     0.9781 Validation Accuracy: 0.613600\n",
      "Epoch 476, CIFAR-10 Batch 3:  Loss:     0.9612 Validation Accuracy: 0.612200\n",
      "Epoch 476, CIFAR-10 Batch 4:  Loss:     0.9760 Validation Accuracy: 0.610600\n",
      "Epoch 476, CIFAR-10 Batch 5:  Loss:     0.9749 Validation Accuracy: 0.611800\n",
      "Epoch 477, CIFAR-10 Batch 1:  Loss:     0.9628 Validation Accuracy: 0.610800\n",
      "Epoch 477, CIFAR-10 Batch 2:  Loss:     0.9777 Validation Accuracy: 0.614400\n",
      "Epoch 477, CIFAR-10 Batch 3:  Loss:     0.9608 Validation Accuracy: 0.612200\n",
      "Epoch 477, CIFAR-10 Batch 4:  Loss:     0.9756 Validation Accuracy: 0.611600\n",
      "Epoch 477, CIFAR-10 Batch 5:  Loss:     0.9744 Validation Accuracy: 0.611400\n",
      "Epoch 478, CIFAR-10 Batch 1:  Loss:     0.9623 Validation Accuracy: 0.611000\n",
      "Epoch 478, CIFAR-10 Batch 2:  Loss:     0.9773 Validation Accuracy: 0.614200\n",
      "Epoch 478, CIFAR-10 Batch 3:  Loss:     0.9604 Validation Accuracy: 0.612200\n",
      "Epoch 478, CIFAR-10 Batch 4:  Loss:     0.9751 Validation Accuracy: 0.612000\n",
      "Epoch 478, CIFAR-10 Batch 5:  Loss:     0.9740 Validation Accuracy: 0.612000\n",
      "Epoch 479, CIFAR-10 Batch 1:  Loss:     0.9618 Validation Accuracy: 0.611400\n",
      "Epoch 479, CIFAR-10 Batch 2:  Loss:     0.9768 Validation Accuracy: 0.613800\n",
      "Epoch 479, CIFAR-10 Batch 3:  Loss:     0.9600 Validation Accuracy: 0.612000\n",
      "Epoch 479, CIFAR-10 Batch 4:  Loss:     0.9746 Validation Accuracy: 0.611800\n",
      "Epoch 479, CIFAR-10 Batch 5:  Loss:     0.9735 Validation Accuracy: 0.612000\n",
      "Epoch 480, CIFAR-10 Batch 1:  Loss:     0.9613 Validation Accuracy: 0.611600\n",
      "Epoch 480, CIFAR-10 Batch 2:  Loss:     0.9763 Validation Accuracy: 0.613200\n",
      "Epoch 480, CIFAR-10 Batch 3:  Loss:     0.9595 Validation Accuracy: 0.612400\n",
      "Epoch 480, CIFAR-10 Batch 4:  Loss:     0.9741 Validation Accuracy: 0.611800\n",
      "Epoch 480, CIFAR-10 Batch 5:  Loss:     0.9731 Validation Accuracy: 0.612000\n",
      "Epoch 481, CIFAR-10 Batch 1:  Loss:     0.9608 Validation Accuracy: 0.611600\n",
      "Epoch 481, CIFAR-10 Batch 2:  Loss:     0.9758 Validation Accuracy: 0.613200\n",
      "Epoch 481, CIFAR-10 Batch 3:  Loss:     0.9591 Validation Accuracy: 0.612400\n",
      "Epoch 481, CIFAR-10 Batch 4:  Loss:     0.9736 Validation Accuracy: 0.612200\n",
      "Epoch 481, CIFAR-10 Batch 5:  Loss:     0.9726 Validation Accuracy: 0.611600\n",
      "Epoch 482, CIFAR-10 Batch 1:  Loss:     0.9602 Validation Accuracy: 0.611600\n",
      "Epoch 482, CIFAR-10 Batch 2:  Loss:     0.9753 Validation Accuracy: 0.613200\n",
      "Epoch 482, CIFAR-10 Batch 3:  Loss:     0.9587 Validation Accuracy: 0.612400\n",
      "Epoch 482, CIFAR-10 Batch 4:  Loss:     0.9732 Validation Accuracy: 0.611600\n",
      "Epoch 482, CIFAR-10 Batch 5:  Loss:     0.9721 Validation Accuracy: 0.612200\n",
      "Epoch 483, CIFAR-10 Batch 1:  Loss:     0.9597 Validation Accuracy: 0.611800\n",
      "Epoch 483, CIFAR-10 Batch 2:  Loss:     0.9749 Validation Accuracy: 0.613400\n",
      "Epoch 483, CIFAR-10 Batch 3:  Loss:     0.9583 Validation Accuracy: 0.612600\n",
      "Epoch 483, CIFAR-10 Batch 4:  Loss:     0.9728 Validation Accuracy: 0.612200\n",
      "Epoch 483, CIFAR-10 Batch 5:  Loss:     0.9717 Validation Accuracy: 0.612600\n",
      "Epoch 484, CIFAR-10 Batch 1:  Loss:     0.9593 Validation Accuracy: 0.611800\n",
      "Epoch 484, CIFAR-10 Batch 2:  Loss:     0.9744 Validation Accuracy: 0.613600\n",
      "Epoch 484, CIFAR-10 Batch 3:  Loss:     0.9579 Validation Accuracy: 0.612800\n",
      "Epoch 484, CIFAR-10 Batch 4:  Loss:     0.9723 Validation Accuracy: 0.611600\n",
      "Epoch 484, CIFAR-10 Batch 5:  Loss:     0.9712 Validation Accuracy: 0.612400\n",
      "Epoch 485, CIFAR-10 Batch 1:  Loss:     0.9588 Validation Accuracy: 0.612600\n",
      "Epoch 485, CIFAR-10 Batch 2:  Loss:     0.9740 Validation Accuracy: 0.613600\n",
      "Epoch 485, CIFAR-10 Batch 3:  Loss:     0.9575 Validation Accuracy: 0.613200\n",
      "Epoch 485, CIFAR-10 Batch 4:  Loss:     0.9718 Validation Accuracy: 0.611400\n",
      "Epoch 485, CIFAR-10 Batch 5:  Loss:     0.9707 Validation Accuracy: 0.611800\n",
      "Epoch 486, CIFAR-10 Batch 1:  Loss:     0.9583 Validation Accuracy: 0.613000\n",
      "Epoch 486, CIFAR-10 Batch 2:  Loss:     0.9735 Validation Accuracy: 0.613000\n",
      "Epoch 486, CIFAR-10 Batch 3:  Loss:     0.9571 Validation Accuracy: 0.613000\n",
      "Epoch 486, CIFAR-10 Batch 4:  Loss:     0.9713 Validation Accuracy: 0.611600\n",
      "Epoch 486, CIFAR-10 Batch 5:  Loss:     0.9702 Validation Accuracy: 0.611800\n",
      "Epoch 487, CIFAR-10 Batch 1:  Loss:     0.9577 Validation Accuracy: 0.613400\n",
      "Epoch 487, CIFAR-10 Batch 2:  Loss:     0.9730 Validation Accuracy: 0.613000\n",
      "Epoch 487, CIFAR-10 Batch 3:  Loss:     0.9566 Validation Accuracy: 0.613400\n",
      "Epoch 487, CIFAR-10 Batch 4:  Loss:     0.9708 Validation Accuracy: 0.611200\n",
      "Epoch 487, CIFAR-10 Batch 5:  Loss:     0.9698 Validation Accuracy: 0.612200\n",
      "Epoch 488, CIFAR-10 Batch 1:  Loss:     0.9572 Validation Accuracy: 0.613000\n",
      "Epoch 488, CIFAR-10 Batch 2:  Loss:     0.9725 Validation Accuracy: 0.612800\n",
      "Epoch 488, CIFAR-10 Batch 3:  Loss:     0.9562 Validation Accuracy: 0.613200\n",
      "Epoch 488, CIFAR-10 Batch 4:  Loss:     0.9704 Validation Accuracy: 0.611600\n",
      "Epoch 488, CIFAR-10 Batch 5:  Loss:     0.9693 Validation Accuracy: 0.612000\n",
      "Epoch 489, CIFAR-10 Batch 1:  Loss:     0.9568 Validation Accuracy: 0.613800\n",
      "Epoch 489, CIFAR-10 Batch 2:  Loss:     0.9721 Validation Accuracy: 0.613000\n",
      "Epoch 489, CIFAR-10 Batch 3:  Loss:     0.9558 Validation Accuracy: 0.613200\n",
      "Epoch 489, CIFAR-10 Batch 4:  Loss:     0.9699 Validation Accuracy: 0.611600\n",
      "Epoch 489, CIFAR-10 Batch 5:  Loss:     0.9688 Validation Accuracy: 0.612400\n",
      "Epoch 490, CIFAR-10 Batch 1:  Loss:     0.9563 Validation Accuracy: 0.613600\n",
      "Epoch 490, CIFAR-10 Batch 2:  Loss:     0.9716 Validation Accuracy: 0.613200\n",
      "Epoch 490, CIFAR-10 Batch 3:  Loss:     0.9554 Validation Accuracy: 0.613600\n",
      "Epoch 490, CIFAR-10 Batch 4:  Loss:     0.9694 Validation Accuracy: 0.612000\n",
      "Epoch 490, CIFAR-10 Batch 5:  Loss:     0.9683 Validation Accuracy: 0.612400\n",
      "Epoch 491, CIFAR-10 Batch 1:  Loss:     0.9559 Validation Accuracy: 0.613800\n",
      "Epoch 491, CIFAR-10 Batch 2:  Loss:     0.9711 Validation Accuracy: 0.613000\n",
      "Epoch 491, CIFAR-10 Batch 3:  Loss:     0.9549 Validation Accuracy: 0.613800\n",
      "Epoch 491, CIFAR-10 Batch 4:  Loss:     0.9689 Validation Accuracy: 0.612200\n",
      "Epoch 491, CIFAR-10 Batch 5:  Loss:     0.9679 Validation Accuracy: 0.612200\n",
      "Epoch 492, CIFAR-10 Batch 1:  Loss:     0.9554 Validation Accuracy: 0.613800\n",
      "Epoch 492, CIFAR-10 Batch 2:  Loss:     0.9706 Validation Accuracy: 0.613200\n",
      "Epoch 492, CIFAR-10 Batch 3:  Loss:     0.9544 Validation Accuracy: 0.614400\n",
      "Epoch 492, CIFAR-10 Batch 4:  Loss:     0.9684 Validation Accuracy: 0.612200\n",
      "Epoch 492, CIFAR-10 Batch 5:  Loss:     0.9674 Validation Accuracy: 0.612400\n",
      "Epoch 493, CIFAR-10 Batch 1:  Loss:     0.9548 Validation Accuracy: 0.613000\n",
      "Epoch 493, CIFAR-10 Batch 2:  Loss:     0.9700 Validation Accuracy: 0.613600\n",
      "Epoch 493, CIFAR-10 Batch 3:  Loss:     0.9539 Validation Accuracy: 0.614600\n",
      "Epoch 493, CIFAR-10 Batch 4:  Loss:     0.9679 Validation Accuracy: 0.612400\n",
      "Epoch 493, CIFAR-10 Batch 5:  Loss:     0.9669 Validation Accuracy: 0.612400\n",
      "Epoch 494, CIFAR-10 Batch 1:  Loss:     0.9543 Validation Accuracy: 0.613000\n",
      "Epoch 494, CIFAR-10 Batch 2:  Loss:     0.9696 Validation Accuracy: 0.614200\n",
      "Epoch 494, CIFAR-10 Batch 3:  Loss:     0.9535 Validation Accuracy: 0.615000\n",
      "Epoch 494, CIFAR-10 Batch 4:  Loss:     0.9675 Validation Accuracy: 0.612000\n",
      "Epoch 494, CIFAR-10 Batch 5:  Loss:     0.9665 Validation Accuracy: 0.612600\n",
      "Epoch 495, CIFAR-10 Batch 1:  Loss:     0.9539 Validation Accuracy: 0.613200\n",
      "Epoch 495, CIFAR-10 Batch 2:  Loss:     0.9691 Validation Accuracy: 0.614600\n",
      "Epoch 495, CIFAR-10 Batch 3:  Loss:     0.9531 Validation Accuracy: 0.614400\n",
      "Epoch 495, CIFAR-10 Batch 4:  Loss:     0.9670 Validation Accuracy: 0.612400\n",
      "Epoch 495, CIFAR-10 Batch 5:  Loss:     0.9660 Validation Accuracy: 0.613000\n",
      "Epoch 496, CIFAR-10 Batch 1:  Loss:     0.9534 Validation Accuracy: 0.613000\n",
      "Epoch 496, CIFAR-10 Batch 2:  Loss:     0.9686 Validation Accuracy: 0.615000\n",
      "Epoch 496, CIFAR-10 Batch 3:  Loss:     0.9527 Validation Accuracy: 0.614400\n",
      "Epoch 496, CIFAR-10 Batch 4:  Loss:     0.9666 Validation Accuracy: 0.612400\n",
      "Epoch 496, CIFAR-10 Batch 5:  Loss:     0.9656 Validation Accuracy: 0.613400\n",
      "Epoch 497, CIFAR-10 Batch 1:  Loss:     0.9529 Validation Accuracy: 0.613200\n",
      "Epoch 497, CIFAR-10 Batch 2:  Loss:     0.9681 Validation Accuracy: 0.614800\n",
      "Epoch 497, CIFAR-10 Batch 3:  Loss:     0.9523 Validation Accuracy: 0.614600\n",
      "Epoch 497, CIFAR-10 Batch 4:  Loss:     0.9661 Validation Accuracy: 0.612200\n",
      "Epoch 497, CIFAR-10 Batch 5:  Loss:     0.9651 Validation Accuracy: 0.614000\n",
      "Epoch 498, CIFAR-10 Batch 1:  Loss:     0.9524 Validation Accuracy: 0.612800\n",
      "Epoch 498, CIFAR-10 Batch 2:  Loss:     0.9676 Validation Accuracy: 0.615000\n",
      "Epoch 498, CIFAR-10 Batch 3:  Loss:     0.9519 Validation Accuracy: 0.614800\n",
      "Epoch 498, CIFAR-10 Batch 4:  Loss:     0.9657 Validation Accuracy: 0.612400\n",
      "Epoch 498, CIFAR-10 Batch 5:  Loss:     0.9646 Validation Accuracy: 0.614200\n",
      "Epoch 499, CIFAR-10 Batch 1:  Loss:     0.9519 Validation Accuracy: 0.613200\n",
      "Epoch 499, CIFAR-10 Batch 2:  Loss:     0.9672 Validation Accuracy: 0.614800\n",
      "Epoch 499, CIFAR-10 Batch 3:  Loss:     0.9515 Validation Accuracy: 0.614400\n",
      "Epoch 499, CIFAR-10 Batch 4:  Loss:     0.9652 Validation Accuracy: 0.612600\n",
      "Epoch 499, CIFAR-10 Batch 5:  Loss:     0.9642 Validation Accuracy: 0.614600\n",
      "Epoch 500, CIFAR-10 Batch 1:  Loss:     0.9514 Validation Accuracy: 0.613400\n",
      "Epoch 500, CIFAR-10 Batch 2:  Loss:     0.9666 Validation Accuracy: 0.614800\n",
      "Epoch 500, CIFAR-10 Batch 3:  Loss:     0.9510 Validation Accuracy: 0.614800\n",
      "Epoch 500, CIFAR-10 Batch 4:  Loss:     0.9647 Validation Accuracy: 0.612200\n",
      "Epoch 500, CIFAR-10 Batch 5:  Loss:     0.9637 Validation Accuracy: 0.614200\n",
      "Epoch 501, CIFAR-10 Batch 1:  Loss:     0.9509 Validation Accuracy: 0.613200\n",
      "Epoch 501, CIFAR-10 Batch 2:  Loss:     0.9661 Validation Accuracy: 0.615400\n",
      "Epoch 501, CIFAR-10 Batch 3:  Loss:     0.9506 Validation Accuracy: 0.615000\n",
      "Epoch 501, CIFAR-10 Batch 4:  Loss:     0.9643 Validation Accuracy: 0.612400\n",
      "Epoch 501, CIFAR-10 Batch 5:  Loss:     0.9632 Validation Accuracy: 0.614400\n",
      "Epoch 502, CIFAR-10 Batch 1:  Loss:     0.9504 Validation Accuracy: 0.613400\n",
      "Epoch 502, CIFAR-10 Batch 2:  Loss:     0.9656 Validation Accuracy: 0.615200\n",
      "Epoch 502, CIFAR-10 Batch 3:  Loss:     0.9502 Validation Accuracy: 0.614600\n",
      "Epoch 502, CIFAR-10 Batch 4:  Loss:     0.9639 Validation Accuracy: 0.612200\n",
      "Epoch 502, CIFAR-10 Batch 5:  Loss:     0.9628 Validation Accuracy: 0.614400\n",
      "Epoch 503, CIFAR-10 Batch 1:  Loss:     0.9499 Validation Accuracy: 0.613600\n",
      "Epoch 503, CIFAR-10 Batch 2:  Loss:     0.9652 Validation Accuracy: 0.615400\n",
      "Epoch 503, CIFAR-10 Batch 3:  Loss:     0.9499 Validation Accuracy: 0.615000\n",
      "Epoch 503, CIFAR-10 Batch 4:  Loss:     0.9634 Validation Accuracy: 0.612800\n",
      "Epoch 503, CIFAR-10 Batch 5:  Loss:     0.9623 Validation Accuracy: 0.614600\n",
      "Epoch 504, CIFAR-10 Batch 1:  Loss:     0.9494 Validation Accuracy: 0.613800\n",
      "Epoch 504, CIFAR-10 Batch 2:  Loss:     0.9647 Validation Accuracy: 0.615200\n",
      "Epoch 504, CIFAR-10 Batch 3:  Loss:     0.9495 Validation Accuracy: 0.615200\n",
      "Epoch 504, CIFAR-10 Batch 4:  Loss:     0.9630 Validation Accuracy: 0.613400\n",
      "Epoch 504, CIFAR-10 Batch 5:  Loss:     0.9619 Validation Accuracy: 0.614200\n",
      "Epoch 505, CIFAR-10 Batch 1:  Loss:     0.9490 Validation Accuracy: 0.614400\n",
      "Epoch 505, CIFAR-10 Batch 2:  Loss:     0.9643 Validation Accuracy: 0.615800\n",
      "Epoch 505, CIFAR-10 Batch 3:  Loss:     0.9490 Validation Accuracy: 0.615200\n",
      "Epoch 505, CIFAR-10 Batch 4:  Loss:     0.9625 Validation Accuracy: 0.613400\n",
      "Epoch 505, CIFAR-10 Batch 5:  Loss:     0.9614 Validation Accuracy: 0.614400\n",
      "Epoch 506, CIFAR-10 Batch 1:  Loss:     0.9485 Validation Accuracy: 0.615200\n",
      "Epoch 506, CIFAR-10 Batch 2:  Loss:     0.9638 Validation Accuracy: 0.615600\n",
      "Epoch 506, CIFAR-10 Batch 3:  Loss:     0.9486 Validation Accuracy: 0.615400\n",
      "Epoch 506, CIFAR-10 Batch 4:  Loss:     0.9620 Validation Accuracy: 0.613200\n",
      "Epoch 506, CIFAR-10 Batch 5:  Loss:     0.9609 Validation Accuracy: 0.615000\n",
      "Epoch 507, CIFAR-10 Batch 1:  Loss:     0.9480 Validation Accuracy: 0.614600\n",
      "Epoch 507, CIFAR-10 Batch 2:  Loss:     0.9632 Validation Accuracy: 0.616000\n",
      "Epoch 507, CIFAR-10 Batch 3:  Loss:     0.9481 Validation Accuracy: 0.615200\n",
      "Epoch 507, CIFAR-10 Batch 4:  Loss:     0.9615 Validation Accuracy: 0.614200\n",
      "Epoch 507, CIFAR-10 Batch 5:  Loss:     0.9604 Validation Accuracy: 0.615400\n",
      "Epoch 508, CIFAR-10 Batch 1:  Loss:     0.9475 Validation Accuracy: 0.614800\n",
      "Epoch 508, CIFAR-10 Batch 2:  Loss:     0.9627 Validation Accuracy: 0.616400\n",
      "Epoch 508, CIFAR-10 Batch 3:  Loss:     0.9478 Validation Accuracy: 0.615200\n",
      "Epoch 508, CIFAR-10 Batch 4:  Loss:     0.9611 Validation Accuracy: 0.614000\n",
      "Epoch 508, CIFAR-10 Batch 5:  Loss:     0.9600 Validation Accuracy: 0.615800\n",
      "Epoch 509, CIFAR-10 Batch 1:  Loss:     0.9470 Validation Accuracy: 0.615200\n",
      "Epoch 509, CIFAR-10 Batch 2:  Loss:     0.9622 Validation Accuracy: 0.616200\n",
      "Epoch 509, CIFAR-10 Batch 3:  Loss:     0.9474 Validation Accuracy: 0.614800\n",
      "Epoch 509, CIFAR-10 Batch 4:  Loss:     0.9607 Validation Accuracy: 0.614400\n",
      "Epoch 509, CIFAR-10 Batch 5:  Loss:     0.9596 Validation Accuracy: 0.616200\n",
      "Epoch 510, CIFAR-10 Batch 1:  Loss:     0.9465 Validation Accuracy: 0.615000\n",
      "Epoch 510, CIFAR-10 Batch 2:  Loss:     0.9618 Validation Accuracy: 0.616000\n",
      "Epoch 510, CIFAR-10 Batch 3:  Loss:     0.9471 Validation Accuracy: 0.615200\n",
      "Epoch 510, CIFAR-10 Batch 4:  Loss:     0.9603 Validation Accuracy: 0.614800\n",
      "Epoch 510, CIFAR-10 Batch 5:  Loss:     0.9591 Validation Accuracy: 0.616000\n",
      "Epoch 511, CIFAR-10 Batch 1:  Loss:     0.9461 Validation Accuracy: 0.615000\n",
      "Epoch 511, CIFAR-10 Batch 2:  Loss:     0.9615 Validation Accuracy: 0.616200\n",
      "Epoch 511, CIFAR-10 Batch 3:  Loss:     0.9466 Validation Accuracy: 0.615400\n",
      "Epoch 511, CIFAR-10 Batch 4:  Loss:     0.9597 Validation Accuracy: 0.615600\n",
      "Epoch 511, CIFAR-10 Batch 5:  Loss:     0.9586 Validation Accuracy: 0.616200\n",
      "Epoch 512, CIFAR-10 Batch 1:  Loss:     0.9458 Validation Accuracy: 0.615200\n",
      "Epoch 512, CIFAR-10 Batch 2:  Loss:     0.9610 Validation Accuracy: 0.616000\n",
      "Epoch 512, CIFAR-10 Batch 3:  Loss:     0.9461 Validation Accuracy: 0.615000\n",
      "Epoch 512, CIFAR-10 Batch 4:  Loss:     0.9591 Validation Accuracy: 0.615400\n",
      "Epoch 512, CIFAR-10 Batch 5:  Loss:     0.9581 Validation Accuracy: 0.616000\n",
      "Epoch 513, CIFAR-10 Batch 1:  Loss:     0.9453 Validation Accuracy: 0.615400\n",
      "Epoch 513, CIFAR-10 Batch 2:  Loss:     0.9605 Validation Accuracy: 0.616000\n",
      "Epoch 513, CIFAR-10 Batch 3:  Loss:     0.9457 Validation Accuracy: 0.615600\n",
      "Epoch 513, CIFAR-10 Batch 4:  Loss:     0.9586 Validation Accuracy: 0.615400\n",
      "Epoch 513, CIFAR-10 Batch 5:  Loss:     0.9577 Validation Accuracy: 0.615800\n",
      "Epoch 514, CIFAR-10 Batch 1:  Loss:     0.9447 Validation Accuracy: 0.615000\n",
      "Epoch 514, CIFAR-10 Batch 2:  Loss:     0.9599 Validation Accuracy: 0.616200\n",
      "Epoch 514, CIFAR-10 Batch 3:  Loss:     0.9452 Validation Accuracy: 0.615600\n",
      "Epoch 514, CIFAR-10 Batch 4:  Loss:     0.9582 Validation Accuracy: 0.615800\n",
      "Epoch 514, CIFAR-10 Batch 5:  Loss:     0.9572 Validation Accuracy: 0.615800\n",
      "Epoch 515, CIFAR-10 Batch 1:  Loss:     0.9441 Validation Accuracy: 0.614800\n",
      "Epoch 515, CIFAR-10 Batch 2:  Loss:     0.9593 Validation Accuracy: 0.616600\n",
      "Epoch 515, CIFAR-10 Batch 3:  Loss:     0.9448 Validation Accuracy: 0.616200\n",
      "Epoch 515, CIFAR-10 Batch 4:  Loss:     0.9579 Validation Accuracy: 0.616000\n",
      "Epoch 515, CIFAR-10 Batch 5:  Loss:     0.9568 Validation Accuracy: 0.615800\n",
      "Epoch 516, CIFAR-10 Batch 1:  Loss:     0.9436 Validation Accuracy: 0.614000\n",
      "Epoch 516, CIFAR-10 Batch 2:  Loss:     0.9588 Validation Accuracy: 0.616400\n",
      "Epoch 516, CIFAR-10 Batch 3:  Loss:     0.9446 Validation Accuracy: 0.616200\n",
      "Epoch 516, CIFAR-10 Batch 4:  Loss:     0.9576 Validation Accuracy: 0.616600\n",
      "Epoch 516, CIFAR-10 Batch 5:  Loss:     0.9564 Validation Accuracy: 0.616800\n",
      "Epoch 517, CIFAR-10 Batch 1:  Loss:     0.9432 Validation Accuracy: 0.614800\n",
      "Epoch 517, CIFAR-10 Batch 2:  Loss:     0.9585 Validation Accuracy: 0.616600\n",
      "Epoch 517, CIFAR-10 Batch 3:  Loss:     0.9443 Validation Accuracy: 0.616200\n",
      "Epoch 517, CIFAR-10 Batch 4:  Loss:     0.9572 Validation Accuracy: 0.616400\n",
      "Epoch 517, CIFAR-10 Batch 5:  Loss:     0.9560 Validation Accuracy: 0.616800\n",
      "Epoch 518, CIFAR-10 Batch 1:  Loss:     0.9428 Validation Accuracy: 0.614800\n",
      "Epoch 518, CIFAR-10 Batch 2:  Loss:     0.9582 Validation Accuracy: 0.616200\n",
      "Epoch 518, CIFAR-10 Batch 3:  Loss:     0.9440 Validation Accuracy: 0.615400\n",
      "Epoch 518, CIFAR-10 Batch 4:  Loss:     0.9568 Validation Accuracy: 0.617200\n",
      "Epoch 518, CIFAR-10 Batch 5:  Loss:     0.9556 Validation Accuracy: 0.616600\n",
      "Epoch 519, CIFAR-10 Batch 1:  Loss:     0.9425 Validation Accuracy: 0.614800\n",
      "Epoch 519, CIFAR-10 Batch 2:  Loss:     0.9578 Validation Accuracy: 0.616400\n",
      "Epoch 519, CIFAR-10 Batch 3:  Loss:     0.9435 Validation Accuracy: 0.616000\n",
      "Epoch 519, CIFAR-10 Batch 4:  Loss:     0.9562 Validation Accuracy: 0.617000\n",
      "Epoch 519, CIFAR-10 Batch 5:  Loss:     0.9551 Validation Accuracy: 0.616000\n",
      "Epoch 520, CIFAR-10 Batch 1:  Loss:     0.9421 Validation Accuracy: 0.614800\n",
      "Epoch 520, CIFAR-10 Batch 2:  Loss:     0.9573 Validation Accuracy: 0.616200\n",
      "Epoch 520, CIFAR-10 Batch 3:  Loss:     0.9430 Validation Accuracy: 0.616600\n",
      "Epoch 520, CIFAR-10 Batch 4:  Loss:     0.9556 Validation Accuracy: 0.616600\n",
      "Epoch 520, CIFAR-10 Batch 5:  Loss:     0.9546 Validation Accuracy: 0.616000\n",
      "Epoch 521, CIFAR-10 Batch 1:  Loss:     0.9416 Validation Accuracy: 0.614600\n",
      "Epoch 521, CIFAR-10 Batch 2:  Loss:     0.9567 Validation Accuracy: 0.615800\n",
      "Epoch 521, CIFAR-10 Batch 3:  Loss:     0.9425 Validation Accuracy: 0.617800\n",
      "Epoch 521, CIFAR-10 Batch 4:  Loss:     0.9550 Validation Accuracy: 0.616200\n",
      "Epoch 521, CIFAR-10 Batch 5:  Loss:     0.9541 Validation Accuracy: 0.616000\n",
      "Epoch 522, CIFAR-10 Batch 1:  Loss:     0.9410 Validation Accuracy: 0.614400\n",
      "Epoch 522, CIFAR-10 Batch 2:  Loss:     0.9560 Validation Accuracy: 0.616800\n",
      "Epoch 522, CIFAR-10 Batch 3:  Loss:     0.9419 Validation Accuracy: 0.617800\n",
      "Epoch 522, CIFAR-10 Batch 4:  Loss:     0.9545 Validation Accuracy: 0.616600\n",
      "Epoch 522, CIFAR-10 Batch 5:  Loss:     0.9536 Validation Accuracy: 0.616400\n",
      "Epoch 523, CIFAR-10 Batch 1:  Loss:     0.9404 Validation Accuracy: 0.613800\n",
      "Epoch 523, CIFAR-10 Batch 2:  Loss:     0.9555 Validation Accuracy: 0.616600\n",
      "Epoch 523, CIFAR-10 Batch 3:  Loss:     0.9416 Validation Accuracy: 0.618400\n",
      "Epoch 523, CIFAR-10 Batch 4:  Loss:     0.9541 Validation Accuracy: 0.616200\n",
      "Epoch 523, CIFAR-10 Batch 5:  Loss:     0.9532 Validation Accuracy: 0.616600\n",
      "Epoch 524, CIFAR-10 Batch 1:  Loss:     0.9400 Validation Accuracy: 0.615000\n",
      "Epoch 524, CIFAR-10 Batch 2:  Loss:     0.9550 Validation Accuracy: 0.617400\n",
      "Epoch 524, CIFAR-10 Batch 3:  Loss:     0.9412 Validation Accuracy: 0.618600\n",
      "Epoch 524, CIFAR-10 Batch 4:  Loss:     0.9537 Validation Accuracy: 0.617000\n",
      "Epoch 524, CIFAR-10 Batch 5:  Loss:     0.9527 Validation Accuracy: 0.616400\n",
      "Epoch 525, CIFAR-10 Batch 1:  Loss:     0.9396 Validation Accuracy: 0.615200\n",
      "Epoch 525, CIFAR-10 Batch 2:  Loss:     0.9547 Validation Accuracy: 0.617400\n",
      "Epoch 525, CIFAR-10 Batch 3:  Loss:     0.9408 Validation Accuracy: 0.618800\n",
      "Epoch 525, CIFAR-10 Batch 4:  Loss:     0.9532 Validation Accuracy: 0.616400\n",
      "Epoch 525, CIFAR-10 Batch 5:  Loss:     0.9523 Validation Accuracy: 0.616400\n",
      "Epoch 526, CIFAR-10 Batch 1:  Loss:     0.9392 Validation Accuracy: 0.615600\n",
      "Epoch 526, CIFAR-10 Batch 2:  Loss:     0.9542 Validation Accuracy: 0.617400\n",
      "Epoch 526, CIFAR-10 Batch 3:  Loss:     0.9405 Validation Accuracy: 0.617800\n",
      "Epoch 526, CIFAR-10 Batch 4:  Loss:     0.9529 Validation Accuracy: 0.616400\n",
      "Epoch 526, CIFAR-10 Batch 5:  Loss:     0.9519 Validation Accuracy: 0.616200\n",
      "Epoch 527, CIFAR-10 Batch 1:  Loss:     0.9388 Validation Accuracy: 0.616200\n",
      "Epoch 527, CIFAR-10 Batch 2:  Loss:     0.9536 Validation Accuracy: 0.617800\n",
      "Epoch 527, CIFAR-10 Batch 3:  Loss:     0.9397 Validation Accuracy: 0.618400\n",
      "Epoch 527, CIFAR-10 Batch 4:  Loss:     0.9522 Validation Accuracy: 0.618000\n",
      "Epoch 527, CIFAR-10 Batch 5:  Loss:     0.9515 Validation Accuracy: 0.616600\n",
      "Epoch 528, CIFAR-10 Batch 1:  Loss:     0.9383 Validation Accuracy: 0.616800\n",
      "Epoch 528, CIFAR-10 Batch 2:  Loss:     0.9535 Validation Accuracy: 0.617800\n",
      "Epoch 528, CIFAR-10 Batch 3:  Loss:     0.9401 Validation Accuracy: 0.618600\n",
      "Epoch 528, CIFAR-10 Batch 4:  Loss:     0.9522 Validation Accuracy: 0.615000\n",
      "Epoch 528, CIFAR-10 Batch 5:  Loss:     0.9512 Validation Accuracy: 0.617200\n",
      "Epoch 529, CIFAR-10 Batch 1:  Loss:     0.9379 Validation Accuracy: 0.615600\n",
      "Epoch 529, CIFAR-10 Batch 2:  Loss:     0.9524 Validation Accuracy: 0.620600\n",
      "Epoch 529, CIFAR-10 Batch 3:  Loss:     0.9382 Validation Accuracy: 0.617400\n",
      "Epoch 529, CIFAR-10 Batch 4:  Loss:     0.9513 Validation Accuracy: 0.619000\n",
      "Epoch 529, CIFAR-10 Batch 5:  Loss:     0.9512 Validation Accuracy: 0.618800\n",
      "Epoch 530, CIFAR-10 Batch 1:  Loss:     0.9386 Validation Accuracy: 0.614600\n",
      "Epoch 530, CIFAR-10 Batch 2:  Loss:     0.9554 Validation Accuracy: 0.618000\n",
      "Epoch 530, CIFAR-10 Batch 3:  Loss:     0.9440 Validation Accuracy: 0.618600\n",
      "Epoch 530, CIFAR-10 Batch 4:  Loss:     0.9554 Validation Accuracy: 0.616200\n",
      "Epoch 530, CIFAR-10 Batch 5:  Loss:     0.9538 Validation Accuracy: 0.614800\n",
      "Epoch 531, CIFAR-10 Batch 1:  Loss:     0.9403 Validation Accuracy: 0.615800\n",
      "Epoch 531, CIFAR-10 Batch 2:  Loss:     0.9537 Validation Accuracy: 0.618400\n",
      "Epoch 531, CIFAR-10 Batch 3:  Loss:     0.9386 Validation Accuracy: 0.617000\n",
      "Epoch 531, CIFAR-10 Batch 4:  Loss:     0.9550 Validation Accuracy: 0.616200\n",
      "Epoch 531, CIFAR-10 Batch 5:  Loss:     0.9557 Validation Accuracy: 0.616000\n",
      "Epoch 532, CIFAR-10 Batch 1:  Loss:     0.9440 Validation Accuracy: 0.612000\n",
      "Epoch 532, CIFAR-10 Batch 2:  Loss:     0.9599 Validation Accuracy: 0.615000\n",
      "Epoch 532, CIFAR-10 Batch 3:  Loss:     0.9467 Validation Accuracy: 0.618800\n",
      "Epoch 532, CIFAR-10 Batch 4:  Loss:     0.9537 Validation Accuracy: 0.615400\n",
      "Epoch 532, CIFAR-10 Batch 5:  Loss:     0.9501 Validation Accuracy: 0.618000\n",
      "Epoch 533, CIFAR-10 Batch 1:  Loss:     0.9364 Validation Accuracy: 0.617800\n",
      "Epoch 533, CIFAR-10 Batch 2:  Loss:     0.9513 Validation Accuracy: 0.618000\n",
      "Epoch 533, CIFAR-10 Batch 3:  Loss:     0.9397 Validation Accuracy: 0.619800\n",
      "Epoch 533, CIFAR-10 Batch 4:  Loss:     0.9509 Validation Accuracy: 0.616200\n",
      "Epoch 533, CIFAR-10 Batch 5:  Loss:     0.9496 Validation Accuracy: 0.617200\n",
      "Epoch 534, CIFAR-10 Batch 1:  Loss:     0.9362 Validation Accuracy: 0.614400\n",
      "Epoch 534, CIFAR-10 Batch 2:  Loss:     0.9487 Validation Accuracy: 0.620600\n",
      "Epoch 534, CIFAR-10 Batch 3:  Loss:     0.9353 Validation Accuracy: 0.619600\n",
      "Epoch 534, CIFAR-10 Batch 4:  Loss:     0.9481 Validation Accuracy: 0.618200\n",
      "Epoch 534, CIFAR-10 Batch 5:  Loss:     0.9473 Validation Accuracy: 0.618000\n",
      "Epoch 535, CIFAR-10 Batch 1:  Loss:     0.9347 Validation Accuracy: 0.617000\n",
      "Epoch 535, CIFAR-10 Batch 2:  Loss:     0.9485 Validation Accuracy: 0.621800\n",
      "Epoch 535, CIFAR-10 Batch 3:  Loss:     0.9354 Validation Accuracy: 0.619200\n",
      "Epoch 535, CIFAR-10 Batch 4:  Loss:     0.9477 Validation Accuracy: 0.618200\n",
      "Epoch 535, CIFAR-10 Batch 5:  Loss:     0.9469 Validation Accuracy: 0.619400\n",
      "Epoch 536, CIFAR-10 Batch 1:  Loss:     0.9348 Validation Accuracy: 0.616600\n",
      "Epoch 536, CIFAR-10 Batch 2:  Loss:     0.9497 Validation Accuracy: 0.620600\n",
      "Epoch 536, CIFAR-10 Batch 3:  Loss:     0.9377 Validation Accuracy: 0.619600\n",
      "Epoch 536, CIFAR-10 Batch 4:  Loss:     0.9484 Validation Accuracy: 0.617200\n",
      "Epoch 536, CIFAR-10 Batch 5:  Loss:     0.9463 Validation Accuracy: 0.618800\n",
      "Epoch 537, CIFAR-10 Batch 1:  Loss:     0.9341 Validation Accuracy: 0.617800\n",
      "Epoch 537, CIFAR-10 Batch 2:  Loss:     0.9488 Validation Accuracy: 0.620600\n",
      "Epoch 537, CIFAR-10 Batch 3:  Loss:     0.9371 Validation Accuracy: 0.619200\n",
      "Epoch 537, CIFAR-10 Batch 4:  Loss:     0.9484 Validation Accuracy: 0.618200\n",
      "Epoch 537, CIFAR-10 Batch 5:  Loss:     0.9463 Validation Accuracy: 0.619200\n",
      "Epoch 538, CIFAR-10 Batch 1:  Loss:     0.9340 Validation Accuracy: 0.616800\n",
      "Epoch 538, CIFAR-10 Batch 2:  Loss:     0.9478 Validation Accuracy: 0.620400\n",
      "Epoch 538, CIFAR-10 Batch 3:  Loss:     0.9354 Validation Accuracy: 0.620400\n",
      "Epoch 538, CIFAR-10 Batch 4:  Loss:     0.9474 Validation Accuracy: 0.618600\n",
      "Epoch 538, CIFAR-10 Batch 5:  Loss:     0.9460 Validation Accuracy: 0.618400\n",
      "Epoch 539, CIFAR-10 Batch 1:  Loss:     0.9339 Validation Accuracy: 0.618400\n",
      "Epoch 539, CIFAR-10 Batch 2:  Loss:     0.9480 Validation Accuracy: 0.621400\n",
      "Epoch 539, CIFAR-10 Batch 3:  Loss:     0.9357 Validation Accuracy: 0.619000\n",
      "Epoch 539, CIFAR-10 Batch 4:  Loss:     0.9471 Validation Accuracy: 0.617600\n",
      "Epoch 539, CIFAR-10 Batch 5:  Loss:     0.9456 Validation Accuracy: 0.619200\n",
      "Epoch 540, CIFAR-10 Batch 1:  Loss:     0.9334 Validation Accuracy: 0.618000\n",
      "Epoch 540, CIFAR-10 Batch 2:  Loss:     0.9477 Validation Accuracy: 0.621600\n",
      "Epoch 540, CIFAR-10 Batch 3:  Loss:     0.9359 Validation Accuracy: 0.620000\n",
      "Epoch 540, CIFAR-10 Batch 4:  Loss:     0.9470 Validation Accuracy: 0.617200\n",
      "Epoch 540, CIFAR-10 Batch 5:  Loss:     0.9451 Validation Accuracy: 0.619800\n",
      "Epoch 541, CIFAR-10 Batch 1:  Loss:     0.9327 Validation Accuracy: 0.618600\n",
      "Epoch 541, CIFAR-10 Batch 2:  Loss:     0.9468 Validation Accuracy: 0.620800\n",
      "Epoch 541, CIFAR-10 Batch 3:  Loss:     0.9348 Validation Accuracy: 0.620200\n",
      "Epoch 541, CIFAR-10 Batch 4:  Loss:     0.9462 Validation Accuracy: 0.617400\n",
      "Epoch 541, CIFAR-10 Batch 5:  Loss:     0.9445 Validation Accuracy: 0.619200\n",
      "Epoch 542, CIFAR-10 Batch 1:  Loss:     0.9322 Validation Accuracy: 0.618000\n",
      "Epoch 542, CIFAR-10 Batch 2:  Loss:     0.9464 Validation Accuracy: 0.621600\n",
      "Epoch 542, CIFAR-10 Batch 3:  Loss:     0.9344 Validation Accuracy: 0.620600\n",
      "Epoch 542, CIFAR-10 Batch 4:  Loss:     0.9455 Validation Accuracy: 0.618200\n",
      "Epoch 542, CIFAR-10 Batch 5:  Loss:     0.9440 Validation Accuracy: 0.619400\n",
      "Epoch 543, CIFAR-10 Batch 1:  Loss:     0.9318 Validation Accuracy: 0.618400\n",
      "Epoch 543, CIFAR-10 Batch 2:  Loss:     0.9463 Validation Accuracy: 0.621600\n",
      "Epoch 543, CIFAR-10 Batch 3:  Loss:     0.9344 Validation Accuracy: 0.620400\n",
      "Epoch 543, CIFAR-10 Batch 4:  Loss:     0.9452 Validation Accuracy: 0.618600\n",
      "Epoch 543, CIFAR-10 Batch 5:  Loss:     0.9435 Validation Accuracy: 0.620000\n",
      "Epoch 544, CIFAR-10 Batch 1:  Loss:     0.9313 Validation Accuracy: 0.617600\n",
      "Epoch 544, CIFAR-10 Batch 2:  Loss:     0.9456 Validation Accuracy: 0.621400\n",
      "Epoch 544, CIFAR-10 Batch 3:  Loss:     0.9338 Validation Accuracy: 0.620200\n",
      "Epoch 544, CIFAR-10 Batch 4:  Loss:     0.9447 Validation Accuracy: 0.618600\n",
      "Epoch 544, CIFAR-10 Batch 5:  Loss:     0.9431 Validation Accuracy: 0.619800\n",
      "Epoch 545, CIFAR-10 Batch 1:  Loss:     0.9310 Validation Accuracy: 0.618000\n",
      "Epoch 545, CIFAR-10 Batch 2:  Loss:     0.9453 Validation Accuracy: 0.621800\n",
      "Epoch 545, CIFAR-10 Batch 3:  Loss:     0.9336 Validation Accuracy: 0.619800\n",
      "Epoch 545, CIFAR-10 Batch 4:  Loss:     0.9443 Validation Accuracy: 0.617800\n",
      "Epoch 545, CIFAR-10 Batch 5:  Loss:     0.9428 Validation Accuracy: 0.620200\n",
      "Epoch 546, CIFAR-10 Batch 1:  Loss:     0.9306 Validation Accuracy: 0.618200\n",
      "Epoch 546, CIFAR-10 Batch 2:  Loss:     0.9449 Validation Accuracy: 0.621800\n",
      "Epoch 546, CIFAR-10 Batch 3:  Loss:     0.9332 Validation Accuracy: 0.620400\n",
      "Epoch 546, CIFAR-10 Batch 4:  Loss:     0.9439 Validation Accuracy: 0.617400\n",
      "Epoch 546, CIFAR-10 Batch 5:  Loss:     0.9424 Validation Accuracy: 0.620000\n",
      "Epoch 547, CIFAR-10 Batch 1:  Loss:     0.9302 Validation Accuracy: 0.618200\n",
      "Epoch 547, CIFAR-10 Batch 2:  Loss:     0.9446 Validation Accuracy: 0.621600\n",
      "Epoch 547, CIFAR-10 Batch 3:  Loss:     0.9331 Validation Accuracy: 0.620000\n",
      "Epoch 547, CIFAR-10 Batch 4:  Loss:     0.9435 Validation Accuracy: 0.618400\n",
      "Epoch 547, CIFAR-10 Batch 5:  Loss:     0.9420 Validation Accuracy: 0.620200\n",
      "Epoch 548, CIFAR-10 Batch 1:  Loss:     0.9298 Validation Accuracy: 0.618000\n",
      "Epoch 548, CIFAR-10 Batch 2:  Loss:     0.9441 Validation Accuracy: 0.622000\n",
      "Epoch 548, CIFAR-10 Batch 3:  Loss:     0.9327 Validation Accuracy: 0.620600\n",
      "Epoch 548, CIFAR-10 Batch 4:  Loss:     0.9431 Validation Accuracy: 0.618800\n",
      "Epoch 548, CIFAR-10 Batch 5:  Loss:     0.9416 Validation Accuracy: 0.620200\n",
      "Epoch 549, CIFAR-10 Batch 1:  Loss:     0.9294 Validation Accuracy: 0.617800\n",
      "Epoch 549, CIFAR-10 Batch 2:  Loss:     0.9437 Validation Accuracy: 0.621600\n",
      "Epoch 549, CIFAR-10 Batch 3:  Loss:     0.9323 Validation Accuracy: 0.620400\n",
      "Epoch 549, CIFAR-10 Batch 4:  Loss:     0.9426 Validation Accuracy: 0.618800\n",
      "Epoch 549, CIFAR-10 Batch 5:  Loss:     0.9411 Validation Accuracy: 0.620800\n",
      "Epoch 550, CIFAR-10 Batch 1:  Loss:     0.9289 Validation Accuracy: 0.617800\n",
      "Epoch 550, CIFAR-10 Batch 2:  Loss:     0.9432 Validation Accuracy: 0.622200\n",
      "Epoch 550, CIFAR-10 Batch 3:  Loss:     0.9319 Validation Accuracy: 0.620800\n",
      "Epoch 550, CIFAR-10 Batch 4:  Loss:     0.9420 Validation Accuracy: 0.619200\n",
      "Epoch 550, CIFAR-10 Batch 5:  Loss:     0.9406 Validation Accuracy: 0.621000\n",
      "Epoch 551, CIFAR-10 Batch 1:  Loss:     0.9285 Validation Accuracy: 0.618600\n",
      "Epoch 551, CIFAR-10 Batch 2:  Loss:     0.9427 Validation Accuracy: 0.622400\n",
      "Epoch 551, CIFAR-10 Batch 3:  Loss:     0.9315 Validation Accuracy: 0.621600\n",
      "Epoch 551, CIFAR-10 Batch 4:  Loss:     0.9416 Validation Accuracy: 0.620000\n",
      "Epoch 551, CIFAR-10 Batch 5:  Loss:     0.9402 Validation Accuracy: 0.621000\n",
      "Epoch 552, CIFAR-10 Batch 1:  Loss:     0.9281 Validation Accuracy: 0.618400\n",
      "Epoch 552, CIFAR-10 Batch 2:  Loss:     0.9423 Validation Accuracy: 0.621400\n",
      "Epoch 552, CIFAR-10 Batch 3:  Loss:     0.9314 Validation Accuracy: 0.620800\n",
      "Epoch 552, CIFAR-10 Batch 4:  Loss:     0.9412 Validation Accuracy: 0.621600\n",
      "Epoch 552, CIFAR-10 Batch 5:  Loss:     0.9398 Validation Accuracy: 0.621400\n",
      "Epoch 553, CIFAR-10 Batch 1:  Loss:     0.9276 Validation Accuracy: 0.618800\n",
      "Epoch 553, CIFAR-10 Batch 2:  Loss:     0.9417 Validation Accuracy: 0.621200\n",
      "Epoch 553, CIFAR-10 Batch 3:  Loss:     0.9308 Validation Accuracy: 0.620600\n",
      "Epoch 553, CIFAR-10 Batch 4:  Loss:     0.9407 Validation Accuracy: 0.621000\n",
      "Epoch 553, CIFAR-10 Batch 5:  Loss:     0.9394 Validation Accuracy: 0.621800\n",
      "Epoch 554, CIFAR-10 Batch 1:  Loss:     0.9273 Validation Accuracy: 0.619000\n",
      "Epoch 554, CIFAR-10 Batch 2:  Loss:     0.9415 Validation Accuracy: 0.622200\n",
      "Epoch 554, CIFAR-10 Batch 3:  Loss:     0.9306 Validation Accuracy: 0.620400\n",
      "Epoch 554, CIFAR-10 Batch 4:  Loss:     0.9404 Validation Accuracy: 0.621000\n",
      "Epoch 554, CIFAR-10 Batch 5:  Loss:     0.9390 Validation Accuracy: 0.621200\n",
      "Epoch 555, CIFAR-10 Batch 1:  Loss:     0.9270 Validation Accuracy: 0.618800\n",
      "Epoch 555, CIFAR-10 Batch 2:  Loss:     0.9411 Validation Accuracy: 0.621800\n",
      "Epoch 555, CIFAR-10 Batch 3:  Loss:     0.9304 Validation Accuracy: 0.620400\n",
      "Epoch 555, CIFAR-10 Batch 4:  Loss:     0.9401 Validation Accuracy: 0.621400\n",
      "Epoch 555, CIFAR-10 Batch 5:  Loss:     0.9387 Validation Accuracy: 0.620600\n",
      "Epoch 556, CIFAR-10 Batch 1:  Loss:     0.9267 Validation Accuracy: 0.618600\n",
      "Epoch 556, CIFAR-10 Batch 2:  Loss:     0.9409 Validation Accuracy: 0.621400\n",
      "Epoch 556, CIFAR-10 Batch 3:  Loss:     0.9303 Validation Accuracy: 0.620400\n",
      "Epoch 556, CIFAR-10 Batch 4:  Loss:     0.9397 Validation Accuracy: 0.621200\n",
      "Epoch 556, CIFAR-10 Batch 5:  Loss:     0.9383 Validation Accuracy: 0.621000\n",
      "Epoch 557, CIFAR-10 Batch 1:  Loss:     0.9265 Validation Accuracy: 0.618200\n",
      "Epoch 557, CIFAR-10 Batch 2:  Loss:     0.9407 Validation Accuracy: 0.621400\n",
      "Epoch 557, CIFAR-10 Batch 3:  Loss:     0.9302 Validation Accuracy: 0.620200\n",
      "Epoch 557, CIFAR-10 Batch 4:  Loss:     0.9393 Validation Accuracy: 0.621200\n",
      "Epoch 557, CIFAR-10 Batch 5:  Loss:     0.9378 Validation Accuracy: 0.621600\n",
      "Epoch 558, CIFAR-10 Batch 1:  Loss:     0.9261 Validation Accuracy: 0.618600\n",
      "Epoch 558, CIFAR-10 Batch 2:  Loss:     0.9401 Validation Accuracy: 0.621200\n",
      "Epoch 558, CIFAR-10 Batch 3:  Loss:     0.9296 Validation Accuracy: 0.619800\n",
      "Epoch 558, CIFAR-10 Batch 4:  Loss:     0.9386 Validation Accuracy: 0.620200\n",
      "Epoch 558, CIFAR-10 Batch 5:  Loss:     0.9372 Validation Accuracy: 0.620800\n",
      "Epoch 559, CIFAR-10 Batch 1:  Loss:     0.9257 Validation Accuracy: 0.619400\n",
      "Epoch 559, CIFAR-10 Batch 2:  Loss:     0.9396 Validation Accuracy: 0.622200\n",
      "Epoch 559, CIFAR-10 Batch 3:  Loss:     0.9290 Validation Accuracy: 0.620000\n",
      "Epoch 559, CIFAR-10 Batch 4:  Loss:     0.9379 Validation Accuracy: 0.621000\n",
      "Epoch 559, CIFAR-10 Batch 5:  Loss:     0.9366 Validation Accuracy: 0.621000\n",
      "Epoch 560, CIFAR-10 Batch 1:  Loss:     0.9253 Validation Accuracy: 0.619400\n",
      "Epoch 560, CIFAR-10 Batch 2:  Loss:     0.9389 Validation Accuracy: 0.622200\n",
      "Epoch 560, CIFAR-10 Batch 3:  Loss:     0.9282 Validation Accuracy: 0.620200\n",
      "Epoch 560, CIFAR-10 Batch 4:  Loss:     0.9372 Validation Accuracy: 0.621800\n",
      "Epoch 560, CIFAR-10 Batch 5:  Loss:     0.9360 Validation Accuracy: 0.622000\n",
      "Epoch 561, CIFAR-10 Batch 1:  Loss:     0.9249 Validation Accuracy: 0.619200\n",
      "Epoch 561, CIFAR-10 Batch 2:  Loss:     0.9386 Validation Accuracy: 0.621800\n",
      "Epoch 561, CIFAR-10 Batch 3:  Loss:     0.9281 Validation Accuracy: 0.620600\n",
      "Epoch 561, CIFAR-10 Batch 4:  Loss:     0.9368 Validation Accuracy: 0.621600\n",
      "Epoch 561, CIFAR-10 Batch 5:  Loss:     0.9355 Validation Accuracy: 0.621600\n",
      "Epoch 562, CIFAR-10 Batch 1:  Loss:     0.9244 Validation Accuracy: 0.619400\n",
      "Epoch 562, CIFAR-10 Batch 2:  Loss:     0.9380 Validation Accuracy: 0.622000\n",
      "Epoch 562, CIFAR-10 Batch 3:  Loss:     0.9276 Validation Accuracy: 0.620800\n",
      "Epoch 562, CIFAR-10 Batch 4:  Loss:     0.9365 Validation Accuracy: 0.621600\n",
      "Epoch 562, CIFAR-10 Batch 5:  Loss:     0.9352 Validation Accuracy: 0.621600\n",
      "Epoch 563, CIFAR-10 Batch 1:  Loss:     0.9241 Validation Accuracy: 0.619400\n",
      "Epoch 563, CIFAR-10 Batch 2:  Loss:     0.9376 Validation Accuracy: 0.621800\n",
      "Epoch 563, CIFAR-10 Batch 3:  Loss:     0.9272 Validation Accuracy: 0.621000\n",
      "Epoch 563, CIFAR-10 Batch 4:  Loss:     0.9361 Validation Accuracy: 0.622000\n",
      "Epoch 563, CIFAR-10 Batch 5:  Loss:     0.9349 Validation Accuracy: 0.621600\n",
      "Epoch 564, CIFAR-10 Batch 1:  Loss:     0.9239 Validation Accuracy: 0.618200\n",
      "Epoch 564, CIFAR-10 Batch 2:  Loss:     0.9376 Validation Accuracy: 0.621800\n",
      "Epoch 564, CIFAR-10 Batch 3:  Loss:     0.9273 Validation Accuracy: 0.620800\n",
      "Epoch 564, CIFAR-10 Batch 4:  Loss:     0.9359 Validation Accuracy: 0.621200\n",
      "Epoch 564, CIFAR-10 Batch 5:  Loss:     0.9344 Validation Accuracy: 0.621400\n",
      "Epoch 565, CIFAR-10 Batch 1:  Loss:     0.9235 Validation Accuracy: 0.618200\n",
      "Epoch 565, CIFAR-10 Batch 2:  Loss:     0.9371 Validation Accuracy: 0.621800\n",
      "Epoch 565, CIFAR-10 Batch 3:  Loss:     0.9268 Validation Accuracy: 0.621000\n",
      "Epoch 565, CIFAR-10 Batch 4:  Loss:     0.9354 Validation Accuracy: 0.620800\n",
      "Epoch 565, CIFAR-10 Batch 5:  Loss:     0.9340 Validation Accuracy: 0.622200\n",
      "Epoch 566, CIFAR-10 Batch 1:  Loss:     0.9233 Validation Accuracy: 0.618400\n",
      "Epoch 566, CIFAR-10 Batch 2:  Loss:     0.9369 Validation Accuracy: 0.622000\n",
      "Epoch 566, CIFAR-10 Batch 3:  Loss:     0.9265 Validation Accuracy: 0.622000\n",
      "Epoch 566, CIFAR-10 Batch 4:  Loss:     0.9348 Validation Accuracy: 0.621600\n",
      "Epoch 566, CIFAR-10 Batch 5:  Loss:     0.9335 Validation Accuracy: 0.623000\n",
      "Epoch 567, CIFAR-10 Batch 1:  Loss:     0.9230 Validation Accuracy: 0.618000\n",
      "Epoch 567, CIFAR-10 Batch 2:  Loss:     0.9365 Validation Accuracy: 0.622600\n",
      "Epoch 567, CIFAR-10 Batch 3:  Loss:     0.9260 Validation Accuracy: 0.621600\n",
      "Epoch 567, CIFAR-10 Batch 4:  Loss:     0.9342 Validation Accuracy: 0.621600\n",
      "Epoch 567, CIFAR-10 Batch 5:  Loss:     0.9330 Validation Accuracy: 0.623000\n",
      "Epoch 568, CIFAR-10 Batch 1:  Loss:     0.9225 Validation Accuracy: 0.618600\n",
      "Epoch 568, CIFAR-10 Batch 2:  Loss:     0.9358 Validation Accuracy: 0.621200\n",
      "Epoch 568, CIFAR-10 Batch 3:  Loss:     0.9250 Validation Accuracy: 0.621400\n",
      "Epoch 568, CIFAR-10 Batch 4:  Loss:     0.9335 Validation Accuracy: 0.622600\n",
      "Epoch 568, CIFAR-10 Batch 5:  Loss:     0.9325 Validation Accuracy: 0.622600\n",
      "Epoch 569, CIFAR-10 Batch 1:  Loss:     0.9224 Validation Accuracy: 0.619000\n",
      "Epoch 569, CIFAR-10 Batch 2:  Loss:     0.9357 Validation Accuracy: 0.622000\n",
      "Epoch 569, CIFAR-10 Batch 3:  Loss:     0.9248 Validation Accuracy: 0.621400\n",
      "Epoch 569, CIFAR-10 Batch 4:  Loss:     0.9330 Validation Accuracy: 0.623000\n",
      "Epoch 569, CIFAR-10 Batch 5:  Loss:     0.9320 Validation Accuracy: 0.622600\n",
      "Epoch 570, CIFAR-10 Batch 1:  Loss:     0.9219 Validation Accuracy: 0.619400\n",
      "Epoch 570, CIFAR-10 Batch 2:  Loss:     0.9351 Validation Accuracy: 0.621800\n",
      "Epoch 570, CIFAR-10 Batch 3:  Loss:     0.9239 Validation Accuracy: 0.621600\n",
      "Epoch 570, CIFAR-10 Batch 4:  Loss:     0.9324 Validation Accuracy: 0.623400\n",
      "Epoch 570, CIFAR-10 Batch 5:  Loss:     0.9318 Validation Accuracy: 0.622000\n",
      "Epoch 571, CIFAR-10 Batch 1:  Loss:     0.9220 Validation Accuracy: 0.620200\n",
      "Epoch 571, CIFAR-10 Batch 2:  Loss:     0.9353 Validation Accuracy: 0.621200\n",
      "Epoch 571, CIFAR-10 Batch 3:  Loss:     0.9240 Validation Accuracy: 0.621000\n",
      "Epoch 571, CIFAR-10 Batch 4:  Loss:     0.9321 Validation Accuracy: 0.623000\n",
      "Epoch 571, CIFAR-10 Batch 5:  Loss:     0.9315 Validation Accuracy: 0.622000\n",
      "Epoch 572, CIFAR-10 Batch 1:  Loss:     0.9219 Validation Accuracy: 0.619600\n",
      "Epoch 572, CIFAR-10 Batch 2:  Loss:     0.9354 Validation Accuracy: 0.620200\n",
      "Epoch 572, CIFAR-10 Batch 3:  Loss:     0.9241 Validation Accuracy: 0.621800\n",
      "Epoch 572, CIFAR-10 Batch 4:  Loss:     0.9318 Validation Accuracy: 0.623200\n",
      "Epoch 572, CIFAR-10 Batch 5:  Loss:     0.9311 Validation Accuracy: 0.622000\n",
      "Epoch 573, CIFAR-10 Batch 1:  Loss:     0.9215 Validation Accuracy: 0.619800\n",
      "Epoch 573, CIFAR-10 Batch 2:  Loss:     0.9350 Validation Accuracy: 0.619800\n",
      "Epoch 573, CIFAR-10 Batch 3:  Loss:     0.9235 Validation Accuracy: 0.622400\n",
      "Epoch 573, CIFAR-10 Batch 4:  Loss:     0.9313 Validation Accuracy: 0.624000\n",
      "Epoch 573, CIFAR-10 Batch 5:  Loss:     0.9310 Validation Accuracy: 0.621400\n",
      "Epoch 574, CIFAR-10 Batch 1:  Loss:     0.9215 Validation Accuracy: 0.618600\n",
      "Epoch 574, CIFAR-10 Batch 2:  Loss:     0.9348 Validation Accuracy: 0.619600\n",
      "Epoch 574, CIFAR-10 Batch 3:  Loss:     0.9230 Validation Accuracy: 0.622600\n",
      "Epoch 574, CIFAR-10 Batch 4:  Loss:     0.9308 Validation Accuracy: 0.624200\n",
      "Epoch 574, CIFAR-10 Batch 5:  Loss:     0.9308 Validation Accuracy: 0.620800\n",
      "Epoch 575, CIFAR-10 Batch 1:  Loss:     0.9218 Validation Accuracy: 0.618200\n",
      "Epoch 575, CIFAR-10 Batch 2:  Loss:     0.9351 Validation Accuracy: 0.619600\n",
      "Epoch 575, CIFAR-10 Batch 3:  Loss:     0.9227 Validation Accuracy: 0.623600\n",
      "Epoch 575, CIFAR-10 Batch 4:  Loss:     0.9303 Validation Accuracy: 0.624600\n",
      "Epoch 575, CIFAR-10 Batch 5:  Loss:     0.9307 Validation Accuracy: 0.620800\n",
      "Epoch 576, CIFAR-10 Batch 1:  Loss:     0.9221 Validation Accuracy: 0.616800\n",
      "Epoch 576, CIFAR-10 Batch 2:  Loss:     0.9352 Validation Accuracy: 0.619400\n",
      "Epoch 576, CIFAR-10 Batch 3:  Loss:     0.9221 Validation Accuracy: 0.624600\n",
      "Epoch 576, CIFAR-10 Batch 4:  Loss:     0.9298 Validation Accuracy: 0.624600\n",
      "Epoch 576, CIFAR-10 Batch 5:  Loss:     0.9308 Validation Accuracy: 0.621200\n",
      "Epoch 577, CIFAR-10 Batch 1:  Loss:     0.9227 Validation Accuracy: 0.616800\n",
      "Epoch 577, CIFAR-10 Batch 2:  Loss:     0.9354 Validation Accuracy: 0.618600\n",
      "Epoch 577, CIFAR-10 Batch 3:  Loss:     0.9211 Validation Accuracy: 0.624400\n",
      "Epoch 577, CIFAR-10 Batch 4:  Loss:     0.9293 Validation Accuracy: 0.624800\n",
      "Epoch 577, CIFAR-10 Batch 5:  Loss:     0.9318 Validation Accuracy: 0.620800\n",
      "Epoch 578, CIFAR-10 Batch 1:  Loss:     0.9248 Validation Accuracy: 0.615800\n",
      "Epoch 578, CIFAR-10 Batch 2:  Loss:     0.9363 Validation Accuracy: 0.618800\n",
      "Epoch 578, CIFAR-10 Batch 3:  Loss:     0.9202 Validation Accuracy: 0.625000\n",
      "Epoch 578, CIFAR-10 Batch 4:  Loss:     0.9291 Validation Accuracy: 0.624000\n",
      "Epoch 578, CIFAR-10 Batch 5:  Loss:     0.9340 Validation Accuracy: 0.617800\n",
      "Epoch 579, CIFAR-10 Batch 1:  Loss:     0.9285 Validation Accuracy: 0.613000\n",
      "Epoch 579, CIFAR-10 Batch 2:  Loss:     0.9379 Validation Accuracy: 0.617000\n",
      "Epoch 579, CIFAR-10 Batch 3:  Loss:     0.9189 Validation Accuracy: 0.625800\n",
      "Epoch 579, CIFAR-10 Batch 4:  Loss:     0.9297 Validation Accuracy: 0.623200\n",
      "Epoch 579, CIFAR-10 Batch 5:  Loss:     0.9382 Validation Accuracy: 0.616200\n",
      "Epoch 580, CIFAR-10 Batch 1:  Loss:     0.9337 Validation Accuracy: 0.609000\n",
      "Epoch 580, CIFAR-10 Batch 2:  Loss:     0.9384 Validation Accuracy: 0.618000\n",
      "Epoch 580, CIFAR-10 Batch 3:  Loss:     0.9161 Validation Accuracy: 0.625200\n",
      "Epoch 580, CIFAR-10 Batch 4:  Loss:     0.9334 Validation Accuracy: 0.621800\n",
      "Epoch 580, CIFAR-10 Batch 5:  Loss:     0.9473 Validation Accuracy: 0.612800\n",
      "Epoch 581, CIFAR-10 Batch 1:  Loss:     0.9402 Validation Accuracy: 0.605600\n",
      "Epoch 581, CIFAR-10 Batch 2:  Loss:     0.9354 Validation Accuracy: 0.619400\n",
      "Epoch 581, CIFAR-10 Batch 3:  Loss:     0.9132 Validation Accuracy: 0.623400\n",
      "Epoch 581, CIFAR-10 Batch 4:  Loss:     0.9495 Validation Accuracy: 0.614000\n",
      "Epoch 581, CIFAR-10 Batch 5:  Loss:     0.9662 Validation Accuracy: 0.604600\n",
      "Epoch 582, CIFAR-10 Batch 1:  Loss:     0.9432 Validation Accuracy: 0.606200\n",
      "Epoch 582, CIFAR-10 Batch 2:  Loss:     0.9270 Validation Accuracy: 0.623800\n",
      "Epoch 582, CIFAR-10 Batch 3:  Loss:     0.9246 Validation Accuracy: 0.617200\n",
      "Epoch 582, CIFAR-10 Batch 4:  Loss:     0.9930 Validation Accuracy: 0.599200\n",
      "Epoch 582, CIFAR-10 Batch 5:  Loss:     0.9787 Validation Accuracy: 0.598600\n",
      "Epoch 583, CIFAR-10 Batch 1:  Loss:     0.9233 Validation Accuracy: 0.614400\n",
      "Epoch 583, CIFAR-10 Batch 2:  Loss:     0.9355 Validation Accuracy: 0.619400\n",
      "Epoch 583, CIFAR-10 Batch 3:  Loss:     0.9673 Validation Accuracy: 0.598000\n",
      "Epoch 583, CIFAR-10 Batch 4:  Loss:     0.9944 Validation Accuracy: 0.598200\n",
      "Epoch 583, CIFAR-10 Batch 5:  Loss:     0.9300 Validation Accuracy: 0.623400\n",
      "Epoch 584, CIFAR-10 Batch 1:  Loss:     0.9349 Validation Accuracy: 0.612800\n",
      "Epoch 584, CIFAR-10 Batch 2:  Loss:     0.9767 Validation Accuracy: 0.602000\n",
      "Epoch 584, CIFAR-10 Batch 3:  Loss:     0.9365 Validation Accuracy: 0.611000\n",
      "Epoch 584, CIFAR-10 Batch 4:  Loss:     0.9295 Validation Accuracy: 0.625400\n",
      "Epoch 584, CIFAR-10 Batch 5:  Loss:     0.9484 Validation Accuracy: 0.614800\n",
      "Epoch 585, CIFAR-10 Batch 1:  Loss:     0.9529 Validation Accuracy: 0.604200\n",
      "Epoch 585, CIFAR-10 Batch 2:  Loss:     0.9290 Validation Accuracy: 0.624400\n",
      "Epoch 585, CIFAR-10 Batch 3:  Loss:     0.9229 Validation Accuracy: 0.622800\n",
      "Epoch 585, CIFAR-10 Batch 4:  Loss:     0.9507 Validation Accuracy: 0.619000\n",
      "Epoch 585, CIFAR-10 Batch 5:  Loss:     0.9283 Validation Accuracy: 0.624600\n",
      "Epoch 586, CIFAR-10 Batch 1:  Loss:     0.9134 Validation Accuracy: 0.623400\n",
      "Epoch 586, CIFAR-10 Batch 2:  Loss:     0.9416 Validation Accuracy: 0.618600\n",
      "Epoch 586, CIFAR-10 Batch 3:  Loss:     0.9090 Validation Accuracy: 0.624600\n",
      "Epoch 586, CIFAR-10 Batch 4:  Loss:     0.9365 Validation Accuracy: 0.623000\n",
      "Epoch 586, CIFAR-10 Batch 5:  Loss:     0.9340 Validation Accuracy: 0.624200\n",
      "Epoch 587, CIFAR-10 Batch 1:  Loss:     0.9101 Validation Accuracy: 0.625000\n",
      "Epoch 587, CIFAR-10 Batch 2:  Loss:     0.9302 Validation Accuracy: 0.622400\n",
      "Epoch 587, CIFAR-10 Batch 3:  Loss:     0.9205 Validation Accuracy: 0.619600\n",
      "Epoch 587, CIFAR-10 Batch 4:  Loss:     0.9290 Validation Accuracy: 0.622200\n",
      "Epoch 587, CIFAR-10 Batch 5:  Loss:     0.9233 Validation Accuracy: 0.626000\n",
      "Epoch 588, CIFAR-10 Batch 1:  Loss:     0.9255 Validation Accuracy: 0.620400\n",
      "Epoch 588, CIFAR-10 Batch 2:  Loss:     0.9275 Validation Accuracy: 0.622400\n",
      "Epoch 588, CIFAR-10 Batch 3:  Loss:     0.9079 Validation Accuracy: 0.625600\n",
      "Epoch 588, CIFAR-10 Batch 4:  Loss:     0.9282 Validation Accuracy: 0.626800\n",
      "Epoch 588, CIFAR-10 Batch 5:  Loss:     0.9221 Validation Accuracy: 0.625000\n",
      "Epoch 589, CIFAR-10 Batch 1:  Loss:     0.9094 Validation Accuracy: 0.624800\n",
      "Epoch 589, CIFAR-10 Batch 2:  Loss:     0.9244 Validation Accuracy: 0.624200\n",
      "Epoch 589, CIFAR-10 Batch 3:  Loss:     0.9064 Validation Accuracy: 0.625200\n",
      "Epoch 589, CIFAR-10 Batch 4:  Loss:     0.9245 Validation Accuracy: 0.626000\n",
      "Epoch 589, CIFAR-10 Batch 5:  Loss:     0.9208 Validation Accuracy: 0.625600\n",
      "Epoch 590, CIFAR-10 Batch 1:  Loss:     0.9075 Validation Accuracy: 0.625800\n",
      "Epoch 590, CIFAR-10 Batch 2:  Loss:     0.9220 Validation Accuracy: 0.624200\n",
      "Epoch 590, CIFAR-10 Batch 3:  Loss:     0.9091 Validation Accuracy: 0.627200\n",
      "Epoch 590, CIFAR-10 Batch 4:  Loss:     0.9271 Validation Accuracy: 0.624000\n",
      "Epoch 590, CIFAR-10 Batch 5:  Loss:     0.9192 Validation Accuracy: 0.626200\n",
      "Epoch 591, CIFAR-10 Batch 1:  Loss:     0.9119 Validation Accuracy: 0.625800\n",
      "Epoch 591, CIFAR-10 Batch 2:  Loss:     0.9251 Validation Accuracy: 0.623400\n",
      "Epoch 591, CIFAR-10 Batch 3:  Loss:     0.9068 Validation Accuracy: 0.626800\n",
      "Epoch 591, CIFAR-10 Batch 4:  Loss:     0.9241 Validation Accuracy: 0.624800\n",
      "Epoch 591, CIFAR-10 Batch 5:  Loss:     0.9194 Validation Accuracy: 0.626200\n",
      "Epoch 592, CIFAR-10 Batch 1:  Loss:     0.9100 Validation Accuracy: 0.625400\n",
      "Epoch 592, CIFAR-10 Batch 2:  Loss:     0.9220 Validation Accuracy: 0.625400\n",
      "Epoch 592, CIFAR-10 Batch 3:  Loss:     0.9053 Validation Accuracy: 0.624400\n",
      "Epoch 592, CIFAR-10 Batch 4:  Loss:     0.9223 Validation Accuracy: 0.625400\n",
      "Epoch 592, CIFAR-10 Batch 5:  Loss:     0.9172 Validation Accuracy: 0.625400\n",
      "Epoch 593, CIFAR-10 Batch 1:  Loss:     0.9078 Validation Accuracy: 0.624400\n",
      "Epoch 593, CIFAR-10 Batch 2:  Loss:     0.9207 Validation Accuracy: 0.627000\n",
      "Epoch 593, CIFAR-10 Batch 3:  Loss:     0.9053 Validation Accuracy: 0.627200\n",
      "Epoch 593, CIFAR-10 Batch 4:  Loss:     0.9232 Validation Accuracy: 0.625800\n",
      "Epoch 593, CIFAR-10 Batch 5:  Loss:     0.9169 Validation Accuracy: 0.626800\n",
      "Epoch 594, CIFAR-10 Batch 1:  Loss:     0.9074 Validation Accuracy: 0.625200\n",
      "Epoch 594, CIFAR-10 Batch 2:  Loss:     0.9215 Validation Accuracy: 0.623200\n",
      "Epoch 594, CIFAR-10 Batch 3:  Loss:     0.9063 Validation Accuracy: 0.628400\n",
      "Epoch 594, CIFAR-10 Batch 4:  Loss:     0.9236 Validation Accuracy: 0.625400\n",
      "Epoch 594, CIFAR-10 Batch 5:  Loss:     0.9174 Validation Accuracy: 0.625600\n",
      "Epoch 595, CIFAR-10 Batch 1:  Loss:     0.9089 Validation Accuracy: 0.626200\n",
      "Epoch 595, CIFAR-10 Batch 2:  Loss:     0.9220 Validation Accuracy: 0.622800\n",
      "Epoch 595, CIFAR-10 Batch 3:  Loss:     0.9058 Validation Accuracy: 0.628000\n",
      "Epoch 595, CIFAR-10 Batch 4:  Loss:     0.9229 Validation Accuracy: 0.625200\n",
      "Epoch 595, CIFAR-10 Batch 5:  Loss:     0.9167 Validation Accuracy: 0.626800\n",
      "Epoch 596, CIFAR-10 Batch 1:  Loss:     0.9083 Validation Accuracy: 0.624600\n",
      "Epoch 596, CIFAR-10 Batch 2:  Loss:     0.9216 Validation Accuracy: 0.624400\n",
      "Epoch 596, CIFAR-10 Batch 3:  Loss:     0.9051 Validation Accuracy: 0.626800\n",
      "Epoch 596, CIFAR-10 Batch 4:  Loss:     0.9222 Validation Accuracy: 0.625200\n",
      "Epoch 596, CIFAR-10 Batch 5:  Loss:     0.9157 Validation Accuracy: 0.625800\n",
      "Epoch 597, CIFAR-10 Batch 1:  Loss:     0.9075 Validation Accuracy: 0.624400\n",
      "Epoch 597, CIFAR-10 Batch 2:  Loss:     0.9209 Validation Accuracy: 0.623800\n",
      "Epoch 597, CIFAR-10 Batch 3:  Loss:     0.9047 Validation Accuracy: 0.627800\n",
      "Epoch 597, CIFAR-10 Batch 4:  Loss:     0.9218 Validation Accuracy: 0.624400\n",
      "Epoch 597, CIFAR-10 Batch 5:  Loss:     0.9153 Validation Accuracy: 0.626200\n",
      "Epoch 598, CIFAR-10 Batch 1:  Loss:     0.9072 Validation Accuracy: 0.624200\n",
      "Epoch 598, CIFAR-10 Batch 2:  Loss:     0.9206 Validation Accuracy: 0.624000\n",
      "Epoch 598, CIFAR-10 Batch 3:  Loss:     0.9046 Validation Accuracy: 0.628000\n",
      "Epoch 598, CIFAR-10 Batch 4:  Loss:     0.9218 Validation Accuracy: 0.626200\n",
      "Epoch 598, CIFAR-10 Batch 5:  Loss:     0.9153 Validation Accuracy: 0.627000\n",
      "Epoch 599, CIFAR-10 Batch 1:  Loss:     0.9068 Validation Accuracy: 0.625000\n",
      "Epoch 599, CIFAR-10 Batch 2:  Loss:     0.9203 Validation Accuracy: 0.623400\n",
      "Epoch 599, CIFAR-10 Batch 3:  Loss:     0.9045 Validation Accuracy: 0.627400\n",
      "Epoch 599, CIFAR-10 Batch 4:  Loss:     0.9219 Validation Accuracy: 0.626000\n",
      "Epoch 599, CIFAR-10 Batch 5:  Loss:     0.9151 Validation Accuracy: 0.625600\n",
      "Epoch 600, CIFAR-10 Batch 1:  Loss:     0.9064 Validation Accuracy: 0.625400\n",
      "Epoch 600, CIFAR-10 Batch 2:  Loss:     0.9202 Validation Accuracy: 0.624000\n",
      "Epoch 600, CIFAR-10 Batch 3:  Loss:     0.9046 Validation Accuracy: 0.626000\n",
      "Epoch 600, CIFAR-10 Batch 4:  Loss:     0.9219 Validation Accuracy: 0.626000\n",
      "Epoch 600, CIFAR-10 Batch 5:  Loss:     0.9146 Validation Accuracy: 0.625800\n",
      "Epoch 601, CIFAR-10 Batch 1:  Loss:     0.9060 Validation Accuracy: 0.625400\n",
      "Epoch 601, CIFAR-10 Batch 2:  Loss:     0.9201 Validation Accuracy: 0.623600\n",
      "Epoch 601, CIFAR-10 Batch 3:  Loss:     0.9046 Validation Accuracy: 0.625800\n",
      "Epoch 601, CIFAR-10 Batch 4:  Loss:     0.9216 Validation Accuracy: 0.625000\n",
      "Epoch 601, CIFAR-10 Batch 5:  Loss:     0.9140 Validation Accuracy: 0.625800\n",
      "Epoch 602, CIFAR-10 Batch 1:  Loss:     0.9059 Validation Accuracy: 0.627000\n",
      "Epoch 602, CIFAR-10 Batch 2:  Loss:     0.9201 Validation Accuracy: 0.623200\n",
      "Epoch 602, CIFAR-10 Batch 3:  Loss:     0.9045 Validation Accuracy: 0.626600\n",
      "Epoch 602, CIFAR-10 Batch 4:  Loss:     0.9212 Validation Accuracy: 0.625000\n",
      "Epoch 602, CIFAR-10 Batch 5:  Loss:     0.9137 Validation Accuracy: 0.626200\n",
      "Epoch 603, CIFAR-10 Batch 1:  Loss:     0.9057 Validation Accuracy: 0.627000\n",
      "Epoch 603, CIFAR-10 Batch 2:  Loss:     0.9198 Validation Accuracy: 0.623200\n",
      "Epoch 603, CIFAR-10 Batch 3:  Loss:     0.9043 Validation Accuracy: 0.625600\n",
      "Epoch 603, CIFAR-10 Batch 4:  Loss:     0.9208 Validation Accuracy: 0.625200\n",
      "Epoch 603, CIFAR-10 Batch 5:  Loss:     0.9135 Validation Accuracy: 0.626200\n",
      "Epoch 604, CIFAR-10 Batch 1:  Loss:     0.9054 Validation Accuracy: 0.626600\n",
      "Epoch 604, CIFAR-10 Batch 2:  Loss:     0.9194 Validation Accuracy: 0.623000\n",
      "Epoch 604, CIFAR-10 Batch 3:  Loss:     0.9040 Validation Accuracy: 0.626200\n",
      "Epoch 604, CIFAR-10 Batch 4:  Loss:     0.9206 Validation Accuracy: 0.624800\n",
      "Epoch 604, CIFAR-10 Batch 5:  Loss:     0.9132 Validation Accuracy: 0.625800\n",
      "Epoch 605, CIFAR-10 Batch 1:  Loss:     0.9050 Validation Accuracy: 0.626400\n",
      "Epoch 605, CIFAR-10 Batch 2:  Loss:     0.9190 Validation Accuracy: 0.622400\n",
      "Epoch 605, CIFAR-10 Batch 3:  Loss:     0.9038 Validation Accuracy: 0.626400\n",
      "Epoch 605, CIFAR-10 Batch 4:  Loss:     0.9204 Validation Accuracy: 0.624400\n",
      "Epoch 605, CIFAR-10 Batch 5:  Loss:     0.9129 Validation Accuracy: 0.625400\n",
      "Epoch 606, CIFAR-10 Batch 1:  Loss:     0.9045 Validation Accuracy: 0.626200\n",
      "Epoch 606, CIFAR-10 Batch 2:  Loss:     0.9187 Validation Accuracy: 0.622400\n",
      "Epoch 606, CIFAR-10 Batch 3:  Loss:     0.9037 Validation Accuracy: 0.626200\n",
      "Epoch 606, CIFAR-10 Batch 4:  Loss:     0.9202 Validation Accuracy: 0.624200\n",
      "Epoch 606, CIFAR-10 Batch 5:  Loss:     0.9125 Validation Accuracy: 0.625800\n",
      "Epoch 607, CIFAR-10 Batch 1:  Loss:     0.9042 Validation Accuracy: 0.625800\n",
      "Epoch 607, CIFAR-10 Batch 2:  Loss:     0.9185 Validation Accuracy: 0.621800\n",
      "Epoch 607, CIFAR-10 Batch 3:  Loss:     0.9037 Validation Accuracy: 0.627200\n",
      "Epoch 607, CIFAR-10 Batch 4:  Loss:     0.9200 Validation Accuracy: 0.624400\n",
      "Epoch 607, CIFAR-10 Batch 5:  Loss:     0.9122 Validation Accuracy: 0.626000\n",
      "Epoch 608, CIFAR-10 Batch 1:  Loss:     0.9041 Validation Accuracy: 0.626400\n",
      "Epoch 608, CIFAR-10 Batch 2:  Loss:     0.9183 Validation Accuracy: 0.622000\n",
      "Epoch 608, CIFAR-10 Batch 3:  Loss:     0.9035 Validation Accuracy: 0.627600\n",
      "Epoch 608, CIFAR-10 Batch 4:  Loss:     0.9196 Validation Accuracy: 0.624600\n",
      "Epoch 608, CIFAR-10 Batch 5:  Loss:     0.9118 Validation Accuracy: 0.625600\n",
      "Epoch 609, CIFAR-10 Batch 1:  Loss:     0.9039 Validation Accuracy: 0.626000\n",
      "Epoch 609, CIFAR-10 Batch 2:  Loss:     0.9181 Validation Accuracy: 0.622600\n",
      "Epoch 609, CIFAR-10 Batch 3:  Loss:     0.9031 Validation Accuracy: 0.627600\n",
      "Epoch 609, CIFAR-10 Batch 4:  Loss:     0.9191 Validation Accuracy: 0.624600\n",
      "Epoch 609, CIFAR-10 Batch 5:  Loss:     0.9114 Validation Accuracy: 0.626200\n",
      "Epoch 610, CIFAR-10 Batch 1:  Loss:     0.9037 Validation Accuracy: 0.625600\n",
      "Epoch 610, CIFAR-10 Batch 2:  Loss:     0.9178 Validation Accuracy: 0.622800\n",
      "Epoch 610, CIFAR-10 Batch 3:  Loss:     0.9027 Validation Accuracy: 0.627400\n",
      "Epoch 610, CIFAR-10 Batch 4:  Loss:     0.9185 Validation Accuracy: 0.624800\n",
      "Epoch 610, CIFAR-10 Batch 5:  Loss:     0.9110 Validation Accuracy: 0.626200\n",
      "Epoch 611, CIFAR-10 Batch 1:  Loss:     0.9035 Validation Accuracy: 0.626400\n",
      "Epoch 611, CIFAR-10 Batch 2:  Loss:     0.9174 Validation Accuracy: 0.623000\n",
      "Epoch 611, CIFAR-10 Batch 3:  Loss:     0.9022 Validation Accuracy: 0.627000\n",
      "Epoch 611, CIFAR-10 Batch 4:  Loss:     0.9179 Validation Accuracy: 0.625200\n",
      "Epoch 611, CIFAR-10 Batch 5:  Loss:     0.9106 Validation Accuracy: 0.626600\n",
      "Epoch 612, CIFAR-10 Batch 1:  Loss:     0.9032 Validation Accuracy: 0.626200\n",
      "Epoch 612, CIFAR-10 Batch 2:  Loss:     0.9169 Validation Accuracy: 0.623000\n",
      "Epoch 612, CIFAR-10 Batch 3:  Loss:     0.9017 Validation Accuracy: 0.627000\n",
      "Epoch 612, CIFAR-10 Batch 4:  Loss:     0.9175 Validation Accuracy: 0.625200\n",
      "Epoch 612, CIFAR-10 Batch 5:  Loss:     0.9103 Validation Accuracy: 0.627200\n",
      "Epoch 613, CIFAR-10 Batch 1:  Loss:     0.9028 Validation Accuracy: 0.626000\n",
      "Epoch 613, CIFAR-10 Batch 2:  Loss:     0.9164 Validation Accuracy: 0.623600\n",
      "Epoch 613, CIFAR-10 Batch 3:  Loss:     0.9013 Validation Accuracy: 0.627000\n",
      "Epoch 613, CIFAR-10 Batch 4:  Loss:     0.9171 Validation Accuracy: 0.625400\n",
      "Epoch 613, CIFAR-10 Batch 5:  Loss:     0.9100 Validation Accuracy: 0.626800\n",
      "Epoch 614, CIFAR-10 Batch 1:  Loss:     0.9023 Validation Accuracy: 0.625600\n",
      "Epoch 614, CIFAR-10 Batch 2:  Loss:     0.9158 Validation Accuracy: 0.624000\n",
      "Epoch 614, CIFAR-10 Batch 3:  Loss:     0.9010 Validation Accuracy: 0.627000\n",
      "Epoch 614, CIFAR-10 Batch 4:  Loss:     0.9169 Validation Accuracy: 0.624600\n",
      "Epoch 614, CIFAR-10 Batch 5:  Loss:     0.9097 Validation Accuracy: 0.626800\n",
      "Epoch 615, CIFAR-10 Batch 1:  Loss:     0.9019 Validation Accuracy: 0.625400\n",
      "Epoch 615, CIFAR-10 Batch 2:  Loss:     0.9154 Validation Accuracy: 0.624200\n",
      "Epoch 615, CIFAR-10 Batch 3:  Loss:     0.9008 Validation Accuracy: 0.627200\n",
      "Epoch 615, CIFAR-10 Batch 4:  Loss:     0.9167 Validation Accuracy: 0.625200\n",
      "Epoch 615, CIFAR-10 Batch 5:  Loss:     0.9095 Validation Accuracy: 0.627000\n",
      "Epoch 616, CIFAR-10 Batch 1:  Loss:     0.9016 Validation Accuracy: 0.625200\n",
      "Epoch 616, CIFAR-10 Batch 2:  Loss:     0.9151 Validation Accuracy: 0.624000\n",
      "Epoch 616, CIFAR-10 Batch 3:  Loss:     0.9005 Validation Accuracy: 0.627400\n",
      "Epoch 616, CIFAR-10 Batch 4:  Loss:     0.9164 Validation Accuracy: 0.624800\n",
      "Epoch 616, CIFAR-10 Batch 5:  Loss:     0.9091 Validation Accuracy: 0.627200\n",
      "Epoch 617, CIFAR-10 Batch 1:  Loss:     0.9013 Validation Accuracy: 0.625000\n",
      "Epoch 617, CIFAR-10 Batch 2:  Loss:     0.9148 Validation Accuracy: 0.625000\n",
      "Epoch 617, CIFAR-10 Batch 3:  Loss:     0.9002 Validation Accuracy: 0.627600\n",
      "Epoch 617, CIFAR-10 Batch 4:  Loss:     0.9160 Validation Accuracy: 0.625000\n",
      "Epoch 617, CIFAR-10 Batch 5:  Loss:     0.9088 Validation Accuracy: 0.627000\n",
      "Epoch 618, CIFAR-10 Batch 1:  Loss:     0.9011 Validation Accuracy: 0.625200\n",
      "Epoch 618, CIFAR-10 Batch 2:  Loss:     0.9145 Validation Accuracy: 0.625400\n",
      "Epoch 618, CIFAR-10 Batch 3:  Loss:     0.8999 Validation Accuracy: 0.627400\n",
      "Epoch 618, CIFAR-10 Batch 4:  Loss:     0.9155 Validation Accuracy: 0.625400\n",
      "Epoch 618, CIFAR-10 Batch 5:  Loss:     0.9084 Validation Accuracy: 0.627200\n",
      "Epoch 619, CIFAR-10 Batch 1:  Loss:     0.9008 Validation Accuracy: 0.624800\n",
      "Epoch 619, CIFAR-10 Batch 2:  Loss:     0.9142 Validation Accuracy: 0.624800\n",
      "Epoch 619, CIFAR-10 Batch 3:  Loss:     0.8995 Validation Accuracy: 0.627600\n",
      "Epoch 619, CIFAR-10 Batch 4:  Loss:     0.9151 Validation Accuracy: 0.625200\n",
      "Epoch 619, CIFAR-10 Batch 5:  Loss:     0.9081 Validation Accuracy: 0.626800\n",
      "Epoch 620, CIFAR-10 Batch 1:  Loss:     0.9005 Validation Accuracy: 0.624600\n",
      "Epoch 620, CIFAR-10 Batch 2:  Loss:     0.9137 Validation Accuracy: 0.624600\n",
      "Epoch 620, CIFAR-10 Batch 3:  Loss:     0.8991 Validation Accuracy: 0.627800\n",
      "Epoch 620, CIFAR-10 Batch 4:  Loss:     0.9146 Validation Accuracy: 0.625800\n",
      "Epoch 620, CIFAR-10 Batch 5:  Loss:     0.9077 Validation Accuracy: 0.627000\n",
      "Epoch 621, CIFAR-10 Batch 1:  Loss:     0.9002 Validation Accuracy: 0.625200\n",
      "Epoch 621, CIFAR-10 Batch 2:  Loss:     0.9133 Validation Accuracy: 0.625000\n",
      "Epoch 621, CIFAR-10 Batch 3:  Loss:     0.8987 Validation Accuracy: 0.627600\n",
      "Epoch 621, CIFAR-10 Batch 4:  Loss:     0.9142 Validation Accuracy: 0.626000\n",
      "Epoch 621, CIFAR-10 Batch 5:  Loss:     0.9074 Validation Accuracy: 0.627200\n",
      "Epoch 622, CIFAR-10 Batch 1:  Loss:     0.8998 Validation Accuracy: 0.625200\n",
      "Epoch 622, CIFAR-10 Batch 2:  Loss:     0.9128 Validation Accuracy: 0.624800\n",
      "Epoch 622, CIFAR-10 Batch 3:  Loss:     0.8982 Validation Accuracy: 0.627400\n",
      "Epoch 622, CIFAR-10 Batch 4:  Loss:     0.9138 Validation Accuracy: 0.626000\n",
      "Epoch 622, CIFAR-10 Batch 5:  Loss:     0.9072 Validation Accuracy: 0.626800\n",
      "Epoch 623, CIFAR-10 Batch 1:  Loss:     0.8993 Validation Accuracy: 0.626400\n",
      "Epoch 623, CIFAR-10 Batch 2:  Loss:     0.9123 Validation Accuracy: 0.625000\n",
      "Epoch 623, CIFAR-10 Batch 3:  Loss:     0.8979 Validation Accuracy: 0.627400\n",
      "Epoch 623, CIFAR-10 Batch 4:  Loss:     0.9135 Validation Accuracy: 0.625800\n",
      "Epoch 623, CIFAR-10 Batch 5:  Loss:     0.9069 Validation Accuracy: 0.627400\n",
      "Epoch 624, CIFAR-10 Batch 1:  Loss:     0.8989 Validation Accuracy: 0.626600\n",
      "Epoch 624, CIFAR-10 Batch 2:  Loss:     0.9119 Validation Accuracy: 0.625200\n",
      "Epoch 624, CIFAR-10 Batch 3:  Loss:     0.8976 Validation Accuracy: 0.627600\n",
      "Epoch 624, CIFAR-10 Batch 4:  Loss:     0.9133 Validation Accuracy: 0.625800\n",
      "Epoch 624, CIFAR-10 Batch 5:  Loss:     0.9067 Validation Accuracy: 0.627800\n",
      "Epoch 625, CIFAR-10 Batch 1:  Loss:     0.8986 Validation Accuracy: 0.626600\n",
      "Epoch 625, CIFAR-10 Batch 2:  Loss:     0.9115 Validation Accuracy: 0.625200\n",
      "Epoch 625, CIFAR-10 Batch 3:  Loss:     0.8974 Validation Accuracy: 0.627800\n",
      "Epoch 625, CIFAR-10 Batch 4:  Loss:     0.9130 Validation Accuracy: 0.625400\n",
      "Epoch 625, CIFAR-10 Batch 5:  Loss:     0.9064 Validation Accuracy: 0.627800\n",
      "Epoch 626, CIFAR-10 Batch 1:  Loss:     0.8982 Validation Accuracy: 0.626600\n",
      "Epoch 626, CIFAR-10 Batch 2:  Loss:     0.9112 Validation Accuracy: 0.625000\n",
      "Epoch 626, CIFAR-10 Batch 3:  Loss:     0.8972 Validation Accuracy: 0.628000\n",
      "Epoch 626, CIFAR-10 Batch 4:  Loss:     0.9128 Validation Accuracy: 0.625000\n",
      "Epoch 626, CIFAR-10 Batch 5:  Loss:     0.9061 Validation Accuracy: 0.627200\n",
      "Epoch 627, CIFAR-10 Batch 1:  Loss:     0.8979 Validation Accuracy: 0.626400\n",
      "Epoch 627, CIFAR-10 Batch 2:  Loss:     0.9110 Validation Accuracy: 0.625400\n",
      "Epoch 627, CIFAR-10 Batch 3:  Loss:     0.8970 Validation Accuracy: 0.628000\n",
      "Epoch 627, CIFAR-10 Batch 4:  Loss:     0.9125 Validation Accuracy: 0.624800\n",
      "Epoch 627, CIFAR-10 Batch 5:  Loss:     0.9058 Validation Accuracy: 0.627200\n",
      "Epoch 628, CIFAR-10 Batch 1:  Loss:     0.8977 Validation Accuracy: 0.626600\n",
      "Epoch 628, CIFAR-10 Batch 2:  Loss:     0.9107 Validation Accuracy: 0.625000\n",
      "Epoch 628, CIFAR-10 Batch 3:  Loss:     0.8968 Validation Accuracy: 0.628200\n",
      "Epoch 628, CIFAR-10 Batch 4:  Loss:     0.9121 Validation Accuracy: 0.625000\n",
      "Epoch 628, CIFAR-10 Batch 5:  Loss:     0.9055 Validation Accuracy: 0.627200\n",
      "Epoch 629, CIFAR-10 Batch 1:  Loss:     0.8974 Validation Accuracy: 0.626200\n",
      "Epoch 629, CIFAR-10 Batch 2:  Loss:     0.9104 Validation Accuracy: 0.625400\n",
      "Epoch 629, CIFAR-10 Batch 3:  Loss:     0.8964 Validation Accuracy: 0.628200\n",
      "Epoch 629, CIFAR-10 Batch 4:  Loss:     0.9116 Validation Accuracy: 0.625400\n",
      "Epoch 629, CIFAR-10 Batch 5:  Loss:     0.9051 Validation Accuracy: 0.627200\n",
      "Epoch 630, CIFAR-10 Batch 1:  Loss:     0.8971 Validation Accuracy: 0.626400\n",
      "Epoch 630, CIFAR-10 Batch 2:  Loss:     0.9100 Validation Accuracy: 0.625400\n",
      "Epoch 630, CIFAR-10 Batch 3:  Loss:     0.8959 Validation Accuracy: 0.628200\n",
      "Epoch 630, CIFAR-10 Batch 4:  Loss:     0.9110 Validation Accuracy: 0.625400\n",
      "Epoch 630, CIFAR-10 Batch 5:  Loss:     0.9047 Validation Accuracy: 0.627600\n",
      "Epoch 631, CIFAR-10 Batch 1:  Loss:     0.8968 Validation Accuracy: 0.625800\n",
      "Epoch 631, CIFAR-10 Batch 2:  Loss:     0.9095 Validation Accuracy: 0.625400\n",
      "Epoch 631, CIFAR-10 Batch 3:  Loss:     0.8954 Validation Accuracy: 0.628200\n",
      "Epoch 631, CIFAR-10 Batch 4:  Loss:     0.9104 Validation Accuracy: 0.626000\n",
      "Epoch 631, CIFAR-10 Batch 5:  Loss:     0.9043 Validation Accuracy: 0.627800\n",
      "Epoch 632, CIFAR-10 Batch 1:  Loss:     0.8964 Validation Accuracy: 0.626200\n",
      "Epoch 632, CIFAR-10 Batch 2:  Loss:     0.9091 Validation Accuracy: 0.625200\n",
      "Epoch 632, CIFAR-10 Batch 3:  Loss:     0.8950 Validation Accuracy: 0.628200\n",
      "Epoch 632, CIFAR-10 Batch 4:  Loss:     0.9101 Validation Accuracy: 0.626400\n",
      "Epoch 632, CIFAR-10 Batch 5:  Loss:     0.9040 Validation Accuracy: 0.627600\n",
      "Epoch 633, CIFAR-10 Batch 1:  Loss:     0.8960 Validation Accuracy: 0.626400\n",
      "Epoch 633, CIFAR-10 Batch 2:  Loss:     0.9087 Validation Accuracy: 0.624400\n",
      "Epoch 633, CIFAR-10 Batch 3:  Loss:     0.8947 Validation Accuracy: 0.628200\n",
      "Epoch 633, CIFAR-10 Batch 4:  Loss:     0.9099 Validation Accuracy: 0.626000\n",
      "Epoch 633, CIFAR-10 Batch 5:  Loss:     0.9038 Validation Accuracy: 0.627600\n",
      "Epoch 634, CIFAR-10 Batch 1:  Loss:     0.8956 Validation Accuracy: 0.626000\n",
      "Epoch 634, CIFAR-10 Batch 2:  Loss:     0.9083 Validation Accuracy: 0.624800\n",
      "Epoch 634, CIFAR-10 Batch 3:  Loss:     0.8945 Validation Accuracy: 0.628200\n",
      "Epoch 634, CIFAR-10 Batch 4:  Loss:     0.9096 Validation Accuracy: 0.625600\n",
      "Epoch 634, CIFAR-10 Batch 5:  Loss:     0.9036 Validation Accuracy: 0.627800\n",
      "Epoch 635, CIFAR-10 Batch 1:  Loss:     0.8953 Validation Accuracy: 0.625600\n",
      "Epoch 635, CIFAR-10 Batch 2:  Loss:     0.9080 Validation Accuracy: 0.625000\n",
      "Epoch 635, CIFAR-10 Batch 3:  Loss:     0.8943 Validation Accuracy: 0.627800\n",
      "Epoch 635, CIFAR-10 Batch 4:  Loss:     0.9094 Validation Accuracy: 0.626000\n",
      "Epoch 635, CIFAR-10 Batch 5:  Loss:     0.9034 Validation Accuracy: 0.627600\n",
      "Epoch 636, CIFAR-10 Batch 1:  Loss:     0.8950 Validation Accuracy: 0.625600\n",
      "Epoch 636, CIFAR-10 Batch 2:  Loss:     0.9077 Validation Accuracy: 0.625200\n",
      "Epoch 636, CIFAR-10 Batch 3:  Loss:     0.8940 Validation Accuracy: 0.628000\n",
      "Epoch 636, CIFAR-10 Batch 4:  Loss:     0.9091 Validation Accuracy: 0.625600\n",
      "Epoch 636, CIFAR-10 Batch 5:  Loss:     0.9031 Validation Accuracy: 0.627200\n",
      "Epoch 637, CIFAR-10 Batch 1:  Loss:     0.8947 Validation Accuracy: 0.626200\n",
      "Epoch 637, CIFAR-10 Batch 2:  Loss:     0.9074 Validation Accuracy: 0.625400\n",
      "Epoch 637, CIFAR-10 Batch 3:  Loss:     0.8937 Validation Accuracy: 0.627800\n",
      "Epoch 637, CIFAR-10 Batch 4:  Loss:     0.9087 Validation Accuracy: 0.626200\n",
      "Epoch 637, CIFAR-10 Batch 5:  Loss:     0.9028 Validation Accuracy: 0.627000\n",
      "Epoch 638, CIFAR-10 Batch 1:  Loss:     0.8944 Validation Accuracy: 0.626200\n",
      "Epoch 638, CIFAR-10 Batch 2:  Loss:     0.9071 Validation Accuracy: 0.625400\n",
      "Epoch 638, CIFAR-10 Batch 3:  Loss:     0.8934 Validation Accuracy: 0.628200\n",
      "Epoch 638, CIFAR-10 Batch 4:  Loss:     0.9084 Validation Accuracy: 0.626400\n",
      "Epoch 638, CIFAR-10 Batch 5:  Loss:     0.9024 Validation Accuracy: 0.627000\n",
      "Epoch 639, CIFAR-10 Batch 1:  Loss:     0.8941 Validation Accuracy: 0.626200\n",
      "Epoch 639, CIFAR-10 Batch 2:  Loss:     0.9067 Validation Accuracy: 0.626000\n",
      "Epoch 639, CIFAR-10 Batch 3:  Loss:     0.8930 Validation Accuracy: 0.628200\n",
      "Epoch 639, CIFAR-10 Batch 4:  Loss:     0.9078 Validation Accuracy: 0.626200\n",
      "Epoch 639, CIFAR-10 Batch 5:  Loss:     0.9021 Validation Accuracy: 0.626800\n",
      "Epoch 640, CIFAR-10 Batch 1:  Loss:     0.8938 Validation Accuracy: 0.625800\n",
      "Epoch 640, CIFAR-10 Batch 2:  Loss:     0.9063 Validation Accuracy: 0.626600\n",
      "Epoch 640, CIFAR-10 Batch 3:  Loss:     0.8925 Validation Accuracy: 0.628400\n",
      "Epoch 640, CIFAR-10 Batch 4:  Loss:     0.9073 Validation Accuracy: 0.627000\n",
      "Epoch 640, CIFAR-10 Batch 5:  Loss:     0.9017 Validation Accuracy: 0.626400\n",
      "Epoch 641, CIFAR-10 Batch 1:  Loss:     0.8935 Validation Accuracy: 0.626000\n",
      "Epoch 641, CIFAR-10 Batch 2:  Loss:     0.9058 Validation Accuracy: 0.626000\n",
      "Epoch 641, CIFAR-10 Batch 3:  Loss:     0.8920 Validation Accuracy: 0.628200\n",
      "Epoch 641, CIFAR-10 Batch 4:  Loss:     0.9068 Validation Accuracy: 0.627400\n",
      "Epoch 641, CIFAR-10 Batch 5:  Loss:     0.9013 Validation Accuracy: 0.626400\n",
      "Epoch 642, CIFAR-10 Batch 1:  Loss:     0.8932 Validation Accuracy: 0.626000\n",
      "Epoch 642, CIFAR-10 Batch 2:  Loss:     0.9054 Validation Accuracy: 0.626400\n",
      "Epoch 642, CIFAR-10 Batch 3:  Loss:     0.8915 Validation Accuracy: 0.628200\n",
      "Epoch 642, CIFAR-10 Batch 4:  Loss:     0.9063 Validation Accuracy: 0.627800\n",
      "Epoch 642, CIFAR-10 Batch 5:  Loss:     0.9010 Validation Accuracy: 0.625800\n",
      "Epoch 643, CIFAR-10 Batch 1:  Loss:     0.8928 Validation Accuracy: 0.626200\n",
      "Epoch 643, CIFAR-10 Batch 2:  Loss:     0.9049 Validation Accuracy: 0.626400\n",
      "Epoch 643, CIFAR-10 Batch 3:  Loss:     0.8911 Validation Accuracy: 0.628600\n",
      "Epoch 643, CIFAR-10 Batch 4:  Loss:     0.9060 Validation Accuracy: 0.627800\n",
      "Epoch 643, CIFAR-10 Batch 5:  Loss:     0.9008 Validation Accuracy: 0.625800\n",
      "Epoch 644, CIFAR-10 Batch 1:  Loss:     0.8925 Validation Accuracy: 0.626600\n",
      "Epoch 644, CIFAR-10 Batch 2:  Loss:     0.9045 Validation Accuracy: 0.626400\n",
      "Epoch 644, CIFAR-10 Batch 3:  Loss:     0.8908 Validation Accuracy: 0.628800\n",
      "Epoch 644, CIFAR-10 Batch 4:  Loss:     0.9057 Validation Accuracy: 0.627800\n",
      "Epoch 644, CIFAR-10 Batch 5:  Loss:     0.9006 Validation Accuracy: 0.625800\n",
      "Epoch 645, CIFAR-10 Batch 1:  Loss:     0.8921 Validation Accuracy: 0.626800\n",
      "Epoch 645, CIFAR-10 Batch 2:  Loss:     0.9042 Validation Accuracy: 0.626800\n",
      "Epoch 645, CIFAR-10 Batch 3:  Loss:     0.8907 Validation Accuracy: 0.628800\n",
      "Epoch 645, CIFAR-10 Batch 4:  Loss:     0.9056 Validation Accuracy: 0.627600\n",
      "Epoch 645, CIFAR-10 Batch 5:  Loss:     0.9005 Validation Accuracy: 0.626200\n",
      "Epoch 646, CIFAR-10 Batch 1:  Loss:     0.8918 Validation Accuracy: 0.627400\n",
      "Epoch 646, CIFAR-10 Batch 2:  Loss:     0.9039 Validation Accuracy: 0.627000\n",
      "Epoch 646, CIFAR-10 Batch 3:  Loss:     0.8905 Validation Accuracy: 0.628200\n",
      "Epoch 646, CIFAR-10 Batch 4:  Loss:     0.9054 Validation Accuracy: 0.627400\n",
      "Epoch 646, CIFAR-10 Batch 5:  Loss:     0.9003 Validation Accuracy: 0.626800\n",
      "Epoch 647, CIFAR-10 Batch 1:  Loss:     0.8915 Validation Accuracy: 0.627400\n",
      "Epoch 647, CIFAR-10 Batch 2:  Loss:     0.9035 Validation Accuracy: 0.626800\n",
      "Epoch 647, CIFAR-10 Batch 3:  Loss:     0.8902 Validation Accuracy: 0.627800\n",
      "Epoch 647, CIFAR-10 Batch 4:  Loss:     0.9053 Validation Accuracy: 0.627200\n",
      "Epoch 647, CIFAR-10 Batch 5:  Loss:     0.9001 Validation Accuracy: 0.627200\n",
      "Epoch 648, CIFAR-10 Batch 1:  Loss:     0.8912 Validation Accuracy: 0.628000\n",
      "Epoch 648, CIFAR-10 Batch 2:  Loss:     0.9032 Validation Accuracy: 0.626800\n",
      "Epoch 648, CIFAR-10 Batch 3:  Loss:     0.8900 Validation Accuracy: 0.627800\n",
      "Epoch 648, CIFAR-10 Batch 4:  Loss:     0.9050 Validation Accuracy: 0.628000\n",
      "Epoch 648, CIFAR-10 Batch 5:  Loss:     0.8999 Validation Accuracy: 0.626600\n",
      "Epoch 649, CIFAR-10 Batch 1:  Loss:     0.8910 Validation Accuracy: 0.628400\n",
      "Epoch 649, CIFAR-10 Batch 2:  Loss:     0.9029 Validation Accuracy: 0.627600\n",
      "Epoch 649, CIFAR-10 Batch 3:  Loss:     0.8897 Validation Accuracy: 0.628000\n",
      "Epoch 649, CIFAR-10 Batch 4:  Loss:     0.9047 Validation Accuracy: 0.628400\n",
      "Epoch 649, CIFAR-10 Batch 5:  Loss:     0.8996 Validation Accuracy: 0.626200\n",
      "Epoch 650, CIFAR-10 Batch 1:  Loss:     0.8907 Validation Accuracy: 0.628600\n",
      "Epoch 650, CIFAR-10 Batch 2:  Loss:     0.9025 Validation Accuracy: 0.627400\n",
      "Epoch 650, CIFAR-10 Batch 3:  Loss:     0.8893 Validation Accuracy: 0.628000\n",
      "Epoch 650, CIFAR-10 Batch 4:  Loss:     0.9042 Validation Accuracy: 0.629600\n",
      "Epoch 650, CIFAR-10 Batch 5:  Loss:     0.8993 Validation Accuracy: 0.625800\n",
      "Epoch 651, CIFAR-10 Batch 1:  Loss:     0.8905 Validation Accuracy: 0.629000\n",
      "Epoch 651, CIFAR-10 Batch 2:  Loss:     0.9022 Validation Accuracy: 0.627600\n",
      "Epoch 651, CIFAR-10 Batch 3:  Loss:     0.8889 Validation Accuracy: 0.628200\n",
      "Epoch 651, CIFAR-10 Batch 4:  Loss:     0.9038 Validation Accuracy: 0.629200\n",
      "Epoch 651, CIFAR-10 Batch 5:  Loss:     0.8990 Validation Accuracy: 0.625000\n",
      "Epoch 652, CIFAR-10 Batch 1:  Loss:     0.8904 Validation Accuracy: 0.628800\n",
      "Epoch 652, CIFAR-10 Batch 2:  Loss:     0.9018 Validation Accuracy: 0.627600\n",
      "Epoch 652, CIFAR-10 Batch 3:  Loss:     0.8884 Validation Accuracy: 0.628200\n",
      "Epoch 652, CIFAR-10 Batch 4:  Loss:     0.9034 Validation Accuracy: 0.628600\n",
      "Epoch 652, CIFAR-10 Batch 5:  Loss:     0.8988 Validation Accuracy: 0.624600\n",
      "Epoch 653, CIFAR-10 Batch 1:  Loss:     0.8901 Validation Accuracy: 0.627400\n",
      "Epoch 653, CIFAR-10 Batch 2:  Loss:     0.9013 Validation Accuracy: 0.627600\n",
      "Epoch 653, CIFAR-10 Batch 3:  Loss:     0.8880 Validation Accuracy: 0.629200\n",
      "Epoch 653, CIFAR-10 Batch 4:  Loss:     0.9031 Validation Accuracy: 0.629600\n",
      "Epoch 653, CIFAR-10 Batch 5:  Loss:     0.8986 Validation Accuracy: 0.624400\n",
      "Epoch 654, CIFAR-10 Batch 1:  Loss:     0.8900 Validation Accuracy: 0.627000\n",
      "Epoch 654, CIFAR-10 Batch 2:  Loss:     0.9009 Validation Accuracy: 0.627600\n",
      "Epoch 654, CIFAR-10 Batch 3:  Loss:     0.8875 Validation Accuracy: 0.629000\n",
      "Epoch 654, CIFAR-10 Batch 4:  Loss:     0.9029 Validation Accuracy: 0.629200\n",
      "Epoch 654, CIFAR-10 Batch 5:  Loss:     0.8985 Validation Accuracy: 0.622800\n",
      "Epoch 655, CIFAR-10 Batch 1:  Loss:     0.8898 Validation Accuracy: 0.626800\n",
      "Epoch 655, CIFAR-10 Batch 2:  Loss:     0.9005 Validation Accuracy: 0.628200\n",
      "Epoch 655, CIFAR-10 Batch 3:  Loss:     0.8872 Validation Accuracy: 0.630600\n",
      "Epoch 655, CIFAR-10 Batch 4:  Loss:     0.9028 Validation Accuracy: 0.629000\n",
      "Epoch 655, CIFAR-10 Batch 5:  Loss:     0.8986 Validation Accuracy: 0.621800\n",
      "Epoch 656, CIFAR-10 Batch 1:  Loss:     0.8898 Validation Accuracy: 0.626400\n",
      "Epoch 656, CIFAR-10 Batch 2:  Loss:     0.9002 Validation Accuracy: 0.627800\n",
      "Epoch 656, CIFAR-10 Batch 3:  Loss:     0.8868 Validation Accuracy: 0.630400\n",
      "Epoch 656, CIFAR-10 Batch 4:  Loss:     0.9028 Validation Accuracy: 0.628600\n",
      "Epoch 656, CIFAR-10 Batch 5:  Loss:     0.8987 Validation Accuracy: 0.622200\n",
      "Epoch 657, CIFAR-10 Batch 1:  Loss:     0.8899 Validation Accuracy: 0.626200\n",
      "Epoch 657, CIFAR-10 Batch 2:  Loss:     0.8997 Validation Accuracy: 0.627800\n",
      "Epoch 657, CIFAR-10 Batch 3:  Loss:     0.8864 Validation Accuracy: 0.630200\n",
      "Epoch 657, CIFAR-10 Batch 4:  Loss:     0.9028 Validation Accuracy: 0.628600\n",
      "Epoch 657, CIFAR-10 Batch 5:  Loss:     0.8990 Validation Accuracy: 0.622000\n",
      "Epoch 658, CIFAR-10 Batch 1:  Loss:     0.8900 Validation Accuracy: 0.626400\n",
      "Epoch 658, CIFAR-10 Batch 2:  Loss:     0.8992 Validation Accuracy: 0.627400\n",
      "Epoch 658, CIFAR-10 Batch 3:  Loss:     0.8860 Validation Accuracy: 0.630400\n",
      "Epoch 658, CIFAR-10 Batch 4:  Loss:     0.9031 Validation Accuracy: 0.629200\n",
      "Epoch 658, CIFAR-10 Batch 5:  Loss:     0.8994 Validation Accuracy: 0.621600\n",
      "Epoch 659, CIFAR-10 Batch 1:  Loss:     0.8901 Validation Accuracy: 0.626200\n",
      "Epoch 659, CIFAR-10 Batch 2:  Loss:     0.8987 Validation Accuracy: 0.626800\n",
      "Epoch 659, CIFAR-10 Batch 3:  Loss:     0.8857 Validation Accuracy: 0.629600\n",
      "Epoch 659, CIFAR-10 Batch 4:  Loss:     0.9038 Validation Accuracy: 0.628000\n",
      "Epoch 659, CIFAR-10 Batch 5:  Loss:     0.9000 Validation Accuracy: 0.622600\n",
      "Epoch 660, CIFAR-10 Batch 1:  Loss:     0.8903 Validation Accuracy: 0.625200\n",
      "Epoch 660, CIFAR-10 Batch 2:  Loss:     0.8979 Validation Accuracy: 0.627400\n",
      "Epoch 660, CIFAR-10 Batch 3:  Loss:     0.8854 Validation Accuracy: 0.628800\n",
      "Epoch 660, CIFAR-10 Batch 4:  Loss:     0.9050 Validation Accuracy: 0.625600\n",
      "Epoch 660, CIFAR-10 Batch 5:  Loss:     0.9010 Validation Accuracy: 0.620600\n",
      "Epoch 661, CIFAR-10 Batch 1:  Loss:     0.8905 Validation Accuracy: 0.625200\n",
      "Epoch 661, CIFAR-10 Batch 2:  Loss:     0.8970 Validation Accuracy: 0.628200\n",
      "Epoch 661, CIFAR-10 Batch 3:  Loss:     0.8856 Validation Accuracy: 0.629600\n",
      "Epoch 661, CIFAR-10 Batch 4:  Loss:     0.9075 Validation Accuracy: 0.625200\n",
      "Epoch 661, CIFAR-10 Batch 5:  Loss:     0.9022 Validation Accuracy: 0.620200\n",
      "Epoch 662, CIFAR-10 Batch 1:  Loss:     0.8904 Validation Accuracy: 0.625000\n",
      "Epoch 662, CIFAR-10 Batch 2:  Loss:     0.8960 Validation Accuracy: 0.628600\n",
      "Epoch 662, CIFAR-10 Batch 3:  Loss:     0.8865 Validation Accuracy: 0.627400\n",
      "Epoch 662, CIFAR-10 Batch 4:  Loss:     0.9118 Validation Accuracy: 0.625400\n",
      "Epoch 662, CIFAR-10 Batch 5:  Loss:     0.9037 Validation Accuracy: 0.619800\n",
      "Epoch 663, CIFAR-10 Batch 1:  Loss:     0.8898 Validation Accuracy: 0.626800\n",
      "Epoch 663, CIFAR-10 Batch 2:  Loss:     0.8952 Validation Accuracy: 0.630000\n",
      "Epoch 663, CIFAR-10 Batch 3:  Loss:     0.8891 Validation Accuracy: 0.626200\n",
      "Epoch 663, CIFAR-10 Batch 4:  Loss:     0.9178 Validation Accuracy: 0.625600\n",
      "Epoch 663, CIFAR-10 Batch 5:  Loss:     0.9044 Validation Accuracy: 0.619600\n",
      "Epoch 664, CIFAR-10 Batch 1:  Loss:     0.8885 Validation Accuracy: 0.626600\n",
      "Epoch 664, CIFAR-10 Batch 2:  Loss:     0.8961 Validation Accuracy: 0.628000\n",
      "Epoch 664, CIFAR-10 Batch 3:  Loss:     0.8942 Validation Accuracy: 0.622800\n",
      "Epoch 664, CIFAR-10 Batch 4:  Loss:     0.9235 Validation Accuracy: 0.622600\n",
      "Epoch 664, CIFAR-10 Batch 5:  Loss:     0.9018 Validation Accuracy: 0.618400\n",
      "Epoch 665, CIFAR-10 Batch 1:  Loss:     0.8873 Validation Accuracy: 0.627000\n",
      "Epoch 665, CIFAR-10 Batch 2:  Loss:     0.9016 Validation Accuracy: 0.625200\n",
      "Epoch 665, CIFAR-10 Batch 3:  Loss:     0.8991 Validation Accuracy: 0.621600\n",
      "Epoch 665, CIFAR-10 Batch 4:  Loss:     0.9194 Validation Accuracy: 0.624600\n",
      "Epoch 665, CIFAR-10 Batch 5:  Loss:     0.8942 Validation Accuracy: 0.623200\n",
      "Epoch 666, CIFAR-10 Batch 1:  Loss:     0.8895 Validation Accuracy: 0.626000\n",
      "Epoch 666, CIFAR-10 Batch 2:  Loss:     0.9083 Validation Accuracy: 0.625600\n",
      "Epoch 666, CIFAR-10 Batch 3:  Loss:     0.8948 Validation Accuracy: 0.622800\n",
      "Epoch 666, CIFAR-10 Batch 4:  Loss:     0.9039 Validation Accuracy: 0.632400\n",
      "Epoch 666, CIFAR-10 Batch 5:  Loss:     0.8891 Validation Accuracy: 0.630600\n",
      "Epoch 667, CIFAR-10 Batch 1:  Loss:     0.8918 Validation Accuracy: 0.623000\n",
      "Epoch 667, CIFAR-10 Batch 2:  Loss:     0.9032 Validation Accuracy: 0.627600\n",
      "Epoch 667, CIFAR-10 Batch 3:  Loss:     0.8823 Validation Accuracy: 0.626600\n",
      "Epoch 667, CIFAR-10 Batch 4:  Loss:     0.8949 Validation Accuracy: 0.630800\n",
      "Epoch 667, CIFAR-10 Batch 5:  Loss:     0.8904 Validation Accuracy: 0.629200\n",
      "Epoch 668, CIFAR-10 Batch 1:  Loss:     0.8887 Validation Accuracy: 0.623000\n",
      "Epoch 668, CIFAR-10 Batch 2:  Loss:     0.8939 Validation Accuracy: 0.630800\n",
      "Epoch 668, CIFAR-10 Batch 3:  Loss:     0.8762 Validation Accuracy: 0.632000\n",
      "Epoch 668, CIFAR-10 Batch 4:  Loss:     0.8959 Validation Accuracy: 0.630000\n",
      "Epoch 668, CIFAR-10 Batch 5:  Loss:     0.8925 Validation Accuracy: 0.631800\n",
      "Epoch 669, CIFAR-10 Batch 1:  Loss:     0.8840 Validation Accuracy: 0.625200\n",
      "Epoch 669, CIFAR-10 Batch 2:  Loss:     0.8903 Validation Accuracy: 0.629200\n",
      "Epoch 669, CIFAR-10 Batch 3:  Loss:     0.8767 Validation Accuracy: 0.631400\n",
      "Epoch 669, CIFAR-10 Batch 4:  Loss:     0.8997 Validation Accuracy: 0.628600\n",
      "Epoch 669, CIFAR-10 Batch 5:  Loss:     0.8942 Validation Accuracy: 0.629400\n",
      "Epoch 670, CIFAR-10 Batch 1:  Loss:     0.8811 Validation Accuracy: 0.627400\n",
      "Epoch 670, CIFAR-10 Batch 2:  Loss:     0.8900 Validation Accuracy: 0.630400\n",
      "Epoch 670, CIFAR-10 Batch 3:  Loss:     0.8795 Validation Accuracy: 0.631000\n",
      "Epoch 670, CIFAR-10 Batch 4:  Loss:     0.9031 Validation Accuracy: 0.625600\n",
      "Epoch 670, CIFAR-10 Batch 5:  Loss:     0.8930 Validation Accuracy: 0.628400\n",
      "Epoch 671, CIFAR-10 Batch 1:  Loss:     0.8793 Validation Accuracy: 0.628600\n",
      "Epoch 671, CIFAR-10 Batch 2:  Loss:     0.8921 Validation Accuracy: 0.628800\n",
      "Epoch 671, CIFAR-10 Batch 3:  Loss:     0.8824 Validation Accuracy: 0.629200\n",
      "Epoch 671, CIFAR-10 Batch 4:  Loss:     0.9019 Validation Accuracy: 0.624200\n",
      "Epoch 671, CIFAR-10 Batch 5:  Loss:     0.8883 Validation Accuracy: 0.629800\n",
      "Epoch 672, CIFAR-10 Batch 1:  Loss:     0.8799 Validation Accuracy: 0.627800\n",
      "Epoch 672, CIFAR-10 Batch 2:  Loss:     0.8948 Validation Accuracy: 0.625800\n",
      "Epoch 672, CIFAR-10 Batch 3:  Loss:     0.8812 Validation Accuracy: 0.629000\n",
      "Epoch 672, CIFAR-10 Batch 4:  Loss:     0.8973 Validation Accuracy: 0.627600\n",
      "Epoch 672, CIFAR-10 Batch 5:  Loss:     0.8855 Validation Accuracy: 0.630000\n",
      "Epoch 673, CIFAR-10 Batch 1:  Loss:     0.8815 Validation Accuracy: 0.628200\n",
      "Epoch 673, CIFAR-10 Batch 2:  Loss:     0.8944 Validation Accuracy: 0.625200\n",
      "Epoch 673, CIFAR-10 Batch 3:  Loss:     0.8783 Validation Accuracy: 0.632400\n",
      "Epoch 673, CIFAR-10 Batch 4:  Loss:     0.8940 Validation Accuracy: 0.631400\n",
      "Epoch 673, CIFAR-10 Batch 5:  Loss:     0.8848 Validation Accuracy: 0.630600\n",
      "Epoch 674, CIFAR-10 Batch 1:  Loss:     0.8813 Validation Accuracy: 0.627800\n",
      "Epoch 674, CIFAR-10 Batch 2:  Loss:     0.8922 Validation Accuracy: 0.626600\n",
      "Epoch 674, CIFAR-10 Batch 3:  Loss:     0.8764 Validation Accuracy: 0.631600\n",
      "Epoch 674, CIFAR-10 Batch 4:  Loss:     0.8927 Validation Accuracy: 0.632600\n",
      "Epoch 674, CIFAR-10 Batch 5:  Loss:     0.8846 Validation Accuracy: 0.629800\n",
      "Epoch 675, CIFAR-10 Batch 1:  Loss:     0.8802 Validation Accuracy: 0.628400\n",
      "Epoch 675, CIFAR-10 Batch 2:  Loss:     0.8906 Validation Accuracy: 0.628200\n",
      "Epoch 675, CIFAR-10 Batch 3:  Loss:     0.8755 Validation Accuracy: 0.632600\n",
      "Epoch 675, CIFAR-10 Batch 4:  Loss:     0.8924 Validation Accuracy: 0.632400\n",
      "Epoch 675, CIFAR-10 Batch 5:  Loss:     0.8847 Validation Accuracy: 0.630200\n",
      "Epoch 676, CIFAR-10 Batch 1:  Loss:     0.8793 Validation Accuracy: 0.628000\n",
      "Epoch 676, CIFAR-10 Batch 2:  Loss:     0.8898 Validation Accuracy: 0.629200\n",
      "Epoch 676, CIFAR-10 Batch 3:  Loss:     0.8753 Validation Accuracy: 0.633000\n",
      "Epoch 676, CIFAR-10 Batch 4:  Loss:     0.8931 Validation Accuracy: 0.631200\n",
      "Epoch 676, CIFAR-10 Batch 5:  Loss:     0.8853 Validation Accuracy: 0.630400\n",
      "Epoch 677, CIFAR-10 Batch 1:  Loss:     0.8787 Validation Accuracy: 0.627800\n",
      "Epoch 677, CIFAR-10 Batch 2:  Loss:     0.8894 Validation Accuracy: 0.629800\n",
      "Epoch 677, CIFAR-10 Batch 3:  Loss:     0.8756 Validation Accuracy: 0.632600\n",
      "Epoch 677, CIFAR-10 Batch 4:  Loss:     0.8944 Validation Accuracy: 0.629600\n",
      "Epoch 677, CIFAR-10 Batch 5:  Loss:     0.8860 Validation Accuracy: 0.630600\n",
      "Epoch 678, CIFAR-10 Batch 1:  Loss:     0.8784 Validation Accuracy: 0.627800\n",
      "Epoch 678, CIFAR-10 Batch 2:  Loss:     0.8896 Validation Accuracy: 0.629800\n",
      "Epoch 678, CIFAR-10 Batch 3:  Loss:     0.8766 Validation Accuracy: 0.632400\n",
      "Epoch 678, CIFAR-10 Batch 4:  Loss:     0.8956 Validation Accuracy: 0.626800\n",
      "Epoch 678, CIFAR-10 Batch 5:  Loss:     0.8863 Validation Accuracy: 0.631400\n",
      "Epoch 679, CIFAR-10 Batch 1:  Loss:     0.8782 Validation Accuracy: 0.628400\n",
      "Epoch 679, CIFAR-10 Batch 2:  Loss:     0.8900 Validation Accuracy: 0.628000\n",
      "Epoch 679, CIFAR-10 Batch 3:  Loss:     0.8773 Validation Accuracy: 0.631000\n",
      "Epoch 679, CIFAR-10 Batch 4:  Loss:     0.8958 Validation Accuracy: 0.627000\n",
      "Epoch 679, CIFAR-10 Batch 5:  Loss:     0.8859 Validation Accuracy: 0.631400\n",
      "Epoch 680, CIFAR-10 Batch 1:  Loss:     0.8780 Validation Accuracy: 0.627800\n",
      "Epoch 680, CIFAR-10 Batch 2:  Loss:     0.8904 Validation Accuracy: 0.628200\n",
      "Epoch 680, CIFAR-10 Batch 3:  Loss:     0.8776 Validation Accuracy: 0.631600\n",
      "Epoch 680, CIFAR-10 Batch 4:  Loss:     0.8953 Validation Accuracy: 0.626800\n",
      "Epoch 680, CIFAR-10 Batch 5:  Loss:     0.8850 Validation Accuracy: 0.630800\n",
      "Epoch 681, CIFAR-10 Batch 1:  Loss:     0.8777 Validation Accuracy: 0.627600\n",
      "Epoch 681, CIFAR-10 Batch 2:  Loss:     0.8903 Validation Accuracy: 0.627600\n",
      "Epoch 681, CIFAR-10 Batch 3:  Loss:     0.8773 Validation Accuracy: 0.631400\n",
      "Epoch 681, CIFAR-10 Batch 4:  Loss:     0.8945 Validation Accuracy: 0.628400\n",
      "Epoch 681, CIFAR-10 Batch 5:  Loss:     0.8843 Validation Accuracy: 0.629800\n",
      "Epoch 682, CIFAR-10 Batch 1:  Loss:     0.8773 Validation Accuracy: 0.627400\n",
      "Epoch 682, CIFAR-10 Batch 2:  Loss:     0.8899 Validation Accuracy: 0.627600\n",
      "Epoch 682, CIFAR-10 Batch 3:  Loss:     0.8768 Validation Accuracy: 0.631600\n",
      "Epoch 682, CIFAR-10 Batch 4:  Loss:     0.8938 Validation Accuracy: 0.629400\n",
      "Epoch 682, CIFAR-10 Batch 5:  Loss:     0.8837 Validation Accuracy: 0.629000\n",
      "Epoch 683, CIFAR-10 Batch 1:  Loss:     0.8769 Validation Accuracy: 0.627800\n",
      "Epoch 683, CIFAR-10 Batch 2:  Loss:     0.8894 Validation Accuracy: 0.628200\n",
      "Epoch 683, CIFAR-10 Batch 3:  Loss:     0.8765 Validation Accuracy: 0.631600\n",
      "Epoch 683, CIFAR-10 Batch 4:  Loss:     0.8933 Validation Accuracy: 0.629400\n",
      "Epoch 683, CIFAR-10 Batch 5:  Loss:     0.8832 Validation Accuracy: 0.629600\n",
      "Epoch 684, CIFAR-10 Batch 1:  Loss:     0.8764 Validation Accuracy: 0.628400\n",
      "Epoch 684, CIFAR-10 Batch 2:  Loss:     0.8889 Validation Accuracy: 0.629000\n",
      "Epoch 684, CIFAR-10 Batch 3:  Loss:     0.8763 Validation Accuracy: 0.631800\n",
      "Epoch 684, CIFAR-10 Batch 4:  Loss:     0.8931 Validation Accuracy: 0.628200\n",
      "Epoch 684, CIFAR-10 Batch 5:  Loss:     0.8830 Validation Accuracy: 0.629600\n",
      "Epoch 685, CIFAR-10 Batch 1:  Loss:     0.8760 Validation Accuracy: 0.628200\n",
      "Epoch 685, CIFAR-10 Batch 2:  Loss:     0.8886 Validation Accuracy: 0.629800\n",
      "Epoch 685, CIFAR-10 Batch 3:  Loss:     0.8760 Validation Accuracy: 0.630800\n",
      "Epoch 685, CIFAR-10 Batch 4:  Loss:     0.8928 Validation Accuracy: 0.628400\n",
      "Epoch 685, CIFAR-10 Batch 5:  Loss:     0.8828 Validation Accuracy: 0.629600\n",
      "Epoch 686, CIFAR-10 Batch 1:  Loss:     0.8757 Validation Accuracy: 0.628400\n",
      "Epoch 686, CIFAR-10 Batch 2:  Loss:     0.8882 Validation Accuracy: 0.629400\n",
      "Epoch 686, CIFAR-10 Batch 3:  Loss:     0.8758 Validation Accuracy: 0.630400\n",
      "Epoch 686, CIFAR-10 Batch 4:  Loss:     0.8925 Validation Accuracy: 0.628000\n",
      "Epoch 686, CIFAR-10 Batch 5:  Loss:     0.8826 Validation Accuracy: 0.629400\n",
      "Epoch 687, CIFAR-10 Batch 1:  Loss:     0.8754 Validation Accuracy: 0.627800\n",
      "Epoch 687, CIFAR-10 Batch 2:  Loss:     0.8879 Validation Accuracy: 0.630000\n",
      "Epoch 687, CIFAR-10 Batch 3:  Loss:     0.8755 Validation Accuracy: 0.630600\n",
      "Epoch 687, CIFAR-10 Batch 4:  Loss:     0.8922 Validation Accuracy: 0.628600\n",
      "Epoch 687, CIFAR-10 Batch 5:  Loss:     0.8825 Validation Accuracy: 0.630600\n",
      "Epoch 688, CIFAR-10 Batch 1:  Loss:     0.8751 Validation Accuracy: 0.627800\n",
      "Epoch 688, CIFAR-10 Batch 2:  Loss:     0.8876 Validation Accuracy: 0.630200\n",
      "Epoch 688, CIFAR-10 Batch 3:  Loss:     0.8753 Validation Accuracy: 0.631000\n",
      "Epoch 688, CIFAR-10 Batch 4:  Loss:     0.8919 Validation Accuracy: 0.629200\n",
      "Epoch 688, CIFAR-10 Batch 5:  Loss:     0.8823 Validation Accuracy: 0.630400\n",
      "Epoch 689, CIFAR-10 Batch 1:  Loss:     0.8749 Validation Accuracy: 0.628200\n",
      "Epoch 689, CIFAR-10 Batch 2:  Loss:     0.8873 Validation Accuracy: 0.630200\n",
      "Epoch 689, CIFAR-10 Batch 3:  Loss:     0.8750 Validation Accuracy: 0.630800\n",
      "Epoch 689, CIFAR-10 Batch 4:  Loss:     0.8916 Validation Accuracy: 0.628800\n",
      "Epoch 689, CIFAR-10 Batch 5:  Loss:     0.8821 Validation Accuracy: 0.630400\n",
      "Epoch 690, CIFAR-10 Batch 1:  Loss:     0.8746 Validation Accuracy: 0.628800\n",
      "Epoch 690, CIFAR-10 Batch 2:  Loss:     0.8871 Validation Accuracy: 0.629800\n",
      "Epoch 690, CIFAR-10 Batch 3:  Loss:     0.8748 Validation Accuracy: 0.630600\n",
      "Epoch 690, CIFAR-10 Batch 4:  Loss:     0.8913 Validation Accuracy: 0.628600\n",
      "Epoch 690, CIFAR-10 Batch 5:  Loss:     0.8817 Validation Accuracy: 0.630600\n",
      "Epoch 691, CIFAR-10 Batch 1:  Loss:     0.8743 Validation Accuracy: 0.628800\n",
      "Epoch 691, CIFAR-10 Batch 2:  Loss:     0.8869 Validation Accuracy: 0.629800\n",
      "Epoch 691, CIFAR-10 Batch 3:  Loss:     0.8745 Validation Accuracy: 0.631200\n",
      "Epoch 691, CIFAR-10 Batch 4:  Loss:     0.8908 Validation Accuracy: 0.627800\n",
      "Epoch 691, CIFAR-10 Batch 5:  Loss:     0.8813 Validation Accuracy: 0.630400\n",
      "Epoch 692, CIFAR-10 Batch 1:  Loss:     0.8741 Validation Accuracy: 0.629000\n",
      "Epoch 692, CIFAR-10 Batch 2:  Loss:     0.8867 Validation Accuracy: 0.630000\n",
      "Epoch 692, CIFAR-10 Batch 3:  Loss:     0.8741 Validation Accuracy: 0.631200\n",
      "Epoch 692, CIFAR-10 Batch 4:  Loss:     0.8901 Validation Accuracy: 0.629200\n",
      "Epoch 692, CIFAR-10 Batch 5:  Loss:     0.8807 Validation Accuracy: 0.630200\n",
      "Epoch 693, CIFAR-10 Batch 1:  Loss:     0.8738 Validation Accuracy: 0.629600\n",
      "Epoch 693, CIFAR-10 Batch 2:  Loss:     0.8863 Validation Accuracy: 0.630600\n",
      "Epoch 693, CIFAR-10 Batch 3:  Loss:     0.8735 Validation Accuracy: 0.631400\n",
      "Epoch 693, CIFAR-10 Batch 4:  Loss:     0.8892 Validation Accuracy: 0.629200\n",
      "Epoch 693, CIFAR-10 Batch 5:  Loss:     0.8801 Validation Accuracy: 0.631000\n",
      "Epoch 694, CIFAR-10 Batch 1:  Loss:     0.8735 Validation Accuracy: 0.628800\n",
      "Epoch 694, CIFAR-10 Batch 2:  Loss:     0.8860 Validation Accuracy: 0.630400\n",
      "Epoch 694, CIFAR-10 Batch 3:  Loss:     0.8729 Validation Accuracy: 0.632400\n",
      "Epoch 694, CIFAR-10 Batch 4:  Loss:     0.8885 Validation Accuracy: 0.629800\n",
      "Epoch 694, CIFAR-10 Batch 5:  Loss:     0.8795 Validation Accuracy: 0.631000\n",
      "Epoch 695, CIFAR-10 Batch 1:  Loss:     0.8731 Validation Accuracy: 0.628800\n",
      "Epoch 695, CIFAR-10 Batch 2:  Loss:     0.8855 Validation Accuracy: 0.631000\n",
      "Epoch 695, CIFAR-10 Batch 3:  Loss:     0.8722 Validation Accuracy: 0.632800\n",
      "Epoch 695, CIFAR-10 Batch 4:  Loss:     0.8877 Validation Accuracy: 0.630000\n",
      "Epoch 695, CIFAR-10 Batch 5:  Loss:     0.8790 Validation Accuracy: 0.630800\n",
      "Epoch 696, CIFAR-10 Batch 1:  Loss:     0.8727 Validation Accuracy: 0.628600\n",
      "Epoch 696, CIFAR-10 Batch 2:  Loss:     0.8849 Validation Accuracy: 0.630800\n",
      "Epoch 696, CIFAR-10 Batch 3:  Loss:     0.8717 Validation Accuracy: 0.632800\n",
      "Epoch 696, CIFAR-10 Batch 4:  Loss:     0.8873 Validation Accuracy: 0.630600\n",
      "Epoch 696, CIFAR-10 Batch 5:  Loss:     0.8787 Validation Accuracy: 0.630600\n",
      "Epoch 697, CIFAR-10 Batch 1:  Loss:     0.8722 Validation Accuracy: 0.628600\n",
      "Epoch 697, CIFAR-10 Batch 2:  Loss:     0.8845 Validation Accuracy: 0.630600\n",
      "Epoch 697, CIFAR-10 Batch 3:  Loss:     0.8714 Validation Accuracy: 0.632600\n",
      "Epoch 697, CIFAR-10 Batch 4:  Loss:     0.8871 Validation Accuracy: 0.630400\n",
      "Epoch 697, CIFAR-10 Batch 5:  Loss:     0.8784 Validation Accuracy: 0.630200\n",
      "Epoch 698, CIFAR-10 Batch 1:  Loss:     0.8719 Validation Accuracy: 0.629000\n",
      "Epoch 698, CIFAR-10 Batch 2:  Loss:     0.8842 Validation Accuracy: 0.631200\n",
      "Epoch 698, CIFAR-10 Batch 3:  Loss:     0.8711 Validation Accuracy: 0.632600\n",
      "Epoch 698, CIFAR-10 Batch 4:  Loss:     0.8868 Validation Accuracy: 0.630200\n",
      "Epoch 698, CIFAR-10 Batch 5:  Loss:     0.8782 Validation Accuracy: 0.628800\n",
      "Epoch 699, CIFAR-10 Batch 1:  Loss:     0.8716 Validation Accuracy: 0.628400\n",
      "Epoch 699, CIFAR-10 Batch 2:  Loss:     0.8839 Validation Accuracy: 0.631200\n",
      "Epoch 699, CIFAR-10 Batch 3:  Loss:     0.8709 Validation Accuracy: 0.632200\n",
      "Epoch 699, CIFAR-10 Batch 4:  Loss:     0.8866 Validation Accuracy: 0.629600\n",
      "Epoch 699, CIFAR-10 Batch 5:  Loss:     0.8781 Validation Accuracy: 0.629800\n",
      "Epoch 700, CIFAR-10 Batch 1:  Loss:     0.8714 Validation Accuracy: 0.628400\n",
      "Epoch 700, CIFAR-10 Batch 2:  Loss:     0.8837 Validation Accuracy: 0.631600\n",
      "Epoch 700, CIFAR-10 Batch 3:  Loss:     0.8706 Validation Accuracy: 0.632200\n",
      "Epoch 700, CIFAR-10 Batch 4:  Loss:     0.8864 Validation Accuracy: 0.629000\n",
      "Epoch 700, CIFAR-10 Batch 5:  Loss:     0.8780 Validation Accuracy: 0.630200\n",
      "Epoch 701, CIFAR-10 Batch 1:  Loss:     0.8712 Validation Accuracy: 0.628000\n",
      "Epoch 701, CIFAR-10 Batch 2:  Loss:     0.8834 Validation Accuracy: 0.631800\n",
      "Epoch 701, CIFAR-10 Batch 3:  Loss:     0.8704 Validation Accuracy: 0.632400\n",
      "Epoch 701, CIFAR-10 Batch 4:  Loss:     0.8862 Validation Accuracy: 0.628600\n",
      "Epoch 701, CIFAR-10 Batch 5:  Loss:     0.8778 Validation Accuracy: 0.631000\n",
      "Epoch 702, CIFAR-10 Batch 1:  Loss:     0.8709 Validation Accuracy: 0.627800\n",
      "Epoch 702, CIFAR-10 Batch 2:  Loss:     0.8830 Validation Accuracy: 0.631400\n",
      "Epoch 702, CIFAR-10 Batch 3:  Loss:     0.8700 Validation Accuracy: 0.632400\n",
      "Epoch 702, CIFAR-10 Batch 4:  Loss:     0.8860 Validation Accuracy: 0.628400\n",
      "Epoch 702, CIFAR-10 Batch 5:  Loss:     0.8777 Validation Accuracy: 0.631000\n",
      "Epoch 703, CIFAR-10 Batch 1:  Loss:     0.8706 Validation Accuracy: 0.627400\n",
      "Epoch 703, CIFAR-10 Batch 2:  Loss:     0.8826 Validation Accuracy: 0.631200\n",
      "Epoch 703, CIFAR-10 Batch 3:  Loss:     0.8697 Validation Accuracy: 0.632400\n",
      "Epoch 703, CIFAR-10 Batch 4:  Loss:     0.8857 Validation Accuracy: 0.628200\n",
      "Epoch 703, CIFAR-10 Batch 5:  Loss:     0.8775 Validation Accuracy: 0.631000\n",
      "Epoch 704, CIFAR-10 Batch 1:  Loss:     0.8703 Validation Accuracy: 0.627400\n",
      "Epoch 704, CIFAR-10 Batch 2:  Loss:     0.8822 Validation Accuracy: 0.631800\n",
      "Epoch 704, CIFAR-10 Batch 3:  Loss:     0.8693 Validation Accuracy: 0.633000\n",
      "Epoch 704, CIFAR-10 Batch 4:  Loss:     0.8854 Validation Accuracy: 0.628200\n",
      "Epoch 704, CIFAR-10 Batch 5:  Loss:     0.8773 Validation Accuracy: 0.631000\n",
      "Epoch 705, CIFAR-10 Batch 1:  Loss:     0.8698 Validation Accuracy: 0.627400\n",
      "Epoch 705, CIFAR-10 Batch 2:  Loss:     0.8819 Validation Accuracy: 0.631600\n",
      "Epoch 705, CIFAR-10 Batch 3:  Loss:     0.8691 Validation Accuracy: 0.632800\n",
      "Epoch 705, CIFAR-10 Batch 4:  Loss:     0.8852 Validation Accuracy: 0.628000\n",
      "Epoch 705, CIFAR-10 Batch 5:  Loss:     0.8769 Validation Accuracy: 0.630400\n",
      "Epoch 706, CIFAR-10 Batch 1:  Loss:     0.8694 Validation Accuracy: 0.627800\n",
      "Epoch 706, CIFAR-10 Batch 2:  Loss:     0.8816 Validation Accuracy: 0.631800\n",
      "Epoch 706, CIFAR-10 Batch 3:  Loss:     0.8688 Validation Accuracy: 0.632800\n",
      "Epoch 706, CIFAR-10 Batch 4:  Loss:     0.8848 Validation Accuracy: 0.627800\n",
      "Epoch 706, CIFAR-10 Batch 5:  Loss:     0.8764 Validation Accuracy: 0.630400\n",
      "Epoch 707, CIFAR-10 Batch 1:  Loss:     0.8691 Validation Accuracy: 0.628600\n",
      "Epoch 707, CIFAR-10 Batch 2:  Loss:     0.8814 Validation Accuracy: 0.632000\n",
      "Epoch 707, CIFAR-10 Batch 3:  Loss:     0.8684 Validation Accuracy: 0.632800\n",
      "Epoch 707, CIFAR-10 Batch 4:  Loss:     0.8842 Validation Accuracy: 0.627800\n",
      "Epoch 707, CIFAR-10 Batch 5:  Loss:     0.8759 Validation Accuracy: 0.630200\n",
      "Epoch 708, CIFAR-10 Batch 1:  Loss:     0.8687 Validation Accuracy: 0.629000\n",
      "Epoch 708, CIFAR-10 Batch 2:  Loss:     0.8810 Validation Accuracy: 0.632000\n",
      "Epoch 708, CIFAR-10 Batch 3:  Loss:     0.8680 Validation Accuracy: 0.633000\n",
      "Epoch 708, CIFAR-10 Batch 4:  Loss:     0.8837 Validation Accuracy: 0.628600\n",
      "Epoch 708, CIFAR-10 Batch 5:  Loss:     0.8753 Validation Accuracy: 0.630600\n",
      "Epoch 709, CIFAR-10 Batch 1:  Loss:     0.8682 Validation Accuracy: 0.629000\n",
      "Epoch 709, CIFAR-10 Batch 2:  Loss:     0.8807 Validation Accuracy: 0.632000\n",
      "Epoch 709, CIFAR-10 Batch 3:  Loss:     0.8676 Validation Accuracy: 0.632800\n",
      "Epoch 709, CIFAR-10 Batch 4:  Loss:     0.8832 Validation Accuracy: 0.629000\n",
      "Epoch 709, CIFAR-10 Batch 5:  Loss:     0.8748 Validation Accuracy: 0.629800\n",
      "Epoch 710, CIFAR-10 Batch 1:  Loss:     0.8678 Validation Accuracy: 0.628800\n",
      "Epoch 710, CIFAR-10 Batch 2:  Loss:     0.8804 Validation Accuracy: 0.631600\n",
      "Epoch 710, CIFAR-10 Batch 3:  Loss:     0.8673 Validation Accuracy: 0.632600\n",
      "Epoch 710, CIFAR-10 Batch 4:  Loss:     0.8828 Validation Accuracy: 0.629200\n",
      "Epoch 710, CIFAR-10 Batch 5:  Loss:     0.8743 Validation Accuracy: 0.629400\n",
      "Epoch 711, CIFAR-10 Batch 1:  Loss:     0.8674 Validation Accuracy: 0.629400\n",
      "Epoch 711, CIFAR-10 Batch 2:  Loss:     0.8802 Validation Accuracy: 0.631600\n",
      "Epoch 711, CIFAR-10 Batch 3:  Loss:     0.8669 Validation Accuracy: 0.632800\n",
      "Epoch 711, CIFAR-10 Batch 4:  Loss:     0.8824 Validation Accuracy: 0.628400\n",
      "Epoch 711, CIFAR-10 Batch 5:  Loss:     0.8739 Validation Accuracy: 0.629400\n",
      "Epoch 712, CIFAR-10 Batch 1:  Loss:     0.8671 Validation Accuracy: 0.630400\n",
      "Epoch 712, CIFAR-10 Batch 2:  Loss:     0.8799 Validation Accuracy: 0.632000\n",
      "Epoch 712, CIFAR-10 Batch 3:  Loss:     0.8666 Validation Accuracy: 0.632600\n",
      "Epoch 712, CIFAR-10 Batch 4:  Loss:     0.8820 Validation Accuracy: 0.628400\n",
      "Epoch 712, CIFAR-10 Batch 5:  Loss:     0.8736 Validation Accuracy: 0.629800\n",
      "Epoch 713, CIFAR-10 Batch 1:  Loss:     0.8668 Validation Accuracy: 0.631000\n",
      "Epoch 713, CIFAR-10 Batch 2:  Loss:     0.8796 Validation Accuracy: 0.632000\n",
      "Epoch 713, CIFAR-10 Batch 3:  Loss:     0.8663 Validation Accuracy: 0.632600\n",
      "Epoch 713, CIFAR-10 Batch 4:  Loss:     0.8817 Validation Accuracy: 0.628200\n",
      "Epoch 713, CIFAR-10 Batch 5:  Loss:     0.8733 Validation Accuracy: 0.630000\n",
      "Epoch 714, CIFAR-10 Batch 1:  Loss:     0.8665 Validation Accuracy: 0.631200\n",
      "Epoch 714, CIFAR-10 Batch 2:  Loss:     0.8793 Validation Accuracy: 0.632400\n",
      "Epoch 714, CIFAR-10 Batch 3:  Loss:     0.8660 Validation Accuracy: 0.632400\n",
      "Epoch 714, CIFAR-10 Batch 4:  Loss:     0.8814 Validation Accuracy: 0.627600\n",
      "Epoch 714, CIFAR-10 Batch 5:  Loss:     0.8731 Validation Accuracy: 0.629400\n",
      "Epoch 715, CIFAR-10 Batch 1:  Loss:     0.8662 Validation Accuracy: 0.631600\n",
      "Epoch 715, CIFAR-10 Batch 2:  Loss:     0.8789 Validation Accuracy: 0.632600\n",
      "Epoch 715, CIFAR-10 Batch 3:  Loss:     0.8657 Validation Accuracy: 0.632200\n",
      "Epoch 715, CIFAR-10 Batch 4:  Loss:     0.8812 Validation Accuracy: 0.627600\n",
      "Epoch 715, CIFAR-10 Batch 5:  Loss:     0.8729 Validation Accuracy: 0.630000\n",
      "Epoch 716, CIFAR-10 Batch 1:  Loss:     0.8659 Validation Accuracy: 0.631600\n",
      "Epoch 716, CIFAR-10 Batch 2:  Loss:     0.8786 Validation Accuracy: 0.632600\n",
      "Epoch 716, CIFAR-10 Batch 3:  Loss:     0.8654 Validation Accuracy: 0.632200\n",
      "Epoch 716, CIFAR-10 Batch 4:  Loss:     0.8810 Validation Accuracy: 0.627800\n",
      "Epoch 716, CIFAR-10 Batch 5:  Loss:     0.8727 Validation Accuracy: 0.629600\n",
      "Epoch 717, CIFAR-10 Batch 1:  Loss:     0.8656 Validation Accuracy: 0.631600\n",
      "Epoch 717, CIFAR-10 Batch 2:  Loss:     0.8783 Validation Accuracy: 0.632400\n",
      "Epoch 717, CIFAR-10 Batch 3:  Loss:     0.8651 Validation Accuracy: 0.632400\n",
      "Epoch 717, CIFAR-10 Batch 4:  Loss:     0.8808 Validation Accuracy: 0.627800\n",
      "Epoch 717, CIFAR-10 Batch 5:  Loss:     0.8725 Validation Accuracy: 0.630000\n",
      "Epoch 718, CIFAR-10 Batch 1:  Loss:     0.8653 Validation Accuracy: 0.631200\n",
      "Epoch 718, CIFAR-10 Batch 2:  Loss:     0.8779 Validation Accuracy: 0.632200\n",
      "Epoch 718, CIFAR-10 Batch 3:  Loss:     0.8647 Validation Accuracy: 0.632000\n",
      "Epoch 718, CIFAR-10 Batch 4:  Loss:     0.8805 Validation Accuracy: 0.628000\n",
      "Epoch 718, CIFAR-10 Batch 5:  Loss:     0.8723 Validation Accuracy: 0.629600\n",
      "Epoch 719, CIFAR-10 Batch 1:  "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.6406000256538391\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+/+/N3zExfgt4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f71b0267080>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. That's because there are many more techniques that can be applied to your model and we recemmond that once you are done with this project, you explore!\n",
    "\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
