{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 10:\n",
      "Image - Min Value: 24 Max Value: 130\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 4 Name: deer\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njQl6AGjs/wCMj7S6AwR1rgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fadb41236a0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 10\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    xmax, xmin = x.max(),x.min()\n",
    "    y = (x-xmin)/(xmax-xmin)\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "Look into LabelBinarizer in the preprocessing module of sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "map = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(map)\n",
    "    return lb.transform(x)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = (None,image_shape[0],image_shape[1],image_shape[2])\n",
    "    return tf.placeholder(tf.float32,shape=shape,name=\"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = [None,n_classes]\n",
    "    return tf.placeholder(tf.int16,shape=shape,name=\"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,name=\"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers.\n",
    "\n",
    "** Hint: **\n",
    "\n",
    "When unpacking values as an argument in Python, look into the [unpacking](https://docs.python.org/3/tutorial/controlflow.html#unpacking-argument-lists) operator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    filter_size_width = int(conv_ksize[0])\n",
    "    filter_size_height = int(conv_ksize[1])\n",
    "    input_size = int(x_tensor.get_shape()[3])\n",
    "#     print([filter_size_width,filter_size_height,input_size,conv_num_outputs])\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal(\\\n",
    "                                              [filter_size_width,filter_size_height,\\\n",
    "                                               input_size,conv_num_outputs],stddev=0.005))\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    x = tf.nn.conv2d(input=x_tensor,filter=weights,\\\n",
    "                            strides=[1,conv_strides[0],conv_strides[1],1],\n",
    "                            padding='SAME')\n",
    "    x = tf.nn.bias_add(x,bias)\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    return tf.nn.max_pool(x,ksize=[1,pool_ksize[0],pool_ksize[1],1],\\\n",
    "                          strides=[1,pool_strides[0],pool_strides[1],1],\\\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    batch_size, dim1, dim2, dim3 = x_tensor.get_shape().as_list()\n",
    "    flat_dims = dim1 * dim2 * dim3\n",
    "\n",
    "    return tf.reshape(x_tensor,[-1, flat_dims])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    f_size = x_tensor.get_shape().as_list()[1]\n",
    "    weights = tf.Variable(tf.truncated_normal([f_size,num_outputs],stddev=0.005))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    fc = tf.add(tf.matmul(x_tensor,weights),bias)\n",
    "    \n",
    "    return tf.nn.relu(fc)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    size = x_tensor.get_shape().as_list()[1]\n",
    "    weights = tf.Variable(tf.truncated_normal([size,num_outputs],stddev=0.005))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    out = tf.add(tf.matmul(x_tensor,weights),bias)\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv_ksize = (4,4)\n",
    "    conv_strides = (2,2)\n",
    "    conv_num_outputs = 256\n",
    "    pool_ksize = (4,4)\n",
    "    pool_strides = (2,2)\n",
    "    num_outputs = 10\n",
    "    \n",
    "    x = conv2d_maxpool(x,conv_num_outputs=conv_num_outputs,\\\n",
    "                       conv_ksize=conv_ksize,conv_strides=conv_strides,\\\n",
    "                      pool_ksize=pool_ksize,pool_strides=pool_strides)\n",
    "    x = tf.nn.dropout(x,keep_prob)\n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    x = flatten(x)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    x = fully_conn(x,num_outputs)\n",
    "    x = tf.nn.dropout(x,keep_prob)\n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return output(x,num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer,feed_dict={x:feature_batch,y:label_batch,keep_prob:keep_probability})\n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost,{x:feature_batch,y:label_batch,keep_prob:1.})\n",
    "    valid_acc = session.run(accuracy,{x:valid_features,y:valid_labels,keep_prob:1.})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss,valid_acc))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 600\n",
    "batch_size = 1024\n",
    "keep_probability = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.3026 Validation Accuracy: 0.098800\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.3024 Validation Accuracy: 0.105000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.3021 Validation Accuracy: 0.105000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.3015 Validation Accuracy: 0.105000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     2.3006 Validation Accuracy: 0.105000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     2.2990 Validation Accuracy: 0.105000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     2.2971 Validation Accuracy: 0.105000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     2.2946 Validation Accuracy: 0.105000\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     2.2915 Validation Accuracy: 0.105400\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     2.2874 Validation Accuracy: 0.105600\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     2.2823 Validation Accuracy: 0.108600\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     2.2758 Validation Accuracy: 0.112000\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     2.2677 Validation Accuracy: 0.120400\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     2.2582 Validation Accuracy: 0.131400\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     2.2476 Validation Accuracy: 0.137600\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     2.2353 Validation Accuracy: 0.142400\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     2.2223 Validation Accuracy: 0.144800\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     2.2085 Validation Accuracy: 0.148400\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     2.1938 Validation Accuracy: 0.152800\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     2.1788 Validation Accuracy: 0.155400\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     2.1637 Validation Accuracy: 0.155000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     2.1496 Validation Accuracy: 0.163400\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     2.1364 Validation Accuracy: 0.184400\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     2.1241 Validation Accuracy: 0.191400\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     2.1123 Validation Accuracy: 0.201600\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     2.1012 Validation Accuracy: 0.216800\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     2.0907 Validation Accuracy: 0.227800\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     2.0808 Validation Accuracy: 0.232000\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     2.0714 Validation Accuracy: 0.226600\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     2.0634 Validation Accuracy: 0.225800\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     2.0569 Validation Accuracy: 0.228000\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     2.0493 Validation Accuracy: 0.237200\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     2.0396 Validation Accuracy: 0.240800\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     2.0348 Validation Accuracy: 0.247000\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     2.0303 Validation Accuracy: 0.246600\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     2.0224 Validation Accuracy: 0.248400\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     2.0177 Validation Accuracy: 0.251600\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     2.0138 Validation Accuracy: 0.253800\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     2.0069 Validation Accuracy: 0.253200\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     2.0027 Validation Accuracy: 0.252000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.9991 Validation Accuracy: 0.251400\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.9931 Validation Accuracy: 0.255600\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.9890 Validation Accuracy: 0.257400\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.9853 Validation Accuracy: 0.258000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.9797 Validation Accuracy: 0.262200\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.9756 Validation Accuracy: 0.262600\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.9718 Validation Accuracy: 0.262200\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.9664 Validation Accuracy: 0.266000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.9618 Validation Accuracy: 0.267200\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.9577 Validation Accuracy: 0.268400\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.9525 Validation Accuracy: 0.272200\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.9472 Validation Accuracy: 0.271000\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.9426 Validation Accuracy: 0.270400\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.9373 Validation Accuracy: 0.273400\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.9314 Validation Accuracy: 0.278800\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.9259 Validation Accuracy: 0.281200\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.9202 Validation Accuracy: 0.283000\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.9139 Validation Accuracy: 0.279800\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.9075 Validation Accuracy: 0.283800\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.9012 Validation Accuracy: 0.288400\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.8945 Validation Accuracy: 0.287800\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.8874 Validation Accuracy: 0.292600\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.8802 Validation Accuracy: 0.296000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.8731 Validation Accuracy: 0.299400\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.8658 Validation Accuracy: 0.303600\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.8581 Validation Accuracy: 0.307400\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.8503 Validation Accuracy: 0.307800\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.8424 Validation Accuracy: 0.308800\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.8345 Validation Accuracy: 0.309600\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.8266 Validation Accuracy: 0.309000\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.8187 Validation Accuracy: 0.316600\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.8109 Validation Accuracy: 0.314600\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.8032 Validation Accuracy: 0.322800\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     1.7958 Validation Accuracy: 0.322400\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     1.7888 Validation Accuracy: 0.328400\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     1.7825 Validation Accuracy: 0.326000\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     1.7777 Validation Accuracy: 0.334600\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     1.7754 Validation Accuracy: 0.326600\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     1.7714 Validation Accuracy: 0.342000\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     1.7615 Validation Accuracy: 0.338400\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     1.7536 Validation Accuracy: 0.336000\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     1.7528 Validation Accuracy: 0.346800\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     1.7488 Validation Accuracy: 0.341400\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     1.7402 Validation Accuracy: 0.345400\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     1.7376 Validation Accuracy: 0.348200\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     1.7357 Validation Accuracy: 0.345800\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     1.7284 Validation Accuracy: 0.351200\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     1.7244 Validation Accuracy: 0.350800\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     1.7229 Validation Accuracy: 0.350000\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     1.7174 Validation Accuracy: 0.357800\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     1.7127 Validation Accuracy: 0.353200\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     1.7105 Validation Accuracy: 0.354200\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     1.7068 Validation Accuracy: 0.359000\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     1.7021 Validation Accuracy: 0.356400\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     1.6985 Validation Accuracy: 0.360400\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     1.6960 Validation Accuracy: 0.365200\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     1.6921 Validation Accuracy: 0.360400\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     1.6876 Validation Accuracy: 0.367200\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     1.6849 Validation Accuracy: 0.370800\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     1.6820 Validation Accuracy: 0.364600\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:     1.6778 Validation Accuracy: 0.372000\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:     1.6744 Validation Accuracy: 0.370200\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:     1.6711 Validation Accuracy: 0.370400\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:     1.6681 Validation Accuracy: 0.376200\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:     1.6650 Validation Accuracy: 0.371800\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:     1.6611 Validation Accuracy: 0.374600\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:     1.6577 Validation Accuracy: 0.376000\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:     1.6548 Validation Accuracy: 0.378000\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss:     1.6517 Validation Accuracy: 0.378800\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:     1.6487 Validation Accuracy: 0.376400\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:     1.6455 Validation Accuracy: 0.380200\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:     1.6421 Validation Accuracy: 0.381400\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:     1.6389 Validation Accuracy: 0.382200\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:     1.6358 Validation Accuracy: 0.385400\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:     1.6327 Validation Accuracy: 0.384600\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:     1.6298 Validation Accuracy: 0.384800\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:     1.6269 Validation Accuracy: 0.386800\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:     1.6240 Validation Accuracy: 0.389200\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:     1.6212 Validation Accuracy: 0.388000\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:     1.6186 Validation Accuracy: 0.390600\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:     1.6160 Validation Accuracy: 0.389400\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:     1.6137 Validation Accuracy: 0.389400\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:     1.6113 Validation Accuracy: 0.392600\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:     1.6086 Validation Accuracy: 0.392600\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:     1.6052 Validation Accuracy: 0.392400\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:     1.6010 Validation Accuracy: 0.396400\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:     1.5970 Validation Accuracy: 0.399400\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:     1.5940 Validation Accuracy: 0.398800\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:     1.5917 Validation Accuracy: 0.404200\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:     1.5897 Validation Accuracy: 0.401600\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:     1.5872 Validation Accuracy: 0.404600\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:     1.5840 Validation Accuracy: 0.404000\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:     1.5804 Validation Accuracy: 0.407200\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:     1.5771 Validation Accuracy: 0.407400\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:     1.5743 Validation Accuracy: 0.408400\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:     1.5720 Validation Accuracy: 0.412800\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:     1.5704 Validation Accuracy: 0.411200\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:     1.5701 Validation Accuracy: 0.414400\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:     1.5715 Validation Accuracy: 0.410600\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:     1.5732 Validation Accuracy: 0.415000\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:     1.5663 Validation Accuracy: 0.413000\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:     1.5587 Validation Accuracy: 0.417600\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:     1.5606 Validation Accuracy: 0.419800\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:     1.5563 Validation Accuracy: 0.416200\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:     1.5505 Validation Accuracy: 0.422400\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:     1.5523 Validation Accuracy: 0.424600\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:     1.5458 Validation Accuracy: 0.422400\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:     1.5432 Validation Accuracy: 0.423800\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:     1.5438 Validation Accuracy: 0.429200\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:     1.5371 Validation Accuracy: 0.429000\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:     1.5363 Validation Accuracy: 0.425200\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:     1.5356 Validation Accuracy: 0.428400\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:     1.5294 Validation Accuracy: 0.434200\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:     1.5297 Validation Accuracy: 0.431200\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:     1.5274 Validation Accuracy: 0.431200\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:     1.5226 Validation Accuracy: 0.432800\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:     1.5229 Validation Accuracy: 0.432800\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:     1.5194 Validation Accuracy: 0.437600\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:     1.5160 Validation Accuracy: 0.435400\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:     1.5158 Validation Accuracy: 0.434600\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:     1.5120 Validation Accuracy: 0.441200\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:     1.5093 Validation Accuracy: 0.438200\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:     1.5086 Validation Accuracy: 0.436000\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:     1.5051 Validation Accuracy: 0.445200\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:     1.5027 Validation Accuracy: 0.441600\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:     1.5016 Validation Accuracy: 0.436000\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:     1.4985 Validation Accuracy: 0.443200\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:     1.4964 Validation Accuracy: 0.443000\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:     1.4949 Validation Accuracy: 0.438400\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:     1.4921 Validation Accuracy: 0.444600\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:     1.4900 Validation Accuracy: 0.446200\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:     1.4887 Validation Accuracy: 0.441600\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss:     1.4861 Validation Accuracy: 0.447000\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:     1.4840 Validation Accuracy: 0.447600\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:     1.4825 Validation Accuracy: 0.444000\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:     1.4804 Validation Accuracy: 0.449000\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:     1.4782 Validation Accuracy: 0.450000\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:     1.4767 Validation Accuracy: 0.446400\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:     1.4749 Validation Accuracy: 0.450200\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:     1.4727 Validation Accuracy: 0.448800\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:     1.4710 Validation Accuracy: 0.450400\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:     1.4694 Validation Accuracy: 0.451200\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:     1.4675 Validation Accuracy: 0.450200\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:     1.4656 Validation Accuracy: 0.450600\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:     1.4641 Validation Accuracy: 0.453800\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:     1.4624 Validation Accuracy: 0.451600\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:     1.4606 Validation Accuracy: 0.454000\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:     1.4590 Validation Accuracy: 0.454800\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:     1.4574 Validation Accuracy: 0.452200\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:     1.4557 Validation Accuracy: 0.456600\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:     1.4541 Validation Accuracy: 0.455000\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:     1.4527 Validation Accuracy: 0.455000\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:     1.4515 Validation Accuracy: 0.454200\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:     1.4505 Validation Accuracy: 0.456600\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:     1.4505 Validation Accuracy: 0.453000\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:     1.4518 Validation Accuracy: 0.461200\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:     1.4553 Validation Accuracy: 0.448800\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:     1.4547 Validation Accuracy: 0.459600\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:     1.4492 Validation Accuracy: 0.450800\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:     1.4411 Validation Accuracy: 0.457200\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss:     1.4412 Validation Accuracy: 0.460400\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss:     1.4446 Validation Accuracy: 0.452800\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss:     1.4406 Validation Accuracy: 0.464400\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss:     1.4355 Validation Accuracy: 0.458800\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss:     1.4359 Validation Accuracy: 0.460000\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss:     1.4362 Validation Accuracy: 0.461200\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss:     1.4329 Validation Accuracy: 0.460600\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss:     1.4302 Validation Accuracy: 0.463400\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss:     1.4305 Validation Accuracy: 0.462600\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss:     1.4297 Validation Accuracy: 0.462000\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss:     1.4271 Validation Accuracy: 0.464200\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss:     1.4257 Validation Accuracy: 0.463200\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss:     1.4249 Validation Accuracy: 0.465200\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss:     1.4236 Validation Accuracy: 0.463200\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss:     1.4222 Validation Accuracy: 0.466000\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss:     1.4205 Validation Accuracy: 0.469200\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss:     1.4190 Validation Accuracy: 0.465200\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss:     1.4183 Validation Accuracy: 0.467000\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss:     1.4173 Validation Accuracy: 0.469200\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss:     1.4153 Validation Accuracy: 0.466800\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss:     1.4139 Validation Accuracy: 0.468600\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss:     1.4133 Validation Accuracy: 0.469600\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss:     1.4121 Validation Accuracy: 0.470000\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss:     1.4104 Validation Accuracy: 0.468600\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss:     1.4091 Validation Accuracy: 0.470600\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss:     1.4083 Validation Accuracy: 0.470200\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss:     1.4070 Validation Accuracy: 0.472400\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss:     1.4056 Validation Accuracy: 0.472000\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss:     1.4044 Validation Accuracy: 0.470600\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss:     1.4032 Validation Accuracy: 0.469400\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss:     1.4019 Validation Accuracy: 0.471400\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss:     1.4008 Validation Accuracy: 0.472400\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss:     1.3998 Validation Accuracy: 0.471600\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss:     1.3986 Validation Accuracy: 0.472000\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss:     1.3972 Validation Accuracy: 0.471600\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss:     1.3961 Validation Accuracy: 0.473000\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss:     1.3952 Validation Accuracy: 0.471400\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss:     1.3944 Validation Accuracy: 0.474600\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss:     1.3937 Validation Accuracy: 0.472800\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss:     1.3934 Validation Accuracy: 0.473400\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss:     1.3926 Validation Accuracy: 0.472200\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss:     1.3911 Validation Accuracy: 0.474200\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss:     1.3888 Validation Accuracy: 0.473600\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss:     1.3872 Validation Accuracy: 0.473800\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss:     1.3863 Validation Accuracy: 0.474400\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss:     1.3854 Validation Accuracy: 0.472600\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss:     1.3840 Validation Accuracy: 0.477400\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss:     1.3823 Validation Accuracy: 0.474000\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss:     1.3810 Validation Accuracy: 0.479000\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss:     1.3799 Validation Accuracy: 0.476200\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss:     1.3789 Validation Accuracy: 0.473000\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss:     1.3781 Validation Accuracy: 0.479200\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss:     1.3772 Validation Accuracy: 0.474400\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss:     1.3761 Validation Accuracy: 0.478600\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss:     1.3750 Validation Accuracy: 0.476000\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss:     1.3744 Validation Accuracy: 0.478200\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss:     1.3746 Validation Accuracy: 0.477400\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss:     1.3762 Validation Accuracy: 0.477800\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss:     1.3794 Validation Accuracy: 0.474400\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss:     1.3826 Validation Accuracy: 0.472400\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss:     1.3821 Validation Accuracy: 0.470400\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss:     1.3761 Validation Accuracy: 0.478600\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss:     1.3676 Validation Accuracy: 0.476600\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss:     1.3656 Validation Accuracy: 0.482400\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss:     1.3691 Validation Accuracy: 0.479800\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss:     1.3705 Validation Accuracy: 0.477800\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss:     1.3666 Validation Accuracy: 0.480800\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss:     1.3611 Validation Accuracy: 0.479200\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss:     1.3610 Validation Accuracy: 0.479800\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss:     1.3637 Validation Accuracy: 0.482600\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss:     1.3619 Validation Accuracy: 0.479400\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss:     1.3575 Validation Accuracy: 0.483000\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss:     1.3561 Validation Accuracy: 0.482800\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss:     1.3575 Validation Accuracy: 0.480200\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss:     1.3569 Validation Accuracy: 0.483200\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss:     1.3538 Validation Accuracy: 0.482000\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss:     1.3522 Validation Accuracy: 0.482600\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss:     1.3524 Validation Accuracy: 0.485200\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss:     1.3517 Validation Accuracy: 0.481400\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss:     1.3500 Validation Accuracy: 0.485400\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss:     1.3487 Validation Accuracy: 0.484000\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss:     1.3479 Validation Accuracy: 0.483800\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss:     1.3469 Validation Accuracy: 0.485200\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss:     1.3458 Validation Accuracy: 0.483000\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss:     1.3450 Validation Accuracy: 0.486400\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss:     1.3442 Validation Accuracy: 0.485600\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss:     1.3429 Validation Accuracy: 0.486800\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss:     1.3415 Validation Accuracy: 0.486600\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss:     1.3404 Validation Accuracy: 0.485600\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss:     1.3398 Validation Accuracy: 0.488200\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss:     1.3392 Validation Accuracy: 0.487600\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss:     1.3382 Validation Accuracy: 0.488400\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss:     1.3369 Validation Accuracy: 0.487600\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss:     1.3356 Validation Accuracy: 0.488600\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss:     1.3347 Validation Accuracy: 0.486200\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss:     1.3338 Validation Accuracy: 0.489800\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss:     1.3328 Validation Accuracy: 0.489600\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss:     1.3317 Validation Accuracy: 0.488000\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss:     1.3308 Validation Accuracy: 0.490000\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss:     1.3300 Validation Accuracy: 0.488400\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss:     1.3293 Validation Accuracy: 0.491200\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss:     1.3287 Validation Accuracy: 0.487600\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss:     1.3281 Validation Accuracy: 0.490400\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss:     1.3278 Validation Accuracy: 0.487400\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss:     1.3278 Validation Accuracy: 0.490400\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss:     1.3284 Validation Accuracy: 0.487000\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss:     1.3286 Validation Accuracy: 0.485200\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss:     1.3287 Validation Accuracy: 0.486600\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss:     1.3259 Validation Accuracy: 0.489200\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss:     1.3228 Validation Accuracy: 0.488800\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss:     1.3203 Validation Accuracy: 0.493000\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss:     1.3194 Validation Accuracy: 0.490600\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss:     1.3193 Validation Accuracy: 0.494800\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss:     1.3190 Validation Accuracy: 0.490400\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss:     1.3179 Validation Accuracy: 0.492600\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss:     1.3160 Validation Accuracy: 0.493200\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss:     1.3148 Validation Accuracy: 0.490400\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss:     1.3146 Validation Accuracy: 0.494400\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss:     1.3147 Validation Accuracy: 0.488600\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss:     1.3142 Validation Accuracy: 0.496400\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss:     1.3125 Validation Accuracy: 0.491000\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss:     1.3104 Validation Accuracy: 0.495800\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss:     1.3086 Validation Accuracy: 0.494200\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss:     1.3077 Validation Accuracy: 0.495400\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss:     1.3074 Validation Accuracy: 0.494800\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss:     1.3071 Validation Accuracy: 0.492600\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss:     1.3064 Validation Accuracy: 0.495400\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss:     1.3050 Validation Accuracy: 0.493800\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss:     1.3036 Validation Accuracy: 0.498000\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss:     1.3023 Validation Accuracy: 0.496800\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss:     1.3016 Validation Accuracy: 0.498200\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss:     1.3012 Validation Accuracy: 0.495400\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss:     1.3011 Validation Accuracy: 0.499000\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss:     1.3014 Validation Accuracy: 0.497600\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss:     1.3016 Validation Accuracy: 0.495800\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss:     1.3024 Validation Accuracy: 0.494400\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss:     1.3029 Validation Accuracy: 0.495000\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss:     1.3043 Validation Accuracy: 0.488600\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss:     1.3070 Validation Accuracy: 0.494400\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss:     1.3065 Validation Accuracy: 0.486600\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss:     1.3044 Validation Accuracy: 0.494200\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss:     1.2956 Validation Accuracy: 0.492000\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss:     1.2909 Validation Accuracy: 0.499200\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss:     1.2928 Validation Accuracy: 0.501800\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss:     1.2959 Validation Accuracy: 0.489200\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss:     1.2957 Validation Accuracy: 0.499400\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss:     1.2906 Validation Accuracy: 0.495600\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss:     1.2880 Validation Accuracy: 0.500000\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss:     1.2890 Validation Accuracy: 0.502800\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss:     1.2891 Validation Accuracy: 0.494800\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss:     1.2867 Validation Accuracy: 0.503000\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss:     1.2843 Validation Accuracy: 0.499600\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss:     1.2847 Validation Accuracy: 0.499600\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss:     1.2856 Validation Accuracy: 0.502600\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss:     1.2840 Validation Accuracy: 0.498400\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss:     1.2812 Validation Accuracy: 0.502600\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss:     1.2800 Validation Accuracy: 0.503200\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss:     1.2802 Validation Accuracy: 0.500400\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss:     1.2799 Validation Accuracy: 0.504200\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss:     1.2784 Validation Accuracy: 0.502000\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss:     1.2770 Validation Accuracy: 0.503000\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss:     1.2767 Validation Accuracy: 0.506000\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss:     1.2767 Validation Accuracy: 0.500000\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss:     1.2759 Validation Accuracy: 0.504800\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss:     1.2744 Validation Accuracy: 0.499800\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss:     1.2731 Validation Accuracy: 0.504200\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss:     1.2726 Validation Accuracy: 0.504000\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss:     1.2722 Validation Accuracy: 0.503200\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss:     1.2713 Validation Accuracy: 0.504800\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss:     1.2700 Validation Accuracy: 0.503400\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss:     1.2689 Validation Accuracy: 0.504200\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss:     1.2682 Validation Accuracy: 0.506600\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss:     1.2678 Validation Accuracy: 0.504200\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss:     1.2674 Validation Accuracy: 0.506600\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss:     1.2667 Validation Accuracy: 0.504200\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss:     1.2660 Validation Accuracy: 0.508200\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss:     1.2659 Validation Accuracy: 0.505400\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss:     1.2665 Validation Accuracy: 0.506200\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss:     1.2685 Validation Accuracy: 0.503600\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss:     1.2708 Validation Accuracy: 0.503400\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss:     1.2739 Validation Accuracy: 0.498800\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss:     1.2717 Validation Accuracy: 0.503400\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss:     1.2671 Validation Accuracy: 0.501000\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss:     1.2612 Validation Accuracy: 0.509800\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss:     1.2599 Validation Accuracy: 0.504800\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss:     1.2621 Validation Accuracy: 0.507800\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss:     1.2627 Validation Accuracy: 0.506000\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss:     1.2606 Validation Accuracy: 0.504400\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss:     1.2572 Validation Accuracy: 0.510000\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss:     1.2564 Validation Accuracy: 0.505200\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss:     1.2576 Validation Accuracy: 0.511600\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss:     1.2569 Validation Accuracy: 0.506000\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss:     1.2541 Validation Accuracy: 0.509000\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss:     1.2516 Validation Accuracy: 0.511000\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss:     1.2516 Validation Accuracy: 0.507600\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss:     1.2527 Validation Accuracy: 0.511400\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss:     1.2520 Validation Accuracy: 0.507000\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss:     1.2498 Validation Accuracy: 0.509200\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss:     1.2480 Validation Accuracy: 0.508400\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss:     1.2476 Validation Accuracy: 0.510800\n",
      "Epoch 401, CIFAR-10 Batch 1:  Loss:     1.2478 Validation Accuracy: 0.510800\n",
      "Epoch 402, CIFAR-10 Batch 1:  Loss:     1.2473 Validation Accuracy: 0.509000\n",
      "Epoch 403, CIFAR-10 Batch 1:  Loss:     1.2461 Validation Accuracy: 0.510000\n",
      "Epoch 404, CIFAR-10 Batch 1:  Loss:     1.2447 Validation Accuracy: 0.509000\n",
      "Epoch 405, CIFAR-10 Batch 1:  Loss:     1.2440 Validation Accuracy: 0.512800\n",
      "Epoch 406, CIFAR-10 Batch 1:  Loss:     1.2438 Validation Accuracy: 0.510000\n",
      "Epoch 407, CIFAR-10 Batch 1:  Loss:     1.2434 Validation Accuracy: 0.511600\n",
      "Epoch 408, CIFAR-10 Batch 1:  Loss:     1.2425 Validation Accuracy: 0.511000\n",
      "Epoch 409, CIFAR-10 Batch 1:  Loss:     1.2412 Validation Accuracy: 0.513600\n",
      "Epoch 410, CIFAR-10 Batch 1:  Loss:     1.2400 Validation Accuracy: 0.510800\n",
      "Epoch 411, CIFAR-10 Batch 1:  Loss:     1.2393 Validation Accuracy: 0.511800\n",
      "Epoch 412, CIFAR-10 Batch 1:  Loss:     1.2389 Validation Accuracy: 0.512800\n",
      "Epoch 413, CIFAR-10 Batch 1:  Loss:     1.2384 Validation Accuracy: 0.511400\n",
      "Epoch 414, CIFAR-10 Batch 1:  Loss:     1.2377 Validation Accuracy: 0.513200\n",
      "Epoch 415, CIFAR-10 Batch 1:  Loss:     1.2367 Validation Accuracy: 0.514000\n",
      "Epoch 416, CIFAR-10 Batch 1:  Loss:     1.2358 Validation Accuracy: 0.512600\n",
      "Epoch 417, CIFAR-10 Batch 1:  Loss:     1.2349 Validation Accuracy: 0.513400\n",
      "Epoch 418, CIFAR-10 Batch 1:  Loss:     1.2342 Validation Accuracy: 0.513200\n",
      "Epoch 419, CIFAR-10 Batch 1:  Loss:     1.2336 Validation Accuracy: 0.512600\n",
      "Epoch 420, CIFAR-10 Batch 1:  Loss:     1.2330 Validation Accuracy: 0.515600\n",
      "Epoch 421, CIFAR-10 Batch 1:  Loss:     1.2325 Validation Accuracy: 0.512400\n",
      "Epoch 422, CIFAR-10 Batch 1:  Loss:     1.2318 Validation Accuracy: 0.516000\n",
      "Epoch 423, CIFAR-10 Batch 1:  Loss:     1.2312 Validation Accuracy: 0.510800\n",
      "Epoch 424, CIFAR-10 Batch 1:  Loss:     1.2307 Validation Accuracy: 0.514800\n",
      "Epoch 425, CIFAR-10 Batch 1:  Loss:     1.2305 Validation Accuracy: 0.509400\n",
      "Epoch 426, CIFAR-10 Batch 1:  Loss:     1.2312 Validation Accuracy: 0.513800\n",
      "Epoch 427, CIFAR-10 Batch 1:  Loss:     1.2335 Validation Accuracy: 0.506000\n",
      "Epoch 428, CIFAR-10 Batch 1:  Loss:     1.2397 Validation Accuracy: 0.512400\n",
      "Epoch 429, CIFAR-10 Batch 1:  Loss:     1.2486 Validation Accuracy: 0.500800\n",
      "Epoch 430, CIFAR-10 Batch 1:  Loss:     1.2605 Validation Accuracy: 0.508200\n",
      "Epoch 431, CIFAR-10 Batch 1:  Loss:     1.2525 Validation Accuracy: 0.497000\n",
      "Epoch 432, CIFAR-10 Batch 1:  Loss:     1.2367 Validation Accuracy: 0.513600\n",
      "Epoch 433, CIFAR-10 Batch 1:  Loss:     1.2276 Validation Accuracy: 0.509800\n",
      "Epoch 434, CIFAR-10 Batch 1:  Loss:     1.2332 Validation Accuracy: 0.509000\n",
      "Epoch 435, CIFAR-10 Batch 1:  Loss:     1.2404 Validation Accuracy: 0.513000\n",
      "Epoch 436, CIFAR-10 Batch 1:  Loss:     1.2317 Validation Accuracy: 0.503400\n",
      "Epoch 437, CIFAR-10 Batch 1:  Loss:     1.2250 Validation Accuracy: 0.518400\n",
      "Epoch 438, CIFAR-10 Batch 1:  Loss:     1.2276 Validation Accuracy: 0.511800\n",
      "Epoch 439, CIFAR-10 Batch 1:  Loss:     1.2285 Validation Accuracy: 0.510000\n",
      "Epoch 440, CIFAR-10 Batch 1:  Loss:     1.2236 Validation Accuracy: 0.517600\n",
      "Epoch 441, CIFAR-10 Batch 1:  Loss:     1.2204 Validation Accuracy: 0.513200\n",
      "Epoch 442, CIFAR-10 Batch 1:  Loss:     1.2245 Validation Accuracy: 0.511200\n",
      "Epoch 443, CIFAR-10 Batch 1:  Loss:     1.2253 Validation Accuracy: 0.513400\n",
      "Epoch 444, CIFAR-10 Batch 1:  Loss:     1.2184 Validation Accuracy: 0.510800\n",
      "Epoch 445, CIFAR-10 Batch 1:  Loss:     1.2176 Validation Accuracy: 0.513800\n",
      "Epoch 446, CIFAR-10 Batch 1:  Loss:     1.2215 Validation Accuracy: 0.514000\n",
      "Epoch 447, CIFAR-10 Batch 1:  Loss:     1.2188 Validation Accuracy: 0.512200\n",
      "Epoch 448, CIFAR-10 Batch 1:  Loss:     1.2150 Validation Accuracy: 0.516000\n",
      "Epoch 449, CIFAR-10 Batch 1:  Loss:     1.2160 Validation Accuracy: 0.518400\n",
      "Epoch 450, CIFAR-10 Batch 1:  Loss:     1.2164 Validation Accuracy: 0.512400\n",
      "Epoch 451, CIFAR-10 Batch 1:  Loss:     1.2140 Validation Accuracy: 0.517000\n",
      "Epoch 452, CIFAR-10 Batch 1:  Loss:     1.2129 Validation Accuracy: 0.520000\n",
      "Epoch 453, CIFAR-10 Batch 1:  Loss:     1.2136 Validation Accuracy: 0.511800\n",
      "Epoch 454, CIFAR-10 Batch 1:  Loss:     1.2126 Validation Accuracy: 0.519600\n",
      "Epoch 455, CIFAR-10 Batch 1:  Loss:     1.2107 Validation Accuracy: 0.517200\n",
      "Epoch 456, CIFAR-10 Batch 1:  Loss:     1.2106 Validation Accuracy: 0.514400\n",
      "Epoch 457, CIFAR-10 Batch 1:  Loss:     1.2108 Validation Accuracy: 0.520400\n",
      "Epoch 458, CIFAR-10 Batch 1:  Loss:     1.2096 Validation Accuracy: 0.513200\n",
      "Epoch 459, CIFAR-10 Batch 1:  Loss:     1.2083 Validation Accuracy: 0.516600\n",
      "Epoch 460, CIFAR-10 Batch 1:  Loss:     1.2078 Validation Accuracy: 0.518600\n",
      "Epoch 461, CIFAR-10 Batch 1:  Loss:     1.2074 Validation Accuracy: 0.514000\n",
      "Epoch 462, CIFAR-10 Batch 1:  Loss:     1.2067 Validation Accuracy: 0.520200\n",
      "Epoch 463, CIFAR-10 Batch 1:  Loss:     1.2060 Validation Accuracy: 0.515400\n",
      "Epoch 464, CIFAR-10 Batch 1:  Loss:     1.2052 Validation Accuracy: 0.517600\n",
      "Epoch 465, CIFAR-10 Batch 1:  Loss:     1.2047 Validation Accuracy: 0.518600\n",
      "Epoch 466, CIFAR-10 Batch 1:  Loss:     1.2041 Validation Accuracy: 0.519400\n",
      "Epoch 467, CIFAR-10 Batch 1:  Loss:     1.2033 Validation Accuracy: 0.517800\n",
      "Epoch 468, CIFAR-10 Batch 1:  Loss:     1.2024 Validation Accuracy: 0.517600\n",
      "Epoch 469, CIFAR-10 Batch 1:  Loss:     1.2020 Validation Accuracy: 0.519400\n",
      "Epoch 470, CIFAR-10 Batch 1:  Loss:     1.2016 Validation Accuracy: 0.518800\n",
      "Epoch 471, CIFAR-10 Batch 1:  Loss:     1.2009 Validation Accuracy: 0.520800\n",
      "Epoch 472, CIFAR-10 Batch 1:  Loss:     1.2000 Validation Accuracy: 0.516600\n",
      "Epoch 473, CIFAR-10 Batch 1:  Loss:     1.1994 Validation Accuracy: 0.521400\n",
      "Epoch 474, CIFAR-10 Batch 1:  Loss:     1.1990 Validation Accuracy: 0.518400\n",
      "Epoch 475, CIFAR-10 Batch 1:  Loss:     1.1983 Validation Accuracy: 0.519400\n",
      "Epoch 476, CIFAR-10 Batch 1:  Loss:     1.1974 Validation Accuracy: 0.520000\n",
      "Epoch 477, CIFAR-10 Batch 1:  Loss:     1.1967 Validation Accuracy: 0.520600\n",
      "Epoch 478, CIFAR-10 Batch 1:  Loss:     1.1962 Validation Accuracy: 0.519200\n",
      "Epoch 479, CIFAR-10 Batch 1:  Loss:     1.1957 Validation Accuracy: 0.519400\n",
      "Epoch 480, CIFAR-10 Batch 1:  Loss:     1.1950 Validation Accuracy: 0.521000\n",
      "Epoch 481, CIFAR-10 Batch 1:  Loss:     1.1943 Validation Accuracy: 0.518400\n",
      "Epoch 482, CIFAR-10 Batch 1:  Loss:     1.1937 Validation Accuracy: 0.521800\n",
      "Epoch 483, CIFAR-10 Batch 1:  Loss:     1.1931 Validation Accuracy: 0.518600\n",
      "Epoch 484, CIFAR-10 Batch 1:  Loss:     1.1926 Validation Accuracy: 0.522600\n",
      "Epoch 485, CIFAR-10 Batch 1:  Loss:     1.1920 Validation Accuracy: 0.519000\n",
      "Epoch 486, CIFAR-10 Batch 1:  Loss:     1.1915 Validation Accuracy: 0.521400\n",
      "Epoch 487, CIFAR-10 Batch 1:  Loss:     1.1911 Validation Accuracy: 0.517800\n",
      "Epoch 488, CIFAR-10 Batch 1:  Loss:     1.1909 Validation Accuracy: 0.524600\n",
      "Epoch 489, CIFAR-10 Batch 1:  Loss:     1.1912 Validation Accuracy: 0.518200\n",
      "Epoch 490, CIFAR-10 Batch 1:  Loss:     1.1921 Validation Accuracy: 0.525400\n",
      "Epoch 491, CIFAR-10 Batch 1:  Loss:     1.1945 Validation Accuracy: 0.513600\n",
      "Epoch 492, CIFAR-10 Batch 1:  Loss:     1.1981 Validation Accuracy: 0.522800\n",
      "Epoch 493, CIFAR-10 Batch 1:  Loss:     1.2039 Validation Accuracy: 0.511600\n",
      "Epoch 494, CIFAR-10 Batch 1:  Loss:     1.2048 Validation Accuracy: 0.514000\n",
      "Epoch 495, CIFAR-10 Batch 1:  Loss:     1.2012 Validation Accuracy: 0.514800\n",
      "Epoch 496, CIFAR-10 Batch 1:  Loss:     1.1904 Validation Accuracy: 0.522000\n",
      "Epoch 497, CIFAR-10 Batch 1:  Loss:     1.1848 Validation Accuracy: 0.522000\n",
      "Epoch 498, CIFAR-10 Batch 1:  Loss:     1.1878 Validation Accuracy: 0.516000\n",
      "Epoch 499, CIFAR-10 Batch 1:  Loss:     1.1927 Validation Accuracy: 0.522400\n",
      "Epoch 500, CIFAR-10 Batch 1:  Loss:     1.1930 Validation Accuracy: 0.517400\n",
      "Epoch 501, CIFAR-10 Batch 1:  Loss:     1.1864 Validation Accuracy: 0.523400\n",
      "Epoch 502, CIFAR-10 Batch 1:  Loss:     1.1818 Validation Accuracy: 0.520800\n",
      "Epoch 503, CIFAR-10 Batch 1:  Loss:     1.1833 Validation Accuracy: 0.521200\n",
      "Epoch 504, CIFAR-10 Batch 1:  Loss:     1.1861 Validation Accuracy: 0.523200\n",
      "Epoch 505, CIFAR-10 Batch 1:  Loss:     1.1847 Validation Accuracy: 0.520400\n",
      "Epoch 506, CIFAR-10 Batch 1:  Loss:     1.1804 Validation Accuracy: 0.524400\n",
      "Epoch 507, CIFAR-10 Batch 1:  Loss:     1.1791 Validation Accuracy: 0.523600\n",
      "Epoch 508, CIFAR-10 Batch 1:  Loss:     1.1811 Validation Accuracy: 0.522200\n",
      "Epoch 509, CIFAR-10 Batch 1:  Loss:     1.1815 Validation Accuracy: 0.523800\n",
      "Epoch 510, CIFAR-10 Batch 1:  Loss:     1.1790 Validation Accuracy: 0.522600\n",
      "Epoch 511, CIFAR-10 Batch 1:  Loss:     1.1766 Validation Accuracy: 0.522400\n",
      "Epoch 512, CIFAR-10 Batch 1:  Loss:     1.1767 Validation Accuracy: 0.523200\n",
      "Epoch 513, CIFAR-10 Batch 1:  Loss:     1.1777 Validation Accuracy: 0.522800\n",
      "Epoch 514, CIFAR-10 Batch 1:  Loss:     1.1769 Validation Accuracy: 0.524200\n",
      "Epoch 515, CIFAR-10 Batch 1:  Loss:     1.1749 Validation Accuracy: 0.522400\n",
      "Epoch 516, CIFAR-10 Batch 1:  Loss:     1.1737 Validation Accuracy: 0.522800\n",
      "Epoch 517, CIFAR-10 Batch 1:  Loss:     1.1739 Validation Accuracy: 0.525000\n",
      "Epoch 518, CIFAR-10 Batch 1:  Loss:     1.1741 Validation Accuracy: 0.523200\n",
      "Epoch 519, CIFAR-10 Batch 1:  Loss:     1.1731 Validation Accuracy: 0.524400\n",
      "Epoch 520, CIFAR-10 Batch 1:  Loss:     1.1717 Validation Accuracy: 0.522600\n",
      "Epoch 521, CIFAR-10 Batch 1:  Loss:     1.1708 Validation Accuracy: 0.522200\n",
      "Epoch 522, CIFAR-10 Batch 1:  Loss:     1.1707 Validation Accuracy: 0.523400\n",
      "Epoch 523, CIFAR-10 Batch 1:  Loss:     1.1706 Validation Accuracy: 0.522600\n",
      "Epoch 524, CIFAR-10 Batch 1:  Loss:     1.1699 Validation Accuracy: 0.524800\n",
      "Epoch 525, CIFAR-10 Batch 1:  Loss:     1.1688 Validation Accuracy: 0.523400\n",
      "Epoch 526, CIFAR-10 Batch 1:  Loss:     1.1679 Validation Accuracy: 0.523600\n",
      "Epoch 527, CIFAR-10 Batch 1:  Loss:     1.1675 Validation Accuracy: 0.525200\n",
      "Epoch 528, CIFAR-10 Batch 1:  Loss:     1.1673 Validation Accuracy: 0.522600\n",
      "Epoch 529, CIFAR-10 Batch 1:  Loss:     1.1668 Validation Accuracy: 0.523200\n",
      "Epoch 530, CIFAR-10 Batch 1:  Loss:     1.1660 Validation Accuracy: 0.524400\n",
      "Epoch 531, CIFAR-10 Batch 1:  Loss:     1.1651 Validation Accuracy: 0.524800\n",
      "Epoch 532, CIFAR-10 Batch 1:  Loss:     1.1644 Validation Accuracy: 0.524000\n",
      "Epoch 533, CIFAR-10 Batch 1:  Loss:     1.1639 Validation Accuracy: 0.525600\n",
      "Epoch 534, CIFAR-10 Batch 1:  Loss:     1.1635 Validation Accuracy: 0.524600\n",
      "Epoch 535, CIFAR-10 Batch 1:  Loss:     1.1630 Validation Accuracy: 0.525800\n",
      "Epoch 536, CIFAR-10 Batch 1:  Loss:     1.1624 Validation Accuracy: 0.524400\n",
      "Epoch 537, CIFAR-10 Batch 1:  Loss:     1.1617 Validation Accuracy: 0.526200\n",
      "Epoch 538, CIFAR-10 Batch 1:  Loss:     1.1610 Validation Accuracy: 0.524400\n",
      "Epoch 539, CIFAR-10 Batch 1:  Loss:     1.1605 Validation Accuracy: 0.525600\n",
      "Epoch 540, CIFAR-10 Batch 1:  Loss:     1.1601 Validation Accuracy: 0.525400\n",
      "Epoch 541, CIFAR-10 Batch 1:  Loss:     1.1599 Validation Accuracy: 0.527000\n",
      "Epoch 542, CIFAR-10 Batch 1:  Loss:     1.1600 Validation Accuracy: 0.524600\n",
      "Epoch 543, CIFAR-10 Batch 1:  Loss:     1.1607 Validation Accuracy: 0.528200\n",
      "Epoch 544, CIFAR-10 Batch 1:  Loss:     1.1626 Validation Accuracy: 0.519400\n",
      "Epoch 545, CIFAR-10 Batch 1:  Loss:     1.1671 Validation Accuracy: 0.525200\n",
      "Epoch 546, CIFAR-10 Batch 1:  Loss:     1.1738 Validation Accuracy: 0.519200\n",
      "Epoch 547, CIFAR-10 Batch 1:  Loss:     1.1834 Validation Accuracy: 0.524600\n",
      "Epoch 548, CIFAR-10 Batch 1:  Loss:     1.1814 Validation Accuracy: 0.516000\n",
      "Epoch 549, CIFAR-10 Batch 1:  Loss:     1.1711 Validation Accuracy: 0.527600\n",
      "Epoch 550, CIFAR-10 Batch 1:  Loss:     1.1572 Validation Accuracy: 0.521200\n",
      "Epoch 551, CIFAR-10 Batch 1:  Loss:     1.1561 Validation Accuracy: 0.522800\n",
      "Epoch 552, CIFAR-10 Batch 1:  Loss:     1.1647 Validation Accuracy: 0.526400\n",
      "Epoch 553, CIFAR-10 Batch 1:  Loss:     1.1665 Validation Accuracy: 0.518800\n",
      "Epoch 554, CIFAR-10 Batch 1:  Loss:     1.1595 Validation Accuracy: 0.528200\n",
      "Epoch 555, CIFAR-10 Batch 1:  Loss:     1.1520 Validation Accuracy: 0.526200\n",
      "Epoch 556, CIFAR-10 Batch 1:  Loss:     1.1542 Validation Accuracy: 0.522800\n",
      "Epoch 557, CIFAR-10 Batch 1:  Loss:     1.1596 Validation Accuracy: 0.527800\n",
      "Epoch 558, CIFAR-10 Batch 1:  Loss:     1.1564 Validation Accuracy: 0.520800\n",
      "Epoch 559, CIFAR-10 Batch 1:  Loss:     1.1504 Validation Accuracy: 0.529800\n",
      "Epoch 560, CIFAR-10 Batch 1:  Loss:     1.1497 Validation Accuracy: 0.530000\n",
      "Epoch 561, CIFAR-10 Batch 1:  Loss:     1.1530 Validation Accuracy: 0.521200\n",
      "Epoch 562, CIFAR-10 Batch 1:  Loss:     1.1530 Validation Accuracy: 0.529400\n",
      "Epoch 563, CIFAR-10 Batch 1:  Loss:     1.1489 Validation Accuracy: 0.525200\n",
      "Epoch 564, CIFAR-10 Batch 1:  Loss:     1.1470 Validation Accuracy: 0.526400\n",
      "Epoch 565, CIFAR-10 Batch 1:  Loss:     1.1487 Validation Accuracy: 0.527200\n",
      "Epoch 566, CIFAR-10 Batch 1:  Loss:     1.1491 Validation Accuracy: 0.523400\n",
      "Epoch 567, CIFAR-10 Batch 1:  Loss:     1.1465 Validation Accuracy: 0.530200\n",
      "Epoch 568, CIFAR-10 Batch 1:  Loss:     1.1446 Validation Accuracy: 0.528200\n",
      "Epoch 569, CIFAR-10 Batch 1:  Loss:     1.1452 Validation Accuracy: 0.526600\n",
      "Epoch 570, CIFAR-10 Batch 1:  Loss:     1.1459 Validation Accuracy: 0.528400\n",
      "Epoch 571, CIFAR-10 Batch 1:  Loss:     1.1444 Validation Accuracy: 0.525200\n",
      "Epoch 572, CIFAR-10 Batch 1:  Loss:     1.1425 Validation Accuracy: 0.528600\n",
      "Epoch 573, CIFAR-10 Batch 1:  Loss:     1.1423 Validation Accuracy: 0.530400\n",
      "Epoch 574, CIFAR-10 Batch 1:  Loss:     1.1427 Validation Accuracy: 0.525800\n",
      "Epoch 575, CIFAR-10 Batch 1:  Loss:     1.1421 Validation Accuracy: 0.531400\n",
      "Epoch 576, CIFAR-10 Batch 1:  Loss:     1.1405 Validation Accuracy: 0.526000\n",
      "Epoch 577, CIFAR-10 Batch 1:  Loss:     1.1397 Validation Accuracy: 0.529600\n",
      "Epoch 578, CIFAR-10 Batch 1:  Loss:     1.1398 Validation Accuracy: 0.532400\n",
      "Epoch 579, CIFAR-10 Batch 1:  Loss:     1.1396 Validation Accuracy: 0.526200\n",
      "Epoch 580, CIFAR-10 Batch 1:  Loss:     1.1387 Validation Accuracy: 0.532200\n",
      "Epoch 581, CIFAR-10 Batch 1:  Loss:     1.1376 Validation Accuracy: 0.529000\n",
      "Epoch 582, CIFAR-10 Batch 1:  Loss:     1.1371 Validation Accuracy: 0.528200\n",
      "Epoch 583, CIFAR-10 Batch 1:  Loss:     1.1370 Validation Accuracy: 0.529200\n",
      "Epoch 584, CIFAR-10 Batch 1:  Loss:     1.1366 Validation Accuracy: 0.527400\n",
      "Epoch 585, CIFAR-10 Batch 1:  Loss:     1.1358 Validation Accuracy: 0.530200\n",
      "Epoch 586, CIFAR-10 Batch 1:  Loss:     1.1351 Validation Accuracy: 0.528600\n",
      "Epoch 587, CIFAR-10 Batch 1:  Loss:     1.1347 Validation Accuracy: 0.529600\n",
      "Epoch 588, CIFAR-10 Batch 1:  Loss:     1.1347 Validation Accuracy: 0.531200\n",
      "Epoch 589, CIFAR-10 Batch 1:  Loss:     1.1347 Validation Accuracy: 0.528200\n",
      "Epoch 590, CIFAR-10 Batch 1:  Loss:     1.1348 Validation Accuracy: 0.531600\n",
      "Epoch 591, CIFAR-10 Batch 1:  Loss:     1.1355 Validation Accuracy: 0.529000\n",
      "Epoch 592, CIFAR-10 Batch 1:  Loss:     1.1373 Validation Accuracy: 0.530000\n",
      "Epoch 593, CIFAR-10 Batch 1:  Loss:     1.1407 Validation Accuracy: 0.527200\n",
      "Epoch 594, CIFAR-10 Batch 1:  Loss:     1.1449 Validation Accuracy: 0.524200\n",
      "Epoch 595, CIFAR-10 Batch 1:  Loss:     1.1482 Validation Accuracy: 0.523400\n",
      "Epoch 596, CIFAR-10 Batch 1:  Loss:     1.1463 Validation Accuracy: 0.523200\n",
      "Epoch 597, CIFAR-10 Batch 1:  Loss:     1.1389 Validation Accuracy: 0.525400\n",
      "Epoch 598, CIFAR-10 Batch 1:  Loss:     1.1306 Validation Accuracy: 0.529200\n",
      "Epoch 599, CIFAR-10 Batch 1:  Loss:     1.1280 Validation Accuracy: 0.531800\n",
      "Epoch 600, CIFAR-10 Batch 1:  Loss:     1.1314 Validation Accuracy: 0.529200\n",
      "Epoch 601, CIFAR-10 Batch 1:  Loss:     1.1353 Validation Accuracy: 0.527400\n",
      "Epoch 602, CIFAR-10 Batch 1:  Loss:     1.1346 Validation Accuracy: 0.525400\n",
      "Epoch 603, CIFAR-10 Batch 1:  Loss:     1.1295 Validation Accuracy: 0.531000\n",
      "Epoch 604, CIFAR-10 Batch 1:  Loss:     1.1255 Validation Accuracy: 0.533000\n",
      "Epoch 605, CIFAR-10 Batch 1:  Loss:     1.1260 Validation Accuracy: 0.530800\n",
      "Epoch 606, CIFAR-10 Batch 1:  Loss:     1.1284 Validation Accuracy: 0.529600\n",
      "Epoch 607, CIFAR-10 Batch 1:  Loss:     1.1286 Validation Accuracy: 0.530000\n",
      "Epoch 608, CIFAR-10 Batch 1:  Loss:     1.1257 Validation Accuracy: 0.530600\n",
      "Epoch 609, CIFAR-10 Batch 1:  Loss:     1.1231 Validation Accuracy: 0.533400\n",
      "Epoch 610, CIFAR-10 Batch 1:  Loss:     1.1230 Validation Accuracy: 0.531400\n",
      "Epoch 611, CIFAR-10 Batch 1:  Loss:     1.1240 Validation Accuracy: 0.529800\n",
      "Epoch 612, CIFAR-10 Batch 1:  Loss:     1.1240 Validation Accuracy: 0.530600\n",
      "Epoch 613, CIFAR-10 Batch 1:  Loss:     1.1223 Validation Accuracy: 0.531400\n",
      "Epoch 614, CIFAR-10 Batch 1:  Loss:     1.1207 Validation Accuracy: 0.534000\n",
      "Epoch 615, CIFAR-10 Batch 1:  Loss:     1.1202 Validation Accuracy: 0.531400\n",
      "Epoch 616, CIFAR-10 Batch 1:  Loss:     1.1204 Validation Accuracy: 0.531800\n",
      "Epoch 617, CIFAR-10 Batch 1:  Loss:     1.1202 Validation Accuracy: 0.531000\n",
      "Epoch 618, CIFAR-10 Batch 1:  Loss:     1.1191 Validation Accuracy: 0.531000\n",
      "Epoch 619, CIFAR-10 Batch 1:  Loss:     1.1180 Validation Accuracy: 0.533400\n",
      "Epoch 620, CIFAR-10 Batch 1:  Loss:     1.1174 Validation Accuracy: 0.531200\n",
      "Epoch 621, CIFAR-10 Batch 1:  Loss:     1.1173 Validation Accuracy: 0.532400\n",
      "Epoch 622, CIFAR-10 Batch 1:  Loss:     1.1171 Validation Accuracy: 0.532000\n",
      "Epoch 623, CIFAR-10 Batch 1:  Loss:     1.1164 Validation Accuracy: 0.532600\n",
      "Epoch 624, CIFAR-10 Batch 1:  Loss:     1.1153 Validation Accuracy: 0.533000\n",
      "Epoch 625, CIFAR-10 Batch 1:  Loss:     1.1145 Validation Accuracy: 0.532400\n",
      "Epoch 626, CIFAR-10 Batch 1:  Loss:     1.1141 Validation Accuracy: 0.532200\n",
      "Epoch 627, CIFAR-10 Batch 1:  Loss:     1.1139 Validation Accuracy: 0.533800\n",
      "Epoch 628, CIFAR-10 Batch 1:  Loss:     1.1136 Validation Accuracy: 0.532200\n",
      "Epoch 629, CIFAR-10 Batch 1:  Loss:     1.1130 Validation Accuracy: 0.533600\n",
      "Epoch 630, CIFAR-10 Batch 1:  Loss:     1.1121 Validation Accuracy: 0.532400\n",
      "Epoch 631, CIFAR-10 Batch 1:  Loss:     1.1114 Validation Accuracy: 0.532200\n",
      "Epoch 632, CIFAR-10 Batch 1:  Loss:     1.1108 Validation Accuracy: 0.532000\n",
      "Epoch 633, CIFAR-10 Batch 1:  Loss:     1.1104 Validation Accuracy: 0.531800\n",
      "Epoch 634, CIFAR-10 Batch 1:  Loss:     1.1101 Validation Accuracy: 0.532200\n",
      "Epoch 635, CIFAR-10 Batch 1:  Loss:     1.1096 Validation Accuracy: 0.532600\n",
      "Epoch 636, CIFAR-10 Batch 1:  Loss:     1.1091 Validation Accuracy: 0.533000\n",
      "Epoch 637, CIFAR-10 Batch 1:  Loss:     1.1084 Validation Accuracy: 0.532200\n",
      "Epoch 638, CIFAR-10 Batch 1:  Loss:     1.1077 Validation Accuracy: 0.532800\n",
      "Epoch 639, CIFAR-10 Batch 1:  Loss:     1.1072 Validation Accuracy: 0.531200\n",
      "Epoch 640, CIFAR-10 Batch 1:  Loss:     1.1067 Validation Accuracy: 0.531400\n",
      "Epoch 641, CIFAR-10 Batch 1:  Loss:     1.1063 Validation Accuracy: 0.531200\n",
      "Epoch 642, CIFAR-10 Batch 1:  Loss:     1.1061 Validation Accuracy: 0.533000\n",
      "Epoch 643, CIFAR-10 Batch 1:  Loss:     1.1059 Validation Accuracy: 0.533600\n",
      "Epoch 644, CIFAR-10 Batch 1:  Loss:     1.1059 Validation Accuracy: 0.533600\n",
      "Epoch 645, CIFAR-10 Batch 1:  Loss:     1.1063 Validation Accuracy: 0.533200\n",
      "Epoch 646, CIFAR-10 Batch 1:  Loss:     1.1072 Validation Accuracy: 0.535800\n",
      "Epoch 647, CIFAR-10 Batch 1:  Loss:     1.1089 Validation Accuracy: 0.534600\n",
      "Epoch 648, CIFAR-10 Batch 1:  Loss:     1.1105 Validation Accuracy: 0.535000\n",
      "Epoch 649, CIFAR-10 Batch 1:  Loss:     1.1121 Validation Accuracy: 0.530200\n",
      "Epoch 650, CIFAR-10 Batch 1:  Loss:     1.1106 Validation Accuracy: 0.531000\n",
      "Epoch 651, CIFAR-10 Batch 1:  Loss:     1.1098 Validation Accuracy: 0.530400\n",
      "Epoch 652, CIFAR-10 Batch 1:  Loss:     1.1078 Validation Accuracy: 0.531800\n",
      "Epoch 653, CIFAR-10 Batch 1:  Loss:     1.1061 Validation Accuracy: 0.532600\n",
      "Epoch 654, CIFAR-10 Batch 1:  Loss:     1.1037 Validation Accuracy: 0.529600\n",
      "Epoch 655, CIFAR-10 Batch 1:  Loss:     1.1006 Validation Accuracy: 0.534800\n",
      "Epoch 656, CIFAR-10 Batch 1:  Loss:     1.0990 Validation Accuracy: 0.535600\n",
      "Epoch 657, CIFAR-10 Batch 1:  Loss:     1.0999 Validation Accuracy: 0.533600\n",
      "Epoch 658, CIFAR-10 Batch 1:  Loss:     1.1018 Validation Accuracy: 0.533800\n",
      "Epoch 659, CIFAR-10 Batch 1:  Loss:     1.1023 Validation Accuracy: 0.531000\n",
      "Epoch 660, CIFAR-10 Batch 1:  Loss:     1.1004 Validation Accuracy: 0.534200\n",
      "Epoch 661, CIFAR-10 Batch 1:  Loss:     1.0975 Validation Accuracy: 0.535400\n",
      "Epoch 662, CIFAR-10 Batch 1:  Loss:     1.0957 Validation Accuracy: 0.536000\n",
      "Epoch 663, CIFAR-10 Batch 1:  Loss:     1.0954 Validation Accuracy: 0.535400\n",
      "Epoch 664, CIFAR-10 Batch 1:  Loss:     1.0958 Validation Accuracy: 0.533600\n",
      "Epoch 665, CIFAR-10 Batch 1:  Loss:     1.0957 Validation Accuracy: 0.536000\n",
      "Epoch 666, CIFAR-10 Batch 1:  Loss:     1.0950 Validation Accuracy: 0.535400\n",
      "Epoch 667, CIFAR-10 Batch 1:  Loss:     1.0943 Validation Accuracy: 0.537400\n",
      "Epoch 668, CIFAR-10 Batch 1:  Loss:     1.0938 Validation Accuracy: 0.536200\n",
      "Epoch 669, CIFAR-10 Batch 1:  Loss:     1.0933 Validation Accuracy: 0.537200\n",
      "Epoch 670, CIFAR-10 Batch 1:  Loss:     1.0923 Validation Accuracy: 0.534800\n",
      "Epoch 671, CIFAR-10 Batch 1:  Loss:     1.0912 Validation Accuracy: 0.536800\n",
      "Epoch 672, CIFAR-10 Batch 1:  Loss:     1.0904 Validation Accuracy: 0.535600\n",
      "Epoch 673, CIFAR-10 Batch 1:  Loss:     1.0902 Validation Accuracy: 0.536400\n",
      "Epoch 674, CIFAR-10 Batch 1:  Loss:     1.0907 Validation Accuracy: 0.536000\n",
      "Epoch 675, CIFAR-10 Batch 1:  Loss:     1.0914 Validation Accuracy: 0.535200\n",
      "Epoch 676, CIFAR-10 Batch 1:  Loss:     1.0930 Validation Accuracy: 0.536400\n",
      "Epoch 677, CIFAR-10 Batch 1:  Loss:     1.0964 Validation Accuracy: 0.531600\n",
      "Epoch 678, CIFAR-10 Batch 1:  Loss:     1.1051 Validation Accuracy: 0.535800\n",
      "Epoch 679, CIFAR-10 Batch 1:  Loss:     1.1165 Validation Accuracy: 0.525600\n",
      "Epoch 680, CIFAR-10 Batch 1:  Loss:     1.1318 Validation Accuracy: 0.529600\n",
      "Epoch 681, CIFAR-10 Batch 1:  Loss:     1.1228 Validation Accuracy: 0.523200\n",
      "Epoch 682, CIFAR-10 Batch 1:  Loss:     1.1029 Validation Accuracy: 0.531600\n",
      "Epoch 683, CIFAR-10 Batch 1:  Loss:     1.0904 Validation Accuracy: 0.537200\n",
      "Epoch 684, CIFAR-10 Batch 1:  Loss:     1.0972 Validation Accuracy: 0.531400\n",
      "Epoch 685, CIFAR-10 Batch 1:  Loss:     1.1086 Validation Accuracy: 0.531800\n",
      "Epoch 686, CIFAR-10 Batch 1:  Loss:     1.0994 Validation Accuracy: 0.528400\n",
      "Epoch 687, CIFAR-10 Batch 1:  Loss:     1.0867 Validation Accuracy: 0.535800\n",
      "Epoch 688, CIFAR-10 Batch 1:  Loss:     1.0880 Validation Accuracy: 0.537600\n",
      "Epoch 689, CIFAR-10 Batch 1:  Loss:     1.0946 Validation Accuracy: 0.534400\n",
      "Epoch 690, CIFAR-10 Batch 1:  Loss:     1.0921 Validation Accuracy: 0.536200\n",
      "Epoch 691, CIFAR-10 Batch 1:  Loss:     1.0844 Validation Accuracy: 0.539000\n",
      "Epoch 692, CIFAR-10 Batch 1:  Loss:     1.0848 Validation Accuracy: 0.536200\n",
      "Epoch 693, CIFAR-10 Batch 1:  Loss:     1.0887 Validation Accuracy: 0.538800\n",
      "Epoch 694, CIFAR-10 Batch 1:  Loss:     1.0857 Validation Accuracy: 0.536800\n",
      "Epoch 695, CIFAR-10 Batch 1:  Loss:     1.0818 Validation Accuracy: 0.536800\n",
      "Epoch 696, CIFAR-10 Batch 1:  Loss:     1.0829 Validation Accuracy: 0.539200\n",
      "Epoch 697, CIFAR-10 Batch 1:  Loss:     1.0837 Validation Accuracy: 0.537400\n",
      "Epoch 698, CIFAR-10 Batch 1:  Loss:     1.0810 Validation Accuracy: 0.537600\n",
      "Epoch 699, CIFAR-10 Batch 1:  Loss:     1.0792 Validation Accuracy: 0.539600\n",
      "Epoch 700, CIFAR-10 Batch 1:  Loss:     1.0804 Validation Accuracy: 0.536600\n",
      "Epoch 701, CIFAR-10 Batch 1:  Loss:     1.0805 Validation Accuracy: 0.538600\n",
      "Epoch 702, CIFAR-10 Batch 1:  Loss:     1.0779 Validation Accuracy: 0.536800\n",
      "Epoch 703, CIFAR-10 Batch 1:  Loss:     1.0770 Validation Accuracy: 0.539200\n",
      "Epoch 704, CIFAR-10 Batch 1:  Loss:     1.0779 Validation Accuracy: 0.538200\n",
      "Epoch 705, CIFAR-10 Batch 1:  Loss:     1.0771 Validation Accuracy: 0.537400\n",
      "Epoch 706, CIFAR-10 Batch 1:  Loss:     1.0750 Validation Accuracy: 0.539000\n",
      "Epoch 707, CIFAR-10 Batch 1:  Loss:     1.0746 Validation Accuracy: 0.539000\n",
      "Epoch 708, CIFAR-10 Batch 1:  Loss:     1.0754 Validation Accuracy: 0.537000\n",
      "Epoch 709, CIFAR-10 Batch 1:  Loss:     1.0748 Validation Accuracy: 0.539800\n",
      "Epoch 710, CIFAR-10 Batch 1:  Loss:     1.0730 Validation Accuracy: 0.539000\n",
      "Epoch 711, CIFAR-10 Batch 1:  Loss:     1.0725 Validation Accuracy: 0.540200\n",
      "Epoch 712, CIFAR-10 Batch 1:  Loss:     1.0730 Validation Accuracy: 0.541200\n",
      "Epoch 713, CIFAR-10 Batch 1:  Loss:     1.0724 Validation Accuracy: 0.537200\n",
      "Epoch 714, CIFAR-10 Batch 1:  Loss:     1.0710 Validation Accuracy: 0.540200\n",
      "Epoch 715, CIFAR-10 Batch 1:  Loss:     1.0704 Validation Accuracy: 0.540400\n",
      "Epoch 716, CIFAR-10 Batch 1:  Loss:     1.0705 Validation Accuracy: 0.538600\n",
      "Epoch 717, CIFAR-10 Batch 1:  Loss:     1.0703 Validation Accuracy: 0.540000\n",
      "Epoch 718, CIFAR-10 Batch 1:  Loss:     1.0693 Validation Accuracy: 0.541000\n",
      "Epoch 719, CIFAR-10 Batch 1:  Loss:     1.0684 Validation Accuracy: 0.542800\n",
      "Epoch 720, CIFAR-10 Batch 1:  Loss:     1.0682 Validation Accuracy: 0.541400\n",
      "Epoch 721, CIFAR-10 Batch 1:  Loss:     1.0681 Validation Accuracy: 0.540200\n",
      "Epoch 722, CIFAR-10 Batch 1:  Loss:     1.0674 Validation Accuracy: 0.542000\n",
      "Epoch 723, CIFAR-10 Batch 1:  Loss:     1.0666 Validation Accuracy: 0.541800\n",
      "Epoch 724, CIFAR-10 Batch 1:  Loss:     1.0662 Validation Accuracy: 0.542200\n",
      "Epoch 725, CIFAR-10 Batch 1:  Loss:     1.0659 Validation Accuracy: 0.541000\n",
      "Epoch 726, CIFAR-10 Batch 1:  Loss:     1.0655 Validation Accuracy: 0.541800\n",
      "Epoch 727, CIFAR-10 Batch 1:  Loss:     1.0649 Validation Accuracy: 0.541600\n",
      "Epoch 728, CIFAR-10 Batch 1:  Loss:     1.0644 Validation Accuracy: 0.542600\n",
      "Epoch 729, CIFAR-10 Batch 1:  Loss:     1.0641 Validation Accuracy: 0.541000\n",
      "Epoch 730, CIFAR-10 Batch 1:  Loss:     1.0640 Validation Accuracy: 0.539800\n",
      "Epoch 731, CIFAR-10 Batch 1:  Loss:     1.0640 Validation Accuracy: 0.537600\n",
      "Epoch 732, CIFAR-10 Batch 1:  Loss:     1.0645 Validation Accuracy: 0.540200\n",
      "Epoch 733, CIFAR-10 Batch 1:  Loss:     1.0660 Validation Accuracy: 0.537600\n",
      "Epoch 734, CIFAR-10 Batch 1:  Loss:     1.0699 Validation Accuracy: 0.538800\n",
      "Epoch 735, CIFAR-10 Batch 1:  Loss:     1.0758 Validation Accuracy: 0.538400\n",
      "Epoch 736, CIFAR-10 Batch 1:  Loss:     1.0866 Validation Accuracy: 0.531200\n",
      "Epoch 737, CIFAR-10 Batch 1:  Loss:     1.0911 Validation Accuracy: 0.531800\n",
      "Epoch 738, CIFAR-10 Batch 1:  Loss:     1.0918 Validation Accuracy: 0.530600\n",
      "Epoch 739, CIFAR-10 Batch 1:  Loss:     1.0745 Validation Accuracy: 0.536400\n",
      "Epoch 740, CIFAR-10 Batch 1:  Loss:     1.0613 Validation Accuracy: 0.540600\n",
      "Epoch 741, CIFAR-10 Batch 1:  Loss:     1.0610 Validation Accuracy: 0.542000\n",
      "Epoch 742, CIFAR-10 Batch 1:  Loss:     1.0690 Validation Accuracy: 0.537200\n",
      "Epoch 743, CIFAR-10 Batch 1:  Loss:     1.0738 Validation Accuracy: 0.534800\n",
      "Epoch 744, CIFAR-10 Batch 1:  Loss:     1.0657 Validation Accuracy: 0.540000\n",
      "Epoch 745, CIFAR-10 Batch 1:  Loss:     1.0580 Validation Accuracy: 0.540000\n",
      "Epoch 746, CIFAR-10 Batch 1:  Loss:     1.0592 Validation Accuracy: 0.542400\n",
      "Epoch 747, CIFAR-10 Batch 1:  Loss:     1.0634 Validation Accuracy: 0.537800\n",
      "Epoch 748, CIFAR-10 Batch 1:  Loss:     1.0627 Validation Accuracy: 0.538800\n",
      "Epoch 749, CIFAR-10 Batch 1:  Loss:     1.0573 Validation Accuracy: 0.539800\n",
      "Epoch 750, CIFAR-10 Batch 1:  Loss:     1.0557 Validation Accuracy: 0.542600\n",
      "Epoch 751, CIFAR-10 Batch 1:  Loss:     1.0582 Validation Accuracy: 0.542600\n",
      "Epoch 752, CIFAR-10 Batch 1:  Loss:     1.0579 Validation Accuracy: 0.543000\n",
      "Epoch 753, CIFAR-10 Batch 1:  Loss:     1.0554 Validation Accuracy: 0.542200\n",
      "Epoch 754, CIFAR-10 Batch 1:  Loss:     1.0537 Validation Accuracy: 0.544000\n",
      "Epoch 755, CIFAR-10 Batch 1:  Loss:     1.0541 Validation Accuracy: 0.543200\n",
      "Epoch 756, CIFAR-10 Batch 1:  Loss:     1.0545 Validation Accuracy: 0.541600\n",
      "Epoch 757, CIFAR-10 Batch 1:  Loss:     1.0532 Validation Accuracy: 0.541600\n",
      "Epoch 758, CIFAR-10 Batch 1:  Loss:     1.0518 Validation Accuracy: 0.541600\n",
      "Epoch 759, CIFAR-10 Batch 1:  Loss:     1.0514 Validation Accuracy: 0.542000\n",
      "Epoch 760, CIFAR-10 Batch 1:  Loss:     1.0514 Validation Accuracy: 0.542200\n",
      "Epoch 761, CIFAR-10 Batch 1:  Loss:     1.0511 Validation Accuracy: 0.541000\n",
      "Epoch 762, CIFAR-10 Batch 1:  Loss:     1.0500 Validation Accuracy: 0.541600\n",
      "Epoch 763, CIFAR-10 Batch 1:  Loss:     1.0489 Validation Accuracy: 0.543400\n",
      "Epoch 764, CIFAR-10 Batch 1:  Loss:     1.0487 Validation Accuracy: 0.542800\n",
      "Epoch 765, CIFAR-10 Batch 1:  Loss:     1.0488 Validation Accuracy: 0.542000\n",
      "Epoch 766, CIFAR-10 Batch 1:  Loss:     1.0483 Validation Accuracy: 0.543200\n",
      "Epoch 767, CIFAR-10 Batch 1:  Loss:     1.0472 Validation Accuracy: 0.543600\n",
      "Epoch 768, CIFAR-10 Batch 1:  Loss:     1.0463 Validation Accuracy: 0.542400\n",
      "Epoch 769, CIFAR-10 Batch 1:  Loss:     1.0462 Validation Accuracy: 0.542000\n",
      "Epoch 770, CIFAR-10 Batch 1:  Loss:     1.0463 Validation Accuracy: 0.541200\n",
      "Epoch 771, CIFAR-10 Batch 1:  Loss:     1.0458 Validation Accuracy: 0.543800\n",
      "Epoch 772, CIFAR-10 Batch 1:  Loss:     1.0448 Validation Accuracy: 0.545000\n",
      "Epoch 773, CIFAR-10 Batch 1:  Loss:     1.0440 Validation Accuracy: 0.542600\n",
      "Epoch 774, CIFAR-10 Batch 1:  Loss:     1.0437 Validation Accuracy: 0.541800\n",
      "Epoch 775, CIFAR-10 Batch 1:  Loss:     1.0435 Validation Accuracy: 0.544000\n",
      "Epoch 776, CIFAR-10 Batch 1:  Loss:     1.0432 Validation Accuracy: 0.544400\n",
      "Epoch 777, CIFAR-10 Batch 1:  Loss:     1.0427 Validation Accuracy: 0.545000\n",
      "Epoch 778, CIFAR-10 Batch 1:  Loss:     1.0420 Validation Accuracy: 0.544200\n",
      "Epoch 779, CIFAR-10 Batch 1:  Loss:     1.0413 Validation Accuracy: 0.543400\n",
      "Epoch 780, CIFAR-10 Batch 1:  Loss:     1.0408 Validation Accuracy: 0.543600\n",
      "Epoch 781, CIFAR-10 Batch 1:  Loss:     1.0405 Validation Accuracy: 0.543200\n",
      "Epoch 782, CIFAR-10 Batch 1:  Loss:     1.0402 Validation Accuracy: 0.543400\n",
      "Epoch 783, CIFAR-10 Batch 1:  Loss:     1.0399 Validation Accuracy: 0.544000\n",
      "Epoch 784, CIFAR-10 Batch 1:  Loss:     1.0394 Validation Accuracy: 0.543800\n",
      "Epoch 785, CIFAR-10 Batch 1:  Loss:     1.0388 Validation Accuracy: 0.542600\n",
      "Epoch 786, CIFAR-10 Batch 1:  Loss:     1.0382 Validation Accuracy: 0.544200\n",
      "Epoch 787, CIFAR-10 Batch 1:  Loss:     1.0377 Validation Accuracy: 0.543600\n",
      "Epoch 788, CIFAR-10 Batch 1:  Loss:     1.0373 Validation Accuracy: 0.543600\n",
      "Epoch 789, CIFAR-10 Batch 1:  Loss:     1.0369 Validation Accuracy: 0.543600\n",
      "Epoch 790, CIFAR-10 Batch 1:  Loss:     1.0365 Validation Accuracy: 0.544000\n",
      "Epoch 791, CIFAR-10 Batch 1:  Loss:     1.0361 Validation Accuracy: 0.544800\n",
      "Epoch 792, CIFAR-10 Batch 1:  Loss:     1.0356 Validation Accuracy: 0.544000\n",
      "Epoch 793, CIFAR-10 Batch 1:  Loss:     1.0352 Validation Accuracy: 0.545000\n",
      "Epoch 794, CIFAR-10 Batch 1:  Loss:     1.0347 Validation Accuracy: 0.543800\n",
      "Epoch 795, CIFAR-10 Batch 1:  Loss:     1.0342 Validation Accuracy: 0.544800\n",
      "Epoch 796, CIFAR-10 Batch 1:  Loss:     1.0337 Validation Accuracy: 0.543800\n",
      "Epoch 797, CIFAR-10 Batch 1:  Loss:     1.0333 Validation Accuracy: 0.544800\n",
      "Epoch 798, CIFAR-10 Batch 1:  Loss:     1.0328 Validation Accuracy: 0.543800\n",
      "Epoch 799, CIFAR-10 Batch 1:  Loss:     1.0324 Validation Accuracy: 0.544000\n",
      "Epoch 800, CIFAR-10 Batch 1:  Loss:     1.0319 Validation Accuracy: 0.543800\n",
      "Epoch 801, CIFAR-10 Batch 1:  Loss:     1.0315 Validation Accuracy: 0.543600\n",
      "Epoch 802, CIFAR-10 Batch 1:  Loss:     1.0312 Validation Accuracy: 0.543000\n",
      "Epoch 803, CIFAR-10 Batch 1:  Loss:     1.0309 Validation Accuracy: 0.542000\n",
      "Epoch 804, CIFAR-10 Batch 1:  Loss:     1.0307 Validation Accuracy: 0.543400\n",
      "Epoch 805, CIFAR-10 Batch 1:  Loss:     1.0307 Validation Accuracy: 0.542200\n",
      "Epoch 806, CIFAR-10 Batch 1:  Loss:     1.0311 Validation Accuracy: 0.543000\n",
      "Epoch 807, CIFAR-10 Batch 1:  Loss:     1.0321 Validation Accuracy: 0.542000\n",
      "Epoch 808, CIFAR-10 Batch 1:  Loss:     1.0342 Validation Accuracy: 0.545000\n",
      "Epoch 809, CIFAR-10 Batch 1:  Loss:     1.0379 Validation Accuracy: 0.538800\n",
      "Epoch 810, CIFAR-10 Batch 1:  Loss:     1.0440 Validation Accuracy: 0.540600\n",
      "Epoch 811, CIFAR-10 Batch 1:  Loss:     1.0507 Validation Accuracy: 0.536400\n",
      "Epoch 812, CIFAR-10 Batch 1:  Loss:     1.0564 Validation Accuracy: 0.538600\n",
      "Epoch 813, CIFAR-10 Batch 1:  Loss:     1.0529 Validation Accuracy: 0.533600\n",
      "Epoch 814, CIFAR-10 Batch 1:  Loss:     1.0428 Validation Accuracy: 0.540600\n",
      "Epoch 815, CIFAR-10 Batch 1:  Loss:     1.0328 Validation Accuracy: 0.542200\n",
      "Epoch 816, CIFAR-10 Batch 1:  Loss:     1.0319 Validation Accuracy: 0.543800\n",
      "Epoch 817, CIFAR-10 Batch 1:  Loss:     1.0411 Validation Accuracy: 0.542200\n",
      "Epoch 818, CIFAR-10 Batch 1:  Loss:     1.0501 Validation Accuracy: 0.533200\n",
      "Epoch 819, CIFAR-10 Batch 1:  Loss:     1.0519 Validation Accuracy: 0.535800\n",
      "Epoch 820, CIFAR-10 Batch 1:  Loss:     1.0388 Validation Accuracy: 0.539200\n",
      "Epoch 821, CIFAR-10 Batch 1:  Loss:     1.0292 Validation Accuracy: 0.542400\n",
      "Epoch 822, CIFAR-10 Batch 1:  Loss:     1.0287 Validation Accuracy: 0.546400\n",
      "Epoch 823, CIFAR-10 Batch 1:  Loss:     1.0330 Validation Accuracy: 0.541400\n",
      "Epoch 824, CIFAR-10 Batch 1:  Loss:     1.0315 Validation Accuracy: 0.542600\n",
      "Epoch 825, CIFAR-10 Batch 1:  Loss:     1.0258 Validation Accuracy: 0.545200\n",
      "Epoch 826, CIFAR-10 Batch 1:  Loss:     1.0252 Validation Accuracy: 0.545000\n",
      "Epoch 827, CIFAR-10 Batch 1:  Loss:     1.0286 Validation Accuracy: 0.543200\n",
      "Epoch 828, CIFAR-10 Batch 1:  Loss:     1.0285 Validation Accuracy: 0.543600\n",
      "Epoch 829, CIFAR-10 Batch 1:  Loss:     1.0233 Validation Accuracy: 0.545200\n",
      "Epoch 830, CIFAR-10 Batch 1:  Loss:     1.0192 Validation Accuracy: 0.546400\n",
      "Epoch 831, CIFAR-10 Batch 1:  Loss:     1.0209 Validation Accuracy: 0.545200\n",
      "Epoch 832, CIFAR-10 Batch 1:  Loss:     1.0242 Validation Accuracy: 0.544600\n",
      "Epoch 833, CIFAR-10 Batch 1:  Loss:     1.0238 Validation Accuracy: 0.545600\n",
      "Epoch 834, CIFAR-10 Batch 1:  Loss:     1.0204 Validation Accuracy: 0.545800\n",
      "Epoch 835, CIFAR-10 Batch 1:  Loss:     1.0185 Validation Accuracy: 0.545600\n",
      "Epoch 836, CIFAR-10 Batch 1:  Loss:     1.0189 Validation Accuracy: 0.545400\n",
      "Epoch 837, CIFAR-10 Batch 1:  Loss:     1.0192 Validation Accuracy: 0.544200\n",
      "Epoch 838, CIFAR-10 Batch 1:  Loss:     1.0176 Validation Accuracy: 0.544400\n",
      "Epoch 839, CIFAR-10 Batch 1:  Loss:     1.0159 Validation Accuracy: 0.546400\n",
      "Epoch 840, CIFAR-10 Batch 1:  Loss:     1.0162 Validation Accuracy: 0.544400\n",
      "Epoch 841, CIFAR-10 Batch 1:  Loss:     1.0171 Validation Accuracy: 0.547600\n",
      "Epoch 842, CIFAR-10 Batch 1:  Loss:     1.0167 Validation Accuracy: 0.545400\n",
      "Epoch 843, CIFAR-10 Batch 1:  Loss:     1.0150 Validation Accuracy: 0.546600\n",
      "Epoch 844, CIFAR-10 Batch 1:  Loss:     1.0136 Validation Accuracy: 0.545600\n",
      "Epoch 845, CIFAR-10 Batch 1:  Loss:     1.0134 Validation Accuracy: 0.545400\n",
      "Epoch 846, CIFAR-10 Batch 1:  Loss:     1.0135 Validation Accuracy: 0.545800\n",
      "Epoch 847, CIFAR-10 Batch 1:  Loss:     1.0131 Validation Accuracy: 0.545200\n",
      "Epoch 848, CIFAR-10 Batch 1:  Loss:     1.0121 Validation Accuracy: 0.546800\n",
      "Epoch 849, CIFAR-10 Batch 1:  Loss:     1.0115 Validation Accuracy: 0.547000\n",
      "Epoch 850, CIFAR-10 Batch 1:  Loss:     1.0114 Validation Accuracy: 0.546200\n",
      "Epoch 851, CIFAR-10 Batch 1:  Loss:     1.0116 Validation Accuracy: 0.546000\n",
      "Epoch 852, CIFAR-10 Batch 1:  Loss:     1.0113 Validation Accuracy: 0.548000\n",
      "Epoch 853, CIFAR-10 Batch 1:  Loss:     1.0107 Validation Accuracy: 0.546000\n",
      "Epoch 854, CIFAR-10 Batch 1:  Loss:     1.0100 Validation Accuracy: 0.547400\n",
      "Epoch 855, CIFAR-10 Batch 1:  Loss:     1.0098 Validation Accuracy: 0.546200\n",
      "Epoch 856, CIFAR-10 Batch 1:  Loss:     1.0098 Validation Accuracy: 0.550600\n",
      "Epoch 857, CIFAR-10 Batch 1:  Loss:     1.0098 Validation Accuracy: 0.545400\n",
      "Epoch 858, CIFAR-10 Batch 1:  Loss:     1.0096 Validation Accuracy: 0.550200\n",
      "Epoch 859, CIFAR-10 Batch 1:  Loss:     1.0095 Validation Accuracy: 0.545800\n",
      "Epoch 860, CIFAR-10 Batch 1:  Loss:     1.0095 Validation Accuracy: 0.549400\n",
      "Epoch 861, CIFAR-10 Batch 1:  Loss:     1.0104 Validation Accuracy: 0.546000\n",
      "Epoch 862, CIFAR-10 Batch 1:  Loss:     1.0112 Validation Accuracy: 0.548200\n",
      "Epoch 863, CIFAR-10 Batch 1:  Loss:     1.0130 Validation Accuracy: 0.544400\n",
      "Epoch 864, CIFAR-10 Batch 1:  Loss:     1.0138 Validation Accuracy: 0.546400\n",
      "Epoch 865, CIFAR-10 Batch 1:  Loss:     1.0159 Validation Accuracy: 0.541000\n",
      "Epoch 866, CIFAR-10 Batch 1:  Loss:     1.0148 Validation Accuracy: 0.545200\n",
      "Epoch 867, CIFAR-10 Batch 1:  Loss:     1.0147 Validation Accuracy: 0.541800\n",
      "Epoch 868, CIFAR-10 Batch 1:  Loss:     1.0107 Validation Accuracy: 0.549600\n",
      "Epoch 869, CIFAR-10 Batch 1:  Loss:     1.0075 Validation Accuracy: 0.546800\n",
      "Epoch 870, CIFAR-10 Batch 1:  Loss:     1.0040 Validation Accuracy: 0.550000\n",
      "Epoch 871, CIFAR-10 Batch 1:  Loss:     1.0022 Validation Accuracy: 0.545800\n",
      "Epoch 872, CIFAR-10 Batch 1:  Loss:     1.0020 Validation Accuracy: 0.547000\n",
      "Epoch 873, CIFAR-10 Batch 1:  Loss:     1.0030 Validation Accuracy: 0.550400\n",
      "Epoch 874, CIFAR-10 Batch 1:  Loss:     1.0045 Validation Accuracy: 0.546000\n",
      "Epoch 875, CIFAR-10 Batch 1:  Loss:     1.0050 Validation Accuracy: 0.550400\n",
      "Epoch 876, CIFAR-10 Batch 1:  Loss:     1.0051 Validation Accuracy: 0.546600\n",
      "Epoch 877, CIFAR-10 Batch 1:  Loss:     1.0034 Validation Accuracy: 0.550000\n",
      "Epoch 878, CIFAR-10 Batch 1:  Loss:     1.0017 Validation Accuracy: 0.547000\n",
      "Epoch 879, CIFAR-10 Batch 1:  Loss:     0.9997 Validation Accuracy: 0.548400\n",
      "Epoch 880, CIFAR-10 Batch 1:  Loss:     0.9985 Validation Accuracy: 0.545800\n",
      "Epoch 881, CIFAR-10 Batch 1:  Loss:     0.9979 Validation Accuracy: 0.546600\n",
      "Epoch 882, CIFAR-10 Batch 1:  Loss:     0.9979 Validation Accuracy: 0.548600\n",
      "Epoch 883, CIFAR-10 Batch 1:  Loss:     0.9982 Validation Accuracy: 0.548400\n",
      "Epoch 884, CIFAR-10 Batch 1:  Loss:     0.9985 Validation Accuracy: 0.550600\n",
      "Epoch 885, CIFAR-10 Batch 1:  Loss:     0.9988 Validation Accuracy: 0.546200\n",
      "Epoch 886, CIFAR-10 Batch 1:  Loss:     0.9986 Validation Accuracy: 0.551800\n",
      "Epoch 887, CIFAR-10 Batch 1:  Loss:     0.9984 Validation Accuracy: 0.545600\n",
      "Epoch 888, CIFAR-10 Batch 1:  Loss:     0.9976 Validation Accuracy: 0.551600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2925 Validation Accuracy: 0.105000\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.2427 Validation Accuracy: 0.153800\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     2.1389 Validation Accuracy: 0.189400\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     2.0837 Validation Accuracy: 0.204000\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     2.0443 Validation Accuracy: 0.236800\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.0525 Validation Accuracy: 0.241000\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     2.0300 Validation Accuracy: 0.241800\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.9450 Validation Accuracy: 0.252000\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.9545 Validation Accuracy: 0.261800\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.9303 Validation Accuracy: 0.278400\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.9504 Validation Accuracy: 0.270400\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     1.9081 Validation Accuracy: 0.303600\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     1.8190 Validation Accuracy: 0.312600\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.8244 Validation Accuracy: 0.331600\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.8184 Validation Accuracy: 0.321800\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.8047 Validation Accuracy: 0.335800\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     1.7854 Validation Accuracy: 0.362600\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     1.6986 Validation Accuracy: 0.366800\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     1.7304 Validation Accuracy: 0.366800\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     1.7330 Validation Accuracy: 0.371600\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.7123 Validation Accuracy: 0.384800\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     1.7139 Validation Accuracy: 0.395200\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     1.6333 Validation Accuracy: 0.398800\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     1.6622 Validation Accuracy: 0.399000\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     1.6759 Validation Accuracy: 0.385400\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.6465 Validation Accuracy: 0.407600\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     1.6698 Validation Accuracy: 0.408400\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     1.5986 Validation Accuracy: 0.411400\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     1.6094 Validation Accuracy: 0.418600\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     1.6249 Validation Accuracy: 0.405400\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.5990 Validation Accuracy: 0.420800\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     1.6291 Validation Accuracy: 0.424200\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     1.5654 Validation Accuracy: 0.421000\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     1.5800 Validation Accuracy: 0.427800\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     1.5977 Validation Accuracy: 0.420000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.5666 Validation Accuracy: 0.426600\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     1.6072 Validation Accuracy: 0.433400\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     1.5247 Validation Accuracy: 0.436800\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     1.5474 Validation Accuracy: 0.434000\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     1.5526 Validation Accuracy: 0.432600\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.5406 Validation Accuracy: 0.437600\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     1.5722 Validation Accuracy: 0.447200\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     1.5032 Validation Accuracy: 0.444000\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     1.5382 Validation Accuracy: 0.437600\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     1.5382 Validation Accuracy: 0.436800\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.5188 Validation Accuracy: 0.449400\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     1.5404 Validation Accuracy: 0.450600\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     1.4700 Validation Accuracy: 0.450800\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     1.5028 Validation Accuracy: 0.446000\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     1.5176 Validation Accuracy: 0.448800\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.4874 Validation Accuracy: 0.458800\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     1.5178 Validation Accuracy: 0.460800\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     1.4353 Validation Accuracy: 0.464800\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     1.4765 Validation Accuracy: 0.459800\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     1.4958 Validation Accuracy: 0.452800\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.4644 Validation Accuracy: 0.464000\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     1.4974 Validation Accuracy: 0.469800\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     1.4396 Validation Accuracy: 0.462600\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     1.4696 Validation Accuracy: 0.463600\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     1.4747 Validation Accuracy: 0.460000\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.4513 Validation Accuracy: 0.476400\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     1.4730 Validation Accuracy: 0.475000\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     1.4104 Validation Accuracy: 0.473600\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     1.4513 Validation Accuracy: 0.470400\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     1.4552 Validation Accuracy: 0.465600\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.4327 Validation Accuracy: 0.482800\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     1.4515 Validation Accuracy: 0.481000\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     1.4117 Validation Accuracy: 0.475200\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     1.4473 Validation Accuracy: 0.477200\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     1.4426 Validation Accuracy: 0.473400\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.4123 Validation Accuracy: 0.490400\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     1.4435 Validation Accuracy: 0.487400\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     1.3931 Validation Accuracy: 0.478800\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     1.4371 Validation Accuracy: 0.480200\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     1.4289 Validation Accuracy: 0.476000\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.4137 Validation Accuracy: 0.489200\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     1.4286 Validation Accuracy: 0.489200\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     1.3700 Validation Accuracy: 0.489600\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     1.4134 Validation Accuracy: 0.489000\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     1.4116 Validation Accuracy: 0.485800\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.3963 Validation Accuracy: 0.495000\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     1.4316 Validation Accuracy: 0.480200\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     1.4165 Validation Accuracy: 0.476000\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     1.4129 Validation Accuracy: 0.486000\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     1.4029 Validation Accuracy: 0.490600\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.3782 Validation Accuracy: 0.497200\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     1.4065 Validation Accuracy: 0.496400\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     1.3472 Validation Accuracy: 0.493800\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     1.3918 Validation Accuracy: 0.498200\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     1.3905 Validation Accuracy: 0.501200\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.3672 Validation Accuracy: 0.502400\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     1.3950 Validation Accuracy: 0.503200\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     1.3299 Validation Accuracy: 0.501400\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     1.3818 Validation Accuracy: 0.504000\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     1.3756 Validation Accuracy: 0.501200\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.3595 Validation Accuracy: 0.502800\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     1.3842 Validation Accuracy: 0.499000\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     1.3455 Validation Accuracy: 0.498400\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     1.3702 Validation Accuracy: 0.504000\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     1.3664 Validation Accuracy: 0.506800\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.3489 Validation Accuracy: 0.506200\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     1.3781 Validation Accuracy: 0.503200\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     1.3132 Validation Accuracy: 0.507400\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     1.3628 Validation Accuracy: 0.509400\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     1.3692 Validation Accuracy: 0.506400\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.3360 Validation Accuracy: 0.511200\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     1.3651 Validation Accuracy: 0.508600\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     1.2984 Validation Accuracy: 0.506800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     1.3471 Validation Accuracy: 0.510400\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     1.3616 Validation Accuracy: 0.503400\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.3317 Validation Accuracy: 0.511800\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     1.3514 Validation Accuracy: 0.512200\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     1.2995 Validation Accuracy: 0.506000\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     1.3444 Validation Accuracy: 0.514400\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     1.3328 Validation Accuracy: 0.514800\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.3367 Validation Accuracy: 0.516200\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     1.3426 Validation Accuracy: 0.509600\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     1.3135 Validation Accuracy: 0.504400\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     1.3265 Validation Accuracy: 0.518800\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     1.3245 Validation Accuracy: 0.514600\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.3256 Validation Accuracy: 0.515200\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     1.3152 Validation Accuracy: 0.521000\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     1.2769 Validation Accuracy: 0.512400\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     1.3173 Validation Accuracy: 0.521000\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     1.3149 Validation Accuracy: 0.516600\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.3065 Validation Accuracy: 0.523600\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     1.3093 Validation Accuracy: 0.524600\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     1.2865 Validation Accuracy: 0.514600\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     1.3054 Validation Accuracy: 0.522200\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     1.3050 Validation Accuracy: 0.524600\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     1.3037 Validation Accuracy: 0.525400\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     1.2991 Validation Accuracy: 0.522200\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     1.2640 Validation Accuracy: 0.518000\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     1.3065 Validation Accuracy: 0.527400\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     1.3000 Validation Accuracy: 0.528200\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.2999 Validation Accuracy: 0.525600\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     1.2944 Validation Accuracy: 0.528400\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     1.2642 Validation Accuracy: 0.522200\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     1.2809 Validation Accuracy: 0.529800\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     1.3014 Validation Accuracy: 0.523600\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     1.2798 Validation Accuracy: 0.531600\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     1.2772 Validation Accuracy: 0.532000\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     1.2464 Validation Accuracy: 0.526600\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     1.2864 Validation Accuracy: 0.532800\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     1.2788 Validation Accuracy: 0.526800\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     1.2767 Validation Accuracy: 0.537200\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     1.2658 Validation Accuracy: 0.534800\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     1.2290 Validation Accuracy: 0.531800\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     1.2705 Validation Accuracy: 0.539400\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     1.2656 Validation Accuracy: 0.534000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     1.2810 Validation Accuracy: 0.531600\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     1.2557 Validation Accuracy: 0.544600\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     1.2247 Validation Accuracy: 0.536400\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     1.2441 Validation Accuracy: 0.543200\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     1.2577 Validation Accuracy: 0.537800\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     1.2614 Validation Accuracy: 0.539200\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     1.2534 Validation Accuracy: 0.542600\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     1.2346 Validation Accuracy: 0.530600\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     1.2404 Validation Accuracy: 0.546600\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     1.2505 Validation Accuracy: 0.542800\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     1.2698 Validation Accuracy: 0.536600\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     1.2354 Validation Accuracy: 0.546400\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     1.2042 Validation Accuracy: 0.539800\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     1.2417 Validation Accuracy: 0.546200\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     1.2466 Validation Accuracy: 0.541600\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     1.2419 Validation Accuracy: 0.549000\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     1.2315 Validation Accuracy: 0.542000\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     1.2221 Validation Accuracy: 0.542400\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     1.2260 Validation Accuracy: 0.549600\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     1.2399 Validation Accuracy: 0.540800\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     1.2447 Validation Accuracy: 0.548600\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     1.2221 Validation Accuracy: 0.546800\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     1.2148 Validation Accuracy: 0.542000\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     1.2303 Validation Accuracy: 0.549200\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     1.2274 Validation Accuracy: 0.545400\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     1.2291 Validation Accuracy: 0.551000\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     1.2290 Validation Accuracy: 0.550800\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     1.1864 Validation Accuracy: 0.551400\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     1.2068 Validation Accuracy: 0.557000\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     1.2272 Validation Accuracy: 0.541400\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     1.2271 Validation Accuracy: 0.553200\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     1.2268 Validation Accuracy: 0.548200\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     1.1882 Validation Accuracy: 0.554000\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     1.1934 Validation Accuracy: 0.558800\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     1.2130 Validation Accuracy: 0.551400\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     1.2161 Validation Accuracy: 0.554600\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     1.2091 Validation Accuracy: 0.554400\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     1.1715 Validation Accuracy: 0.562400\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     1.2056 Validation Accuracy: 0.555600\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     1.1999 Validation Accuracy: 0.556400\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     1.2125 Validation Accuracy: 0.557200\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     1.2020 Validation Accuracy: 0.559800\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     1.1850 Validation Accuracy: 0.555800\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     1.1965 Validation Accuracy: 0.559800\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     1.1938 Validation Accuracy: 0.558400\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     1.2166 Validation Accuracy: 0.560000\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     1.1801 Validation Accuracy: 0.561800\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     1.1642 Validation Accuracy: 0.560400\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     1.1886 Validation Accuracy: 0.566000\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     1.1774 Validation Accuracy: 0.564600\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.2146 Validation Accuracy: 0.561400\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     1.1675 Validation Accuracy: 0.565200\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     1.1665 Validation Accuracy: 0.554600\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     1.1848 Validation Accuracy: 0.564400\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     1.2018 Validation Accuracy: 0.555400\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.1988 Validation Accuracy: 0.565400\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     1.1622 Validation Accuracy: 0.567000\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     1.1567 Validation Accuracy: 0.564400\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     1.1746 Validation Accuracy: 0.560400\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     1.1782 Validation Accuracy: 0.562800\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.2023 Validation Accuracy: 0.567600\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     1.1761 Validation Accuracy: 0.564200\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     1.1740 Validation Accuracy: 0.561800\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     1.1595 Validation Accuracy: 0.568200\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     1.1839 Validation Accuracy: 0.565000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.1880 Validation Accuracy: 0.567400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     1.1572 Validation Accuracy: 0.566200\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     1.1505 Validation Accuracy: 0.564400\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     1.1467 Validation Accuracy: 0.570200\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     1.1777 Validation Accuracy: 0.566400\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.1839 Validation Accuracy: 0.574400\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     1.1555 Validation Accuracy: 0.573200\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     1.1305 Validation Accuracy: 0.567000\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     1.1439 Validation Accuracy: 0.572400\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     1.1510 Validation Accuracy: 0.571800\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.1795 Validation Accuracy: 0.570200\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     1.1473 Validation Accuracy: 0.572800\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     1.1403 Validation Accuracy: 0.570800\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     1.1356 Validation Accuracy: 0.574000\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     1.1565 Validation Accuracy: 0.574800\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.1850 Validation Accuracy: 0.571000\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     1.1555 Validation Accuracy: 0.563800\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     1.1313 Validation Accuracy: 0.571800\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     1.1358 Validation Accuracy: 0.578800\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     1.1417 Validation Accuracy: 0.577200\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.1685 Validation Accuracy: 0.582200\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     1.1420 Validation Accuracy: 0.577800\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     1.1185 Validation Accuracy: 0.583000\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     1.1496 Validation Accuracy: 0.571800\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     1.1370 Validation Accuracy: 0.576400\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.1735 Validation Accuracy: 0.577800\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     1.1425 Validation Accuracy: 0.573400\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     1.1130 Validation Accuracy: 0.574600\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     1.1307 Validation Accuracy: 0.577000\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     1.1466 Validation Accuracy: 0.574000\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.1614 Validation Accuracy: 0.582800\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     1.1266 Validation Accuracy: 0.577600\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     1.1132 Validation Accuracy: 0.580000\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     1.1208 Validation Accuracy: 0.578000\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     1.1331 Validation Accuracy: 0.577600\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.1723 Validation Accuracy: 0.579400\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     1.1280 Validation Accuracy: 0.583200\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     1.1018 Validation Accuracy: 0.581600\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     1.1190 Validation Accuracy: 0.582800\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     1.1287 Validation Accuracy: 0.575800\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.1585 Validation Accuracy: 0.583600\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     1.1137 Validation Accuracy: 0.580000\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     1.1195 Validation Accuracy: 0.581400\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     1.1037 Validation Accuracy: 0.584400\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     1.1148 Validation Accuracy: 0.584000\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.1572 Validation Accuracy: 0.582600\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     1.1161 Validation Accuracy: 0.585400\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     1.1074 Validation Accuracy: 0.580200\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     1.1089 Validation Accuracy: 0.578600\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     1.1289 Validation Accuracy: 0.582400\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.1482 Validation Accuracy: 0.584200\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     1.1105 Validation Accuracy: 0.580200\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     1.1050 Validation Accuracy: 0.589000\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     1.1018 Validation Accuracy: 0.582000\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     1.1159 Validation Accuracy: 0.585000\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.1484 Validation Accuracy: 0.586600\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     1.1095 Validation Accuracy: 0.578400\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     1.0979 Validation Accuracy: 0.586200\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     1.1137 Validation Accuracy: 0.581600\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     1.1161 Validation Accuracy: 0.584400\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.1458 Validation Accuracy: 0.587400\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     1.0944 Validation Accuracy: 0.582000\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     1.0934 Validation Accuracy: 0.585000\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     1.0939 Validation Accuracy: 0.590800\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     1.1038 Validation Accuracy: 0.590400\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.1307 Validation Accuracy: 0.590600\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     1.1137 Validation Accuracy: 0.582600\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     1.0782 Validation Accuracy: 0.594800\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     1.0842 Validation Accuracy: 0.587600\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     1.0979 Validation Accuracy: 0.593000\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.1319 Validation Accuracy: 0.587600\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     1.0901 Validation Accuracy: 0.586200\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     1.0781 Validation Accuracy: 0.588200\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     1.0911 Validation Accuracy: 0.585600\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     1.1034 Validation Accuracy: 0.587000\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.1365 Validation Accuracy: 0.590200\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     1.0901 Validation Accuracy: 0.590600\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     1.0667 Validation Accuracy: 0.597200\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     1.0832 Validation Accuracy: 0.594000\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     1.0801 Validation Accuracy: 0.600800\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.1276 Validation Accuracy: 0.600200\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     1.0822 Validation Accuracy: 0.590600\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     1.0737 Validation Accuracy: 0.590400\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     1.0703 Validation Accuracy: 0.594600\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     1.1005 Validation Accuracy: 0.591600\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.1249 Validation Accuracy: 0.595800\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     1.0748 Validation Accuracy: 0.595800\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     1.0744 Validation Accuracy: 0.587400\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     1.0620 Validation Accuracy: 0.593800\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     1.0826 Validation Accuracy: 0.592600\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.1164 Validation Accuracy: 0.595200\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     1.0780 Validation Accuracy: 0.595200\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     1.0619 Validation Accuracy: 0.593000\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     1.0689 Validation Accuracy: 0.597200\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     1.0869 Validation Accuracy: 0.595200\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.1206 Validation Accuracy: 0.596200\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     1.0681 Validation Accuracy: 0.595800\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     1.0548 Validation Accuracy: 0.593000\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     1.0584 Validation Accuracy: 0.596000\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     1.0758 Validation Accuracy: 0.601800\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.1113 Validation Accuracy: 0.598600\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     1.0673 Validation Accuracy: 0.594400\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     1.0685 Validation Accuracy: 0.585600\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     1.0507 Validation Accuracy: 0.598600\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     1.0729 Validation Accuracy: 0.597200\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.0991 Validation Accuracy: 0.603200\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:     1.0583 Validation Accuracy: 0.598800\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:     1.0662 Validation Accuracy: 0.590800\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:     1.0490 Validation Accuracy: 0.599600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, CIFAR-10 Batch 5:  Loss:     1.0595 Validation Accuracy: 0.604600\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.0997 Validation Accuracy: 0.603000\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:     1.0447 Validation Accuracy: 0.598800\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:     1.0618 Validation Accuracy: 0.595200\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:     1.0573 Validation Accuracy: 0.601000\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:     1.0694 Validation Accuracy: 0.602600\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.0937 Validation Accuracy: 0.606600\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:     1.0395 Validation Accuracy: 0.598400\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:     1.0542 Validation Accuracy: 0.596200\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:     1.0482 Validation Accuracy: 0.597800\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:     1.0557 Validation Accuracy: 0.611200\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.0865 Validation Accuracy: 0.607200\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:     1.0434 Validation Accuracy: 0.601600\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:     1.0623 Validation Accuracy: 0.599000\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:     1.0385 Validation Accuracy: 0.601800\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:     1.0556 Validation Accuracy: 0.600800\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.0938 Validation Accuracy: 0.606800\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:     1.0399 Validation Accuracy: 0.608400\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:     1.0265 Validation Accuracy: 0.606600\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:     1.0423 Validation Accuracy: 0.599800\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:     1.0495 Validation Accuracy: 0.607000\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.0944 Validation Accuracy: 0.606400\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:     1.0615 Validation Accuracy: 0.593400\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:     1.0192 Validation Accuracy: 0.602800\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:     1.0431 Validation Accuracy: 0.608200\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:     1.0459 Validation Accuracy: 0.610600\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.0795 Validation Accuracy: 0.609200\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:     1.0329 Validation Accuracy: 0.607000\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:     1.0321 Validation Accuracy: 0.602200\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:     1.0359 Validation Accuracy: 0.599200\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:     1.0416 Validation Accuracy: 0.610000\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.0959 Validation Accuracy: 0.602800\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:     1.0275 Validation Accuracy: 0.605200\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:     1.0199 Validation Accuracy: 0.609400\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:     1.0290 Validation Accuracy: 0.598000\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:     1.0442 Validation Accuracy: 0.608800\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.0881 Validation Accuracy: 0.605000\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:     1.0194 Validation Accuracy: 0.611400\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:     1.0279 Validation Accuracy: 0.602600\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:     1.0250 Validation Accuracy: 0.608000\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:     1.0399 Validation Accuracy: 0.611800\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     1.0760 Validation Accuracy: 0.611400\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:     1.0245 Validation Accuracy: 0.615000\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:     1.0222 Validation Accuracy: 0.610200\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:     1.0062 Validation Accuracy: 0.608000\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:     1.0352 Validation Accuracy: 0.613200\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     1.0819 Validation Accuracy: 0.608000\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:     1.0235 Validation Accuracy: 0.606600\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:     1.0171 Validation Accuracy: 0.611600\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:     1.0238 Validation Accuracy: 0.609400\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:     1.0242 Validation Accuracy: 0.619200\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     1.0687 Validation Accuracy: 0.612000\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:     1.0224 Validation Accuracy: 0.611600\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:     1.0173 Validation Accuracy: 0.606000\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:     1.0201 Validation Accuracy: 0.610000\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:     1.0400 Validation Accuracy: 0.608600\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     1.0815 Validation Accuracy: 0.605200\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:     1.0196 Validation Accuracy: 0.609400\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:     1.0194 Validation Accuracy: 0.609400\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:     1.0130 Validation Accuracy: 0.610800\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:     1.0210 Validation Accuracy: 0.616800\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     1.0722 Validation Accuracy: 0.610400\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:     1.0018 Validation Accuracy: 0.617400\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:     1.0147 Validation Accuracy: 0.606400\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:     1.0019 Validation Accuracy: 0.611600\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:     1.0116 Validation Accuracy: 0.621400\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     1.0654 Validation Accuracy: 0.609200\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:     1.0031 Validation Accuracy: 0.614800\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:     1.0174 Validation Accuracy: 0.611200\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:     1.0167 Validation Accuracy: 0.604000\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:     1.0047 Validation Accuracy: 0.618400\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     1.0714 Validation Accuracy: 0.612600\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:     1.0179 Validation Accuracy: 0.610000\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:     1.0059 Validation Accuracy: 0.609200\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:     0.9978 Validation Accuracy: 0.607800\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:     1.0029 Validation Accuracy: 0.623600\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     1.0645 Validation Accuracy: 0.611000\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:     0.9975 Validation Accuracy: 0.619800\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:     0.9898 Validation Accuracy: 0.611600\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:     1.0058 Validation Accuracy: 0.605400\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:     1.0015 Validation Accuracy: 0.616800\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     1.0476 Validation Accuracy: 0.610200\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:     1.0012 Validation Accuracy: 0.616000\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:     0.9988 Validation Accuracy: 0.617000\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:     0.9910 Validation Accuracy: 0.607600\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:     0.9962 Validation Accuracy: 0.617000\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     1.0488 Validation Accuracy: 0.618000\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:     1.0116 Validation Accuracy: 0.617400\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:     0.9873 Validation Accuracy: 0.609200\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:     1.0043 Validation Accuracy: 0.609600\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:     1.0011 Validation Accuracy: 0.619400\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     1.0528 Validation Accuracy: 0.612600\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:     0.9960 Validation Accuracy: 0.614400\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:     0.9933 Validation Accuracy: 0.612200\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:     0.9930 Validation Accuracy: 0.611400\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:     0.9986 Validation Accuracy: 0.621000\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     1.0421 Validation Accuracy: 0.619000\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:     0.9972 Validation Accuracy: 0.614200\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:     0.9971 Validation Accuracy: 0.612800\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:     0.9784 Validation Accuracy: 0.618000\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:     0.9947 Validation Accuracy: 0.624200\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     1.0497 Validation Accuracy: 0.620400\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:     0.9946 Validation Accuracy: 0.624000\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:     0.9962 Validation Accuracy: 0.608000\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:     0.9785 Validation Accuracy: 0.620200\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:     0.9860 Validation Accuracy: 0.628000\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     1.0578 Validation Accuracy: 0.613800\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:     0.9930 Validation Accuracy: 0.613200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, CIFAR-10 Batch 3:  Loss:     0.9841 Validation Accuracy: 0.616800\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:     0.9855 Validation Accuracy: 0.614000\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:     0.9817 Validation Accuracy: 0.618800\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     1.0395 Validation Accuracy: 0.620200\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:     0.9857 Validation Accuracy: 0.620200\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:     0.9796 Validation Accuracy: 0.615800\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:     0.9737 Validation Accuracy: 0.617000\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:     0.9763 Validation Accuracy: 0.624600\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     1.0309 Validation Accuracy: 0.620800\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:     0.9846 Validation Accuracy: 0.617200\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:     0.9772 Validation Accuracy: 0.619400\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:     0.9771 Validation Accuracy: 0.612800\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:     0.9763 Validation Accuracy: 0.621800\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     1.0209 Validation Accuracy: 0.617000\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:     0.9874 Validation Accuracy: 0.618600\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:     0.9659 Validation Accuracy: 0.621600\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:     0.9776 Validation Accuracy: 0.610800\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:     0.9758 Validation Accuracy: 0.626800\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     1.0147 Validation Accuracy: 0.621800\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:     0.9801 Validation Accuracy: 0.617200\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:     0.9682 Validation Accuracy: 0.623600\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:     0.9681 Validation Accuracy: 0.617800\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:     0.9730 Validation Accuracy: 0.630200\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     1.0208 Validation Accuracy: 0.621400\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:     0.9848 Validation Accuracy: 0.616400\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:     0.9620 Validation Accuracy: 0.619000\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:     0.9730 Validation Accuracy: 0.606800\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:     0.9809 Validation Accuracy: 0.620400\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     1.0115 Validation Accuracy: 0.622800\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:     0.9709 Validation Accuracy: 0.621000\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:     0.9667 Validation Accuracy: 0.619200\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:     0.9628 Validation Accuracy: 0.615000\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:     0.9667 Validation Accuracy: 0.628800\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     1.0091 Validation Accuracy: 0.623200\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:     0.9738 Validation Accuracy: 0.616000\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:     0.9521 Validation Accuracy: 0.620400\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:     0.9615 Validation Accuracy: 0.623800\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:     0.9683 Validation Accuracy: 0.627600\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     1.0207 Validation Accuracy: 0.624000\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:     0.9593 Validation Accuracy: 0.628000\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:     0.9489 Validation Accuracy: 0.625600\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:     0.9594 Validation Accuracy: 0.623800\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:     0.9552 Validation Accuracy: 0.628200\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     1.0166 Validation Accuracy: 0.622400\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:     0.9563 Validation Accuracy: 0.628400\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:     0.9597 Validation Accuracy: 0.623400\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:     0.9557 Validation Accuracy: 0.615600\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:     0.9569 Validation Accuracy: 0.624600\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     1.0080 Validation Accuracy: 0.624000\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:     0.9665 Validation Accuracy: 0.615400\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:     0.9658 Validation Accuracy: 0.622400\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:     0.9568 Validation Accuracy: 0.618800\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:     0.9682 Validation Accuracy: 0.626200\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     1.0025 Validation Accuracy: 0.626600\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:     0.9506 Validation Accuracy: 0.631200\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:     0.9656 Validation Accuracy: 0.629400\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:     0.9710 Validation Accuracy: 0.607600\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:     0.9613 Validation Accuracy: 0.624800\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     1.0094 Validation Accuracy: 0.617800\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:     0.9512 Validation Accuracy: 0.620800\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:     0.9667 Validation Accuracy: 0.625000\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:     0.9374 Validation Accuracy: 0.627200\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:     0.9534 Validation Accuracy: 0.626200\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     1.0092 Validation Accuracy: 0.626000\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:     0.9468 Validation Accuracy: 0.627800\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:     0.9463 Validation Accuracy: 0.628800\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:     0.9555 Validation Accuracy: 0.622800\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:     0.9721 Validation Accuracy: 0.621000\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:     1.0123 Validation Accuracy: 0.626600\n",
      "Epoch 101, CIFAR-10 Batch 2:  Loss:     0.9476 Validation Accuracy: 0.631600\n",
      "Epoch 101, CIFAR-10 Batch 3:  Loss:     0.9368 Validation Accuracy: 0.627800\n",
      "Epoch 101, CIFAR-10 Batch 4:  Loss:     0.9412 Validation Accuracy: 0.625800\n",
      "Epoch 101, CIFAR-10 Batch 5:  Loss:     0.9489 Validation Accuracy: 0.632000\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:     0.9946 Validation Accuracy: 0.627800\n",
      "Epoch 102, CIFAR-10 Batch 2:  Loss:     0.9430 Validation Accuracy: 0.627600\n",
      "Epoch 102, CIFAR-10 Batch 3:  Loss:     0.9402 Validation Accuracy: 0.630400\n",
      "Epoch 102, CIFAR-10 Batch 4:  Loss:     0.9337 Validation Accuracy: 0.624800\n",
      "Epoch 102, CIFAR-10 Batch 5:  Loss:     0.9383 Validation Accuracy: 0.631200\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:     0.9908 Validation Accuracy: 0.632400\n",
      "Epoch 103, CIFAR-10 Batch 2:  Loss:     0.9450 Validation Accuracy: 0.631800\n",
      "Epoch 103, CIFAR-10 Batch 3:  Loss:     0.9327 Validation Accuracy: 0.626800\n",
      "Epoch 103, CIFAR-10 Batch 4:  Loss:     0.9377 Validation Accuracy: 0.623600\n",
      "Epoch 103, CIFAR-10 Batch 5:  Loss:     0.9589 Validation Accuracy: 0.619200\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:     0.9883 Validation Accuracy: 0.628200\n",
      "Epoch 104, CIFAR-10 Batch 2:  Loss:     0.9580 Validation Accuracy: 0.621200\n",
      "Epoch 104, CIFAR-10 Batch 3:  Loss:     0.9558 Validation Accuracy: 0.624800\n",
      "Epoch 104, CIFAR-10 Batch 4:  Loss:     0.9513 Validation Accuracy: 0.623200\n",
      "Epoch 104, CIFAR-10 Batch 5:  Loss:     0.9556 Validation Accuracy: 0.620000\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:     0.9786 Validation Accuracy: 0.630400\n",
      "Epoch 105, CIFAR-10 Batch 2:  Loss:     0.9455 Validation Accuracy: 0.628400\n",
      "Epoch 105, CIFAR-10 Batch 3:  Loss:     0.9486 Validation Accuracy: 0.628600\n",
      "Epoch 105, CIFAR-10 Batch 4:  Loss:     0.9314 Validation Accuracy: 0.631800\n",
      "Epoch 105, CIFAR-10 Batch 5:  Loss:     0.9563 Validation Accuracy: 0.621600\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:     0.9847 Validation Accuracy: 0.631600\n",
      "Epoch 106, CIFAR-10 Batch 2:  Loss:     0.9417 Validation Accuracy: 0.634800\n",
      "Epoch 106, CIFAR-10 Batch 3:  Loss:     0.9254 Validation Accuracy: 0.629600\n",
      "Epoch 106, CIFAR-10 Batch 4:  Loss:     0.9202 Validation Accuracy: 0.630000\n",
      "Epoch 106, CIFAR-10 Batch 5:  Loss:     0.9449 Validation Accuracy: 0.624600\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:     0.9741 Validation Accuracy: 0.631000\n",
      "Epoch 107, CIFAR-10 Batch 2:  Loss:     0.9364 Validation Accuracy: 0.630800\n",
      "Epoch 107, CIFAR-10 Batch 3:  Loss:     0.9271 Validation Accuracy: 0.631400\n",
      "Epoch 107, CIFAR-10 Batch 4:  Loss:     0.9251 Validation Accuracy: 0.632600\n",
      "Epoch 107, CIFAR-10 Batch 5:  Loss:     0.9405 Validation Accuracy: 0.624800\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:     0.9722 Validation Accuracy: 0.633000\n",
      "Epoch 108, CIFAR-10 Batch 2:  Loss:     0.9401 Validation Accuracy: 0.624200\n",
      "Epoch 108, CIFAR-10 Batch 3:  Loss:     0.9367 Validation Accuracy: 0.626800\n",
      "Epoch 108, CIFAR-10 Batch 4:  Loss:     0.9102 Validation Accuracy: 0.628400\n",
      "Epoch 108, CIFAR-10 Batch 5:  Loss:     0.9443 Validation Accuracy: 0.627200\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss:     0.9750 Validation Accuracy: 0.635200\n",
      "Epoch 109, CIFAR-10 Batch 2:  Loss:     0.9301 Validation Accuracy: 0.631600\n",
      "Epoch 109, CIFAR-10 Batch 3:  Loss:     0.9357 Validation Accuracy: 0.628600\n",
      "Epoch 109, CIFAR-10 Batch 4:  Loss:     0.9175 Validation Accuracy: 0.633600\n",
      "Epoch 109, CIFAR-10 Batch 5:  Loss:     0.9418 Validation Accuracy: 0.623000\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:     0.9669 Validation Accuracy: 0.633000\n",
      "Epoch 110, CIFAR-10 Batch 2:  Loss:     0.9245 Validation Accuracy: 0.635600\n",
      "Epoch 110, CIFAR-10 Batch 3:  Loss:     0.9259 Validation Accuracy: 0.633200\n",
      "Epoch 110, CIFAR-10 Batch 4:  Loss:     0.9082 Validation Accuracy: 0.635800\n",
      "Epoch 110, CIFAR-10 Batch 5:  Loss:     0.9311 Validation Accuracy: 0.625800\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:     0.9722 Validation Accuracy: 0.634600\n",
      "Epoch 111, CIFAR-10 Batch 2:  Loss:     0.9349 Validation Accuracy: 0.628000\n",
      "Epoch 111, CIFAR-10 Batch 3:  Loss:     0.9204 Validation Accuracy: 0.629600\n",
      "Epoch 111, CIFAR-10 Batch 4:  Loss:     0.9058 Validation Accuracy: 0.635000\n",
      "Epoch 111, CIFAR-10 Batch 5:  Loss:     0.9238 Validation Accuracy: 0.634800\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:     0.9732 Validation Accuracy: 0.631600\n",
      "Epoch 112, CIFAR-10 Batch 2:  Loss:     0.9362 Validation Accuracy: 0.633000\n",
      "Epoch 112, CIFAR-10 Batch 3:  Loss:     0.9198 Validation Accuracy: 0.623200\n",
      "Epoch 112, CIFAR-10 Batch 4:  Loss:     0.9062 Validation Accuracy: 0.633600\n",
      "Epoch 112, CIFAR-10 Batch 5:  Loss:     0.9230 Validation Accuracy: 0.632400\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:     0.9685 Validation Accuracy: 0.630000\n",
      "Epoch 113, CIFAR-10 Batch 2:  Loss:     0.9205 Validation Accuracy: 0.636600\n",
      "Epoch 113, CIFAR-10 Batch 3:  Loss:     0.9198 Validation Accuracy: 0.633400\n",
      "Epoch 113, CIFAR-10 Batch 4:  Loss:     0.9155 Validation Accuracy: 0.629400\n",
      "Epoch 113, CIFAR-10 Batch 5:  Loss:     0.9199 Validation Accuracy: 0.630600\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:     0.9569 Validation Accuracy: 0.639800\n",
      "Epoch 114, CIFAR-10 Batch 2:  Loss:     0.9157 Validation Accuracy: 0.633000\n",
      "Epoch 114, CIFAR-10 Batch 3:  Loss:     0.9242 Validation Accuracy: 0.631200\n",
      "Epoch 114, CIFAR-10 Batch 4:  Loss:     0.9110 Validation Accuracy: 0.634400\n",
      "Epoch 114, CIFAR-10 Batch 5:  Loss:     0.9188 Validation Accuracy: 0.632200\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:     0.9554 Validation Accuracy: 0.635400\n",
      "Epoch 115, CIFAR-10 Batch 2:  Loss:     0.9210 Validation Accuracy: 0.633600\n",
      "Epoch 115, CIFAR-10 Batch 3:  Loss:     0.8996 Validation Accuracy: 0.637000\n",
      "Epoch 115, CIFAR-10 Batch 4:  Loss:     0.9127 Validation Accuracy: 0.635000\n",
      "Epoch 115, CIFAR-10 Batch 5:  Loss:     0.9196 Validation Accuracy: 0.632600\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:     0.9480 Validation Accuracy: 0.638000\n",
      "Epoch 116, CIFAR-10 Batch 2:  Loss:     0.9225 Validation Accuracy: 0.635400\n",
      "Epoch 116, CIFAR-10 Batch 3:  Loss:     0.8895 Validation Accuracy: 0.635400\n",
      "Epoch 116, CIFAR-10 Batch 4:  Loss:     0.9085 Validation Accuracy: 0.630200\n",
      "Epoch 116, CIFAR-10 Batch 5:  Loss:     0.9274 Validation Accuracy: 0.629000\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:     0.9485 Validation Accuracy: 0.641800\n",
      "Epoch 117, CIFAR-10 Batch 2:  Loss:     0.9131 Validation Accuracy: 0.636400\n",
      "Epoch 117, CIFAR-10 Batch 3:  Loss:     0.9018 Validation Accuracy: 0.637400\n",
      "Epoch 117, CIFAR-10 Batch 4:  Loss:     0.9035 Validation Accuracy: 0.634800\n",
      "Epoch 117, CIFAR-10 Batch 5:  Loss:     0.9005 Validation Accuracy: 0.637200\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:     0.9498 Validation Accuracy: 0.637200\n",
      "Epoch 118, CIFAR-10 Batch 2:  Loss:     0.9162 Validation Accuracy: 0.636600\n",
      "Epoch 118, CIFAR-10 Batch 3:  Loss:     0.9016 Validation Accuracy: 0.637200\n",
      "Epoch 118, CIFAR-10 Batch 4:  Loss:     0.8875 Validation Accuracy: 0.635600\n",
      "Epoch 118, CIFAR-10 Batch 5:  Loss:     0.9022 Validation Accuracy: 0.635800\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:     0.9455 Validation Accuracy: 0.634200\n",
      "Epoch 119, CIFAR-10 Batch 2:  Loss:     0.8979 Validation Accuracy: 0.640600\n",
      "Epoch 119, CIFAR-10 Batch 3:  Loss:     0.8995 Validation Accuracy: 0.636000\n",
      "Epoch 119, CIFAR-10 Batch 4:  Loss:     0.8919 Validation Accuracy: 0.631400\n",
      "Epoch 119, CIFAR-10 Batch 5:  Loss:     0.9049 Validation Accuracy: 0.634800\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:     0.9469 Validation Accuracy: 0.639000\n",
      "Epoch 120, CIFAR-10 Batch 2:  Loss:     0.9117 Validation Accuracy: 0.640600\n",
      "Epoch 120, CIFAR-10 Batch 3:  Loss:     0.9065 Validation Accuracy: 0.637200\n",
      "Epoch 120, CIFAR-10 Batch 4:  Loss:     0.8934 Validation Accuracy: 0.634800\n",
      "Epoch 120, CIFAR-10 Batch 5:  Loss:     0.8958 Validation Accuracy: 0.637400\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:     0.9548 Validation Accuracy: 0.636600\n",
      "Epoch 121, CIFAR-10 Batch 2:  Loss:     0.9141 Validation Accuracy: 0.639000\n",
      "Epoch 121, CIFAR-10 Batch 3:  Loss:     0.8800 Validation Accuracy: 0.640400\n",
      "Epoch 121, CIFAR-10 Batch 4:  Loss:     0.8948 Validation Accuracy: 0.635000\n",
      "Epoch 121, CIFAR-10 Batch 5:  Loss:     0.9076 Validation Accuracy: 0.631200\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:     0.9287 Validation Accuracy: 0.639000\n",
      "Epoch 122, CIFAR-10 Batch 2:  Loss:     0.8997 Validation Accuracy: 0.635600\n",
      "Epoch 122, CIFAR-10 Batch 3:  Loss:     0.8835 Validation Accuracy: 0.639400\n",
      "Epoch 122, CIFAR-10 Batch 4:  Loss:     0.8960 Validation Accuracy: 0.624600\n",
      "Epoch 122, CIFAR-10 Batch 5:  Loss:     0.8961 Validation Accuracy: 0.633000\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:     0.9331 Validation Accuracy: 0.638000\n",
      "Epoch 123, CIFAR-10 Batch 2:  Loss:     0.9115 Validation Accuracy: 0.630400\n",
      "Epoch 123, CIFAR-10 Batch 3:  Loss:     0.8956 Validation Accuracy: 0.637400\n",
      "Epoch 123, CIFAR-10 Batch 4:  Loss:     0.8746 Validation Accuracy: 0.635200\n",
      "Epoch 123, CIFAR-10 Batch 5:  Loss:     0.9080 Validation Accuracy: 0.628200\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:     0.9320 Validation Accuracy: 0.637000\n",
      "Epoch 124, CIFAR-10 Batch 2:  Loss:     0.9054 Validation Accuracy: 0.641600\n",
      "Epoch 124, CIFAR-10 Batch 3:  Loss:     0.8653 Validation Accuracy: 0.642800\n",
      "Epoch 124, CIFAR-10 Batch 4:  Loss:     0.8773 Validation Accuracy: 0.643200\n",
      "Epoch 124, CIFAR-10 Batch 5:  Loss:     0.8968 Validation Accuracy: 0.634600\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:     0.9218 Validation Accuracy: 0.638000\n",
      "Epoch 125, CIFAR-10 Batch 2:  Loss:     0.9186 Validation Accuracy: 0.638800\n",
      "Epoch 125, CIFAR-10 Batch 3:  Loss:     0.8892 Validation Accuracy: 0.637800\n",
      "Epoch 125, CIFAR-10 Batch 4:  Loss:     0.8808 Validation Accuracy: 0.639800\n",
      "Epoch 125, CIFAR-10 Batch 5:  Loss:     0.8841 Validation Accuracy: 0.636400\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:     0.9416 Validation Accuracy: 0.637600\n",
      "Epoch 126, CIFAR-10 Batch 2:  Loss:     0.9042 Validation Accuracy: 0.639800\n",
      "Epoch 126, CIFAR-10 Batch 3:  Loss:     0.8662 Validation Accuracy: 0.641800\n",
      "Epoch 126, CIFAR-10 Batch 4:  Loss:     0.8748 Validation Accuracy: 0.639600\n",
      "Epoch 126, CIFAR-10 Batch 5:  Loss:     0.8920 Validation Accuracy: 0.641400\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:     0.9269 Validation Accuracy: 0.638800\n",
      "Epoch 127, CIFAR-10 Batch 2:  Loss:     0.9010 Validation Accuracy: 0.639200\n",
      "Epoch 127, CIFAR-10 Batch 3:  Loss:     0.8734 Validation Accuracy: 0.638800\n",
      "Epoch 127, CIFAR-10 Batch 4:  Loss:     0.8607 Validation Accuracy: 0.642800\n",
      "Epoch 127, CIFAR-10 Batch 5:  Loss:     0.8691 Validation Accuracy: 0.644800\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:     0.9387 Validation Accuracy: 0.639000\n",
      "Epoch 128, CIFAR-10 Batch 2:  Loss:     0.8906 Validation Accuracy: 0.642000\n",
      "Epoch 128, CIFAR-10 Batch 3:  Loss:     0.8776 Validation Accuracy: 0.638000\n",
      "Epoch 128, CIFAR-10 Batch 4:  Loss:     0.8734 Validation Accuracy: 0.637800\n",
      "Epoch 128, CIFAR-10 Batch 5:  Loss:     0.8809 Validation Accuracy: 0.645200\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:     0.9247 Validation Accuracy: 0.639000\n",
      "Epoch 129, CIFAR-10 Batch 2:  Loss:     0.8814 Validation Accuracy: 0.640800\n",
      "Epoch 129, CIFAR-10 Batch 3:  Loss:     0.8796 Validation Accuracy: 0.642000\n",
      "Epoch 129, CIFAR-10 Batch 4:  Loss:     0.8573 Validation Accuracy: 0.636800\n",
      "Epoch 129, CIFAR-10 Batch 5:  Loss:     0.8764 Validation Accuracy: 0.638800\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:     0.9116 Validation Accuracy: 0.642600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130, CIFAR-10 Batch 2:  Loss:     0.8809 Validation Accuracy: 0.640200\n",
      "Epoch 130, CIFAR-10 Batch 3:  Loss:     0.8964 Validation Accuracy: 0.637000\n",
      "Epoch 130, CIFAR-10 Batch 4:  Loss:     0.8749 Validation Accuracy: 0.632200\n",
      "Epoch 130, CIFAR-10 Batch 5:  Loss:     0.8849 Validation Accuracy: 0.634200\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:     0.9289 Validation Accuracy: 0.636400\n",
      "Epoch 131, CIFAR-10 Batch 2:  Loss:     0.8942 Validation Accuracy: 0.641000\n",
      "Epoch 131, CIFAR-10 Batch 3:  Loss:     0.8707 Validation Accuracy: 0.640200\n",
      "Epoch 131, CIFAR-10 Batch 4:  Loss:     0.8868 Validation Accuracy: 0.634200\n",
      "Epoch 131, CIFAR-10 Batch 5:  Loss:     0.8632 Validation Accuracy: 0.644600\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:     0.9148 Validation Accuracy: 0.643000\n",
      "Epoch 132, CIFAR-10 Batch 2:  Loss:     0.8843 Validation Accuracy: 0.642800\n",
      "Epoch 132, CIFAR-10 Batch 3:  Loss:     0.8691 Validation Accuracy: 0.642400\n",
      "Epoch 132, CIFAR-10 Batch 4:  Loss:     0.8616 Validation Accuracy: 0.640800\n",
      "Epoch 132, CIFAR-10 Batch 5:  Loss:     0.8777 Validation Accuracy: 0.640600\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:     0.9193 Validation Accuracy: 0.639800\n",
      "Epoch 133, CIFAR-10 Batch 2:  Loss:     0.8918 Validation Accuracy: 0.638200\n",
      "Epoch 133, CIFAR-10 Batch 3:  Loss:     0.8877 Validation Accuracy: 0.635400\n",
      "Epoch 133, CIFAR-10 Batch 4:  Loss:     0.8807 Validation Accuracy: 0.635200\n",
      "Epoch 133, CIFAR-10 Batch 5:  Loss:     0.8771 Validation Accuracy: 0.636400\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:     0.9168 Validation Accuracy: 0.641600\n",
      "Epoch 134, CIFAR-10 Batch 2:  Loss:     0.8784 Validation Accuracy: 0.640200\n",
      "Epoch 134, CIFAR-10 Batch 3:  Loss:     0.8830 Validation Accuracy: 0.636400\n",
      "Epoch 134, CIFAR-10 Batch 4:  Loss:     0.8570 Validation Accuracy: 0.645000\n",
      "Epoch 134, CIFAR-10 Batch 5:  Loss:     0.8780 Validation Accuracy: 0.636600\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:     0.9160 Validation Accuracy: 0.641800\n",
      "Epoch 135, CIFAR-10 Batch 2:  Loss:     0.8827 Validation Accuracy: 0.639600\n",
      "Epoch 135, CIFAR-10 Batch 3:  Loss:     0.8692 Validation Accuracy: 0.640800\n",
      "Epoch 135, CIFAR-10 Batch 4:  Loss:     0.8648 Validation Accuracy: 0.637400\n",
      "Epoch 135, CIFAR-10 Batch 5:  Loss:     0.8671 Validation Accuracy: 0.635400\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:     0.9105 Validation Accuracy: 0.641000\n",
      "Epoch 136, CIFAR-10 Batch 2:  Loss:     0.8698 Validation Accuracy: 0.644400\n",
      "Epoch 136, CIFAR-10 Batch 3:  Loss:     0.8681 Validation Accuracy: 0.644000\n",
      "Epoch 136, CIFAR-10 Batch 4:  Loss:     0.8554 Validation Accuracy: 0.639000\n",
      "Epoch 136, CIFAR-10 Batch 5:  Loss:     0.8674 Validation Accuracy: 0.639200\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:     0.9084 Validation Accuracy: 0.641000\n",
      "Epoch 137, CIFAR-10 Batch 2:  Loss:     0.8728 Validation Accuracy: 0.637600\n",
      "Epoch 137, CIFAR-10 Batch 3:  Loss:     0.8639 Validation Accuracy: 0.643800\n",
      "Epoch 137, CIFAR-10 Batch 4:  Loss:     0.8575 Validation Accuracy: 0.643000\n",
      "Epoch 137, CIFAR-10 Batch 5:  Loss:     0.8704 Validation Accuracy: 0.632600\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:     0.9003 Validation Accuracy: 0.648400\n",
      "Epoch 138, CIFAR-10 Batch 2:  Loss:     0.8847 Validation Accuracy: 0.634800\n",
      "Epoch 138, CIFAR-10 Batch 3:  Loss:     0.8582 Validation Accuracy: 0.647000\n",
      "Epoch 138, CIFAR-10 Batch 4:  Loss:     0.8556 Validation Accuracy: 0.644400\n",
      "Epoch 138, CIFAR-10 Batch 5:  Loss:     0.8741 Validation Accuracy: 0.632400\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:     0.9031 Validation Accuracy: 0.642400\n",
      "Epoch 139, CIFAR-10 Batch 2:  Loss:     0.8676 Validation Accuracy: 0.643000\n",
      "Epoch 139, CIFAR-10 Batch 3:  Loss:     0.8701 Validation Accuracy: 0.646000\n",
      "Epoch 139, CIFAR-10 Batch 4:  Loss:     0.8467 Validation Accuracy: 0.646600\n",
      "Epoch 139, CIFAR-10 Batch 5:  Loss:     0.8808 Validation Accuracy: 0.638600\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:     0.8932 Validation Accuracy: 0.650000\n",
      "Epoch 140, CIFAR-10 Batch 2:  Loss:     0.8598 Validation Accuracy: 0.646400\n",
      "Epoch 140, CIFAR-10 Batch 3:  Loss:     0.8564 Validation Accuracy: 0.643400\n",
      "Epoch 140, CIFAR-10 Batch 4:  Loss:     0.8531 Validation Accuracy: 0.644600\n",
      "Epoch 140, CIFAR-10 Batch 5:  Loss:     0.8680 Validation Accuracy: 0.636800\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:     0.8865 Validation Accuracy: 0.649400\n",
      "Epoch 141, CIFAR-10 Batch 2:  Loss:     0.8568 Validation Accuracy: 0.646000\n",
      "Epoch 141, CIFAR-10 Batch 3:  Loss:     0.8489 Validation Accuracy: 0.645600\n",
      "Epoch 141, CIFAR-10 Batch 4:  Loss:     0.8479 Validation Accuracy: 0.646200\n",
      "Epoch 141, CIFAR-10 Batch 5:  Loss:     0.8678 Validation Accuracy: 0.642400\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:     0.9127 Validation Accuracy: 0.643200\n",
      "Epoch 142, CIFAR-10 Batch 2:  Loss:     0.8551 Validation Accuracy: 0.645400\n",
      "Epoch 142, CIFAR-10 Batch 3:  Loss:     0.8727 Validation Accuracy: 0.645000\n",
      "Epoch 142, CIFAR-10 Batch 4:  Loss:     0.8369 Validation Accuracy: 0.645800\n",
      "Epoch 142, CIFAR-10 Batch 5:  Loss:     0.8670 Validation Accuracy: 0.644000\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:     0.8880 Validation Accuracy: 0.648000\n",
      "Epoch 143, CIFAR-10 Batch 2:  Loss:     0.8558 Validation Accuracy: 0.645600\n",
      "Epoch 143, CIFAR-10 Batch 3:  Loss:     0.8475 Validation Accuracy: 0.649000\n",
      "Epoch 143, CIFAR-10 Batch 4:  Loss:     0.8420 Validation Accuracy: 0.648000\n",
      "Epoch 143, CIFAR-10 Batch 5:  Loss:     0.8543 Validation Accuracy: 0.642200\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:     0.8804 Validation Accuracy: 0.646200\n",
      "Epoch 144, CIFAR-10 Batch 2:  Loss:     0.8559 Validation Accuracy: 0.647200\n",
      "Epoch 144, CIFAR-10 Batch 3:  Loss:     0.8532 Validation Accuracy: 0.644600\n",
      "Epoch 144, CIFAR-10 Batch 4:  Loss:     0.8448 Validation Accuracy: 0.648600\n",
      "Epoch 144, CIFAR-10 Batch 5:  Loss:     0.8487 Validation Accuracy: 0.645400\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:     0.8799 Validation Accuracy: 0.648200\n",
      "Epoch 145, CIFAR-10 Batch 2:  Loss:     0.8597 Validation Accuracy: 0.642200\n",
      "Epoch 145, CIFAR-10 Batch 3:  Loss:     0.8395 Validation Accuracy: 0.650000\n",
      "Epoch 145, CIFAR-10 Batch 4:  Loss:     0.8318 Validation Accuracy: 0.642800\n",
      "Epoch 145, CIFAR-10 Batch 5:  Loss:     0.8544 Validation Accuracy: 0.641200\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:     0.8892 Validation Accuracy: 0.646200\n",
      "Epoch 146, CIFAR-10 Batch 2:  Loss:     0.8764 Validation Accuracy: 0.633400\n",
      "Epoch 146, CIFAR-10 Batch 3:  Loss:     0.8463 Validation Accuracy: 0.643600\n",
      "Epoch 146, CIFAR-10 Batch 4:  Loss:     0.8495 Validation Accuracy: 0.639800\n",
      "Epoch 146, CIFAR-10 Batch 5:  Loss:     0.8438 Validation Accuracy: 0.643600\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:     0.8845 Validation Accuracy: 0.647400\n",
      "Epoch 147, CIFAR-10 Batch 2:  Loss:     0.8345 Validation Accuracy: 0.648800\n",
      "Epoch 147, CIFAR-10 Batch 3:  Loss:     0.8484 Validation Accuracy: 0.644400\n",
      "Epoch 147, CIFAR-10 Batch 4:  Loss:     0.8321 Validation Accuracy: 0.643000\n",
      "Epoch 147, CIFAR-10 Batch 5:  Loss:     0.8399 Validation Accuracy: 0.643000\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:     0.8876 Validation Accuracy: 0.649200\n",
      "Epoch 148, CIFAR-10 Batch 2:  Loss:     0.8542 Validation Accuracy: 0.648000\n",
      "Epoch 148, CIFAR-10 Batch 3:  Loss:     0.8602 Validation Accuracy: 0.648000\n",
      "Epoch 148, CIFAR-10 Batch 4:  Loss:     0.8288 Validation Accuracy: 0.649800\n",
      "Epoch 148, CIFAR-10 Batch 5:  Loss:     0.8599 Validation Accuracy: 0.643600\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:     0.8732 Validation Accuracy: 0.648000\n",
      "Epoch 149, CIFAR-10 Batch 2:  Loss:     0.8474 Validation Accuracy: 0.647800\n",
      "Epoch 149, CIFAR-10 Batch 3:  Loss:     0.8499 Validation Accuracy: 0.651400\n",
      "Epoch 149, CIFAR-10 Batch 4:  Loss:     0.8145 Validation Accuracy: 0.648600\n",
      "Epoch 149, CIFAR-10 Batch 5:  Loss:     0.8424 Validation Accuracy: 0.642800\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:     0.8844 Validation Accuracy: 0.647200\n",
      "Epoch 150, CIFAR-10 Batch 2:  Loss:     0.8526 Validation Accuracy: 0.644600\n",
      "Epoch 150, CIFAR-10 Batch 3:  Loss:     0.8559 Validation Accuracy: 0.646200\n",
      "Epoch 150, CIFAR-10 Batch 4:  Loss:     0.8273 Validation Accuracy: 0.649800\n",
      "Epoch 150, CIFAR-10 Batch 5:  Loss:     0.8407 Validation Accuracy: 0.649000\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:     0.8701 Validation Accuracy: 0.649800\n",
      "Epoch 151, CIFAR-10 Batch 2:  Loss:     0.8474 Validation Accuracy: 0.646800\n",
      "Epoch 151, CIFAR-10 Batch 3:  Loss:     0.8380 Validation Accuracy: 0.652200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151, CIFAR-10 Batch 4:  Loss:     0.8220 Validation Accuracy: 0.651800\n",
      "Epoch 151, CIFAR-10 Batch 5:  Loss:     0.8278 Validation Accuracy: 0.643400\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:     0.8795 Validation Accuracy: 0.643000\n",
      "Epoch 152, CIFAR-10 Batch 2:  Loss:     0.8445 Validation Accuracy: 0.647800\n",
      "Epoch 152, CIFAR-10 Batch 3:  Loss:     0.8434 Validation Accuracy: 0.653400\n",
      "Epoch 152, CIFAR-10 Batch 4:  Loss:     0.8124 Validation Accuracy: 0.648400\n",
      "Epoch 152, CIFAR-10 Batch 5:  Loss:     0.8372 Validation Accuracy: 0.646200\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:     0.8686 Validation Accuracy: 0.651400\n",
      "Epoch 153, CIFAR-10 Batch 2:  Loss:     0.8356 Validation Accuracy: 0.650200\n",
      "Epoch 153, CIFAR-10 Batch 3:  Loss:     0.8296 Validation Accuracy: 0.653400\n",
      "Epoch 153, CIFAR-10 Batch 4:  Loss:     0.8148 Validation Accuracy: 0.651200\n",
      "Epoch 153, CIFAR-10 Batch 5:  Loss:     0.8351 Validation Accuracy: 0.646800\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:     0.8499 Validation Accuracy: 0.652600\n",
      "Epoch 154, CIFAR-10 Batch 2:  Loss:     0.8392 Validation Accuracy: 0.651200\n",
      "Epoch 154, CIFAR-10 Batch 3:  Loss:     0.8323 Validation Accuracy: 0.652200\n",
      "Epoch 154, CIFAR-10 Batch 4:  Loss:     0.8186 Validation Accuracy: 0.650000\n",
      "Epoch 154, CIFAR-10 Batch 5:  Loss:     0.8447 Validation Accuracy: 0.640600\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:     0.8729 Validation Accuracy: 0.647600\n",
      "Epoch 155, CIFAR-10 Batch 2:  Loss:     0.8353 Validation Accuracy: 0.650400\n",
      "Epoch 155, CIFAR-10 Batch 3:  Loss:     0.8320 Validation Accuracy: 0.651800\n",
      "Epoch 155, CIFAR-10 Batch 4:  Loss:     0.8186 Validation Accuracy: 0.651200\n",
      "Epoch 155, CIFAR-10 Batch 5:  Loss:     0.8254 Validation Accuracy: 0.649000\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:     0.8633 Validation Accuracy: 0.650000\n",
      "Epoch 156, CIFAR-10 Batch 2:  Loss:     0.8239 Validation Accuracy: 0.649600\n",
      "Epoch 156, CIFAR-10 Batch 3:  Loss:     0.8489 Validation Accuracy: 0.650000\n",
      "Epoch 156, CIFAR-10 Batch 4:  Loss:     0.8098 Validation Accuracy: 0.649600\n",
      "Epoch 156, CIFAR-10 Batch 5:  Loss:     0.8442 Validation Accuracy: 0.642600\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:     0.8616 Validation Accuracy: 0.650800\n",
      "Epoch 157, CIFAR-10 Batch 2:  Loss:     0.8209 Validation Accuracy: 0.651200\n",
      "Epoch 157, CIFAR-10 Batch 3:  Loss:     0.8425 Validation Accuracy: 0.650200\n",
      "Epoch 157, CIFAR-10 Batch 4:  Loss:     0.8005 Validation Accuracy: 0.651000\n",
      "Epoch 157, CIFAR-10 Batch 5:  Loss:     0.8233 Validation Accuracy: 0.650200\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:     0.8652 Validation Accuracy: 0.647000\n",
      "Epoch 158, CIFAR-10 Batch 2:  Loss:     0.8204 Validation Accuracy: 0.654000\n",
      "Epoch 158, CIFAR-10 Batch 3:  Loss:     0.8286 Validation Accuracy: 0.650000\n",
      "Epoch 158, CIFAR-10 Batch 4:  Loss:     0.8031 Validation Accuracy: 0.647000\n",
      "Epoch 158, CIFAR-10 Batch 5:  Loss:     0.8267 Validation Accuracy: 0.648400\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:     0.8678 Validation Accuracy: 0.647200\n",
      "Epoch 159, CIFAR-10 Batch 2:  Loss:     0.8296 Validation Accuracy: 0.651600\n",
      "Epoch 159, CIFAR-10 Batch 3:  Loss:     0.8318 Validation Accuracy: 0.646200\n",
      "Epoch 159, CIFAR-10 Batch 4:  Loss:     0.8001 Validation Accuracy: 0.645800\n",
      "Epoch 159, CIFAR-10 Batch 5:  Loss:     0.8317 Validation Accuracy: 0.645000\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:     0.8763 Validation Accuracy: 0.640800\n",
      "Epoch 160, CIFAR-10 Batch 2:  Loss:     0.8209 Validation Accuracy: 0.649800\n",
      "Epoch 160, CIFAR-10 Batch 3:  Loss:     0.8231 Validation Accuracy: 0.656000\n",
      "Epoch 160, CIFAR-10 Batch 4:  Loss:     0.8073 Validation Accuracy: 0.654600\n",
      "Epoch 160, CIFAR-10 Batch 5:  Loss:     0.8307 Validation Accuracy: 0.650400\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:     0.8477 Validation Accuracy: 0.654800\n",
      "Epoch 161, CIFAR-10 Batch 2:  Loss:     0.8153 Validation Accuracy: 0.654800\n",
      "Epoch 161, CIFAR-10 Batch 3:  Loss:     0.8050 Validation Accuracy: 0.659400\n",
      "Epoch 161, CIFAR-10 Batch 4:  Loss:     0.7908 Validation Accuracy: 0.654800\n",
      "Epoch 161, CIFAR-10 Batch 5:  Loss:     0.8078 Validation Accuracy: 0.654200\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:     0.8622 Validation Accuracy: 0.650400\n",
      "Epoch 162, CIFAR-10 Batch 2:  Loss:     0.8273 Validation Accuracy: 0.644000\n",
      "Epoch 162, CIFAR-10 Batch 3:  Loss:     0.8252 Validation Accuracy: 0.655200\n",
      "Epoch 162, CIFAR-10 Batch 4:  Loss:     0.7986 Validation Accuracy: 0.649000\n",
      "Epoch 162, CIFAR-10 Batch 5:  Loss:     0.8174 Validation Accuracy: 0.649800\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:     0.8426 Validation Accuracy: 0.652400\n",
      "Epoch 163, CIFAR-10 Batch 2:  Loss:     0.8363 Validation Accuracy: 0.648200\n",
      "Epoch 163, CIFAR-10 Batch 3:  Loss:     0.8284 Validation Accuracy: 0.653600\n",
      "Epoch 163, CIFAR-10 Batch 4:  Loss:     0.7877 Validation Accuracy: 0.654000\n",
      "Epoch 163, CIFAR-10 Batch 5:  Loss:     0.8100 Validation Accuracy: 0.655200\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:     0.8373 Validation Accuracy: 0.656000\n",
      "Epoch 164, CIFAR-10 Batch 2:  Loss:     0.8263 Validation Accuracy: 0.651800\n",
      "Epoch 164, CIFAR-10 Batch 3:  Loss:     0.8200 Validation Accuracy: 0.651600\n",
      "Epoch 164, CIFAR-10 Batch 4:  Loss:     0.7916 Validation Accuracy: 0.654000\n",
      "Epoch 164, CIFAR-10 Batch 5:  Loss:     0.8047 Validation Accuracy: 0.654000\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:     0.8408 Validation Accuracy: 0.655400\n",
      "Epoch 165, CIFAR-10 Batch 2:  Loss:     0.8230 Validation Accuracy: 0.652000\n",
      "Epoch 165, CIFAR-10 Batch 3:  Loss:     0.8159 Validation Accuracy: 0.659400\n",
      "Epoch 165, CIFAR-10 Batch 4:  Loss:     0.7913 Validation Accuracy: 0.657800\n",
      "Epoch 165, CIFAR-10 Batch 5:  Loss:     0.8364 Validation Accuracy: 0.648600\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:     0.8475 Validation Accuracy: 0.653200\n",
      "Epoch 166, CIFAR-10 Batch 2:  Loss:     0.8068 Validation Accuracy: 0.652400\n",
      "Epoch 166, CIFAR-10 Batch 3:  Loss:     0.8067 Validation Accuracy: 0.659000\n",
      "Epoch 166, CIFAR-10 Batch 4:  Loss:     0.8011 Validation Accuracy: 0.654600\n",
      "Epoch 166, CIFAR-10 Batch 5:  Loss:     0.8320 Validation Accuracy: 0.643000\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:     0.8424 Validation Accuracy: 0.656200\n",
      "Epoch 167, CIFAR-10 Batch 2:  Loss:     0.8006 Validation Accuracy: 0.654000\n",
      "Epoch 167, CIFAR-10 Batch 3:  Loss:     0.8052 Validation Accuracy: 0.656200\n",
      "Epoch 167, CIFAR-10 Batch 4:  Loss:     0.7912 Validation Accuracy: 0.658000\n",
      "Epoch 167, CIFAR-10 Batch 5:  Loss:     0.8047 Validation Accuracy: 0.652400\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:     0.8619 Validation Accuracy: 0.654600\n",
      "Epoch 168, CIFAR-10 Batch 2:  Loss:     0.8060 Validation Accuracy: 0.651000\n",
      "Epoch 168, CIFAR-10 Batch 3:  Loss:     0.8127 Validation Accuracy: 0.656400\n",
      "Epoch 168, CIFAR-10 Batch 4:  Loss:     0.7905 Validation Accuracy: 0.651000\n",
      "Epoch 168, CIFAR-10 Batch 5:  Loss:     0.8045 Validation Accuracy: 0.658200\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:     0.8373 Validation Accuracy: 0.658400\n",
      "Epoch 169, CIFAR-10 Batch 2:  Loss:     0.8170 Validation Accuracy: 0.642400\n",
      "Epoch 169, CIFAR-10 Batch 3:  Loss:     0.8144 Validation Accuracy: 0.654800\n",
      "Epoch 169, CIFAR-10 Batch 4:  Loss:     0.7947 Validation Accuracy: 0.654000\n",
      "Epoch 169, CIFAR-10 Batch 5:  Loss:     0.8153 Validation Accuracy: 0.652600\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:     0.8316 Validation Accuracy: 0.658000\n",
      "Epoch 170, CIFAR-10 Batch 2:  Loss:     0.8113 Validation Accuracy: 0.656400\n",
      "Epoch 170, CIFAR-10 Batch 3:  Loss:     0.8275 Validation Accuracy: 0.651200\n",
      "Epoch 170, CIFAR-10 Batch 4:  Loss:     0.7864 Validation Accuracy: 0.659200\n",
      "Epoch 170, CIFAR-10 Batch 5:  Loss:     0.8074 Validation Accuracy: 0.651800\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:     0.8309 Validation Accuracy: 0.660400\n",
      "Epoch 171, CIFAR-10 Batch 2:  Loss:     0.8114 Validation Accuracy: 0.652800\n",
      "Epoch 171, CIFAR-10 Batch 3:  Loss:     0.8190 Validation Accuracy: 0.652000\n",
      "Epoch 171, CIFAR-10 Batch 4:  Loss:     0.7741 Validation Accuracy: 0.660600\n",
      "Epoch 171, CIFAR-10 Batch 5:  Loss:     0.8002 Validation Accuracy: 0.656600\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:     0.8226 Validation Accuracy: 0.662400\n",
      "Epoch 172, CIFAR-10 Batch 2:  Loss:     0.8015 Validation Accuracy: 0.652000\n",
      "Epoch 172, CIFAR-10 Batch 3:  Loss:     0.8177 Validation Accuracy: 0.654800\n",
      "Epoch 172, CIFAR-10 Batch 4:  Loss:     0.7775 Validation Accuracy: 0.657800\n",
      "Epoch 172, CIFAR-10 Batch 5:  Loss:     0.7871 Validation Accuracy: 0.662000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173, CIFAR-10 Batch 1:  Loss:     0.8222 Validation Accuracy: 0.661200\n",
      "Epoch 173, CIFAR-10 Batch 2:  Loss:     0.8108 Validation Accuracy: 0.655200\n",
      "Epoch 173, CIFAR-10 Batch 3:  Loss:     0.8130 Validation Accuracy: 0.655000\n",
      "Epoch 173, CIFAR-10 Batch 4:  Loss:     0.7769 Validation Accuracy: 0.660400\n",
      "Epoch 173, CIFAR-10 Batch 5:  Loss:     0.8002 Validation Accuracy: 0.661800\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:     0.8143 Validation Accuracy: 0.661000\n",
      "Epoch 174, CIFAR-10 Batch 2:  Loss:     0.7995 Validation Accuracy: 0.655600\n",
      "Epoch 174, CIFAR-10 Batch 3:  Loss:     0.8090 Validation Accuracy: 0.654800\n",
      "Epoch 174, CIFAR-10 Batch 4:  Loss:     0.7730 Validation Accuracy: 0.653000\n",
      "Epoch 174, CIFAR-10 Batch 5:  Loss:     0.7839 Validation Accuracy: 0.659000\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:     0.8197 Validation Accuracy: 0.655600\n",
      "Epoch 175, CIFAR-10 Batch 2:  Loss:     0.8038 Validation Accuracy: 0.655400\n",
      "Epoch 175, CIFAR-10 Batch 3:  Loss:     0.8156 Validation Accuracy: 0.650800\n",
      "Epoch 175, CIFAR-10 Batch 4:  Loss:     0.7687 Validation Accuracy: 0.656800\n",
      "Epoch 175, CIFAR-10 Batch 5:  Loss:     0.7843 Validation Accuracy: 0.658600\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:     0.8267 Validation Accuracy: 0.661600\n",
      "Epoch 176, CIFAR-10 Batch 2:  Loss:     0.8048 Validation Accuracy: 0.645200\n",
      "Epoch 176, CIFAR-10 Batch 3:  Loss:     0.8110 Validation Accuracy: 0.653000\n",
      "Epoch 176, CIFAR-10 Batch 4:  Loss:     0.7908 Validation Accuracy: 0.656400\n",
      "Epoch 176, CIFAR-10 Batch 5:  Loss:     0.8065 Validation Accuracy: 0.653200\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:     0.8481 Validation Accuracy: 0.650600\n",
      "Epoch 177, CIFAR-10 Batch 2:  Loss:     0.7941 Validation Accuracy: 0.651600\n",
      "Epoch 177, CIFAR-10 Batch 3:  Loss:     0.7991 Validation Accuracy: 0.658200\n",
      "Epoch 177, CIFAR-10 Batch 4:  Loss:     0.7767 Validation Accuracy: 0.654800\n",
      "Epoch 177, CIFAR-10 Batch 5:  Loss:     0.7916 Validation Accuracy: 0.656600\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:     0.8482 Validation Accuracy: 0.647200\n",
      "Epoch 178, CIFAR-10 Batch 2:  Loss:     0.8156 Validation Accuracy: 0.657400\n",
      "Epoch 178, CIFAR-10 Batch 3:  Loss:     0.7984 Validation Accuracy: 0.659000\n",
      "Epoch 178, CIFAR-10 Batch 4:  Loss:     0.7674 Validation Accuracy: 0.659600\n",
      "Epoch 178, CIFAR-10 Batch 5:  Loss:     0.7994 Validation Accuracy: 0.655600\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:     0.8330 Validation Accuracy: 0.658600\n",
      "Epoch 179, CIFAR-10 Batch 2:  Loss:     0.8117 Validation Accuracy: 0.647400\n",
      "Epoch 179, CIFAR-10 Batch 3:  Loss:     0.8093 Validation Accuracy: 0.651200\n",
      "Epoch 179, CIFAR-10 Batch 4:  Loss:     0.7685 Validation Accuracy: 0.658200\n",
      "Epoch 179, CIFAR-10 Batch 5:  Loss:     0.8060 Validation Accuracy: 0.654600\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:     0.8248 Validation Accuracy: 0.654800\n",
      "Epoch 180, CIFAR-10 Batch 2:  Loss:     0.7966 Validation Accuracy: 0.656600\n",
      "Epoch 180, CIFAR-10 Batch 3:  Loss:     0.7992 Validation Accuracy: 0.653200\n",
      "Epoch 180, CIFAR-10 Batch 4:  Loss:     0.7652 Validation Accuracy: 0.660200\n",
      "Epoch 180, CIFAR-10 Batch 5:  Loss:     0.7868 Validation Accuracy: 0.652600\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:     0.8237 Validation Accuracy: 0.654400\n",
      "Epoch 181, CIFAR-10 Batch 2:  Loss:     0.7965 Validation Accuracy: 0.652600\n",
      "Epoch 181, CIFAR-10 Batch 3:  Loss:     0.8080 Validation Accuracy: 0.652000\n",
      "Epoch 181, CIFAR-10 Batch 4:  Loss:     0.7601 Validation Accuracy: 0.663600\n",
      "Epoch 181, CIFAR-10 Batch 5:  Loss:     0.7917 Validation Accuracy: 0.661400\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:     0.8168 Validation Accuracy: 0.659000\n",
      "Epoch 182, CIFAR-10 Batch 2:  Loss:     0.8034 Validation Accuracy: 0.652600\n",
      "Epoch 182, CIFAR-10 Batch 3:  Loss:     0.8142 Validation Accuracy: 0.650200\n",
      "Epoch 182, CIFAR-10 Batch 4:  Loss:     0.7661 Validation Accuracy: 0.657600\n",
      "Epoch 182, CIFAR-10 Batch 5:  Loss:     0.7904 Validation Accuracy: 0.657200\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:     0.8206 Validation Accuracy: 0.654400\n",
      "Epoch 183, CIFAR-10 Batch 2:  Loss:     0.8028 Validation Accuracy: 0.646000\n",
      "Epoch 183, CIFAR-10 Batch 3:  Loss:     0.7969 Validation Accuracy: 0.658000\n",
      "Epoch 183, CIFAR-10 Batch 4:  Loss:     0.7526 Validation Accuracy: 0.655800\n",
      "Epoch 183, CIFAR-10 Batch 5:  Loss:     0.7697 Validation Accuracy: 0.661200\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:     0.8205 Validation Accuracy: 0.655800\n",
      "Epoch 184, CIFAR-10 Batch 2:  Loss:     0.8029 Validation Accuracy: 0.647200\n",
      "Epoch 184, CIFAR-10 Batch 3:  Loss:     0.7906 Validation Accuracy: 0.658600\n",
      "Epoch 184, CIFAR-10 Batch 4:  Loss:     0.7587 Validation Accuracy: 0.663800\n",
      "Epoch 184, CIFAR-10 Batch 5:  Loss:     0.7709 Validation Accuracy: 0.656200\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:     0.7999 Validation Accuracy: 0.659200\n",
      "Epoch 185, CIFAR-10 Batch 2:  Loss:     0.7949 Validation Accuracy: 0.652600\n",
      "Epoch 185, CIFAR-10 Batch 3:  Loss:     0.8136 Validation Accuracy: 0.648000\n",
      "Epoch 185, CIFAR-10 Batch 4:  Loss:     0.7551 Validation Accuracy: 0.660000\n",
      "Epoch 185, CIFAR-10 Batch 5:  Loss:     0.7948 Validation Accuracy: 0.651200\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:     0.8313 Validation Accuracy: 0.654000\n",
      "Epoch 186, CIFAR-10 Batch 2:  Loss:     0.7939 Validation Accuracy: 0.658200\n",
      "Epoch 186, CIFAR-10 Batch 3:  Loss:     0.8110 Validation Accuracy: 0.649000\n",
      "Epoch 186, CIFAR-10 Batch 4:  Loss:     0.7582 Validation Accuracy: 0.657000\n",
      "Epoch 186, CIFAR-10 Batch 5:  Loss:     0.7742 Validation Accuracy: 0.659400\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:     0.8131 Validation Accuracy: 0.657400\n",
      "Epoch 187, CIFAR-10 Batch 2:  Loss:     0.7877 Validation Accuracy: 0.651200\n",
      "Epoch 187, CIFAR-10 Batch 3:  Loss:     0.7981 Validation Accuracy: 0.657200\n",
      "Epoch 187, CIFAR-10 Batch 4:  Loss:     0.7580 Validation Accuracy: 0.665000\n",
      "Epoch 187, CIFAR-10 Batch 5:  Loss:     0.7744 Validation Accuracy: 0.661800\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:     0.7983 Validation Accuracy: 0.659800\n",
      "Epoch 188, CIFAR-10 Batch 2:  Loss:     0.7853 Validation Accuracy: 0.649600\n",
      "Epoch 188, CIFAR-10 Batch 3:  Loss:     0.7808 Validation Accuracy: 0.661600\n",
      "Epoch 188, CIFAR-10 Batch 4:  Loss:     0.7471 Validation Accuracy: 0.656800\n",
      "Epoch 188, CIFAR-10 Batch 5:  Loss:     0.7763 Validation Accuracy: 0.658000\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:     0.8104 Validation Accuracy: 0.660400\n",
      "Epoch 189, CIFAR-10 Batch 2:  Loss:     0.7855 Validation Accuracy: 0.654200\n",
      "Epoch 189, CIFAR-10 Batch 3:  Loss:     0.7764 Validation Accuracy: 0.660400\n",
      "Epoch 189, CIFAR-10 Batch 4:  Loss:     0.7634 Validation Accuracy: 0.659200\n",
      "Epoch 189, CIFAR-10 Batch 5:  Loss:     0.7595 Validation Accuracy: 0.659400\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:     0.8234 Validation Accuracy: 0.648000\n",
      "Epoch 190, CIFAR-10 Batch 2:  Loss:     0.7753 Validation Accuracy: 0.652400\n",
      "Epoch 190, CIFAR-10 Batch 3:  Loss:     0.7867 Validation Accuracy: 0.658000\n",
      "Epoch 190, CIFAR-10 Batch 4:  Loss:     0.7461 Validation Accuracy: 0.661600\n",
      "Epoch 190, CIFAR-10 Batch 5:  Loss:     0.7625 Validation Accuracy: 0.664400\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:     0.8130 Validation Accuracy: 0.660000\n",
      "Epoch 191, CIFAR-10 Batch 2:  Loss:     0.7773 Validation Accuracy: 0.661600\n",
      "Epoch 191, CIFAR-10 Batch 3:  Loss:     0.7638 Validation Accuracy: 0.666400\n",
      "Epoch 191, CIFAR-10 Batch 4:  Loss:     0.7375 Validation Accuracy: 0.662600\n",
      "Epoch 191, CIFAR-10 Batch 5:  Loss:     0.7646 Validation Accuracy: 0.660600\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:     0.8031 Validation Accuracy: 0.661600\n",
      "Epoch 192, CIFAR-10 Batch 2:  Loss:     0.7680 Validation Accuracy: 0.657200\n",
      "Epoch 192, CIFAR-10 Batch 3:  Loss:     0.8019 Validation Accuracy: 0.649600\n",
      "Epoch 192, CIFAR-10 Batch 4:  Loss:     0.7418 Validation Accuracy: 0.654600\n",
      "Epoch 192, CIFAR-10 Batch 5:  Loss:     0.7597 Validation Accuracy: 0.657800\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:     0.8242 Validation Accuracy: 0.658400\n",
      "Epoch 193, CIFAR-10 Batch 2:  Loss:     0.7903 Validation Accuracy: 0.648800\n",
      "Epoch 193, CIFAR-10 Batch 3:  Loss:     0.7784 Validation Accuracy: 0.658200\n",
      "Epoch 193, CIFAR-10 Batch 4:  Loss:     0.7496 Validation Accuracy: 0.661000\n",
      "Epoch 193, CIFAR-10 Batch 5:  Loss:     0.7605 Validation Accuracy: 0.665600\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:     0.7984 Validation Accuracy: 0.659200\n",
      "Epoch 194, CIFAR-10 Batch 2:  Loss:     0.7762 Validation Accuracy: 0.662000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194, CIFAR-10 Batch 3:  Loss:     0.7843 Validation Accuracy: 0.655600\n",
      "Epoch 194, CIFAR-10 Batch 4:  Loss:     0.7449 Validation Accuracy: 0.659600\n",
      "Epoch 194, CIFAR-10 Batch 5:  Loss:     0.7712 Validation Accuracy: 0.657600\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:     0.7941 Validation Accuracy: 0.660000\n",
      "Epoch 195, CIFAR-10 Batch 2:  Loss:     0.7836 Validation Accuracy: 0.655000\n",
      "Epoch 195, CIFAR-10 Batch 3:  Loss:     0.7763 Validation Accuracy: 0.662800\n",
      "Epoch 195, CIFAR-10 Batch 4:  Loss:     0.7407 Validation Accuracy: 0.666600\n",
      "Epoch 195, CIFAR-10 Batch 5:  Loss:     0.7687 Validation Accuracy: 0.656200\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:     0.7884 Validation Accuracy: 0.658800\n",
      "Epoch 196, CIFAR-10 Batch 2:  Loss:     0.7772 Validation Accuracy: 0.658200\n",
      "Epoch 196, CIFAR-10 Batch 3:  Loss:     0.7856 Validation Accuracy: 0.656600\n",
      "Epoch 196, CIFAR-10 Batch 4:  Loss:     0.7469 Validation Accuracy: 0.659000\n",
      "Epoch 196, CIFAR-10 Batch 5:  Loss:     0.7515 Validation Accuracy: 0.662000\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:     0.7916 Validation Accuracy: 0.663800\n",
      "Epoch 197, CIFAR-10 Batch 2:  Loss:     0.7635 Validation Accuracy: 0.664800\n",
      "Epoch 197, CIFAR-10 Batch 3:  Loss:     0.7662 Validation Accuracy: 0.663400\n",
      "Epoch 197, CIFAR-10 Batch 4:  Loss:     0.7366 Validation Accuracy: 0.661000\n",
      "Epoch 197, CIFAR-10 Batch 5:  Loss:     0.7438 Validation Accuracy: 0.664400\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:     0.7876 Validation Accuracy: 0.663400\n",
      "Epoch 198, CIFAR-10 Batch 2:  Loss:     0.7755 Validation Accuracy: 0.653400\n",
      "Epoch 198, CIFAR-10 Batch 3:  Loss:     0.7618 Validation Accuracy: 0.657600\n",
      "Epoch 198, CIFAR-10 Batch 4:  Loss:     0.7303 Validation Accuracy: 0.669200\n",
      "Epoch 198, CIFAR-10 Batch 5:  Loss:     0.7470 Validation Accuracy: 0.663600\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:     0.7920 Validation Accuracy: 0.660600\n",
      "Epoch 199, CIFAR-10 Batch 2:  Loss:     0.7668 Validation Accuracy: 0.659200\n",
      "Epoch 199, CIFAR-10 Batch 3:  Loss:     0.7800 Validation Accuracy: 0.658000\n",
      "Epoch 199, CIFAR-10 Batch 4:  Loss:     0.7338 Validation Accuracy: 0.660800\n",
      "Epoch 199, CIFAR-10 Batch 5:  Loss:     0.7345 Validation Accuracy: 0.662800\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:     0.7733 Validation Accuracy: 0.663200\n",
      "Epoch 200, CIFAR-10 Batch 2:  Loss:     0.7699 Validation Accuracy: 0.662600\n",
      "Epoch 200, CIFAR-10 Batch 3:  Loss:     0.7769 Validation Accuracy: 0.660600\n",
      "Epoch 200, CIFAR-10 Batch 4:  Loss:     0.7300 Validation Accuracy: 0.665000\n",
      "Epoch 200, CIFAR-10 Batch 5:  Loss:     0.7348 Validation Accuracy: 0.669400\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss:     0.7889 Validation Accuracy: 0.660800\n",
      "Epoch 201, CIFAR-10 Batch 2:  Loss:     0.7707 Validation Accuracy: 0.658200\n",
      "Epoch 201, CIFAR-10 Batch 3:  Loss:     0.7828 Validation Accuracy: 0.660800\n",
      "Epoch 201, CIFAR-10 Batch 4:  Loss:     0.7318 Validation Accuracy: 0.661800\n",
      "Epoch 201, CIFAR-10 Batch 5:  Loss:     0.7373 Validation Accuracy: 0.670600\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss:     0.7800 Validation Accuracy: 0.664000\n",
      "Epoch 202, CIFAR-10 Batch 2:  Loss:     0.7646 Validation Accuracy: 0.662600\n",
      "Epoch 202, CIFAR-10 Batch 3:  Loss:     0.7488 Validation Accuracy: 0.675200\n",
      "Epoch 202, CIFAR-10 Batch 4:  Loss:     0.7185 Validation Accuracy: 0.668200\n",
      "Epoch 202, CIFAR-10 Batch 5:  Loss:     0.7501 Validation Accuracy: 0.662800\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss:     0.7671 Validation Accuracy: 0.666000\n",
      "Epoch 203, CIFAR-10 Batch 2:  Loss:     0.7559 Validation Accuracy: 0.664000\n",
      "Epoch 203, CIFAR-10 Batch 3:  Loss:     0.7547 Validation Accuracy: 0.659200\n",
      "Epoch 203, CIFAR-10 Batch 4:  Loss:     0.7283 Validation Accuracy: 0.666400\n",
      "Epoch 203, CIFAR-10 Batch 5:  Loss:     0.7374 Validation Accuracy: 0.665600\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss:     0.7825 Validation Accuracy: 0.665000\n",
      "Epoch 204, CIFAR-10 Batch 2:  Loss:     0.7705 Validation Accuracy: 0.655400\n",
      "Epoch 204, CIFAR-10 Batch 3:  Loss:     0.7818 Validation Accuracy: 0.653800\n",
      "Epoch 204, CIFAR-10 Batch 4:  Loss:     0.7384 Validation Accuracy: 0.662600\n",
      "Epoch 204, CIFAR-10 Batch 5:  Loss:     0.7367 Validation Accuracy: 0.669400\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss:     0.7870 Validation Accuracy: 0.668400\n",
      "Epoch 205, CIFAR-10 Batch 2:  Loss:     0.7420 Validation Accuracy: 0.660400\n",
      "Epoch 205, CIFAR-10 Batch 3:  Loss:     0.7649 Validation Accuracy: 0.661800\n",
      "Epoch 205, CIFAR-10 Batch 4:  Loss:     0.7301 Validation Accuracy: 0.672200\n",
      "Epoch 205, CIFAR-10 Batch 5:  Loss:     0.7371 Validation Accuracy: 0.665800\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss:     0.7848 Validation Accuracy: 0.662000\n",
      "Epoch 206, CIFAR-10 Batch 2:  Loss:     0.7502 Validation Accuracy: 0.661600\n",
      "Epoch 206, CIFAR-10 Batch 3:  Loss:     0.7531 Validation Accuracy: 0.664600\n",
      "Epoch 206, CIFAR-10 Batch 4:  Loss:     0.7169 Validation Accuracy: 0.666600\n",
      "Epoch 206, CIFAR-10 Batch 5:  Loss:     0.7459 Validation Accuracy: 0.661800\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss:     0.7755 Validation Accuracy: 0.663800\n",
      "Epoch 207, CIFAR-10 Batch 2:  Loss:     0.7439 Validation Accuracy: 0.660000\n",
      "Epoch 207, CIFAR-10 Batch 3:  Loss:     0.7738 Validation Accuracy: 0.656400\n",
      "Epoch 207, CIFAR-10 Batch 4:  Loss:     0.7223 Validation Accuracy: 0.668400\n",
      "Epoch 207, CIFAR-10 Batch 5:  Loss:     0.7275 Validation Accuracy: 0.666800\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss:     0.7619 Validation Accuracy: 0.667600\n",
      "Epoch 208, CIFAR-10 Batch 2:  Loss:     0.7518 Validation Accuracy: 0.658000\n",
      "Epoch 208, CIFAR-10 Batch 3:  Loss:     0.7688 Validation Accuracy: 0.661800\n",
      "Epoch 208, CIFAR-10 Batch 4:  Loss:     0.7146 Validation Accuracy: 0.670200\n",
      "Epoch 208, CIFAR-10 Batch 5:  Loss:     0.7357 Validation Accuracy: 0.665600\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss:     0.7674 Validation Accuracy: 0.656600\n",
      "Epoch 209, CIFAR-10 Batch 2:  Loss:     0.7512 Validation Accuracy: 0.664800\n",
      "Epoch 209, CIFAR-10 Batch 3:  Loss:     0.7583 Validation Accuracy: 0.663800\n",
      "Epoch 209, CIFAR-10 Batch 4:  Loss:     0.7200 Validation Accuracy: 0.655800\n",
      "Epoch 209, CIFAR-10 Batch 5:  Loss:     0.7242 Validation Accuracy: 0.673400\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss:     0.7672 Validation Accuracy: 0.660600\n",
      "Epoch 210, CIFAR-10 Batch 2:  Loss:     0.7525 Validation Accuracy: 0.665400\n",
      "Epoch 210, CIFAR-10 Batch 3:  Loss:     0.7582 Validation Accuracy: 0.655000\n",
      "Epoch 210, CIFAR-10 Batch 4:  Loss:     0.7178 Validation Accuracy: 0.665600\n",
      "Epoch 210, CIFAR-10 Batch 5:  Loss:     0.7322 Validation Accuracy: 0.662000\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss:     0.7770 Validation Accuracy: 0.661800\n",
      "Epoch 211, CIFAR-10 Batch 2:  Loss:     0.7600 Validation Accuracy: 0.656400\n",
      "Epoch 211, CIFAR-10 Batch 3:  Loss:     0.7795 Validation Accuracy: 0.662400\n",
      "Epoch 211, CIFAR-10 Batch 4:  Loss:     0.7303 Validation Accuracy: 0.667600\n",
      "Epoch 211, CIFAR-10 Batch 5:  Loss:     0.7347 Validation Accuracy: 0.665000\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss:     0.7689 Validation Accuracy: 0.661800\n",
      "Epoch 212, CIFAR-10 Batch 2:  Loss:     0.7363 Validation Accuracy: 0.663800\n",
      "Epoch 212, CIFAR-10 Batch 3:  Loss:     0.7524 Validation Accuracy: 0.661400\n",
      "Epoch 212, CIFAR-10 Batch 4:  Loss:     0.7221 Validation Accuracy: 0.666400\n",
      "Epoch 212, CIFAR-10 Batch 5:  Loss:     0.7255 Validation Accuracy: 0.666200\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss:     0.7569 Validation Accuracy: 0.666400\n",
      "Epoch 213, CIFAR-10 Batch 2:  Loss:     0.7370 Validation Accuracy: 0.662600\n",
      "Epoch 213, CIFAR-10 Batch 3:  Loss:     0.7565 Validation Accuracy: 0.659800\n",
      "Epoch 213, CIFAR-10 Batch 4:  Loss:     0.7098 Validation Accuracy: 0.666000\n",
      "Epoch 213, CIFAR-10 Batch 5:  Loss:     0.7284 Validation Accuracy: 0.667600\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss:     0.7731 Validation Accuracy: 0.662800\n",
      "Epoch 214, CIFAR-10 Batch 2:  Loss:     0.7448 Validation Accuracy: 0.665400\n",
      "Epoch 214, CIFAR-10 Batch 3:  Loss:     0.7659 Validation Accuracy: 0.660200\n",
      "Epoch 214, CIFAR-10 Batch 4:  Loss:     0.7053 Validation Accuracy: 0.665400\n",
      "Epoch 214, CIFAR-10 Batch 5:  Loss:     0.7402 Validation Accuracy: 0.666000\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss:     0.7804 Validation Accuracy: 0.654800\n",
      "Epoch 215, CIFAR-10 Batch 2:  Loss:     0.7542 Validation Accuracy: 0.665600\n",
      "Epoch 215, CIFAR-10 Batch 3:  Loss:     0.7710 Validation Accuracy: 0.658400\n",
      "Epoch 215, CIFAR-10 Batch 4:  Loss:     0.7046 Validation Accuracy: 0.666600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215, CIFAR-10 Batch 5:  Loss:     0.7252 Validation Accuracy: 0.666800\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss:     0.7517 Validation Accuracy: 0.668400\n",
      "Epoch 216, CIFAR-10 Batch 2:  Loss:     0.7377 Validation Accuracy: 0.665000\n",
      "Epoch 216, CIFAR-10 Batch 3:  Loss:     0.7633 Validation Accuracy: 0.662600\n",
      "Epoch 216, CIFAR-10 Batch 4:  Loss:     0.7156 Validation Accuracy: 0.669800\n",
      "Epoch 216, CIFAR-10 Batch 5:  Loss:     0.7326 Validation Accuracy: 0.663000\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss:     0.7504 Validation Accuracy: 0.669600\n",
      "Epoch 217, CIFAR-10 Batch 2:  Loss:     0.7503 Validation Accuracy: 0.655800\n",
      "Epoch 217, CIFAR-10 Batch 3:  Loss:     0.7788 Validation Accuracy: 0.661000\n",
      "Epoch 217, CIFAR-10 Batch 4:  Loss:     0.7103 Validation Accuracy: 0.662800\n",
      "Epoch 217, CIFAR-10 Batch 5:  Loss:     0.7200 Validation Accuracy: 0.668200\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss:     0.7642 Validation Accuracy: 0.664800\n",
      "Epoch 218, CIFAR-10 Batch 2:  Loss:     0.7585 Validation Accuracy: 0.662000\n",
      "Epoch 218, CIFAR-10 Batch 3:  Loss:     0.7578 Validation Accuracy: 0.658800\n",
      "Epoch 218, CIFAR-10 Batch 4:  Loss:     0.7126 Validation Accuracy: 0.671200\n",
      "Epoch 218, CIFAR-10 Batch 5:  Loss:     0.7316 Validation Accuracy: 0.668200\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss:     0.7509 Validation Accuracy: 0.667600\n",
      "Epoch 219, CIFAR-10 Batch 2:  Loss:     0.7491 Validation Accuracy: 0.657600\n",
      "Epoch 219, CIFAR-10 Batch 3:  Loss:     0.7551 Validation Accuracy: 0.661000\n",
      "Epoch 219, CIFAR-10 Batch 4:  Loss:     0.7169 Validation Accuracy: 0.658400\n",
      "Epoch 219, CIFAR-10 Batch 5:  Loss:     0.7339 Validation Accuracy: 0.665200\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss:     0.7808 Validation Accuracy: 0.657600\n",
      "Epoch 220, CIFAR-10 Batch 2:  Loss:     0.7298 Validation Accuracy: 0.666800\n",
      "Epoch 220, CIFAR-10 Batch 3:  Loss:     0.7537 Validation Accuracy: 0.662000\n",
      "Epoch 220, CIFAR-10 Batch 4:  Loss:     0.7100 Validation Accuracy: 0.663600\n",
      "Epoch 220, CIFAR-10 Batch 5:  Loss:     0.7163 Validation Accuracy: 0.671200\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss:     0.7586 Validation Accuracy: 0.662600\n",
      "Epoch 221, CIFAR-10 Batch 2:  Loss:     0.7431 Validation Accuracy: 0.661000\n",
      "Epoch 221, CIFAR-10 Batch 3:  Loss:     0.7425 Validation Accuracy: 0.666600\n",
      "Epoch 221, CIFAR-10 Batch 4:  Loss:     0.6935 Validation Accuracy: 0.664800\n",
      "Epoch 221, CIFAR-10 Batch 5:  Loss:     0.7254 Validation Accuracy: 0.668400\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss:     0.7416 Validation Accuracy: 0.669600\n",
      "Epoch 222, CIFAR-10 Batch 2:  Loss:     0.7239 Validation Accuracy: 0.666000\n",
      "Epoch 222, CIFAR-10 Batch 3:  Loss:     0.7436 Validation Accuracy: 0.661800\n",
      "Epoch 222, CIFAR-10 Batch 4:  Loss:     0.7042 Validation Accuracy: 0.666400\n",
      "Epoch 222, CIFAR-10 Batch 5:  Loss:     0.7100 Validation Accuracy: 0.666000\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss:     0.7521 Validation Accuracy: 0.667400\n",
      "Epoch 223, CIFAR-10 Batch 2:  Loss:     0.7426 Validation Accuracy: 0.662600\n",
      "Epoch 223, CIFAR-10 Batch 3:  Loss:     0.7376 Validation Accuracy: 0.666400\n",
      "Epoch 223, CIFAR-10 Batch 4:  Loss:     0.7027 Validation Accuracy: 0.663800\n",
      "Epoch 223, CIFAR-10 Batch 5:  Loss:     0.7222 Validation Accuracy: 0.668400\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss:     0.7507 Validation Accuracy: 0.666200\n",
      "Epoch 224, CIFAR-10 Batch 2:  Loss:     0.7523 Validation Accuracy: 0.666000\n",
      "Epoch 224, CIFAR-10 Batch 3:  Loss:     0.7552 Validation Accuracy: 0.659400\n",
      "Epoch 224, CIFAR-10 Batch 4:  Loss:     0.6899 Validation Accuracy: 0.666600\n",
      "Epoch 224, CIFAR-10 Batch 5:  Loss:     0.7204 Validation Accuracy: 0.665200\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss:     0.7470 Validation Accuracy: 0.665400\n",
      "Epoch 225, CIFAR-10 Batch 2:  Loss:     0.7305 Validation Accuracy: 0.667800\n",
      "Epoch 225, CIFAR-10 Batch 3:  Loss:     0.7446 Validation Accuracy: 0.656200\n",
      "Epoch 225, CIFAR-10 Batch 4:  Loss:     0.6924 Validation Accuracy: 0.667600\n",
      "Epoch 225, CIFAR-10 Batch 5:  Loss:     0.7079 Validation Accuracy: 0.665200\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss:     0.7658 Validation Accuracy: 0.665400\n",
      "Epoch 226, CIFAR-10 Batch 2:  Loss:     0.7443 Validation Accuracy: 0.661600\n",
      "Epoch 226, CIFAR-10 Batch 3:  Loss:     0.7303 Validation Accuracy: 0.669400\n",
      "Epoch 226, CIFAR-10 Batch 4:  Loss:     0.6973 Validation Accuracy: 0.665800\n",
      "Epoch 226, CIFAR-10 Batch 5:  Loss:     0.7161 Validation Accuracy: 0.667400\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss:     0.7488 Validation Accuracy: 0.662600\n",
      "Epoch 227, CIFAR-10 Batch 2:  Loss:     0.7206 Validation Accuracy: 0.667000\n",
      "Epoch 227, CIFAR-10 Batch 3:  Loss:     0.7363 Validation Accuracy: 0.663000\n",
      "Epoch 227, CIFAR-10 Batch 4:  Loss:     0.6957 Validation Accuracy: 0.667800\n",
      "Epoch 227, CIFAR-10 Batch 5:  Loss:     0.6964 Validation Accuracy: 0.666400\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss:     0.7646 Validation Accuracy: 0.660800\n",
      "Epoch 228, CIFAR-10 Batch 2:  Loss:     0.7455 Validation Accuracy: 0.665600\n",
      "Epoch 228, CIFAR-10 Batch 3:  Loss:     0.7278 Validation Accuracy: 0.662800\n",
      "Epoch 228, CIFAR-10 Batch 4:  Loss:     0.6971 Validation Accuracy: 0.668200\n",
      "Epoch 228, CIFAR-10 Batch 5:  Loss:     0.7021 Validation Accuracy: 0.671800\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss:     0.7481 Validation Accuracy: 0.667200\n",
      "Epoch 229, CIFAR-10 Batch 2:  Loss:     0.7243 Validation Accuracy: 0.664600\n",
      "Epoch 229, CIFAR-10 Batch 3:  Loss:     0.7194 Validation Accuracy: 0.668000\n",
      "Epoch 229, CIFAR-10 Batch 4:  Loss:     0.6843 Validation Accuracy: 0.666000\n",
      "Epoch 229, CIFAR-10 Batch 5:  Loss:     0.7139 Validation Accuracy: 0.669000\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss:     0.7371 Validation Accuracy: 0.671400\n",
      "Epoch 230, CIFAR-10 Batch 2:  Loss:     0.7107 Validation Accuracy: 0.663400\n",
      "Epoch 230, CIFAR-10 Batch 3:  Loss:     0.7317 Validation Accuracy: 0.665000\n",
      "Epoch 230, CIFAR-10 Batch 4:  Loss:     0.6950 Validation Accuracy: 0.669200\n",
      "Epoch 230, CIFAR-10 Batch 5:  Loss:     0.7103 Validation Accuracy: 0.666600\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss:     0.7349 Validation Accuracy: 0.661800\n",
      "Epoch 231, CIFAR-10 Batch 2:  Loss:     0.7205 Validation Accuracy: 0.665600\n",
      "Epoch 231, CIFAR-10 Batch 3:  Loss:     0.7547 Validation Accuracy: 0.660200\n",
      "Epoch 231, CIFAR-10 Batch 4:  Loss:     0.6826 Validation Accuracy: 0.670000\n",
      "Epoch 231, CIFAR-10 Batch 5:  Loss:     0.6974 Validation Accuracy: 0.667600\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss:     0.7451 Validation Accuracy: 0.669800\n",
      "Epoch 232, CIFAR-10 Batch 2:  Loss:     0.7314 Validation Accuracy: 0.665000\n",
      "Epoch 232, CIFAR-10 Batch 3:  Loss:     0.7193 Validation Accuracy: 0.665200\n",
      "Epoch 232, CIFAR-10 Batch 4:  Loss:     0.6880 Validation Accuracy: 0.669800\n",
      "Epoch 232, CIFAR-10 Batch 5:  Loss:     0.7008 Validation Accuracy: 0.664200\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss:     0.7379 Validation Accuracy: 0.667000\n",
      "Epoch 233, CIFAR-10 Batch 2:  Loss:     0.7426 Validation Accuracy: 0.659200\n",
      "Epoch 233, CIFAR-10 Batch 3:  Loss:     0.7312 Validation Accuracy: 0.666000\n",
      "Epoch 233, CIFAR-10 Batch 4:  Loss:     0.6912 Validation Accuracy: 0.667600\n",
      "Epoch 233, CIFAR-10 Batch 5:  Loss:     0.7043 Validation Accuracy: 0.668600\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss:     0.7475 Validation Accuracy: 0.666600\n",
      "Epoch 234, CIFAR-10 Batch 2:  Loss:     0.7343 Validation Accuracy: 0.655400\n",
      "Epoch 234, CIFAR-10 Batch 3:  Loss:     0.7311 Validation Accuracy: 0.660200\n",
      "Epoch 234, CIFAR-10 Batch 4:  Loss:     0.6924 Validation Accuracy: 0.666800\n",
      "Epoch 234, CIFAR-10 Batch 5:  Loss:     0.6933 Validation Accuracy: 0.668200\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss:     0.7376 Validation Accuracy: 0.666800\n",
      "Epoch 235, CIFAR-10 Batch 2:  Loss:     0.7313 Validation Accuracy: 0.660000\n",
      "Epoch 235, CIFAR-10 Batch 3:  Loss:     0.7204 Validation Accuracy: 0.664400\n",
      "Epoch 235, CIFAR-10 Batch 4:  Loss:     0.6829 Validation Accuracy: 0.667800\n",
      "Epoch 235, CIFAR-10 Batch 5:  Loss:     0.7038 Validation Accuracy: 0.664400\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss:     0.7329 Validation Accuracy: 0.669800\n",
      "Epoch 236, CIFAR-10 Batch 2:  Loss:     0.7284 Validation Accuracy: 0.657400\n",
      "Epoch 236, CIFAR-10 Batch 3:  Loss:     0.7321 Validation Accuracy: 0.659400\n",
      "Epoch 236, CIFAR-10 Batch 4:  Loss:     0.6875 Validation Accuracy: 0.668400\n",
      "Epoch 236, CIFAR-10 Batch 5:  Loss:     0.6972 Validation Accuracy: 0.669600\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss:     0.7257 Validation Accuracy: 0.668600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237, CIFAR-10 Batch 2:  Loss:     0.7249 Validation Accuracy: 0.658200\n",
      "Epoch 237, CIFAR-10 Batch 3:  Loss:     0.7384 Validation Accuracy: 0.659200\n",
      "Epoch 237, CIFAR-10 Batch 4:  Loss:     0.6819 Validation Accuracy: 0.667600\n",
      "Epoch 237, CIFAR-10 Batch 5:  Loss:     0.7074 Validation Accuracy: 0.664200\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss:     0.7338 Validation Accuracy: 0.664000\n",
      "Epoch 238, CIFAR-10 Batch 2:  Loss:     0.7107 Validation Accuracy: 0.664400\n",
      "Epoch 238, CIFAR-10 Batch 3:  Loss:     0.7206 Validation Accuracy: 0.665000\n",
      "Epoch 238, CIFAR-10 Batch 4:  Loss:     0.6763 Validation Accuracy: 0.672400\n",
      "Epoch 238, CIFAR-10 Batch 5:  Loss:     0.7072 Validation Accuracy: 0.665800\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss:     0.7330 Validation Accuracy: 0.666000\n",
      "Epoch 239, CIFAR-10 Batch 2:  Loss:     0.7110 Validation Accuracy: 0.665600\n",
      "Epoch 239, CIFAR-10 Batch 3:  Loss:     0.7112 Validation Accuracy: 0.668800\n",
      "Epoch 239, CIFAR-10 Batch 4:  Loss:     0.6720 Validation Accuracy: 0.669600\n",
      "Epoch 239, CIFAR-10 Batch 5:  Loss:     0.7021 Validation Accuracy: 0.666200\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss:     0.7170 Validation Accuracy: 0.663200\n",
      "Epoch 240, CIFAR-10 Batch 2:  Loss:     0.7092 Validation Accuracy: 0.668800\n",
      "Epoch 240, CIFAR-10 Batch 3:  Loss:     0.7215 Validation Accuracy: 0.663400\n",
      "Epoch 240, CIFAR-10 Batch 4:  Loss:     0.6700 Validation Accuracy: 0.670200\n",
      "Epoch 240, CIFAR-10 Batch 5:  Loss:     0.6785 Validation Accuracy: 0.667000\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss:     0.7312 Validation Accuracy: 0.671200\n",
      "Epoch 241, CIFAR-10 Batch 2:  Loss:     0.7371 Validation Accuracy: 0.658000\n",
      "Epoch 241, CIFAR-10 Batch 3:  Loss:     0.7238 Validation Accuracy: 0.665200\n",
      "Epoch 241, CIFAR-10 Batch 4:  Loss:     0.6795 Validation Accuracy: 0.669600\n",
      "Epoch 241, CIFAR-10 Batch 5:  Loss:     0.7032 Validation Accuracy: 0.671600\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss:     0.7137 Validation Accuracy: 0.671600\n",
      "Epoch 242, CIFAR-10 Batch 2:  Loss:     0.7068 Validation Accuracy: 0.663200\n",
      "Epoch 242, CIFAR-10 Batch 3:  Loss:     0.7234 Validation Accuracy: 0.667000\n",
      "Epoch 242, CIFAR-10 Batch 4:  Loss:     0.6711 Validation Accuracy: 0.670200\n",
      "Epoch 242, CIFAR-10 Batch 5:  Loss:     0.6977 Validation Accuracy: 0.667800\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss:     0.7385 Validation Accuracy: 0.668000\n",
      "Epoch 243, CIFAR-10 Batch 2:  Loss:     0.7506 Validation Accuracy: 0.659200\n",
      "Epoch 243, CIFAR-10 Batch 3:  Loss:     0.7202 Validation Accuracy: 0.658600\n",
      "Epoch 243, CIFAR-10 Batch 4:  Loss:     0.6676 Validation Accuracy: 0.669400\n",
      "Epoch 243, CIFAR-10 Batch 5:  Loss:     0.7206 Validation Accuracy: 0.655400\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss:     0.7470 Validation Accuracy: 0.664400\n",
      "Epoch 244, CIFAR-10 Batch 2:  Loss:     0.7236 Validation Accuracy: 0.655600\n",
      "Epoch 244, CIFAR-10 Batch 3:  Loss:     0.7009 Validation Accuracy: 0.664600\n",
      "Epoch 244, CIFAR-10 Batch 4:  Loss:     0.6894 Validation Accuracy: 0.664000\n",
      "Epoch 244, CIFAR-10 Batch 5:  Loss:     0.7016 Validation Accuracy: 0.662400\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss:     0.7258 Validation Accuracy: 0.665200\n",
      "Epoch 245, CIFAR-10 Batch 2:  Loss:     0.7141 Validation Accuracy: 0.661400\n",
      "Epoch 245, CIFAR-10 Batch 3:  Loss:     0.7238 Validation Accuracy: 0.662400\n",
      "Epoch 245, CIFAR-10 Batch 4:  Loss:     0.7138 Validation Accuracy: 0.650800\n",
      "Epoch 245, CIFAR-10 Batch 5:  Loss:     0.7177 Validation Accuracy: 0.662800\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss:     0.7437 Validation Accuracy: 0.663800\n",
      "Epoch 246, CIFAR-10 Batch 2:  Loss:     0.7192 Validation Accuracy: 0.664000\n",
      "Epoch 246, CIFAR-10 Batch 3:  Loss:     0.7094 Validation Accuracy: 0.667600\n",
      "Epoch 246, CIFAR-10 Batch 4:  Loss:     0.6895 Validation Accuracy: 0.667400\n",
      "Epoch 246, CIFAR-10 Batch 5:  Loss:     0.6986 Validation Accuracy: 0.666600\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss:     0.7370 Validation Accuracy: 0.665600\n",
      "Epoch 247, CIFAR-10 Batch 2:  Loss:     0.7131 Validation Accuracy: 0.669000\n",
      "Epoch 247, CIFAR-10 Batch 3:  Loss:     0.6992 Validation Accuracy: 0.669400\n",
      "Epoch 247, CIFAR-10 Batch 4:  Loss:     0.6836 Validation Accuracy: 0.670400\n",
      "Epoch 247, CIFAR-10 Batch 5:  Loss:     0.6964 Validation Accuracy: 0.667400\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss:     0.7289 Validation Accuracy: 0.666800\n",
      "Epoch 248, CIFAR-10 Batch 2:  Loss:     0.7161 Validation Accuracy: 0.664400\n",
      "Epoch 248, CIFAR-10 Batch 3:  Loss:     0.7152 Validation Accuracy: 0.660400\n",
      "Epoch 248, CIFAR-10 Batch 4:  Loss:     0.6749 Validation Accuracy: 0.669800\n",
      "Epoch 248, CIFAR-10 Batch 5:  Loss:     0.7143 Validation Accuracy: 0.669000\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss:     0.7394 Validation Accuracy: 0.665200\n",
      "Epoch 249, CIFAR-10 Batch 2:  Loss:     0.7016 Validation Accuracy: 0.659800\n",
      "Epoch 249, CIFAR-10 Batch 3:  Loss:     0.7144 Validation Accuracy: 0.664600\n",
      "Epoch 249, CIFAR-10 Batch 4:  Loss:     0.6888 Validation Accuracy: 0.669600\n",
      "Epoch 249, CIFAR-10 Batch 5:  Loss:     0.6967 Validation Accuracy: 0.666000\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss:     0.7191 Validation Accuracy: 0.669200\n",
      "Epoch 250, CIFAR-10 Batch 2:  Loss:     0.7309 Validation Accuracy: 0.652600\n",
      "Epoch 250, CIFAR-10 Batch 3:  Loss:     0.6932 Validation Accuracy: 0.666400\n",
      "Epoch 250, CIFAR-10 Batch 4:  Loss:     0.6848 Validation Accuracy: 0.668400\n",
      "Epoch 250, CIFAR-10 Batch 5:  Loss:     0.6932 Validation Accuracy: 0.664600\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss:     0.7262 Validation Accuracy: 0.667600\n",
      "Epoch 251, CIFAR-10 Batch 2:  Loss:     0.6957 Validation Accuracy: 0.659800\n",
      "Epoch 251, CIFAR-10 Batch 3:  Loss:     0.6973 Validation Accuracy: 0.669600\n",
      "Epoch 251, CIFAR-10 Batch 4:  Loss:     0.6675 Validation Accuracy: 0.671000\n",
      "Epoch 251, CIFAR-10 Batch 5:  Loss:     0.7069 Validation Accuracy: 0.663200\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss:     0.7166 Validation Accuracy: 0.668600\n",
      "Epoch 252, CIFAR-10 Batch 2:  Loss:     0.7146 Validation Accuracy: 0.654200\n",
      "Epoch 252, CIFAR-10 Batch 3:  Loss:     0.7135 Validation Accuracy: 0.667400\n",
      "Epoch 252, CIFAR-10 Batch 4:  Loss:     0.6725 Validation Accuracy: 0.665200\n",
      "Epoch 252, CIFAR-10 Batch 5:  Loss:     0.7184 Validation Accuracy: 0.657400\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss:     0.7087 Validation Accuracy: 0.668200\n",
      "Epoch 253, CIFAR-10 Batch 2:  Loss:     0.7031 Validation Accuracy: 0.656000\n",
      "Epoch 253, CIFAR-10 Batch 3:  Loss:     0.7178 Validation Accuracy: 0.660800\n",
      "Epoch 253, CIFAR-10 Batch 4:  Loss:     0.6960 Validation Accuracy: 0.661200\n",
      "Epoch 253, CIFAR-10 Batch 5:  Loss:     0.7117 Validation Accuracy: 0.664800\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss:     0.7179 Validation Accuracy: 0.665800\n",
      "Epoch 254, CIFAR-10 Batch 2:  Loss:     0.6818 Validation Accuracy: 0.666000\n",
      "Epoch 254, CIFAR-10 Batch 3:  Loss:     0.7111 Validation Accuracy: 0.664600\n",
      "Epoch 254, CIFAR-10 Batch 4:  Loss:     0.6767 Validation Accuracy: 0.667800\n",
      "Epoch 254, CIFAR-10 Batch 5:  Loss:     0.6851 Validation Accuracy: 0.668000\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss:     0.7003 Validation Accuracy: 0.670000\n",
      "Epoch 255, CIFAR-10 Batch 2:  Loss:     0.7104 Validation Accuracy: 0.662200\n",
      "Epoch 255, CIFAR-10 Batch 3:  Loss:     0.7076 Validation Accuracy: 0.659200\n",
      "Epoch 255, CIFAR-10 Batch 4:  Loss:     0.6942 Validation Accuracy: 0.656200\n",
      "Epoch 255, CIFAR-10 Batch 5:  Loss:     0.7004 Validation Accuracy: 0.660800\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss:     0.7170 Validation Accuracy: 0.668000\n",
      "Epoch 256, CIFAR-10 Batch 2:  Loss:     0.7040 Validation Accuracy: 0.653400\n",
      "Epoch 256, CIFAR-10 Batch 3:  Loss:     0.7277 Validation Accuracy: 0.658600\n",
      "Epoch 256, CIFAR-10 Batch 4:  Loss:     0.6839 Validation Accuracy: 0.665000\n",
      "Epoch 256, CIFAR-10 Batch 5:  Loss:     0.7050 Validation Accuracy: 0.671600\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss:     0.7135 Validation Accuracy: 0.668200\n",
      "Epoch 257, CIFAR-10 Batch 2:  Loss:     0.7184 Validation Accuracy: 0.655600\n",
      "Epoch 257, CIFAR-10 Batch 3:  Loss:     0.7097 Validation Accuracy: 0.658600\n",
      "Epoch 257, CIFAR-10 Batch 4:  Loss:     0.6718 Validation Accuracy: 0.664200\n",
      "Epoch 257, CIFAR-10 Batch 5:  Loss:     0.6974 Validation Accuracy: 0.663800\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss:     0.7087 Validation Accuracy: 0.669800\n",
      "Epoch 258, CIFAR-10 Batch 2:  Loss:     0.6991 Validation Accuracy: 0.662000\n",
      "Epoch 258, CIFAR-10 Batch 3:  Loss:     0.7015 Validation Accuracy: 0.662000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258, CIFAR-10 Batch 4:  Loss:     0.6750 Validation Accuracy: 0.667600\n",
      "Epoch 258, CIFAR-10 Batch 5:  Loss:     0.6847 Validation Accuracy: 0.674800\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss:     0.7042 Validation Accuracy: 0.665400\n",
      "Epoch 259, CIFAR-10 Batch 2:  Loss:     0.6912 Validation Accuracy: 0.659600\n",
      "Epoch 259, CIFAR-10 Batch 3:  Loss:     0.6946 Validation Accuracy: 0.663200\n",
      "Epoch 259, CIFAR-10 Batch 4:  Loss:     0.6610 Validation Accuracy: 0.665200\n",
      "Epoch 259, CIFAR-10 Batch 5:  Loss:     0.7007 Validation Accuracy: 0.661800\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss:     0.7081 Validation Accuracy: 0.670400\n",
      "Epoch 260, CIFAR-10 Batch 2:  Loss:     0.6929 Validation Accuracy: 0.663800\n",
      "Epoch 260, CIFAR-10 Batch 3:  Loss:     0.6869 Validation Accuracy: 0.662200\n",
      "Epoch 260, CIFAR-10 Batch 4:  Loss:     0.6729 Validation Accuracy: 0.657200\n",
      "Epoch 260, CIFAR-10 Batch 5:  Loss:     0.6918 Validation Accuracy: 0.663800\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss:     0.7309 Validation Accuracy: 0.657400\n",
      "Epoch 261, CIFAR-10 Batch 2:  Loss:     0.7086 Validation Accuracy: 0.667200\n",
      "Epoch 261, CIFAR-10 Batch 3:  Loss:     0.7134 Validation Accuracy: 0.657200\n",
      "Epoch 261, CIFAR-10 Batch 4:  Loss:     0.6593 Validation Accuracy: 0.663200\n",
      "Epoch 261, CIFAR-10 Batch 5:  Loss:     0.6864 Validation Accuracy: 0.663800\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss:     0.7186 Validation Accuracy: 0.667000\n",
      "Epoch 262, CIFAR-10 Batch 2:  Loss:     0.6895 Validation Accuracy: 0.666400\n",
      "Epoch 262, CIFAR-10 Batch 3:  Loss:     0.6960 Validation Accuracy: 0.658000\n",
      "Epoch 262, CIFAR-10 Batch 4:  Loss:     0.6649 Validation Accuracy: 0.667200\n",
      "Epoch 262, CIFAR-10 Batch 5:  Loss:     0.6653 Validation Accuracy: 0.672600\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss:     0.6888 Validation Accuracy: 0.671000\n",
      "Epoch 263, CIFAR-10 Batch 2:  Loss:     0.7063 Validation Accuracy: 0.659000\n",
      "Epoch 263, CIFAR-10 Batch 3:  Loss:     0.6930 Validation Accuracy: 0.666200\n",
      "Epoch 263, CIFAR-10 Batch 4:  Loss:     0.6752 Validation Accuracy: 0.662000\n",
      "Epoch 263, CIFAR-10 Batch 5:  Loss:     0.6775 Validation Accuracy: 0.669400\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss:     0.7089 Validation Accuracy: 0.669200\n",
      "Epoch 264, CIFAR-10 Batch 2:  Loss:     0.6740 Validation Accuracy: 0.664800\n",
      "Epoch 264, CIFAR-10 Batch 3:  Loss:     0.6867 Validation Accuracy: 0.666800\n",
      "Epoch 264, CIFAR-10 Batch 4:  Loss:     0.6718 Validation Accuracy: 0.666200\n",
      "Epoch 264, CIFAR-10 Batch 5:  Loss:     0.6808 Validation Accuracy: 0.670800\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss:     0.7133 Validation Accuracy: 0.664400\n",
      "Epoch 265, CIFAR-10 Batch 2:  Loss:     0.6746 Validation Accuracy: 0.668200\n",
      "Epoch 265, CIFAR-10 Batch 3:  Loss:     0.6770 Validation Accuracy: 0.665400\n",
      "Epoch 265, CIFAR-10 Batch 4:  Loss:     0.6658 Validation Accuracy: 0.667200\n",
      "Epoch 265, CIFAR-10 Batch 5:  Loss:     0.6935 Validation Accuracy: 0.664000\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss:     0.7052 Validation Accuracy: 0.663400\n",
      "Epoch 266, CIFAR-10 Batch 2:  Loss:     0.6790 Validation Accuracy: 0.662200\n",
      "Epoch 266, CIFAR-10 Batch 3:  Loss:     0.6980 Validation Accuracy: 0.660400\n",
      "Epoch 266, CIFAR-10 Batch 4:  Loss:     0.6585 Validation Accuracy: 0.665800\n",
      "Epoch 266, CIFAR-10 Batch 5:  Loss:     0.6821 Validation Accuracy: 0.672400\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss:     0.6965 Validation Accuracy: 0.665200\n",
      "Epoch 267, CIFAR-10 Batch 2:  Loss:     0.6942 Validation Accuracy: 0.660200\n",
      "Epoch 267, CIFAR-10 Batch 3:  Loss:     0.6784 Validation Accuracy: 0.673800\n",
      "Epoch 267, CIFAR-10 Batch 4:  Loss:     0.6540 Validation Accuracy: 0.668600\n",
      "Epoch 267, CIFAR-10 Batch 5:  Loss:     0.6753 Validation Accuracy: 0.672200\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss:     0.6862 Validation Accuracy: 0.667200\n",
      "Epoch 268, CIFAR-10 Batch 2:  Loss:     0.6952 Validation Accuracy: 0.660800\n",
      "Epoch 268, CIFAR-10 Batch 3:  Loss:     0.6934 Validation Accuracy: 0.665800\n",
      "Epoch 268, CIFAR-10 Batch 4:  Loss:     0.6824 Validation Accuracy: 0.662400\n",
      "Epoch 268, CIFAR-10 Batch 5:  Loss:     0.6953 Validation Accuracy: 0.665200\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss:     0.6894 Validation Accuracy: 0.665800\n",
      "Epoch 269, CIFAR-10 Batch 2:  Loss:     0.6930 Validation Accuracy: 0.660600\n",
      "Epoch 269, CIFAR-10 Batch 3:  Loss:     0.6927 Validation Accuracy: 0.668800\n",
      "Epoch 269, CIFAR-10 Batch 4:  Loss:     0.6604 Validation Accuracy: 0.665000\n",
      "Epoch 269, CIFAR-10 Batch 5:  Loss:     0.6854 Validation Accuracy: 0.667200\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss:     0.7052 Validation Accuracy: 0.663400\n",
      "Epoch 270, CIFAR-10 Batch 2:  Loss:     0.6990 Validation Accuracy: 0.659000\n",
      "Epoch 270, CIFAR-10 Batch 3:  Loss:     0.7099 Validation Accuracy: 0.659000\n",
      "Epoch 270, CIFAR-10 Batch 4:  Loss:     0.6654 Validation Accuracy: 0.657200\n",
      "Epoch 270, CIFAR-10 Batch 5:  Loss:     0.6712 Validation Accuracy: 0.667200\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss:     0.6871 Validation Accuracy: 0.671400\n",
      "Epoch 271, CIFAR-10 Batch 2:  Loss:     0.6951 Validation Accuracy: 0.655600\n",
      "Epoch 271, CIFAR-10 Batch 3:  Loss:     0.6828 Validation Accuracy: 0.666000\n",
      "Epoch 271, CIFAR-10 Batch 4:  Loss:     0.6721 Validation Accuracy: 0.656800\n",
      "Epoch 271, CIFAR-10 Batch 5:  Loss:     0.6975 Validation Accuracy: 0.658000\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss:     0.7123 Validation Accuracy: 0.666200\n",
      "Epoch 272, CIFAR-10 Batch 2:  Loss:     0.6815 Validation Accuracy: 0.663000\n",
      "Epoch 272, CIFAR-10 Batch 3:  Loss:     0.6852 Validation Accuracy: 0.664000\n",
      "Epoch 272, CIFAR-10 Batch 4:  Loss:     0.6550 Validation Accuracy: 0.660400\n",
      "Epoch 272, CIFAR-10 Batch 5:  Loss:     0.6745 Validation Accuracy: 0.671000\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss:     0.6769 Validation Accuracy: 0.670000\n",
      "Epoch 273, CIFAR-10 Batch 2:  Loss:     0.6784 Validation Accuracy: 0.660200\n",
      "Epoch 273, CIFAR-10 Batch 3:  Loss:     0.6914 Validation Accuracy: 0.669400\n",
      "Epoch 273, CIFAR-10 Batch 4:  Loss:     0.6660 Validation Accuracy: 0.665000\n",
      "Epoch 273, CIFAR-10 Batch 5:  Loss:     0.6797 Validation Accuracy: 0.664200\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss:     0.6824 Validation Accuracy: 0.669000\n",
      "Epoch 274, CIFAR-10 Batch 2:  Loss:     0.6728 Validation Accuracy: 0.665200\n",
      "Epoch 274, CIFAR-10 Batch 3:  Loss:     0.6963 Validation Accuracy: 0.666200\n",
      "Epoch 274, CIFAR-10 Batch 4:  Loss:     0.6794 Validation Accuracy: 0.665400\n",
      "Epoch 274, CIFAR-10 Batch 5:  Loss:     0.6641 Validation Accuracy: 0.669600\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss:     0.7003 Validation Accuracy: 0.667400\n",
      "Epoch 275, CIFAR-10 Batch 2:  Loss:     0.6806 Validation Accuracy: 0.664000\n",
      "Epoch 275, CIFAR-10 Batch 3:  Loss:     0.6802 Validation Accuracy: 0.665000\n",
      "Epoch 275, CIFAR-10 Batch 4:  Loss:     0.6484 Validation Accuracy: 0.663800\n",
      "Epoch 275, CIFAR-10 Batch 5:  Loss:     0.6863 Validation Accuracy: 0.663600\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss:     0.6915 Validation Accuracy: 0.666400\n",
      "Epoch 276, CIFAR-10 Batch 2:  Loss:     0.6916 Validation Accuracy: 0.662000\n",
      "Epoch 276, CIFAR-10 Batch 3:  Loss:     0.6909 Validation Accuracy: 0.661400\n",
      "Epoch 276, CIFAR-10 Batch 4:  Loss:     0.6463 Validation Accuracy: 0.660400\n",
      "Epoch 276, CIFAR-10 Batch 5:  Loss:     0.6819 Validation Accuracy: 0.669000\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss:     0.6851 Validation Accuracy: 0.672200\n",
      "Epoch 277, CIFAR-10 Batch 2:  Loss:     0.6831 Validation Accuracy: 0.667600\n",
      "Epoch 277, CIFAR-10 Batch 3:  Loss:     0.6978 Validation Accuracy: 0.658000\n",
      "Epoch 277, CIFAR-10 Batch 4:  Loss:     0.6373 Validation Accuracy: 0.670000\n",
      "Epoch 277, CIFAR-10 Batch 5:  Loss:     0.6627 Validation Accuracy: 0.673800\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss:     0.6902 Validation Accuracy: 0.666600\n",
      "Epoch 278, CIFAR-10 Batch 2:  Loss:     0.6804 Validation Accuracy: 0.661000\n",
      "Epoch 278, CIFAR-10 Batch 3:  Loss:     0.6973 Validation Accuracy: 0.660200\n",
      "Epoch 278, CIFAR-10 Batch 4:  Loss:     0.6620 Validation Accuracy: 0.656600\n",
      "Epoch 278, CIFAR-10 Batch 5:  Loss:     0.6793 Validation Accuracy: 0.657000\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss:     0.6959 Validation Accuracy: 0.665000\n",
      "Epoch 279, CIFAR-10 Batch 2:  Loss:     0.7001 Validation Accuracy: 0.665800\n",
      "Epoch 279, CIFAR-10 Batch 3:  Loss:     0.6886 Validation Accuracy: 0.667400\n",
      "Epoch 279, CIFAR-10 Batch 4:  Loss:     0.6751 Validation Accuracy: 0.657800\n",
      "Epoch 279, CIFAR-10 Batch 5:  Loss:     0.6718 Validation Accuracy: 0.664600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280, CIFAR-10 Batch 1:  Loss:     0.6638 Validation Accuracy: 0.668600\n",
      "Epoch 280, CIFAR-10 Batch 2:  Loss:     0.6834 Validation Accuracy: 0.667600\n",
      "Epoch 280, CIFAR-10 Batch 3:  Loss:     0.6927 Validation Accuracy: 0.659400\n",
      "Epoch 280, CIFAR-10 Batch 4:  Loss:     0.6701 Validation Accuracy: 0.653600\n",
      "Epoch 280, CIFAR-10 Batch 5:  Loss:     0.6705 Validation Accuracy: 0.666400\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss:     0.6857 Validation Accuracy: 0.669800\n",
      "Epoch 281, CIFAR-10 Batch 2:  Loss:     0.6776 Validation Accuracy: 0.668600\n",
      "Epoch 281, CIFAR-10 Batch 3:  Loss:     0.6630 Validation Accuracy: 0.671000\n",
      "Epoch 281, CIFAR-10 Batch 4:  Loss:     0.6487 Validation Accuracy: 0.660200\n",
      "Epoch 281, CIFAR-10 Batch 5:  Loss:     0.6792 Validation Accuracy: 0.661400\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss:     0.6938 Validation Accuracy: 0.668600\n",
      "Epoch 282, CIFAR-10 Batch 2:  Loss:     0.6841 Validation Accuracy: 0.670800\n",
      "Epoch 282, CIFAR-10 Batch 3:  Loss:     0.6803 Validation Accuracy: 0.669600\n",
      "Epoch 282, CIFAR-10 Batch 4:  Loss:     0.6441 Validation Accuracy: 0.665000\n",
      "Epoch 282, CIFAR-10 Batch 5:  Loss:     0.6614 Validation Accuracy: 0.670400\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss:     0.6799 Validation Accuracy: 0.670200\n",
      "Epoch 283, CIFAR-10 Batch 2:  Loss:     0.6640 Validation Accuracy: 0.669600\n",
      "Epoch 283, CIFAR-10 Batch 3:  Loss:     0.6849 Validation Accuracy: 0.666400\n",
      "Epoch 283, CIFAR-10 Batch 4:  Loss:     0.6508 Validation Accuracy: 0.662400\n",
      "Epoch 283, CIFAR-10 Batch 5:  Loss:     0.6718 Validation Accuracy: 0.664200\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss:     0.6799 Validation Accuracy: 0.668400\n",
      "Epoch 284, CIFAR-10 Batch 2:  Loss:     0.6852 Validation Accuracy: 0.663400\n",
      "Epoch 284, CIFAR-10 Batch 3:  Loss:     0.6755 Validation Accuracy: 0.667000\n",
      "Epoch 284, CIFAR-10 Batch 4:  Loss:     0.6571 Validation Accuracy: 0.661600\n",
      "Epoch 284, CIFAR-10 Batch 5:  Loss:     0.6561 Validation Accuracy: 0.666800\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss:     0.6641 Validation Accuracy: 0.669000\n",
      "Epoch 285, CIFAR-10 Batch 2:  Loss:     0.6767 Validation Accuracy: 0.668800\n",
      "Epoch 285, CIFAR-10 Batch 3:  Loss:     0.6669 Validation Accuracy: 0.669400\n",
      "Epoch 285, CIFAR-10 Batch 4:  Loss:     0.6479 Validation Accuracy: 0.659400\n",
      "Epoch 285, CIFAR-10 Batch 5:  Loss:     0.6589 Validation Accuracy: 0.668400\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss:     0.6669 Validation Accuracy: 0.673000\n",
      "Epoch 286, CIFAR-10 Batch 2:  Loss:     0.6593 Validation Accuracy: 0.675800\n",
      "Epoch 286, CIFAR-10 Batch 3:  Loss:     0.6659 Validation Accuracy: 0.675000\n",
      "Epoch 286, CIFAR-10 Batch 4:  Loss:     0.6430 Validation Accuracy: 0.665000\n",
      "Epoch 286, CIFAR-10 Batch 5:  Loss:     0.6728 Validation Accuracy: 0.667600\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss:     0.6635 Validation Accuracy: 0.675600\n",
      "Epoch 287, CIFAR-10 Batch 2:  Loss:     0.6756 Validation Accuracy: 0.666600\n",
      "Epoch 287, CIFAR-10 Batch 3:  Loss:     0.6655 Validation Accuracy: 0.673400\n",
      "Epoch 287, CIFAR-10 Batch 4:  Loss:     0.6395 Validation Accuracy: 0.664000\n",
      "Epoch 287, CIFAR-10 Batch 5:  Loss:     0.6655 Validation Accuracy: 0.663800\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss:     0.6783 Validation Accuracy: 0.671000\n",
      "Epoch 288, CIFAR-10 Batch 2:  Loss:     0.6760 Validation Accuracy: 0.664800\n",
      "Epoch 288, CIFAR-10 Batch 3:  Loss:     0.6574 Validation Accuracy: 0.670000\n",
      "Epoch 288, CIFAR-10 Batch 4:  Loss:     0.6298 Validation Accuracy: 0.664200\n",
      "Epoch 288, CIFAR-10 Batch 5:  Loss:     0.6592 Validation Accuracy: 0.670800\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss:     0.6797 Validation Accuracy: 0.669000\n",
      "Epoch 289, CIFAR-10 Batch 2:  Loss:     0.6735 Validation Accuracy: 0.671400\n",
      "Epoch 289, CIFAR-10 Batch 3:  Loss:     0.6699 Validation Accuracy: 0.668600\n",
      "Epoch 289, CIFAR-10 Batch 4:  Loss:     0.6236 Validation Accuracy: 0.666400\n",
      "Epoch 289, CIFAR-10 Batch 5:  Loss:     0.6556 Validation Accuracy: 0.670400\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss:     0.6495 Validation Accuracy: 0.675000\n",
      "Epoch 290, CIFAR-10 Batch 2:  Loss:     0.6700 Validation Accuracy: 0.670600\n",
      "Epoch 290, CIFAR-10 Batch 3:  Loss:     0.6708 Validation Accuracy: 0.668000\n",
      "Epoch 290, CIFAR-10 Batch 4:  Loss:     0.6430 Validation Accuracy: 0.664200\n",
      "Epoch 290, CIFAR-10 Batch 5:  Loss:     0.6595 Validation Accuracy: 0.668600\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss:     0.6724 Validation Accuracy: 0.672400\n",
      "Epoch 291, CIFAR-10 Batch 2:  Loss:     0.6737 Validation Accuracy: 0.667600\n",
      "Epoch 291, CIFAR-10 Batch 3:  Loss:     0.6525 Validation Accuracy: 0.673400\n",
      "Epoch 291, CIFAR-10 Batch 4:  Loss:     0.6196 Validation Accuracy: 0.672400\n",
      "Epoch 291, CIFAR-10 Batch 5:  Loss:     0.6707 Validation Accuracy: 0.664000\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss:     0.6648 Validation Accuracy: 0.672400\n",
      "Epoch 292, CIFAR-10 Batch 2:  Loss:     0.6766 Validation Accuracy: 0.666400\n",
      "Epoch 292, CIFAR-10 Batch 3:  Loss:     0.6672 Validation Accuracy: 0.672800\n",
      "Epoch 292, CIFAR-10 Batch 4:  Loss:     0.6238 Validation Accuracy: 0.668600\n",
      "Epoch 292, CIFAR-10 Batch 5:  Loss:     0.6559 Validation Accuracy: 0.663800\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss:     0.6657 Validation Accuracy: 0.669200\n",
      "Epoch 293, CIFAR-10 Batch 2:  Loss:     0.6548 Validation Accuracy: 0.671600\n",
      "Epoch 293, CIFAR-10 Batch 3:  Loss:     0.6434 Validation Accuracy: 0.671400\n",
      "Epoch 293, CIFAR-10 Batch 4:  Loss:     0.6264 Validation Accuracy: 0.669600\n",
      "Epoch 293, CIFAR-10 Batch 5:  Loss:     0.6430 Validation Accuracy: 0.666800\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss:     0.6660 Validation Accuracy: 0.670800\n",
      "Epoch 294, CIFAR-10 Batch 2:  Loss:     0.6610 Validation Accuracy: 0.664800\n",
      "Epoch 294, CIFAR-10 Batch 3:  Loss:     0.6526 Validation Accuracy: 0.671200\n",
      "Epoch 294, CIFAR-10 Batch 4:  Loss:     0.6326 Validation Accuracy: 0.657400\n",
      "Epoch 294, CIFAR-10 Batch 5:  Loss:     0.6567 Validation Accuracy: 0.671200\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss:     0.6652 Validation Accuracy: 0.670000\n",
      "Epoch 295, CIFAR-10 Batch 2:  Loss:     0.6683 Validation Accuracy: 0.673200\n",
      "Epoch 295, CIFAR-10 Batch 3:  Loss:     0.6686 Validation Accuracy: 0.668200\n",
      "Epoch 295, CIFAR-10 Batch 4:  Loss:     0.6349 Validation Accuracy: 0.669600\n",
      "Epoch 295, CIFAR-10 Batch 5:  Loss:     0.6433 Validation Accuracy: 0.673600\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss:     0.6563 Validation Accuracy: 0.669400\n",
      "Epoch 296, CIFAR-10 Batch 2:  Loss:     0.6655 Validation Accuracy: 0.669600\n",
      "Epoch 296, CIFAR-10 Batch 3:  Loss:     0.6415 Validation Accuracy: 0.673400\n",
      "Epoch 296, CIFAR-10 Batch 4:  Loss:     0.6159 Validation Accuracy: 0.666600\n",
      "Epoch 296, CIFAR-10 Batch 5:  Loss:     0.6526 Validation Accuracy: 0.672000\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss:     0.6718 Validation Accuracy: 0.669800\n",
      "Epoch 297, CIFAR-10 Batch 2:  Loss:     0.6480 Validation Accuracy: 0.673400\n",
      "Epoch 297, CIFAR-10 Batch 3:  Loss:     0.6777 Validation Accuracy: 0.662600\n",
      "Epoch 297, CIFAR-10 Batch 4:  Loss:     0.6347 Validation Accuracy: 0.667200\n",
      "Epoch 297, CIFAR-10 Batch 5:  Loss:     0.6584 Validation Accuracy: 0.667000\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss:     0.6641 Validation Accuracy: 0.671200\n",
      "Epoch 298, CIFAR-10 Batch 2:  Loss:     0.6526 Validation Accuracy: 0.668800\n",
      "Epoch 298, CIFAR-10 Batch 3:  Loss:     0.6600 Validation Accuracy: 0.666600\n",
      "Epoch 298, CIFAR-10 Batch 4:  Loss:     0.6391 Validation Accuracy: 0.659800\n",
      "Epoch 298, CIFAR-10 Batch 5:  Loss:     0.6498 Validation Accuracy: 0.668600\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss:     0.6577 Validation Accuracy: 0.671800\n",
      "Epoch 299, CIFAR-10 Batch 2:  Loss:     0.6453 Validation Accuracy: 0.669000\n",
      "Epoch 299, CIFAR-10 Batch 3:  Loss:     0.6679 Validation Accuracy: 0.669400\n",
      "Epoch 299, CIFAR-10 Batch 4:  Loss:     0.6318 Validation Accuracy: 0.657400\n",
      "Epoch 299, CIFAR-10 Batch 5:  Loss:     0.6362 Validation Accuracy: 0.669800\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss:     0.6542 Validation Accuracy: 0.671000\n",
      "Epoch 300, CIFAR-10 Batch 2:  Loss:     0.6462 Validation Accuracy: 0.667000\n",
      "Epoch 300, CIFAR-10 Batch 3:  Loss:     0.6621 Validation Accuracy: 0.672400\n",
      "Epoch 300, CIFAR-10 Batch 4:  Loss:     0.6208 Validation Accuracy: 0.666400\n",
      "Epoch 300, CIFAR-10 Batch 5:  Loss:     0.6501 Validation Accuracy: 0.668600\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss:     0.6677 Validation Accuracy: 0.666000\n",
      "Epoch 301, CIFAR-10 Batch 2:  Loss:     0.6634 Validation Accuracy: 0.667200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301, CIFAR-10 Batch 3:  Loss:     0.6521 Validation Accuracy: 0.668800\n",
      "Epoch 301, CIFAR-10 Batch 4:  Loss:     0.6204 Validation Accuracy: 0.665200\n",
      "Epoch 301, CIFAR-10 Batch 5:  Loss:     0.6426 Validation Accuracy: 0.670400\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss:     0.6574 Validation Accuracy: 0.669200\n",
      "Epoch 302, CIFAR-10 Batch 2:  Loss:     0.6581 Validation Accuracy: 0.672000\n",
      "Epoch 302, CIFAR-10 Batch 3:  Loss:     0.6564 Validation Accuracy: 0.668000\n",
      "Epoch 302, CIFAR-10 Batch 4:  Loss:     0.6240 Validation Accuracy: 0.667400\n",
      "Epoch 302, CIFAR-10 Batch 5:  Loss:     0.6315 Validation Accuracy: 0.673000\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss:     0.6595 Validation Accuracy: 0.673400\n",
      "Epoch 303, CIFAR-10 Batch 2:  Loss:     0.6587 Validation Accuracy: 0.673000\n",
      "Epoch 303, CIFAR-10 Batch 3:  Loss:     0.6419 Validation Accuracy: 0.672400\n",
      "Epoch 303, CIFAR-10 Batch 4:  Loss:     0.6008 Validation Accuracy: 0.667800\n",
      "Epoch 303, CIFAR-10 Batch 5:  Loss:     0.6316 Validation Accuracy: 0.669800\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss:     0.6593 Validation Accuracy: 0.677600\n",
      "Epoch 304, CIFAR-10 Batch 2:  Loss:     0.6457 Validation Accuracy: 0.674200\n",
      "Epoch 304, CIFAR-10 Batch 3:  Loss:     0.6532 Validation Accuracy: 0.676000\n",
      "Epoch 304, CIFAR-10 Batch 4:  Loss:     0.6076 Validation Accuracy: 0.672200\n",
      "Epoch 304, CIFAR-10 Batch 5:  Loss:     0.6376 Validation Accuracy: 0.662600\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss:     0.6617 Validation Accuracy: 0.670800\n",
      "Epoch 305, CIFAR-10 Batch 2:  Loss:     0.6598 Validation Accuracy: 0.662800\n",
      "Epoch 305, CIFAR-10 Batch 3:  Loss:     0.6586 Validation Accuracy: 0.667400\n",
      "Epoch 305, CIFAR-10 Batch 4:  Loss:     0.6166 Validation Accuracy: 0.668200\n",
      "Epoch 305, CIFAR-10 Batch 5:  Loss:     0.6288 Validation Accuracy: 0.672200\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss:     0.6508 Validation Accuracy: 0.670400\n",
      "Epoch 306, CIFAR-10 Batch 2:  Loss:     0.6667 Validation Accuracy: 0.668600\n",
      "Epoch 306, CIFAR-10 Batch 3:  Loss:     0.6598 Validation Accuracy: 0.669400\n",
      "Epoch 306, CIFAR-10 Batch 4:  Loss:     0.6053 Validation Accuracy: 0.670600\n",
      "Epoch 306, CIFAR-10 Batch 5:  Loss:     0.6194 Validation Accuracy: 0.670400\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss:     0.6666 Validation Accuracy: 0.674600\n",
      "Epoch 307, CIFAR-10 Batch 2:  Loss:     0.6789 Validation Accuracy: 0.664800\n",
      "Epoch 307, CIFAR-10 Batch 3:  Loss:     0.6417 Validation Accuracy: 0.673000\n",
      "Epoch 307, CIFAR-10 Batch 4:  Loss:     0.6165 Validation Accuracy: 0.665600\n",
      "Epoch 307, CIFAR-10 Batch 5:  Loss:     0.6424 Validation Accuracy: 0.667400\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss:     0.6478 Validation Accuracy: 0.670000\n",
      "Epoch 308, CIFAR-10 Batch 2:  Loss:     0.6509 Validation Accuracy: 0.663000\n",
      "Epoch 308, CIFAR-10 Batch 3:  Loss:     0.6515 Validation Accuracy: 0.668200\n",
      "Epoch 308, CIFAR-10 Batch 4:  Loss:     0.6299 Validation Accuracy: 0.671800\n",
      "Epoch 308, CIFAR-10 Batch 5:  Loss:     0.6340 Validation Accuracy: 0.666200\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss:     0.6652 Validation Accuracy: 0.666800\n",
      "Epoch 309, CIFAR-10 Batch 2:  Loss:     0.6572 Validation Accuracy: 0.669600\n",
      "Epoch 309, CIFAR-10 Batch 3:  Loss:     0.6747 Validation Accuracy: 0.668800\n",
      "Epoch 309, CIFAR-10 Batch 4:  Loss:     0.6314 Validation Accuracy: 0.673000\n",
      "Epoch 309, CIFAR-10 Batch 5:  Loss:     0.6392 Validation Accuracy: 0.665800\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss:     0.6640 Validation Accuracy: 0.665200\n",
      "Epoch 310, CIFAR-10 Batch 2:  Loss:     0.6462 Validation Accuracy: 0.670600\n",
      "Epoch 310, CIFAR-10 Batch 3:  Loss:     0.6706 Validation Accuracy: 0.668600\n",
      "Epoch 310, CIFAR-10 Batch 4:  Loss:     0.6267 Validation Accuracy: 0.669200\n",
      "Epoch 310, CIFAR-10 Batch 5:  Loss:     0.6418 Validation Accuracy: 0.672600\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss:     0.6507 Validation Accuracy: 0.670800\n",
      "Epoch 311, CIFAR-10 Batch 2:  Loss:     0.6638 Validation Accuracy: 0.668000\n",
      "Epoch 311, CIFAR-10 Batch 3:  Loss:     0.6463 Validation Accuracy: 0.664600\n",
      "Epoch 311, CIFAR-10 Batch 4:  Loss:     0.6163 Validation Accuracy: 0.669200\n",
      "Epoch 311, CIFAR-10 Batch 5:  Loss:     0.6574 Validation Accuracy: 0.665000\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss:     0.6699 Validation Accuracy: 0.671000\n",
      "Epoch 312, CIFAR-10 Batch 2:  Loss:     0.6435 Validation Accuracy: 0.671200\n",
      "Epoch 312, CIFAR-10 Batch 3:  Loss:     0.6338 Validation Accuracy: 0.669600\n",
      "Epoch 312, CIFAR-10 Batch 4:  Loss:     0.6110 Validation Accuracy: 0.665000\n",
      "Epoch 312, CIFAR-10 Batch 5:  Loss:     0.6357 Validation Accuracy: 0.670800\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss:     0.6559 Validation Accuracy: 0.672400\n",
      "Epoch 313, CIFAR-10 Batch 2:  Loss:     0.6542 Validation Accuracy: 0.668000\n",
      "Epoch 313, CIFAR-10 Batch 3:  Loss:     0.6470 Validation Accuracy: 0.669000\n",
      "Epoch 313, CIFAR-10 Batch 4:  Loss:     0.6217 Validation Accuracy: 0.665800\n",
      "Epoch 313, CIFAR-10 Batch 5:  Loss:     0.6236 Validation Accuracy: 0.666000\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss:     0.6501 Validation Accuracy: 0.669800\n",
      "Epoch 314, CIFAR-10 Batch 2:  Loss:     0.6404 Validation Accuracy: 0.669200\n",
      "Epoch 314, CIFAR-10 Batch 3:  Loss:     0.6406 Validation Accuracy: 0.667800\n",
      "Epoch 314, CIFAR-10 Batch 4:  Loss:     0.6185 Validation Accuracy: 0.666400\n",
      "Epoch 314, CIFAR-10 Batch 5:  Loss:     0.6337 Validation Accuracy: 0.674800\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss:     0.6680 Validation Accuracy: 0.666200\n",
      "Epoch 315, CIFAR-10 Batch 2:  Loss:     0.6394 Validation Accuracy: 0.671000\n",
      "Epoch 315, CIFAR-10 Batch 3:  Loss:     0.6402 Validation Accuracy: 0.671600\n",
      "Epoch 315, CIFAR-10 Batch 4:  Loss:     0.6174 Validation Accuracy: 0.672800\n",
      "Epoch 315, CIFAR-10 Batch 5:  Loss:     0.6294 Validation Accuracy: 0.667800\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss:     0.6430 Validation Accuracy: 0.670400\n",
      "Epoch 316, CIFAR-10 Batch 2:  Loss:     0.6457 Validation Accuracy: 0.670000\n",
      "Epoch 316, CIFAR-10 Batch 3:  Loss:     0.6386 Validation Accuracy: 0.672200\n",
      "Epoch 316, CIFAR-10 Batch 4:  Loss:     0.6101 Validation Accuracy: 0.666600\n",
      "Epoch 316, CIFAR-10 Batch 5:  Loss:     0.6427 Validation Accuracy: 0.661200\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss:     0.6674 Validation Accuracy: 0.667200\n",
      "Epoch 317, CIFAR-10 Batch 2:  Loss:     0.6706 Validation Accuracy: 0.669200\n",
      "Epoch 317, CIFAR-10 Batch 3:  Loss:     0.6278 Validation Accuracy: 0.672200\n",
      "Epoch 317, CIFAR-10 Batch 4:  Loss:     0.6200 Validation Accuracy: 0.658200\n",
      "Epoch 317, CIFAR-10 Batch 5:  Loss:     0.6371 Validation Accuracy: 0.667800\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss:     0.6521 Validation Accuracy: 0.672400\n",
      "Epoch 318, CIFAR-10 Batch 2:  Loss:     0.6734 Validation Accuracy: 0.663000\n",
      "Epoch 318, CIFAR-10 Batch 3:  Loss:     0.6429 Validation Accuracy: 0.667200\n",
      "Epoch 318, CIFAR-10 Batch 4:  Loss:     0.6093 Validation Accuracy: 0.663600\n",
      "Epoch 318, CIFAR-10 Batch 5:  Loss:     0.6343 Validation Accuracy: 0.661600\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss:     0.6469 Validation Accuracy: 0.670800\n",
      "Epoch 319, CIFAR-10 Batch 2:  Loss:     0.6723 Validation Accuracy: 0.663400\n",
      "Epoch 319, CIFAR-10 Batch 3:  Loss:     0.6289 Validation Accuracy: 0.672600\n",
      "Epoch 319, CIFAR-10 Batch 4:  Loss:     0.6167 Validation Accuracy: 0.666200\n",
      "Epoch 319, CIFAR-10 Batch 5:  Loss:     0.6271 Validation Accuracy: 0.669800\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss:     0.6435 Validation Accuracy: 0.670000\n",
      "Epoch 320, CIFAR-10 Batch 2:  Loss:     0.6639 Validation Accuracy: 0.665600\n",
      "Epoch 320, CIFAR-10 Batch 3:  Loss:     0.6343 Validation Accuracy: 0.669200\n",
      "Epoch 320, CIFAR-10 Batch 4:  Loss:     0.6021 Validation Accuracy: 0.667400\n",
      "Epoch 320, CIFAR-10 Batch 5:  Loss:     0.6180 Validation Accuracy: 0.669600\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss:     0.6325 Validation Accuracy: 0.668400\n",
      "Epoch 321, CIFAR-10 Batch 2:  Loss:     0.6228 Validation Accuracy: 0.674600\n",
      "Epoch 321, CIFAR-10 Batch 3:  Loss:     0.6287 Validation Accuracy: 0.675400\n",
      "Epoch 321, CIFAR-10 Batch 4:  Loss:     0.6201 Validation Accuracy: 0.656400\n",
      "Epoch 321, CIFAR-10 Batch 5:  Loss:     0.6290 Validation Accuracy: 0.669000\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss:     0.6427 Validation Accuracy: 0.666800\n",
      "Epoch 322, CIFAR-10 Batch 2:  Loss:     0.6409 Validation Accuracy: 0.665200\n",
      "Epoch 322, CIFAR-10 Batch 3:  Loss:     0.6477 Validation Accuracy: 0.666000\n",
      "Epoch 322, CIFAR-10 Batch 4:  Loss:     0.6001 Validation Accuracy: 0.669200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 322, CIFAR-10 Batch 5:  Loss:     0.6242 Validation Accuracy: 0.662200\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss:     0.6573 Validation Accuracy: 0.664400\n",
      "Epoch 323, CIFAR-10 Batch 2:  Loss:     0.6542 Validation Accuracy: 0.668600\n",
      "Epoch 323, CIFAR-10 Batch 3:  Loss:     0.6273 Validation Accuracy: 0.671600\n",
      "Epoch 323, CIFAR-10 Batch 4:  Loss:     0.5986 Validation Accuracy: 0.670000\n",
      "Epoch 323, CIFAR-10 Batch 5:  Loss:     0.6245 Validation Accuracy: 0.671800\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss:     0.6287 Validation Accuracy: 0.676800\n",
      "Epoch 324, CIFAR-10 Batch 2:  Loss:     0.6433 Validation Accuracy: 0.664200\n",
      "Epoch 324, CIFAR-10 Batch 3:  Loss:     0.6417 Validation Accuracy: 0.664800\n",
      "Epoch 324, CIFAR-10 Batch 4:  Loss:     0.6045 Validation Accuracy: 0.666200\n",
      "Epoch 324, CIFAR-10 Batch 5:  Loss:     0.6465 Validation Accuracy: 0.661400\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss:     0.6654 Validation Accuracy: 0.660600\n",
      "Epoch 325, CIFAR-10 Batch 2:  Loss:     0.6414 Validation Accuracy: 0.669600\n",
      "Epoch 325, CIFAR-10 Batch 3:  Loss:     0.6357 Validation Accuracy: 0.669000\n",
      "Epoch 325, CIFAR-10 Batch 4:  Loss:     0.5952 Validation Accuracy: 0.671200\n",
      "Epoch 325, CIFAR-10 Batch 5:  Loss:     0.6298 Validation Accuracy: 0.669000\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss:     0.6543 Validation Accuracy: 0.663000\n",
      "Epoch 326, CIFAR-10 Batch 2:  Loss:     0.6474 Validation Accuracy: 0.669400\n",
      "Epoch 326, CIFAR-10 Batch 3:  Loss:     0.6257 Validation Accuracy: 0.669400\n",
      "Epoch 326, CIFAR-10 Batch 4:  Loss:     0.6010 Validation Accuracy: 0.671000\n",
      "Epoch 326, CIFAR-10 Batch 5:  Loss:     0.6088 Validation Accuracy: 0.671200\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss:     0.6405 Validation Accuracy: 0.665400\n",
      "Epoch 327, CIFAR-10 Batch 2:  Loss:     0.6238 Validation Accuracy: 0.670800\n",
      "Epoch 327, CIFAR-10 Batch 3:  Loss:     0.6484 Validation Accuracy: 0.666000\n",
      "Epoch 327, CIFAR-10 Batch 4:  Loss:     0.6051 Validation Accuracy: 0.671800\n",
      "Epoch 327, CIFAR-10 Batch 5:  Loss:     0.6355 Validation Accuracy: 0.666400\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss:     0.6624 Validation Accuracy: 0.667800\n",
      "Epoch 328, CIFAR-10 Batch 2:  Loss:     0.6456 Validation Accuracy: 0.665600\n",
      "Epoch 328, CIFAR-10 Batch 3:  Loss:     0.6303 Validation Accuracy: 0.669600\n",
      "Epoch 328, CIFAR-10 Batch 4:  Loss:     0.5960 Validation Accuracy: 0.676000\n",
      "Epoch 328, CIFAR-10 Batch 5:  Loss:     0.6429 Validation Accuracy: 0.666200\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss:     0.6452 Validation Accuracy: 0.670600\n",
      "Epoch 329, CIFAR-10 Batch 2:  Loss:     0.6682 Validation Accuracy: 0.661800\n",
      "Epoch 329, CIFAR-10 Batch 3:  Loss:     0.6251 Validation Accuracy: 0.670800\n",
      "Epoch 329, CIFAR-10 Batch 4:  Loss:     0.5885 Validation Accuracy: 0.673600\n",
      "Epoch 329, CIFAR-10 Batch 5:  Loss:     0.6277 Validation Accuracy: 0.664200\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss:     0.6405 Validation Accuracy: 0.668000\n",
      "Epoch 330, CIFAR-10 Batch 2:  Loss:     0.6398 Validation Accuracy: 0.666400\n",
      "Epoch 330, CIFAR-10 Batch 3:  Loss:     0.6330 Validation Accuracy: 0.671400\n",
      "Epoch 330, CIFAR-10 Batch 4:  Loss:     0.6199 Validation Accuracy: 0.669800\n",
      "Epoch 330, CIFAR-10 Batch 5:  Loss:     0.6271 Validation Accuracy: 0.671000\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss:     0.6411 Validation Accuracy: 0.667800\n",
      "Epoch 331, CIFAR-10 Batch 2:  Loss:     0.6396 Validation Accuracy: 0.670000\n",
      "Epoch 331, CIFAR-10 Batch 3:  Loss:     0.6226 Validation Accuracy: 0.672600\n",
      "Epoch 331, CIFAR-10 Batch 4:  Loss:     0.5939 Validation Accuracy: 0.673400\n",
      "Epoch 331, CIFAR-10 Batch 5:  Loss:     0.6183 Validation Accuracy: 0.671200\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss:     0.6299 Validation Accuracy: 0.664400\n",
      "Epoch 332, CIFAR-10 Batch 2:  Loss:     0.6312 Validation Accuracy: 0.666200\n",
      "Epoch 332, CIFAR-10 Batch 3:  Loss:     0.6622 Validation Accuracy: 0.661800\n",
      "Epoch 332, CIFAR-10 Batch 4:  Loss:     0.5993 Validation Accuracy: 0.669800\n",
      "Epoch 332, CIFAR-10 Batch 5:  Loss:     0.6316 Validation Accuracy: 0.667600\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss:     0.6482 Validation Accuracy: 0.665600\n",
      "Epoch 333, CIFAR-10 Batch 2:  Loss:     0.6298 Validation Accuracy: 0.672400\n",
      "Epoch 333, CIFAR-10 Batch 3:  Loss:     0.6610 Validation Accuracy: 0.665400\n",
      "Epoch 333, CIFAR-10 Batch 4:  Loss:     0.6233 Validation Accuracy: 0.670800\n",
      "Epoch 333, CIFAR-10 Batch 5:  Loss:     0.6272 Validation Accuracy: 0.666000\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss:     0.6257 Validation Accuracy: 0.674600\n",
      "Epoch 334, CIFAR-10 Batch 2:  Loss:     0.6393 Validation Accuracy: 0.670200\n",
      "Epoch 334, CIFAR-10 Batch 3:  Loss:     0.6226 Validation Accuracy: 0.667800\n",
      "Epoch 334, CIFAR-10 Batch 4:  Loss:     0.5923 Validation Accuracy: 0.675600\n",
      "Epoch 334, CIFAR-10 Batch 5:  Loss:     0.6273 Validation Accuracy: 0.664000\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss:     0.6438 Validation Accuracy: 0.670400\n",
      "Epoch 335, CIFAR-10 Batch 2:  Loss:     0.6465 Validation Accuracy: 0.667400\n",
      "Epoch 335, CIFAR-10 Batch 3:  Loss:     0.6269 Validation Accuracy: 0.666000\n",
      "Epoch 335, CIFAR-10 Batch 4:  Loss:     0.5899 Validation Accuracy: 0.667800\n",
      "Epoch 335, CIFAR-10 Batch 5:  Loss:     0.6077 Validation Accuracy: 0.675000\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss:     0.6273 Validation Accuracy: 0.669800\n",
      "Epoch 336, CIFAR-10 Batch 2:  Loss:     0.6392 Validation Accuracy: 0.668800\n",
      "Epoch 336, CIFAR-10 Batch 3:  Loss:     0.6318 Validation Accuracy: 0.665400\n",
      "Epoch 336, CIFAR-10 Batch 4:  Loss:     0.5964 Validation Accuracy: 0.667800\n",
      "Epoch 336, CIFAR-10 Batch 5:  Loss:     0.6286 Validation Accuracy: 0.664600\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss:     0.6407 Validation Accuracy: 0.669400\n",
      "Epoch 337, CIFAR-10 Batch 2:  Loss:     0.6560 Validation Accuracy: 0.661400\n",
      "Epoch 337, CIFAR-10 Batch 3:  Loss:     0.6307 Validation Accuracy: 0.671400\n",
      "Epoch 337, CIFAR-10 Batch 4:  Loss:     0.5793 Validation Accuracy: 0.670400\n",
      "Epoch 337, CIFAR-10 Batch 5:  Loss:     0.6168 Validation Accuracy: 0.666400\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss:     0.6396 Validation Accuracy: 0.666400\n",
      "Epoch 338, CIFAR-10 Batch 2:  Loss:     0.6354 Validation Accuracy: 0.671200\n",
      "Epoch 338, CIFAR-10 Batch 3:  Loss:     0.6286 Validation Accuracy: 0.669800\n",
      "Epoch 338, CIFAR-10 Batch 4:  Loss:     0.6021 Validation Accuracy: 0.667200\n",
      "Epoch 338, CIFAR-10 Batch 5:  Loss:     0.6286 Validation Accuracy: 0.665000\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss:     0.6308 Validation Accuracy: 0.675200\n",
      "Epoch 339, CIFAR-10 Batch 2:  Loss:     0.6346 Validation Accuracy: 0.669200\n",
      "Epoch 339, CIFAR-10 Batch 3:  Loss:     0.6267 Validation Accuracy: 0.670800\n",
      "Epoch 339, CIFAR-10 Batch 4:  Loss:     0.5836 Validation Accuracy: 0.672400\n",
      "Epoch 339, CIFAR-10 Batch 5:  Loss:     0.6453 Validation Accuracy: 0.662200\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss:     0.6373 Validation Accuracy: 0.667200\n",
      "Epoch 340, CIFAR-10 Batch 2:  Loss:     0.6474 Validation Accuracy: 0.667000\n",
      "Epoch 340, CIFAR-10 Batch 3:  Loss:     0.6156 Validation Accuracy: 0.667800\n",
      "Epoch 340, CIFAR-10 Batch 4:  Loss:     0.5864 Validation Accuracy: 0.676000\n",
      "Epoch 340, CIFAR-10 Batch 5:  Loss:     0.6249 Validation Accuracy: 0.669600\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss:     0.6290 Validation Accuracy: 0.673000\n",
      "Epoch 341, CIFAR-10 Batch 2:  Loss:     0.6251 Validation Accuracy: 0.677400\n",
      "Epoch 341, CIFAR-10 Batch 3:  Loss:     0.6159 Validation Accuracy: 0.670600\n",
      "Epoch 341, CIFAR-10 Batch 4:  Loss:     0.5889 Validation Accuracy: 0.663200\n",
      "Epoch 341, CIFAR-10 Batch 5:  Loss:     0.6249 Validation Accuracy: 0.669000\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss:     0.6410 Validation Accuracy: 0.670600\n",
      "Epoch 342, CIFAR-10 Batch 2:  Loss:     0.6281 Validation Accuracy: 0.665400\n",
      "Epoch 342, CIFAR-10 Batch 3:  Loss:     0.6569 Validation Accuracy: 0.658400\n",
      "Epoch 342, CIFAR-10 Batch 4:  Loss:     0.6056 Validation Accuracy: 0.673000\n",
      "Epoch 342, CIFAR-10 Batch 5:  Loss:     0.6175 Validation Accuracy: 0.667000\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss:     0.6440 Validation Accuracy: 0.667600\n",
      "Epoch 343, CIFAR-10 Batch 2:  Loss:     0.6556 Validation Accuracy: 0.657000\n",
      "Epoch 343, CIFAR-10 Batch 3:  Loss:     0.6583 Validation Accuracy: 0.658800\n",
      "Epoch 343, CIFAR-10 Batch 4:  Loss:     0.6013 Validation Accuracy: 0.671600\n",
      "Epoch 343, CIFAR-10 Batch 5:  Loss:     0.6335 Validation Accuracy: 0.665600\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss:     0.6409 Validation Accuracy: 0.664800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344, CIFAR-10 Batch 2:  Loss:     0.6824 Validation Accuracy: 0.657000\n",
      "Epoch 344, CIFAR-10 Batch 3:  Loss:     0.6027 Validation Accuracy: 0.679200\n",
      "Epoch 344, CIFAR-10 Batch 4:  Loss:     0.6051 Validation Accuracy: 0.661600\n",
      "Epoch 344, CIFAR-10 Batch 5:  Loss:     0.6218 Validation Accuracy: 0.668200\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss:     0.6480 Validation Accuracy: 0.664600\n",
      "Epoch 345, CIFAR-10 Batch 2:  Loss:     0.6366 Validation Accuracy: 0.671600\n",
      "Epoch 345, CIFAR-10 Batch 3:  Loss:     0.6298 Validation Accuracy: 0.669400\n",
      "Epoch 345, CIFAR-10 Batch 4:  Loss:     0.6149 Validation Accuracy: 0.661600\n",
      "Epoch 345, CIFAR-10 Batch 5:  Loss:     0.6146 Validation Accuracy: 0.667400\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss:     0.6401 Validation Accuracy: 0.670600\n",
      "Epoch 346, CIFAR-10 Batch 2:  Loss:     0.6114 Validation Accuracy: 0.673800\n",
      "Epoch 346, CIFAR-10 Batch 3:  Loss:     0.6149 Validation Accuracy: 0.675200\n",
      "Epoch 346, CIFAR-10 Batch 4:  Loss:     0.6138 Validation Accuracy: 0.656600\n",
      "Epoch 346, CIFAR-10 Batch 5:  Loss:     0.6070 Validation Accuracy: 0.670800\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss:     0.6391 Validation Accuracy: 0.666200\n",
      "Epoch 347, CIFAR-10 Batch 2:  Loss:     0.6257 Validation Accuracy: 0.673200\n",
      "Epoch 347, CIFAR-10 Batch 3:  Loss:     0.6204 Validation Accuracy: 0.672400\n",
      "Epoch 347, CIFAR-10 Batch 4:  Loss:     0.6149 Validation Accuracy: 0.656600\n",
      "Epoch 347, CIFAR-10 Batch 5:  Loss:     0.6051 Validation Accuracy: 0.660200\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss:     0.6195 Validation Accuracy: 0.668600\n",
      "Epoch 348, CIFAR-10 Batch 2:  Loss:     0.6079 Validation Accuracy: 0.669800\n",
      "Epoch 348, CIFAR-10 Batch 3:  Loss:     0.6084 Validation Accuracy: 0.667000\n",
      "Epoch 348, CIFAR-10 Batch 4:  Loss:     0.6063 Validation Accuracy: 0.660000\n",
      "Epoch 348, CIFAR-10 Batch 5:  Loss:     0.6076 Validation Accuracy: 0.671800\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss:     0.6389 Validation Accuracy: 0.668600\n",
      "Epoch 349, CIFAR-10 Batch 2:  Loss:     0.6271 Validation Accuracy: 0.666400\n",
      "Epoch 349, CIFAR-10 Batch 3:  Loss:     0.6204 Validation Accuracy: 0.667200\n",
      "Epoch 349, CIFAR-10 Batch 4:  Loss:     0.6107 Validation Accuracy: 0.660200\n",
      "Epoch 349, CIFAR-10 Batch 5:  Loss:     0.6042 Validation Accuracy: 0.668600\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss:     0.6447 Validation Accuracy: 0.666800\n",
      "Epoch 350, CIFAR-10 Batch 2:  Loss:     0.6113 Validation Accuracy: 0.674800\n",
      "Epoch 350, CIFAR-10 Batch 3:  Loss:     0.6169 Validation Accuracy: 0.672400\n",
      "Epoch 350, CIFAR-10 Batch 4:  Loss:     0.5815 Validation Accuracy: 0.675800\n",
      "Epoch 350, CIFAR-10 Batch 5:  Loss:     0.6175 Validation Accuracy: 0.668600\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss:     0.6356 Validation Accuracy: 0.671000\n",
      "Epoch 351, CIFAR-10 Batch 2:  Loss:     0.6135 Validation Accuracy: 0.672000\n",
      "Epoch 351, CIFAR-10 Batch 3:  Loss:     0.6139 Validation Accuracy: 0.676000\n",
      "Epoch 351, CIFAR-10 Batch 4:  Loss:     0.5817 Validation Accuracy: 0.663400\n",
      "Epoch 351, CIFAR-10 Batch 5:  Loss:     0.5908 Validation Accuracy: 0.666800\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss:     0.6408 Validation Accuracy: 0.668600\n",
      "Epoch 352, CIFAR-10 Batch 2:  Loss:     0.6159 Validation Accuracy: 0.677200\n",
      "Epoch 352, CIFAR-10 Batch 3:  Loss:     0.6071 Validation Accuracy: 0.672800\n",
      "Epoch 352, CIFAR-10 Batch 4:  Loss:     0.5962 Validation Accuracy: 0.666200\n",
      "Epoch 352, CIFAR-10 Batch 5:  Loss:     0.6077 Validation Accuracy: 0.666000\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss:     0.6202 Validation Accuracy: 0.671800\n",
      "Epoch 353, CIFAR-10 Batch 2:  Loss:     0.6223 Validation Accuracy: 0.664200\n",
      "Epoch 353, CIFAR-10 Batch 3:  Loss:     0.6192 Validation Accuracy: 0.670400\n",
      "Epoch 353, CIFAR-10 Batch 4:  Loss:     0.5716 Validation Accuracy: 0.667800\n",
      "Epoch 353, CIFAR-10 Batch 5:  Loss:     0.5892 Validation Accuracy: 0.667800\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss:     0.6364 Validation Accuracy: 0.672000\n",
      "Epoch 354, CIFAR-10 Batch 2:  Loss:     0.6157 Validation Accuracy: 0.669000\n",
      "Epoch 354, CIFAR-10 Batch 3:  Loss:     0.6297 Validation Accuracy: 0.664800\n",
      "Epoch 354, CIFAR-10 Batch 4:  Loss:     0.5969 Validation Accuracy: 0.666600\n",
      "Epoch 354, CIFAR-10 Batch 5:  Loss:     0.6009 Validation Accuracy: 0.670000\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss:     0.6197 Validation Accuracy: 0.669400\n",
      "Epoch 355, CIFAR-10 Batch 2:  Loss:     0.6140 Validation Accuracy: 0.669400\n",
      "Epoch 355, CIFAR-10 Batch 3:  Loss:     0.6281 Validation Accuracy: 0.667000\n",
      "Epoch 355, CIFAR-10 Batch 4:  Loss:     0.5828 Validation Accuracy: 0.664200\n",
      "Epoch 355, CIFAR-10 Batch 5:  Loss:     0.5991 Validation Accuracy: 0.667800\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss:     0.6357 Validation Accuracy: 0.661400\n",
      "Epoch 356, CIFAR-10 Batch 2:  Loss:     0.6451 Validation Accuracy: 0.664600\n",
      "Epoch 356, CIFAR-10 Batch 3:  Loss:     0.6344 Validation Accuracy: 0.669000\n",
      "Epoch 356, CIFAR-10 Batch 4:  Loss:     0.5924 Validation Accuracy: 0.664000\n",
      "Epoch 356, CIFAR-10 Batch 5:  Loss:     0.6070 Validation Accuracy: 0.671200\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss:     0.6437 Validation Accuracy: 0.670000\n",
      "Epoch 357, CIFAR-10 Batch 2:  Loss:     0.6248 Validation Accuracy: 0.668400\n",
      "Epoch 357, CIFAR-10 Batch 3:  Loss:     0.6326 Validation Accuracy: 0.667200\n",
      "Epoch 357, CIFAR-10 Batch 4:  Loss:     0.5865 Validation Accuracy: 0.661000\n",
      "Epoch 357, CIFAR-10 Batch 5:  Loss:     0.5969 Validation Accuracy: 0.673800\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss:     0.6386 Validation Accuracy: 0.670800\n",
      "Epoch 358, CIFAR-10 Batch 2:  Loss:     0.6144 Validation Accuracy: 0.672200\n",
      "Epoch 358, CIFAR-10 Batch 3:  Loss:     0.6164 Validation Accuracy: 0.670000\n",
      "Epoch 358, CIFAR-10 Batch 4:  Loss:     0.5752 Validation Accuracy: 0.664200\n",
      "Epoch 358, CIFAR-10 Batch 5:  Loss:     0.6033 Validation Accuracy: 0.673400\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss:     0.6185 Validation Accuracy: 0.669400\n",
      "Epoch 359, CIFAR-10 Batch 2:  Loss:     0.6055 Validation Accuracy: 0.678400\n",
      "Epoch 359, CIFAR-10 Batch 3:  Loss:     0.6289 Validation Accuracy: 0.667800\n",
      "Epoch 359, CIFAR-10 Batch 4:  Loss:     0.6025 Validation Accuracy: 0.659800\n",
      "Epoch 359, CIFAR-10 Batch 5:  Loss:     0.6025 Validation Accuracy: 0.669600\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss:     0.6338 Validation Accuracy: 0.672600\n",
      "Epoch 360, CIFAR-10 Batch 2:  Loss:     0.6030 Validation Accuracy: 0.670200\n",
      "Epoch 360, CIFAR-10 Batch 3:  Loss:     0.6004 Validation Accuracy: 0.669000\n",
      "Epoch 360, CIFAR-10 Batch 4:  Loss:     0.5928 Validation Accuracy: 0.663000\n",
      "Epoch 360, CIFAR-10 Batch 5:  Loss:     0.5986 Validation Accuracy: 0.667400\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss:     0.6188 Validation Accuracy: 0.669600\n",
      "Epoch 361, CIFAR-10 Batch 2:  Loss:     0.6277 Validation Accuracy: 0.665400\n",
      "Epoch 361, CIFAR-10 Batch 3:  Loss:     0.6219 Validation Accuracy: 0.670800\n",
      "Epoch 361, CIFAR-10 Batch 4:  Loss:     0.5730 Validation Accuracy: 0.667400\n",
      "Epoch 361, CIFAR-10 Batch 5:  Loss:     0.5962 Validation Accuracy: 0.663600\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss:     0.6174 Validation Accuracy: 0.671800\n",
      "Epoch 362, CIFAR-10 Batch 2:  Loss:     0.6262 Validation Accuracy: 0.668800\n",
      "Epoch 362, CIFAR-10 Batch 3:  Loss:     0.5940 Validation Accuracy: 0.673400\n",
      "Epoch 362, CIFAR-10 Batch 4:  Loss:     0.5997 Validation Accuracy: 0.652600\n",
      "Epoch 362, CIFAR-10 Batch 5:  Loss:     0.6052 Validation Accuracy: 0.667600\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss:     0.6300 Validation Accuracy: 0.664600\n",
      "Epoch 363, CIFAR-10 Batch 2:  Loss:     0.6178 Validation Accuracy: 0.665200\n",
      "Epoch 363, CIFAR-10 Batch 3:  Loss:     0.6207 Validation Accuracy: 0.673600\n",
      "Epoch 363, CIFAR-10 Batch 4:  Loss:     0.5912 Validation Accuracy: 0.657800\n",
      "Epoch 363, CIFAR-10 Batch 5:  Loss:     0.6111 Validation Accuracy: 0.663400\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss:     0.6093 Validation Accuracy: 0.673800\n",
      "Epoch 364, CIFAR-10 Batch 2:  Loss:     0.6161 Validation Accuracy: 0.665400\n",
      "Epoch 364, CIFAR-10 Batch 3:  Loss:     0.6222 Validation Accuracy: 0.671400\n",
      "Epoch 364, CIFAR-10 Batch 4:  Loss:     0.5915 Validation Accuracy: 0.671400\n",
      "Epoch 364, CIFAR-10 Batch 5:  Loss:     0.6115 Validation Accuracy: 0.664200\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss:     0.6238 Validation Accuracy: 0.672000\n",
      "Epoch 365, CIFAR-10 Batch 2:  Loss:     0.6056 Validation Accuracy: 0.670600\n",
      "Epoch 365, CIFAR-10 Batch 3:  Loss:     0.6631 Validation Accuracy: 0.664400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365, CIFAR-10 Batch 4:  Loss:     0.5758 Validation Accuracy: 0.673400\n",
      "Epoch 365, CIFAR-10 Batch 5:  Loss:     0.5938 Validation Accuracy: 0.665400\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss:     0.6299 Validation Accuracy: 0.672200\n",
      "Epoch 366, CIFAR-10 Batch 2:  Loss:     0.6019 Validation Accuracy: 0.673000\n",
      "Epoch 366, CIFAR-10 Batch 3:  Loss:     0.6217 Validation Accuracy: 0.670600\n",
      "Epoch 366, CIFAR-10 Batch 4:  Loss:     0.5688 Validation Accuracy: 0.668800\n",
      "Epoch 366, CIFAR-10 Batch 5:  Loss:     0.5727 Validation Accuracy: 0.669000\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss:     0.6277 Validation Accuracy: 0.673000\n",
      "Epoch 367, CIFAR-10 Batch 2:  Loss:     0.6280 Validation Accuracy: 0.659400\n",
      "Epoch 367, CIFAR-10 Batch 3:  Loss:     0.6276 Validation Accuracy: 0.663600\n",
      "Epoch 367, CIFAR-10 Batch 4:  Loss:     0.5682 Validation Accuracy: 0.667200\n",
      "Epoch 367, CIFAR-10 Batch 5:  Loss:     0.5983 Validation Accuracy: 0.656000\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss:     0.6171 Validation Accuracy: 0.673200\n",
      "Epoch 368, CIFAR-10 Batch 2:  Loss:     0.6128 Validation Accuracy: 0.669600\n",
      "Epoch 368, CIFAR-10 Batch 3:  Loss:     0.6194 Validation Accuracy: 0.673000\n",
      "Epoch 368, CIFAR-10 Batch 4:  Loss:     0.5774 Validation Accuracy: 0.667800\n",
      "Epoch 368, CIFAR-10 Batch 5:  Loss:     0.6027 Validation Accuracy: 0.666800\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss:     0.6145 Validation Accuracy: 0.673600\n",
      "Epoch 369, CIFAR-10 Batch 2:  Loss:     0.6021 Validation Accuracy: 0.674200\n",
      "Epoch 369, CIFAR-10 Batch 3:  Loss:     0.6134 Validation Accuracy: 0.671200\n",
      "Epoch 369, CIFAR-10 Batch 4:  Loss:     0.5849 Validation Accuracy: 0.659200\n",
      "Epoch 369, CIFAR-10 Batch 5:  Loss:     0.5889 Validation Accuracy: 0.661200\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss:     0.6197 Validation Accuracy: 0.672000\n",
      "Epoch 370, CIFAR-10 Batch 2:  Loss:     0.6140 Validation Accuracy: 0.669600\n",
      "Epoch 370, CIFAR-10 Batch 3:  Loss:     0.6157 Validation Accuracy: 0.670400\n",
      "Epoch 370, CIFAR-10 Batch 4:  Loss:     0.5828 Validation Accuracy: 0.664000\n",
      "Epoch 370, CIFAR-10 Batch 5:  Loss:     0.6095 Validation Accuracy: 0.665600\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss:     0.6272 Validation Accuracy: 0.670800\n",
      "Epoch 371, CIFAR-10 Batch 2:  Loss:     0.6250 Validation Accuracy: 0.663600\n",
      "Epoch 371, CIFAR-10 Batch 3:  Loss:     0.6333 Validation Accuracy: 0.666200\n",
      "Epoch 371, CIFAR-10 Batch 4:  Loss:     0.5763 Validation Accuracy: 0.670600\n",
      "Epoch 371, CIFAR-10 Batch 5:  Loss:     0.5991 Validation Accuracy: 0.664600\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss:     0.6334 Validation Accuracy: 0.673400\n",
      "Epoch 372, CIFAR-10 Batch 2:  Loss:     0.5988 Validation Accuracy: 0.675000\n",
      "Epoch 372, CIFAR-10 Batch 3:  Loss:     0.6340 Validation Accuracy: 0.670400\n",
      "Epoch 372, CIFAR-10 Batch 4:  Loss:     0.5667 Validation Accuracy: 0.668400\n",
      "Epoch 372, CIFAR-10 Batch 5:  Loss:     0.5845 Validation Accuracy: 0.666200\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss:     0.6156 Validation Accuracy: 0.674600\n",
      "Epoch 373, CIFAR-10 Batch 2:  Loss:     0.6041 Validation Accuracy: 0.670200\n",
      "Epoch 373, CIFAR-10 Batch 3:  Loss:     0.5999 Validation Accuracy: 0.669000\n",
      "Epoch 373, CIFAR-10 Batch 4:  Loss:     0.5441 Validation Accuracy: 0.677800\n",
      "Epoch 373, CIFAR-10 Batch 5:  Loss:     0.5811 Validation Accuracy: 0.666200\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss:     0.6227 Validation Accuracy: 0.669200\n",
      "Epoch 374, CIFAR-10 Batch 2:  Loss:     0.6080 Validation Accuracy: 0.667400\n",
      "Epoch 374, CIFAR-10 Batch 3:  Loss:     0.6180 Validation Accuracy: 0.671400\n",
      "Epoch 374, CIFAR-10 Batch 4:  Loss:     0.5743 Validation Accuracy: 0.664200\n",
      "Epoch 374, CIFAR-10 Batch 5:  Loss:     0.5823 Validation Accuracy: 0.669000\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss:     0.6154 Validation Accuracy: 0.670600\n",
      "Epoch 375, CIFAR-10 Batch 2:  Loss:     0.6095 Validation Accuracy: 0.663000\n",
      "Epoch 375, CIFAR-10 Batch 3:  Loss:     0.6094 Validation Accuracy: 0.675600\n",
      "Epoch 375, CIFAR-10 Batch 4:  Loss:     0.5610 Validation Accuracy: 0.671600\n",
      "Epoch 375, CIFAR-10 Batch 5:  Loss:     0.5982 Validation Accuracy: 0.668800\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss:     0.6121 Validation Accuracy: 0.673000\n",
      "Epoch 376, CIFAR-10 Batch 2:  Loss:     0.6261 Validation Accuracy: 0.668200\n",
      "Epoch 376, CIFAR-10 Batch 3:  Loss:     0.6144 Validation Accuracy: 0.672000\n",
      "Epoch 376, CIFAR-10 Batch 4:  Loss:     0.5717 Validation Accuracy: 0.666000\n",
      "Epoch 376, CIFAR-10 Batch 5:  Loss:     0.5965 Validation Accuracy: 0.671600\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss:     0.6095 Validation Accuracy: 0.673200\n",
      "Epoch 377, CIFAR-10 Batch 2:  Loss:     0.6139 Validation Accuracy: 0.673800\n",
      "Epoch 377, CIFAR-10 Batch 3:  Loss:     0.6320 Validation Accuracy: 0.666600\n",
      "Epoch 377, CIFAR-10 Batch 4:  Loss:     0.5789 Validation Accuracy: 0.659600\n",
      "Epoch 377, CIFAR-10 Batch 5:  Loss:     0.6044 Validation Accuracy: 0.663400\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss:     0.6218 Validation Accuracy: 0.673800\n",
      "Epoch 378, CIFAR-10 Batch 2:  Loss:     0.6131 Validation Accuracy: 0.668400\n",
      "Epoch 378, CIFAR-10 Batch 3:  Loss:     0.6331 Validation Accuracy: 0.670800\n",
      "Epoch 378, CIFAR-10 Batch 4:  Loss:     0.5688 Validation Accuracy: 0.669400\n",
      "Epoch 378, CIFAR-10 Batch 5:  Loss:     0.5825 Validation Accuracy: 0.667400\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss:     0.6062 Validation Accuracy: 0.669400\n",
      "Epoch 379, CIFAR-10 Batch 2:  Loss:     0.6268 Validation Accuracy: 0.669200\n",
      "Epoch 379, CIFAR-10 Batch 3:  Loss:     0.6329 Validation Accuracy: 0.671600\n",
      "Epoch 379, CIFAR-10 Batch 4:  Loss:     0.5642 Validation Accuracy: 0.668000\n",
      "Epoch 379, CIFAR-10 Batch 5:  Loss:     0.5845 Validation Accuracy: 0.662400\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss:     0.6266 Validation Accuracy: 0.665200\n",
      "Epoch 380, CIFAR-10 Batch 2:  Loss:     0.6237 Validation Accuracy: 0.666200\n",
      "Epoch 380, CIFAR-10 Batch 3:  Loss:     0.6020 Validation Accuracy: 0.673200\n",
      "Epoch 380, CIFAR-10 Batch 4:  Loss:     0.5723 Validation Accuracy: 0.675400\n",
      "Epoch 380, CIFAR-10 Batch 5:  Loss:     0.6098 Validation Accuracy: 0.666000\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss:     0.6213 Validation Accuracy: 0.669200\n",
      "Epoch 381, CIFAR-10 Batch 2:  Loss:     0.6131 Validation Accuracy: 0.670400\n",
      "Epoch 381, CIFAR-10 Batch 3:  Loss:     0.6078 Validation Accuracy: 0.668600\n",
      "Epoch 381, CIFAR-10 Batch 4:  Loss:     0.5489 Validation Accuracy: 0.674400\n",
      "Epoch 381, CIFAR-10 Batch 5:  Loss:     0.5900 Validation Accuracy: 0.674000\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss:     0.6087 Validation Accuracy: 0.671000\n",
      "Epoch 382, CIFAR-10 Batch 2:  Loss:     0.6129 Validation Accuracy: 0.664200\n",
      "Epoch 382, CIFAR-10 Batch 3:  Loss:     0.6147 Validation Accuracy: 0.668600\n",
      "Epoch 382, CIFAR-10 Batch 4:  Loss:     0.5615 Validation Accuracy: 0.666400\n",
      "Epoch 382, CIFAR-10 Batch 5:  Loss:     0.5833 Validation Accuracy: 0.671800\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss:     0.6211 Validation Accuracy: 0.665600\n",
      "Epoch 383, CIFAR-10 Batch 2:  Loss:     0.6188 Validation Accuracy: 0.670000\n",
      "Epoch 383, CIFAR-10 Batch 3:  Loss:     0.6062 Validation Accuracy: 0.671800\n",
      "Epoch 383, CIFAR-10 Batch 4:  Loss:     0.5692 Validation Accuracy: 0.668400\n",
      "Epoch 383, CIFAR-10 Batch 5:  Loss:     0.5744 Validation Accuracy: 0.667200\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss:     0.6052 Validation Accuracy: 0.672600\n",
      "Epoch 384, CIFAR-10 Batch 2:  Loss:     0.6259 Validation Accuracy: 0.669200\n",
      "Epoch 384, CIFAR-10 Batch 3:  Loss:     0.6140 Validation Accuracy: 0.669400\n",
      "Epoch 384, CIFAR-10 Batch 4:  Loss:     0.5633 Validation Accuracy: 0.669000\n",
      "Epoch 384, CIFAR-10 Batch 5:  Loss:     0.6016 Validation Accuracy: 0.662600\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss:     0.6269 Validation Accuracy: 0.667800\n",
      "Epoch 385, CIFAR-10 Batch 2:  Loss:     0.6168 Validation Accuracy: 0.671600\n",
      "Epoch 385, CIFAR-10 Batch 3:  Loss:     0.6142 Validation Accuracy: 0.667800\n",
      "Epoch 385, CIFAR-10 Batch 4:  Loss:     0.5485 Validation Accuracy: 0.671400\n",
      "Epoch 385, CIFAR-10 Batch 5:  Loss:     0.5746 Validation Accuracy: 0.669800\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss:     0.5962 Validation Accuracy: 0.673000\n",
      "Epoch 386, CIFAR-10 Batch 2:  Loss:     0.5881 Validation Accuracy: 0.673400\n",
      "Epoch 386, CIFAR-10 Batch 3:  Loss:     0.6153 Validation Accuracy: 0.666000\n",
      "Epoch 386, CIFAR-10 Batch 4:  Loss:     0.5715 Validation Accuracy: 0.674400\n",
      "Epoch 386, CIFAR-10 Batch 5:  Loss:     0.5801 Validation Accuracy: 0.666400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387, CIFAR-10 Batch 1:  Loss:     0.6061 Validation Accuracy: 0.670800\n",
      "Epoch 387, CIFAR-10 Batch 2:  Loss:     0.6224 Validation Accuracy: 0.667600\n",
      "Epoch 387, CIFAR-10 Batch 3:  Loss:     0.5945 Validation Accuracy: 0.673800\n",
      "Epoch 387, CIFAR-10 Batch 4:  Loss:     0.5450 Validation Accuracy: 0.672200\n",
      "Epoch 387, CIFAR-10 Batch 5:  Loss:     0.5729 Validation Accuracy: 0.671800\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss:     0.5974 Validation Accuracy: 0.667600\n",
      "Epoch 388, CIFAR-10 Batch 2:  Loss:     0.5937 Validation Accuracy: 0.674600\n",
      "Epoch 388, CIFAR-10 Batch 3:  Loss:     0.5818 Validation Accuracy: 0.674200\n",
      "Epoch 388, CIFAR-10 Batch 4:  Loss:     0.5631 Validation Accuracy: 0.668000\n",
      "Epoch 388, CIFAR-10 Batch 5:  Loss:     0.5742 Validation Accuracy: 0.661800\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss:     0.5979 Validation Accuracy: 0.671200\n",
      "Epoch 389, CIFAR-10 Batch 2:  Loss:     0.6161 Validation Accuracy: 0.670800\n",
      "Epoch 389, CIFAR-10 Batch 3:  Loss:     0.5938 Validation Accuracy: 0.674800\n",
      "Epoch 389, CIFAR-10 Batch 4:  Loss:     0.5531 Validation Accuracy: 0.670800\n",
      "Epoch 389, CIFAR-10 Batch 5:  Loss:     0.5793 Validation Accuracy: 0.669800\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss:     0.5957 Validation Accuracy: 0.672400\n",
      "Epoch 390, CIFAR-10 Batch 2:  Loss:     0.5906 Validation Accuracy: 0.673000\n",
      "Epoch 390, CIFAR-10 Batch 3:  Loss:     0.6016 Validation Accuracy: 0.672600\n",
      "Epoch 390, CIFAR-10 Batch 4:  Loss:     0.5840 Validation Accuracy: 0.659400\n",
      "Epoch 390, CIFAR-10 Batch 5:  Loss:     0.5893 Validation Accuracy: 0.666800\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss:     0.6255 Validation Accuracy: 0.665200\n",
      "Epoch 391, CIFAR-10 Batch 2:  Loss:     0.6116 Validation Accuracy: 0.669800\n",
      "Epoch 391, CIFAR-10 Batch 3:  Loss:     0.6079 Validation Accuracy: 0.673000\n",
      "Epoch 391, CIFAR-10 Batch 4:  Loss:     0.5604 Validation Accuracy: 0.666000\n",
      "Epoch 391, CIFAR-10 Batch 5:  Loss:     0.5874 Validation Accuracy: 0.663600\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss:     0.6045 Validation Accuracy: 0.666600\n",
      "Epoch 392, CIFAR-10 Batch 2:  Loss:     0.5957 Validation Accuracy: 0.672400\n",
      "Epoch 392, CIFAR-10 Batch 3:  Loss:     0.6307 Validation Accuracy: 0.669000\n",
      "Epoch 392, CIFAR-10 Batch 4:  Loss:     0.5673 Validation Accuracy: 0.669800\n",
      "Epoch 392, CIFAR-10 Batch 5:  Loss:     0.5643 Validation Accuracy: 0.666800\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss:     0.6145 Validation Accuracy: 0.668400\n",
      "Epoch 393, CIFAR-10 Batch 2:  Loss:     0.6095 Validation Accuracy: 0.663600\n",
      "Epoch 393, CIFAR-10 Batch 3:  Loss:     0.5858 Validation Accuracy: 0.670400\n",
      "Epoch 393, CIFAR-10 Batch 4:  Loss:     0.5485 Validation Accuracy: 0.670200\n",
      "Epoch 393, CIFAR-10 Batch 5:  Loss:     0.5864 Validation Accuracy: 0.667800\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss:     0.6094 Validation Accuracy: 0.674600\n",
      "Epoch 394, CIFAR-10 Batch 2:  Loss:     0.6047 Validation Accuracy: 0.668400\n",
      "Epoch 394, CIFAR-10 Batch 3:  Loss:     0.5936 Validation Accuracy: 0.670600\n",
      "Epoch 394, CIFAR-10 Batch 4:  Loss:     0.5463 Validation Accuracy: 0.668200\n",
      "Epoch 394, CIFAR-10 Batch 5:  Loss:     0.5796 Validation Accuracy: 0.664200\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss:     0.6100 Validation Accuracy: 0.666800\n",
      "Epoch 395, CIFAR-10 Batch 2:  Loss:     0.5958 Validation Accuracy: 0.672200\n",
      "Epoch 395, CIFAR-10 Batch 3:  Loss:     0.5962 Validation Accuracy: 0.674800\n",
      "Epoch 395, CIFAR-10 Batch 4:  Loss:     0.5593 Validation Accuracy: 0.666800\n",
      "Epoch 395, CIFAR-10 Batch 5:  Loss:     0.5653 Validation Accuracy: 0.669400\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss:     0.5939 Validation Accuracy: 0.672800\n",
      "Epoch 396, CIFAR-10 Batch 2:  Loss:     0.5989 Validation Accuracy: 0.675200\n",
      "Epoch 396, CIFAR-10 Batch 3:  Loss:     0.5796 Validation Accuracy: 0.677400\n",
      "Epoch 396, CIFAR-10 Batch 4:  Loss:     0.5401 Validation Accuracy: 0.667000\n",
      "Epoch 396, CIFAR-10 Batch 5:  Loss:     0.5918 Validation Accuracy: 0.664600\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss:     0.6224 Validation Accuracy: 0.666400\n",
      "Epoch 397, CIFAR-10 Batch 2:  Loss:     0.5990 Validation Accuracy: 0.668000\n",
      "Epoch 397, CIFAR-10 Batch 3:  Loss:     0.6039 Validation Accuracy: 0.675200\n",
      "Epoch 397, CIFAR-10 Batch 4:  Loss:     0.5627 Validation Accuracy: 0.669800\n",
      "Epoch 397, CIFAR-10 Batch 5:  Loss:     0.5854 Validation Accuracy: 0.663000\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss:     0.5939 Validation Accuracy: 0.674000\n",
      "Epoch 398, CIFAR-10 Batch 2:  Loss:     0.6028 Validation Accuracy: 0.673200\n",
      "Epoch 398, CIFAR-10 Batch 3:  Loss:     0.5733 Validation Accuracy: 0.671600\n",
      "Epoch 398, CIFAR-10 Batch 4:  Loss:     0.5309 Validation Accuracy: 0.672600\n",
      "Epoch 398, CIFAR-10 Batch 5:  Loss:     0.5711 Validation Accuracy: 0.670600\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss:     0.5911 Validation Accuracy: 0.674400\n",
      "Epoch 399, CIFAR-10 Batch 2:  Loss:     0.5872 Validation Accuracy: 0.668200\n",
      "Epoch 399, CIFAR-10 Batch 3:  Loss:     0.5799 Validation Accuracy: 0.672000\n",
      "Epoch 399, CIFAR-10 Batch 4:  Loss:     0.5572 Validation Accuracy: 0.671200\n",
      "Epoch 399, CIFAR-10 Batch 5:  Loss:     0.5680 Validation Accuracy: 0.668000\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss:     0.5924 Validation Accuracy: 0.668400\n",
      "Epoch 400, CIFAR-10 Batch 2:  Loss:     0.6010 Validation Accuracy: 0.669600\n",
      "Epoch 400, CIFAR-10 Batch 3:  Loss:     0.5943 Validation Accuracy: 0.674200\n",
      "Epoch 400, CIFAR-10 Batch 4:  Loss:     0.5539 Validation Accuracy: 0.673000\n",
      "Epoch 400, CIFAR-10 Batch 5:  Loss:     0.5855 Validation Accuracy: 0.672400\n",
      "Epoch 401, CIFAR-10 Batch 1:  Loss:     0.6056 Validation Accuracy: 0.670600\n",
      "Epoch 401, CIFAR-10 Batch 2:  Loss:     0.5894 Validation Accuracy: 0.665600\n",
      "Epoch 401, CIFAR-10 Batch 3:  Loss:     0.6145 Validation Accuracy: 0.672200\n",
      "Epoch 401, CIFAR-10 Batch 4:  Loss:     0.5610 Validation Accuracy: 0.673200\n",
      "Epoch 401, CIFAR-10 Batch 5:  Loss:     0.5676 Validation Accuracy: 0.668000\n",
      "Epoch 402, CIFAR-10 Batch 1:  Loss:     0.6056 Validation Accuracy: 0.668200\n",
      "Epoch 402, CIFAR-10 Batch 2:  Loss:     0.5799 Validation Accuracy: 0.667400\n",
      "Epoch 402, CIFAR-10 Batch 3:  Loss:     0.5995 Validation Accuracy: 0.673400\n",
      "Epoch 402, CIFAR-10 Batch 4:  Loss:     0.5811 Validation Accuracy: 0.664200\n",
      "Epoch 402, CIFAR-10 Batch 5:  Loss:     0.5586 Validation Accuracy: 0.670800\n",
      "Epoch 403, CIFAR-10 Batch 1:  Loss:     0.5965 Validation Accuracy: 0.670600\n",
      "Epoch 403, CIFAR-10 Batch 2:  Loss:     0.5814 Validation Accuracy: 0.673000\n",
      "Epoch 403, CIFAR-10 Batch 3:  Loss:     0.5924 Validation Accuracy: 0.672600\n",
      "Epoch 403, CIFAR-10 Batch 4:  Loss:     0.5448 Validation Accuracy: 0.669600\n",
      "Epoch 403, CIFAR-10 Batch 5:  Loss:     0.5584 Validation Accuracy: 0.669000\n",
      "Epoch 404, CIFAR-10 Batch 1:  Loss:     0.6040 Validation Accuracy: 0.667600\n",
      "Epoch 404, CIFAR-10 Batch 2:  Loss:     0.5871 Validation Accuracy: 0.669800\n",
      "Epoch 404, CIFAR-10 Batch 3:  Loss:     0.6178 Validation Accuracy: 0.667200\n",
      "Epoch 404, CIFAR-10 Batch 4:  Loss:     0.5435 Validation Accuracy: 0.669200\n",
      "Epoch 404, CIFAR-10 Batch 5:  Loss:     0.5885 Validation Accuracy: 0.660000\n",
      "Epoch 405, CIFAR-10 Batch 1:  Loss:     0.5962 Validation Accuracy: 0.666000\n",
      "Epoch 405, CIFAR-10 Batch 2:  Loss:     0.6058 Validation Accuracy: 0.666200\n",
      "Epoch 405, CIFAR-10 Batch 3:  Loss:     0.5867 Validation Accuracy: 0.673400\n",
      "Epoch 405, CIFAR-10 Batch 4:  Loss:     0.5304 Validation Accuracy: 0.671800\n",
      "Epoch 405, CIFAR-10 Batch 5:  Loss:     0.5683 Validation Accuracy: 0.674800\n",
      "Epoch 406, CIFAR-10 Batch 1:  Loss:     0.5840 Validation Accuracy: 0.676400\n",
      "Epoch 406, CIFAR-10 Batch 2:  Loss:     0.5836 Validation Accuracy: 0.666200\n",
      "Epoch 406, CIFAR-10 Batch 3:  Loss:     0.5896 Validation Accuracy: 0.675000\n",
      "Epoch 406, CIFAR-10 Batch 4:  Loss:     0.5467 Validation Accuracy: 0.667600\n",
      "Epoch 406, CIFAR-10 Batch 5:  Loss:     0.5633 Validation Accuracy: 0.672400\n",
      "Epoch 407, CIFAR-10 Batch 1:  Loss:     0.6205 Validation Accuracy: 0.666800\n",
      "Epoch 407, CIFAR-10 Batch 2:  Loss:     0.6050 Validation Accuracy: 0.658400\n",
      "Epoch 407, CIFAR-10 Batch 3:  Loss:     0.5979 Validation Accuracy: 0.676200\n",
      "Epoch 407, CIFAR-10 Batch 4:  Loss:     0.5598 Validation Accuracy: 0.671000\n",
      "Epoch 407, CIFAR-10 Batch 5:  Loss:     0.5974 Validation Accuracy: 0.667600\n",
      "Epoch 408, CIFAR-10 Batch 1:  Loss:     0.5965 Validation Accuracy: 0.667600\n",
      "Epoch 408, CIFAR-10 Batch 2:  Loss:     0.6085 Validation Accuracy: 0.664400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408, CIFAR-10 Batch 3:  Loss:     0.5948 Validation Accuracy: 0.676200\n",
      "Epoch 408, CIFAR-10 Batch 4:  Loss:     0.5295 Validation Accuracy: 0.672000\n",
      "Epoch 408, CIFAR-10 Batch 5:  Loss:     0.5566 Validation Accuracy: 0.672600\n",
      "Epoch 409, CIFAR-10 Batch 1:  Loss:     0.5836 Validation Accuracy: 0.672200\n",
      "Epoch 409, CIFAR-10 Batch 2:  Loss:     0.5863 Validation Accuracy: 0.675600\n",
      "Epoch 409, CIFAR-10 Batch 3:  Loss:     0.5767 Validation Accuracy: 0.673400\n",
      "Epoch 409, CIFAR-10 Batch 4:  Loss:     0.5325 Validation Accuracy: 0.667400\n",
      "Epoch 409, CIFAR-10 Batch 5:  Loss:     0.5754 Validation Accuracy: 0.668400\n",
      "Epoch 410, CIFAR-10 Batch 1:  Loss:     0.5871 Validation Accuracy: 0.667600\n",
      "Epoch 410, CIFAR-10 Batch 2:  Loss:     0.5970 Validation Accuracy: 0.668200\n",
      "Epoch 410, CIFAR-10 Batch 3:  Loss:     0.5909 Validation Accuracy: 0.677800\n",
      "Epoch 410, CIFAR-10 Batch 4:  Loss:     0.5363 Validation Accuracy: 0.679800\n",
      "Epoch 410, CIFAR-10 Batch 5:  Loss:     0.5714 Validation Accuracy: 0.666200\n",
      "Epoch 411, CIFAR-10 Batch 1:  Loss:     0.5944 Validation Accuracy: 0.667800\n",
      "Epoch 411, CIFAR-10 Batch 2:  Loss:     0.5802 Validation Accuracy: 0.675600\n",
      "Epoch 411, CIFAR-10 Batch 3:  Loss:     0.5727 Validation Accuracy: 0.671400\n",
      "Epoch 411, CIFAR-10 Batch 4:  Loss:     0.5358 Validation Accuracy: 0.675800\n",
      "Epoch 411, CIFAR-10 Batch 5:  Loss:     0.5630 Validation Accuracy: 0.673800\n",
      "Epoch 412, CIFAR-10 Batch 1:  Loss:     0.6042 Validation Accuracy: 0.670400\n",
      "Epoch 412, CIFAR-10 Batch 2:  Loss:     0.6214 Validation Accuracy: 0.664600\n",
      "Epoch 412, CIFAR-10 Batch 3:  Loss:     0.5871 Validation Accuracy: 0.669800\n",
      "Epoch 412, CIFAR-10 Batch 4:  Loss:     0.5527 Validation Accuracy: 0.670000\n",
      "Epoch 412, CIFAR-10 Batch 5:  Loss:     0.5696 Validation Accuracy: 0.670400\n",
      "Epoch 413, CIFAR-10 Batch 1:  Loss:     0.6014 Validation Accuracy: 0.662800\n",
      "Epoch 413, CIFAR-10 Batch 2:  Loss:     0.5979 Validation Accuracy: 0.664600\n",
      "Epoch 413, CIFAR-10 Batch 3:  Loss:     0.5938 Validation Accuracy: 0.671400\n",
      "Epoch 413, CIFAR-10 Batch 4:  Loss:     0.5454 Validation Accuracy: 0.673200\n",
      "Epoch 413, CIFAR-10 Batch 5:  Loss:     0.5708 Validation Accuracy: 0.671000\n",
      "Epoch 414, CIFAR-10 Batch 1:  Loss:     0.6017 Validation Accuracy: 0.672400\n",
      "Epoch 414, CIFAR-10 Batch 2:  Loss:     0.6067 Validation Accuracy: 0.663000\n",
      "Epoch 414, CIFAR-10 Batch 3:  Loss:     0.5900 Validation Accuracy: 0.675200\n",
      "Epoch 414, CIFAR-10 Batch 4:  Loss:     0.5402 Validation Accuracy: 0.672400\n",
      "Epoch 414, CIFAR-10 Batch 5:  Loss:     0.5531 Validation Accuracy: 0.672200\n",
      "Epoch 415, CIFAR-10 Batch 1:  Loss:     0.6090 Validation Accuracy: 0.668400\n",
      "Epoch 415, CIFAR-10 Batch 2:  Loss:     0.5901 Validation Accuracy: 0.668000\n",
      "Epoch 415, CIFAR-10 Batch 3:  Loss:     0.5905 Validation Accuracy: 0.670200\n",
      "Epoch 415, CIFAR-10 Batch 4:  Loss:     0.5687 Validation Accuracy: 0.670800\n",
      "Epoch 415, CIFAR-10 Batch 5:  Loss:     0.5751 Validation Accuracy: 0.667400\n",
      "Epoch 416, CIFAR-10 Batch 1:  Loss:     0.5989 Validation Accuracy: 0.672000\n",
      "Epoch 416, CIFAR-10 Batch 2:  Loss:     0.5928 Validation Accuracy: 0.670400\n",
      "Epoch 416, CIFAR-10 Batch 3:  Loss:     0.5887 Validation Accuracy: 0.668200\n",
      "Epoch 416, CIFAR-10 Batch 4:  Loss:     0.5355 Validation Accuracy: 0.672000\n",
      "Epoch 416, CIFAR-10 Batch 5:  Loss:     0.5587 Validation Accuracy: 0.672200\n",
      "Epoch 417, CIFAR-10 Batch 1:  Loss:     0.5874 Validation Accuracy: 0.674200\n",
      "Epoch 417, CIFAR-10 Batch 2:  Loss:     0.5826 Validation Accuracy: 0.669000\n",
      "Epoch 417, CIFAR-10 Batch 3:  Loss:     0.5894 Validation Accuracy: 0.673000\n",
      "Epoch 417, CIFAR-10 Batch 4:  Loss:     0.5255 Validation Accuracy: 0.673200\n",
      "Epoch 417, CIFAR-10 Batch 5:  Loss:     0.5562 Validation Accuracy: 0.675200\n",
      "Epoch 418, CIFAR-10 Batch 1:  Loss:     0.5975 Validation Accuracy: 0.667800\n",
      "Epoch 418, CIFAR-10 Batch 2:  Loss:     0.5961 Validation Accuracy: 0.662600\n",
      "Epoch 418, CIFAR-10 Batch 3:  Loss:     0.5821 Validation Accuracy: 0.668800\n",
      "Epoch 418, CIFAR-10 Batch 4:  Loss:     0.5447 Validation Accuracy: 0.669000\n",
      "Epoch 418, CIFAR-10 Batch 5:  Loss:     0.5687 Validation Accuracy: 0.662400\n",
      "Epoch 419, CIFAR-10 Batch 1:  Loss:     0.5868 Validation Accuracy: 0.672600\n",
      "Epoch 419, CIFAR-10 Batch 2:  Loss:     0.5906 Validation Accuracy: 0.661200\n",
      "Epoch 419, CIFAR-10 Batch 3:  Loss:     0.5925 Validation Accuracy: 0.668200\n",
      "Epoch 419, CIFAR-10 Batch 4:  Loss:     0.5478 Validation Accuracy: 0.667800\n",
      "Epoch 419, CIFAR-10 Batch 5:  Loss:     0.5517 Validation Accuracy: 0.664200\n",
      "Epoch 420, CIFAR-10 Batch 1:  Loss:     0.5903 Validation Accuracy: 0.670400\n",
      "Epoch 420, CIFAR-10 Batch 2:  Loss:     0.6306 Validation Accuracy: 0.657000\n",
      "Epoch 420, CIFAR-10 Batch 3:  Loss:     0.5778 Validation Accuracy: 0.666200\n",
      "Epoch 420, CIFAR-10 Batch 4:  Loss:     0.5344 Validation Accuracy: 0.666800\n",
      "Epoch 420, CIFAR-10 Batch 5:  Loss:     0.5676 Validation Accuracy: 0.665600\n",
      "Epoch 421, CIFAR-10 Batch 1:  Loss:     0.5972 Validation Accuracy: 0.670000\n",
      "Epoch 421, CIFAR-10 Batch 2:  Loss:     0.5815 Validation Accuracy: 0.669200\n",
      "Epoch 421, CIFAR-10 Batch 3:  Loss:     0.5581 Validation Accuracy: 0.669000\n",
      "Epoch 421, CIFAR-10 Batch 4:  Loss:     0.5355 Validation Accuracy: 0.673000\n",
      "Epoch 421, CIFAR-10 Batch 5:  Loss:     0.5897 Validation Accuracy: 0.662200\n",
      "Epoch 422, CIFAR-10 Batch 1:  Loss:     0.5945 Validation Accuracy: 0.669000\n",
      "Epoch 422, CIFAR-10 Batch 2:  Loss:     0.6015 Validation Accuracy: 0.667200\n",
      "Epoch 422, CIFAR-10 Batch 3:  Loss:     0.5901 Validation Accuracy: 0.666200\n",
      "Epoch 422, CIFAR-10 Batch 4:  Loss:     0.5378 Validation Accuracy: 0.671200\n",
      "Epoch 422, CIFAR-10 Batch 5:  Loss:     0.5510 Validation Accuracy: 0.671400\n",
      "Epoch 423, CIFAR-10 Batch 1:  Loss:     0.5847 Validation Accuracy: 0.672000\n",
      "Epoch 423, CIFAR-10 Batch 2:  Loss:     0.5839 Validation Accuracy: 0.670600\n",
      "Epoch 423, CIFAR-10 Batch 3:  Loss:     0.5841 Validation Accuracy: 0.664600\n",
      "Epoch 423, CIFAR-10 Batch 4:  Loss:     0.5317 Validation Accuracy: 0.672400\n",
      "Epoch 423, CIFAR-10 Batch 5:  Loss:     0.5680 Validation Accuracy: 0.669000\n",
      "Epoch 424, CIFAR-10 Batch 1:  Loss:     0.5840 Validation Accuracy: 0.674800\n",
      "Epoch 424, CIFAR-10 Batch 2:  Loss:     0.5854 Validation Accuracy: 0.666000\n",
      "Epoch 424, CIFAR-10 Batch 3:  Loss:     0.5749 Validation Accuracy: 0.666400\n",
      "Epoch 424, CIFAR-10 Batch 4:  Loss:     0.5497 Validation Accuracy: 0.663600\n",
      "Epoch 424, CIFAR-10 Batch 5:  Loss:     0.5523 Validation Accuracy: 0.672200\n",
      "Epoch 425, CIFAR-10 Batch 1:  Loss:     0.5964 Validation Accuracy: 0.667000\n",
      "Epoch 425, CIFAR-10 Batch 2:  Loss:     0.5904 Validation Accuracy: 0.665000\n",
      "Epoch 425, CIFAR-10 Batch 3:  Loss:     0.6008 Validation Accuracy: 0.665600\n",
      "Epoch 425, CIFAR-10 Batch 4:  Loss:     0.5440 Validation Accuracy: 0.667600\n",
      "Epoch 425, CIFAR-10 Batch 5:  Loss:     0.5729 Validation Accuracy: 0.667600\n",
      "Epoch 426, CIFAR-10 Batch 1:  Loss:     0.5819 Validation Accuracy: 0.672600\n",
      "Epoch 426, CIFAR-10 Batch 2:  Loss:     0.5852 Validation Accuracy: 0.665400\n",
      "Epoch 426, CIFAR-10 Batch 3:  Loss:     0.5719 Validation Accuracy: 0.672600\n",
      "Epoch 426, CIFAR-10 Batch 4:  Loss:     0.5456 Validation Accuracy: 0.666600\n",
      "Epoch 426, CIFAR-10 Batch 5:  Loss:     0.5588 Validation Accuracy: 0.669400\n",
      "Epoch 427, CIFAR-10 Batch 1:  Loss:     0.5853 Validation Accuracy: 0.667400\n",
      "Epoch 427, CIFAR-10 Batch 2:  Loss:     0.5746 Validation Accuracy: 0.671200\n",
      "Epoch 427, CIFAR-10 Batch 3:  Loss:     0.5791 Validation Accuracy: 0.665800\n",
      "Epoch 427, CIFAR-10 Batch 4:  Loss:     0.5334 Validation Accuracy: 0.667200\n",
      "Epoch 427, CIFAR-10 Batch 5:  Loss:     0.5746 Validation Accuracy: 0.665600\n",
      "Epoch 428, CIFAR-10 Batch 1:  Loss:     0.5838 Validation Accuracy: 0.669800\n",
      "Epoch 428, CIFAR-10 Batch 2:  Loss:     0.5713 Validation Accuracy: 0.669600\n",
      "Epoch 428, CIFAR-10 Batch 3:  Loss:     0.5818 Validation Accuracy: 0.668800\n",
      "Epoch 428, CIFAR-10 Batch 4:  Loss:     0.5176 Validation Accuracy: 0.673000\n",
      "Epoch 428, CIFAR-10 Batch 5:  Loss:     0.5541 Validation Accuracy: 0.669400\n",
      "Epoch 429, CIFAR-10 Batch 1:  Loss:     0.5882 Validation Accuracy: 0.667400\n",
      "Epoch 429, CIFAR-10 Batch 2:  Loss:     0.5640 Validation Accuracy: 0.674200\n",
      "Epoch 429, CIFAR-10 Batch 3:  Loss:     0.5860 Validation Accuracy: 0.666800\n",
      "Epoch 429, CIFAR-10 Batch 4:  Loss:     0.5273 Validation Accuracy: 0.671800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 429, CIFAR-10 Batch 5:  Loss:     0.5687 Validation Accuracy: 0.667400\n",
      "Epoch 430, CIFAR-10 Batch 1:  Loss:     0.6061 Validation Accuracy: 0.667200\n",
      "Epoch 430, CIFAR-10 Batch 2:  Loss:     0.5886 Validation Accuracy: 0.670400\n",
      "Epoch 430, CIFAR-10 Batch 3:  Loss:     0.5792 Validation Accuracy: 0.668800\n",
      "Epoch 430, CIFAR-10 Batch 4:  Loss:     0.5445 Validation Accuracy: 0.667600\n",
      "Epoch 430, CIFAR-10 Batch 5:  Loss:     0.5588 Validation Accuracy: 0.670800\n",
      "Epoch 431, CIFAR-10 Batch 1:  Loss:     0.5844 Validation Accuracy: 0.663400\n",
      "Epoch 431, CIFAR-10 Batch 2:  Loss:     0.5978 Validation Accuracy: 0.669200\n",
      "Epoch 431, CIFAR-10 Batch 3:  Loss:     0.5872 Validation Accuracy: 0.668600\n",
      "Epoch 431, CIFAR-10 Batch 4:  Loss:     0.5237 Validation Accuracy: 0.666400\n",
      "Epoch 431, CIFAR-10 Batch 5:  Loss:     0.5746 Validation Accuracy: 0.664000\n",
      "Epoch 432, CIFAR-10 Batch 1:  Loss:     0.5797 Validation Accuracy: 0.668800\n",
      "Epoch 432, CIFAR-10 Batch 2:  Loss:     0.5746 Validation Accuracy: 0.671400\n",
      "Epoch 432, CIFAR-10 Batch 3:  Loss:     0.5885 Validation Accuracy: 0.668200\n",
      "Epoch 432, CIFAR-10 Batch 4:  Loss:     0.5267 Validation Accuracy: 0.666800\n",
      "Epoch 432, CIFAR-10 Batch 5:  Loss:     0.5596 Validation Accuracy: 0.667600\n",
      "Epoch 433, CIFAR-10 Batch 1:  Loss:     0.5785 Validation Accuracy: 0.669400\n",
      "Epoch 433, CIFAR-10 Batch 2:  Loss:     0.5670 Validation Accuracy: 0.670800\n",
      "Epoch 433, CIFAR-10 Batch 3:  Loss:     0.5629 Validation Accuracy: 0.668000\n",
      "Epoch 433, CIFAR-10 Batch 4:  Loss:     0.5307 Validation Accuracy: 0.669200\n",
      "Epoch 433, CIFAR-10 Batch 5:  Loss:     0.5673 Validation Accuracy: 0.665600\n",
      "Epoch 434, CIFAR-10 Batch 1:  Loss:     0.6188 Validation Accuracy: 0.664000\n",
      "Epoch 434, CIFAR-10 Batch 2:  Loss:     0.5840 Validation Accuracy: 0.671400\n",
      "Epoch 434, CIFAR-10 Batch 3:  Loss:     0.5789 Validation Accuracy: 0.670800\n",
      "Epoch 434, CIFAR-10 Batch 4:  Loss:     0.5212 Validation Accuracy: 0.666200\n",
      "Epoch 434, CIFAR-10 Batch 5:  Loss:     0.5512 Validation Accuracy: 0.666200\n",
      "Epoch 435, CIFAR-10 Batch 1:  Loss:     0.5870 Validation Accuracy: 0.667800\n",
      "Epoch 435, CIFAR-10 Batch 2:  Loss:     0.5839 Validation Accuracy: 0.672600\n",
      "Epoch 435, CIFAR-10 Batch 3:  Loss:     0.6100 Validation Accuracy: 0.664800\n",
      "Epoch 435, CIFAR-10 Batch 4:  Loss:     0.5408 Validation Accuracy: 0.665400\n",
      "Epoch 435, CIFAR-10 Batch 5:  Loss:     0.5532 Validation Accuracy: 0.664000\n",
      "Epoch 436, CIFAR-10 Batch 1:  Loss:     0.5852 Validation Accuracy: 0.669600\n",
      "Epoch 436, CIFAR-10 Batch 2:  Loss:     0.6304 Validation Accuracy: 0.651600\n",
      "Epoch 436, CIFAR-10 Batch 3:  Loss:     0.6088 Validation Accuracy: 0.660600\n",
      "Epoch 436, CIFAR-10 Batch 4:  Loss:     0.5412 Validation Accuracy: 0.661000\n",
      "Epoch 436, CIFAR-10 Batch 5:  Loss:     0.5561 Validation Accuracy: 0.662200\n",
      "Epoch 437, CIFAR-10 Batch 1:  Loss:     0.5885 Validation Accuracy: 0.666000\n",
      "Epoch 437, CIFAR-10 Batch 2:  Loss:     0.5955 Validation Accuracy: 0.666000\n",
      "Epoch 437, CIFAR-10 Batch 3:  Loss:     0.5923 Validation Accuracy: 0.665800\n",
      "Epoch 437, CIFAR-10 Batch 4:  Loss:     0.5485 Validation Accuracy: 0.664800\n",
      "Epoch 437, CIFAR-10 Batch 5:  Loss:     0.5726 Validation Accuracy: 0.655200\n",
      "Epoch 438, CIFAR-10 Batch 1:  Loss:     0.6032 Validation Accuracy: 0.658600\n",
      "Epoch 438, CIFAR-10 Batch 2:  Loss:     0.6164 Validation Accuracy: 0.661400\n",
      "Epoch 438, CIFAR-10 Batch 3:  Loss:     0.5722 Validation Accuracy: 0.665200\n",
      "Epoch 438, CIFAR-10 Batch 4:  Loss:     0.5222 Validation Accuracy: 0.666000\n",
      "Epoch 438, CIFAR-10 Batch 5:  Loss:     0.5665 Validation Accuracy: 0.663800\n",
      "Epoch 439, CIFAR-10 Batch 1:  Loss:     0.6024 Validation Accuracy: 0.664000\n",
      "Epoch 439, CIFAR-10 Batch 2:  Loss:     0.6109 Validation Accuracy: 0.663000\n",
      "Epoch 439, CIFAR-10 Batch 3:  Loss:     0.5835 Validation Accuracy: 0.668600\n",
      "Epoch 439, CIFAR-10 Batch 4:  Loss:     0.5375 Validation Accuracy: 0.667200\n",
      "Epoch 439, CIFAR-10 Batch 5:  Loss:     0.5562 Validation Accuracy: 0.664600\n",
      "Epoch 440, CIFAR-10 Batch 1:  Loss:     0.6086 Validation Accuracy: 0.663600\n",
      "Epoch 440, CIFAR-10 Batch 2:  Loss:     0.5857 Validation Accuracy: 0.666000\n",
      "Epoch 440, CIFAR-10 Batch 3:  Loss:     0.5817 Validation Accuracy: 0.666600\n",
      "Epoch 440, CIFAR-10 Batch 4:  Loss:     0.5398 Validation Accuracy: 0.668600\n",
      "Epoch 440, CIFAR-10 Batch 5:  Loss:     0.5707 Validation Accuracy: 0.663600\n",
      "Epoch 441, CIFAR-10 Batch 1:  Loss:     0.6103 Validation Accuracy: 0.661600\n",
      "Epoch 441, CIFAR-10 Batch 2:  Loss:     0.6094 Validation Accuracy: 0.663600\n",
      "Epoch 441, CIFAR-10 Batch 3:  Loss:     0.5805 Validation Accuracy: 0.670200\n",
      "Epoch 441, CIFAR-10 Batch 4:  Loss:     0.5324 Validation Accuracy: 0.667000\n",
      "Epoch 441, CIFAR-10 Batch 5:  Loss:     0.5626 Validation Accuracy: 0.660600\n",
      "Epoch 442, CIFAR-10 Batch 1:  Loss:     0.6357 Validation Accuracy: 0.656800\n",
      "Epoch 442, CIFAR-10 Batch 2:  Loss:     0.6341 Validation Accuracy: 0.655000\n",
      "Epoch 442, CIFAR-10 Batch 3:  Loss:     0.5879 Validation Accuracy: 0.668400\n",
      "Epoch 442, CIFAR-10 Batch 4:  Loss:     0.5432 Validation Accuracy: 0.667800\n",
      "Epoch 442, CIFAR-10 Batch 5:  Loss:     0.5838 Validation Accuracy: 0.665000\n",
      "Epoch 443, CIFAR-10 Batch 1:  Loss:     0.6168 Validation Accuracy: 0.655200\n",
      "Epoch 443, CIFAR-10 Batch 2:  Loss:     0.5829 Validation Accuracy: 0.666000\n",
      "Epoch 443, CIFAR-10 Batch 3:  Loss:     0.5833 Validation Accuracy: 0.669200\n",
      "Epoch 443, CIFAR-10 Batch 4:  Loss:     0.5347 Validation Accuracy: 0.671600\n",
      "Epoch 443, CIFAR-10 Batch 5:  Loss:     0.5731 Validation Accuracy: 0.667000\n",
      "Epoch 444, CIFAR-10 Batch 1:  Loss:     0.6021 Validation Accuracy: 0.661400\n",
      "Epoch 444, CIFAR-10 Batch 2:  Loss:     0.5816 Validation Accuracy: 0.669400\n",
      "Epoch 444, CIFAR-10 Batch 3:  Loss:     0.5861 Validation Accuracy: 0.668200\n",
      "Epoch 444, CIFAR-10 Batch 4:  Loss:     0.5563 Validation Accuracy: 0.662400\n",
      "Epoch 444, CIFAR-10 Batch 5:  Loss:     0.5737 Validation Accuracy: 0.665400\n",
      "Epoch 445, CIFAR-10 Batch 1:  Loss:     0.6141 Validation Accuracy: 0.664800\n",
      "Epoch 445, CIFAR-10 Batch 2:  Loss:     0.5956 Validation Accuracy: 0.665000\n",
      "Epoch 445, CIFAR-10 Batch 3:  Loss:     0.5658 Validation Accuracy: 0.670800\n",
      "Epoch 445, CIFAR-10 Batch 4:  Loss:     0.5298 Validation Accuracy: 0.670000\n",
      "Epoch 445, CIFAR-10 Batch 5:  Loss:     0.5625 Validation Accuracy: 0.667200\n",
      "Epoch 446, CIFAR-10 Batch 1:  Loss:     0.5814 Validation Accuracy: 0.665800\n",
      "Epoch 446, CIFAR-10 Batch 2:  Loss:     0.5909 Validation Accuracy: 0.666600\n",
      "Epoch 446, CIFAR-10 Batch 3:  Loss:     0.5619 Validation Accuracy: 0.668800\n",
      "Epoch 446, CIFAR-10 Batch 4:  Loss:     0.5350 Validation Accuracy: 0.670400\n",
      "Epoch 446, CIFAR-10 Batch 5:  Loss:     0.5654 Validation Accuracy: 0.668000\n",
      "Epoch 447, CIFAR-10 Batch 1:  Loss:     0.5956 Validation Accuracy: 0.663800\n",
      "Epoch 447, CIFAR-10 Batch 2:  Loss:     0.5870 Validation Accuracy: 0.663600\n",
      "Epoch 447, CIFAR-10 Batch 3:  Loss:     0.5712 Validation Accuracy: 0.662600\n",
      "Epoch 447, CIFAR-10 Batch 4:  Loss:     0.5353 Validation Accuracy: 0.665600\n",
      "Epoch 447, CIFAR-10 Batch 5:  Loss:     0.5772 Validation Accuracy: 0.662600\n",
      "Epoch 448, CIFAR-10 Batch 1:  Loss:     0.6071 Validation Accuracy: 0.663400\n",
      "Epoch 448, CIFAR-10 Batch 2:  Loss:     0.5991 Validation Accuracy: 0.658200\n",
      "Epoch 448, CIFAR-10 Batch 3:  Loss:     0.5676 Validation Accuracy: 0.671600\n",
      "Epoch 448, CIFAR-10 Batch 4:  Loss:     0.5372 Validation Accuracy: 0.671600\n",
      "Epoch 448, CIFAR-10 Batch 5:  Loss:     0.5810 Validation Accuracy: 0.666800\n",
      "Epoch 449, CIFAR-10 Batch 1:  Loss:     0.5685 Validation Accuracy: 0.669800\n",
      "Epoch 449, CIFAR-10 Batch 2:  Loss:     0.5988 Validation Accuracy: 0.665800\n",
      "Epoch 449, CIFAR-10 Batch 3:  Loss:     0.5655 Validation Accuracy: 0.668200\n",
      "Epoch 449, CIFAR-10 Batch 4:  Loss:     0.5407 Validation Accuracy: 0.666200\n",
      "Epoch 449, CIFAR-10 Batch 5:  Loss:     0.5760 Validation Accuracy: 0.659000\n",
      "Epoch 450, CIFAR-10 Batch 1:  Loss:     0.5973 Validation Accuracy: 0.663800\n",
      "Epoch 450, CIFAR-10 Batch 2:  Loss:     0.6372 Validation Accuracy: 0.656200\n",
      "Epoch 450, CIFAR-10 Batch 3:  Loss:     0.5666 Validation Accuracy: 0.670200\n",
      "Epoch 450, CIFAR-10 Batch 4:  Loss:     0.5588 Validation Accuracy: 0.660400\n",
      "Epoch 450, CIFAR-10 Batch 5:  Loss:     0.5876 Validation Accuracy: 0.656400\n",
      "Epoch 451, CIFAR-10 Batch 1:  Loss:     0.6049 Validation Accuracy: 0.665200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451, CIFAR-10 Batch 2:  Loss:     0.6334 Validation Accuracy: 0.658400\n",
      "Epoch 451, CIFAR-10 Batch 3:  Loss:     0.5916 Validation Accuracy: 0.662000\n",
      "Epoch 451, CIFAR-10 Batch 4:  Loss:     0.5596 Validation Accuracy: 0.663400\n",
      "Epoch 451, CIFAR-10 Batch 5:  Loss:     0.6121 Validation Accuracy: 0.640800\n",
      "Epoch 452, CIFAR-10 Batch 1:  Loss:     0.6179 Validation Accuracy: 0.657400\n",
      "Epoch 452, CIFAR-10 Batch 2:  Loss:     0.6269 Validation Accuracy: 0.654000\n",
      "Epoch 452, CIFAR-10 Batch 3:  Loss:     0.5943 Validation Accuracy: 0.658000\n",
      "Epoch 452, CIFAR-10 Batch 4:  Loss:     0.5701 Validation Accuracy: 0.658400\n",
      "Epoch 452, CIFAR-10 Batch 5:  Loss:     0.5904 Validation Accuracy: 0.657200\n",
      "Epoch 453, CIFAR-10 Batch 1:  Loss:     0.6077 Validation Accuracy: 0.667200\n",
      "Epoch 453, CIFAR-10 Batch 2:  Loss:     0.6059 Validation Accuracy: 0.660200\n",
      "Epoch 453, CIFAR-10 Batch 3:  Loss:     0.5704 Validation Accuracy: 0.665800\n",
      "Epoch 453, CIFAR-10 Batch 4:  Loss:     0.5589 Validation Accuracy: 0.664400\n",
      "Epoch 453, CIFAR-10 Batch 5:  Loss:     0.5660 Validation Accuracy: 0.662000\n",
      "Epoch 454, CIFAR-10 Batch 1:  Loss:     0.6023 Validation Accuracy: 0.665000\n",
      "Epoch 454, CIFAR-10 Batch 2:  Loss:     0.6215 Validation Accuracy: 0.666600\n",
      "Epoch 454, CIFAR-10 Batch 3:  Loss:     0.5348 Validation Accuracy: 0.673600\n",
      "Epoch 454, CIFAR-10 Batch 4:  Loss:     0.5257 Validation Accuracy: 0.668400\n",
      "Epoch 454, CIFAR-10 Batch 5:  Loss:     0.5637 Validation Accuracy: 0.668600\n",
      "Epoch 455, CIFAR-10 Batch 1:  Loss:     0.5858 Validation Accuracy: 0.665600\n",
      "Epoch 455, CIFAR-10 Batch 2:  Loss:     0.6071 Validation Accuracy: 0.665200\n",
      "Epoch 455, CIFAR-10 Batch 3:  Loss:     0.5382 Validation Accuracy: 0.675400\n",
      "Epoch 455, CIFAR-10 Batch 4:  Loss:     0.5562 Validation Accuracy: 0.664000\n",
      "Epoch 455, CIFAR-10 Batch 5:  Loss:     0.5700 Validation Accuracy: 0.663400\n",
      "Epoch 456, CIFAR-10 Batch 1:  Loss:     0.6113 Validation Accuracy: 0.661800\n",
      "Epoch 456, CIFAR-10 Batch 2:  Loss:     0.6189 Validation Accuracy: 0.662600\n",
      "Epoch 456, CIFAR-10 Batch 3:  Loss:     0.5464 Validation Accuracy: 0.675800\n",
      "Epoch 456, CIFAR-10 Batch 4:  Loss:     0.5856 Validation Accuracy: 0.657000\n",
      "Epoch 456, CIFAR-10 Batch 5:  Loss:     0.5541 Validation Accuracy: 0.661800\n",
      "Epoch 457, CIFAR-10 Batch 1:  Loss:     0.6153 Validation Accuracy: 0.657000\n",
      "Epoch 457, CIFAR-10 Batch 2:  Loss:     0.6171 Validation Accuracy: 0.653600\n",
      "Epoch 457, CIFAR-10 Batch 3:  Loss:     0.5851 Validation Accuracy: 0.663000\n",
      "Epoch 457, CIFAR-10 Batch 4:  Loss:     0.5649 Validation Accuracy: 0.663200\n",
      "Epoch 457, CIFAR-10 Batch 5:  Loss:     0.5910 Validation Accuracy: 0.649600\n",
      "Epoch 458, CIFAR-10 Batch 1:  Loss:     0.6068 Validation Accuracy: 0.661400\n",
      "Epoch 458, CIFAR-10 Batch 2:  Loss:     0.6107 Validation Accuracy: 0.662800\n",
      "Epoch 458, CIFAR-10 Batch 3:  Loss:     0.5663 Validation Accuracy: 0.661400\n",
      "Epoch 458, CIFAR-10 Batch 4:  Loss:     0.5416 Validation Accuracy: 0.665400\n",
      "Epoch 458, CIFAR-10 Batch 5:  Loss:     0.5758 Validation Accuracy: 0.661400\n",
      "Epoch 459, CIFAR-10 Batch 1:  Loss:     0.6055 Validation Accuracy: 0.666000\n",
      "Epoch 459, CIFAR-10 Batch 2:  Loss:     0.6192 Validation Accuracy: 0.670400\n",
      "Epoch 459, CIFAR-10 Batch 3:  Loss:     0.5490 Validation Accuracy: 0.673400\n",
      "Epoch 459, CIFAR-10 Batch 4:  Loss:     0.5482 Validation Accuracy: 0.664400\n",
      "Epoch 459, CIFAR-10 Batch 5:  Loss:     0.5618 Validation Accuracy: 0.667600\n",
      "Epoch 460, CIFAR-10 Batch 1:  Loss:     0.5943 Validation Accuracy: 0.670600\n",
      "Epoch 460, CIFAR-10 Batch 2:  Loss:     0.5986 Validation Accuracy: 0.673600\n",
      "Epoch 460, CIFAR-10 Batch 3:  Loss:     0.5555 Validation Accuracy: 0.673400\n",
      "Epoch 460, CIFAR-10 Batch 4:  Loss:     0.5392 Validation Accuracy: 0.665600\n",
      "Epoch 460, CIFAR-10 Batch 5:  Loss:     0.5502 Validation Accuracy: 0.661200\n",
      "Epoch 461, CIFAR-10 Batch 1:  Loss:     0.5929 Validation Accuracy: 0.673200\n",
      "Epoch 461, CIFAR-10 Batch 2:  Loss:     0.6187 Validation Accuracy: 0.665400\n",
      "Epoch 461, CIFAR-10 Batch 3:  Loss:     0.5491 Validation Accuracy: 0.672200\n",
      "Epoch 461, CIFAR-10 Batch 4:  Loss:     0.5382 Validation Accuracy: 0.668200\n",
      "Epoch 461, CIFAR-10 Batch 5:  Loss:     0.5622 Validation Accuracy: 0.662600\n",
      "Epoch 462, CIFAR-10 Batch 1:  Loss:     0.5916 Validation Accuracy: 0.671400\n",
      "Epoch 462, CIFAR-10 Batch 2:  Loss:     0.5990 Validation Accuracy: 0.669400\n",
      "Epoch 462, CIFAR-10 Batch 3:  Loss:     0.5514 Validation Accuracy: 0.674800\n",
      "Epoch 462, CIFAR-10 Batch 4:  Loss:     0.5329 Validation Accuracy: 0.668600\n",
      "Epoch 462, CIFAR-10 Batch 5:  Loss:     0.5548 Validation Accuracy: 0.668200\n",
      "Epoch 463, CIFAR-10 Batch 1:  Loss:     0.5868 Validation Accuracy: 0.670200\n",
      "Epoch 463, CIFAR-10 Batch 2:  Loss:     0.5975 Validation Accuracy: 0.670200\n",
      "Epoch 463, CIFAR-10 Batch 3:  Loss:     0.5514 Validation Accuracy: 0.675800\n",
      "Epoch 463, CIFAR-10 Batch 4:  Loss:     0.5479 Validation Accuracy: 0.667600\n",
      "Epoch 463, CIFAR-10 Batch 5:  Loss:     0.5689 Validation Accuracy: 0.660000\n",
      "Epoch 464, CIFAR-10 Batch 1:  Loss:     0.6192 Validation Accuracy: 0.664800\n",
      "Epoch 464, CIFAR-10 Batch 2:  Loss:     0.5749 Validation Accuracy: 0.668200\n",
      "Epoch 464, CIFAR-10 Batch 3:  Loss:     0.5650 Validation Accuracy: 0.673000\n",
      "Epoch 464, CIFAR-10 Batch 4:  Loss:     0.5355 Validation Accuracy: 0.671400\n",
      "Epoch 464, CIFAR-10 Batch 5:  Loss:     0.5520 Validation Accuracy: 0.662600\n",
      "Epoch 465, CIFAR-10 Batch 1:  Loss:     0.5878 Validation Accuracy: 0.672000\n",
      "Epoch 465, CIFAR-10 Batch 2:  Loss:     0.5791 Validation Accuracy: 0.672000\n",
      "Epoch 465, CIFAR-10 Batch 3:  Loss:     0.5497 Validation Accuracy: 0.673200\n",
      "Epoch 465, CIFAR-10 Batch 4:  Loss:     0.5247 Validation Accuracy: 0.671000\n",
      "Epoch 465, CIFAR-10 Batch 5:  Loss:     0.5788 Validation Accuracy: 0.660000\n",
      "Epoch 466, CIFAR-10 Batch 1:  Loss:     0.6001 Validation Accuracy: 0.667200\n",
      "Epoch 466, CIFAR-10 Batch 2:  Loss:     0.6141 Validation Accuracy: 0.672000\n",
      "Epoch 466, CIFAR-10 Batch 3:  Loss:     0.5402 Validation Accuracy: 0.675200\n",
      "Epoch 466, CIFAR-10 Batch 4:  Loss:     0.5415 Validation Accuracy: 0.671000\n",
      "Epoch 466, CIFAR-10 Batch 5:  Loss:     0.5613 Validation Accuracy: 0.669200\n",
      "Epoch 467, CIFAR-10 Batch 1:  Loss:     0.5927 Validation Accuracy: 0.673200\n",
      "Epoch 467, CIFAR-10 Batch 2:  Loss:     0.6011 Validation Accuracy: 0.662800\n",
      "Epoch 467, CIFAR-10 Batch 3:  Loss:     0.5397 Validation Accuracy: 0.670400\n",
      "Epoch 467, CIFAR-10 Batch 4:  Loss:     0.5740 Validation Accuracy: 0.666400\n",
      "Epoch 467, CIFAR-10 Batch 5:  Loss:     0.5753 Validation Accuracy: 0.659200\n",
      "Epoch 468, CIFAR-10 Batch 1:  Loss:     0.5823 Validation Accuracy: 0.675200\n",
      "Epoch 468, CIFAR-10 Batch 2:  Loss:     0.5910 Validation Accuracy: 0.671600\n",
      "Epoch 468, CIFAR-10 Batch 3:  Loss:     0.5506 Validation Accuracy: 0.672200\n",
      "Epoch 468, CIFAR-10 Batch 4:  Loss:     0.5436 Validation Accuracy: 0.670000\n",
      "Epoch 468, CIFAR-10 Batch 5:  Loss:     0.5658 Validation Accuracy: 0.660200\n",
      "Epoch 469, CIFAR-10 Batch 1:  Loss:     0.5922 Validation Accuracy: 0.670800\n",
      "Epoch 469, CIFAR-10 Batch 2:  Loss:     0.6105 Validation Accuracy: 0.657600\n",
      "Epoch 469, CIFAR-10 Batch 3:  Loss:     0.5476 Validation Accuracy: 0.672600\n",
      "Epoch 469, CIFAR-10 Batch 4:  Loss:     0.5574 Validation Accuracy: 0.669600\n",
      "Epoch 469, CIFAR-10 Batch 5:  Loss:     0.5747 Validation Accuracy: 0.655000\n",
      "Epoch 470, CIFAR-10 Batch 1:  Loss:     0.5760 Validation Accuracy: 0.674000\n",
      "Epoch 470, CIFAR-10 Batch 2:  Loss:     0.6227 Validation Accuracy: 0.657200\n",
      "Epoch 470, CIFAR-10 Batch 3:  Loss:     0.5653 Validation Accuracy: 0.667200\n",
      "Epoch 470, CIFAR-10 Batch 4:  Loss:     0.5754 Validation Accuracy: 0.668000\n",
      "Epoch 470, CIFAR-10 Batch 5:  Loss:     0.5584 Validation Accuracy: 0.663600\n",
      "Epoch 471, CIFAR-10 Batch 1:  Loss:     0.5880 Validation Accuracy: 0.673400\n",
      "Epoch 471, CIFAR-10 Batch 2:  Loss:     0.5916 Validation Accuracy: 0.666600\n",
      "Epoch 471, CIFAR-10 Batch 3:  Loss:     0.5421 Validation Accuracy: 0.674200\n",
      "Epoch 471, CIFAR-10 Batch 4:  Loss:     0.5759 Validation Accuracy: 0.668400\n",
      "Epoch 471, CIFAR-10 Batch 5:  Loss:     0.5470 Validation Accuracy: 0.666600\n",
      "Epoch 472, CIFAR-10 Batch 1:  Loss:     0.5839 Validation Accuracy: 0.672600\n",
      "Epoch 472, CIFAR-10 Batch 2:  Loss:     0.6007 Validation Accuracy: 0.658200\n",
      "Epoch 472, CIFAR-10 Batch 3:  Loss:     0.5410 Validation Accuracy: 0.680600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472, CIFAR-10 Batch 4:  Loss:     0.5812 Validation Accuracy: 0.665200\n",
      "Epoch 472, CIFAR-10 Batch 5:  Loss:     0.5539 Validation Accuracy: 0.662000\n",
      "Epoch 473, CIFAR-10 Batch 1:  Loss:     0.5918 Validation Accuracy: 0.668200\n",
      "Epoch 473, CIFAR-10 Batch 2:  Loss:     0.5865 Validation Accuracy: 0.666600\n",
      "Epoch 473, CIFAR-10 Batch 3:  Loss:     0.5467 Validation Accuracy: 0.676400\n",
      "Epoch 473, CIFAR-10 Batch 4:  Loss:     0.5580 Validation Accuracy: 0.671400\n",
      "Epoch 473, CIFAR-10 Batch 5:  Loss:     0.5440 Validation Accuracy: 0.666800\n",
      "Epoch 474, CIFAR-10 Batch 1:  Loss:     0.5682 Validation Accuracy: 0.670800\n",
      "Epoch 474, CIFAR-10 Batch 2:  Loss:     0.5649 Validation Accuracy: 0.665200\n",
      "Epoch 474, CIFAR-10 Batch 3:  Loss:     0.5717 Validation Accuracy: 0.668800\n",
      "Epoch 474, CIFAR-10 Batch 4:  Loss:     0.5503 Validation Accuracy: 0.671600\n",
      "Epoch 474, CIFAR-10 Batch 5:  Loss:     0.5313 Validation Accuracy: 0.667200\n",
      "Epoch 475, CIFAR-10 Batch 1:  Loss:     0.5626 Validation Accuracy: 0.670600\n",
      "Epoch 475, CIFAR-10 Batch 2:  Loss:     0.5810 Validation Accuracy: 0.661200\n",
      "Epoch 475, CIFAR-10 Batch 3:  Loss:     0.5345 Validation Accuracy: 0.672400\n",
      "Epoch 475, CIFAR-10 Batch 4:  Loss:     0.5663 Validation Accuracy: 0.665000\n",
      "Epoch 475, CIFAR-10 Batch 5:  Loss:     0.5373 Validation Accuracy: 0.665000\n",
      "Epoch 476, CIFAR-10 Batch 1:  Loss:     0.5907 Validation Accuracy: 0.665400\n",
      "Epoch 476, CIFAR-10 Batch 2:  Loss:     0.5666 Validation Accuracy: 0.668800\n",
      "Epoch 476, CIFAR-10 Batch 3:  Loss:     0.5395 Validation Accuracy: 0.672600\n",
      "Epoch 476, CIFAR-10 Batch 4:  Loss:     0.5468 Validation Accuracy: 0.666800\n",
      "Epoch 476, CIFAR-10 Batch 5:  Loss:     0.5256 Validation Accuracy: 0.672800\n",
      "Epoch 477, CIFAR-10 Batch 1:  Loss:     0.5829 Validation Accuracy: 0.669400\n",
      "Epoch 477, CIFAR-10 Batch 2:  Loss:     0.5687 Validation Accuracy: 0.668400\n",
      "Epoch 477, CIFAR-10 Batch 3:  Loss:     0.5425 Validation Accuracy: 0.673600\n",
      "Epoch 477, CIFAR-10 Batch 4:  Loss:     0.5438 Validation Accuracy: 0.672800\n",
      "Epoch 477, CIFAR-10 Batch 5:  Loss:     0.5256 Validation Accuracy: 0.667400\n",
      "Epoch 478, CIFAR-10 Batch 1:  Loss:     0.5818 Validation Accuracy: 0.665200\n",
      "Epoch 478, CIFAR-10 Batch 2:  Loss:     0.5710 Validation Accuracy: 0.669400\n",
      "Epoch 478, CIFAR-10 Batch 3:  Loss:     0.5464 Validation Accuracy: 0.675000\n",
      "Epoch 478, CIFAR-10 Batch 4:  Loss:     0.5463 Validation Accuracy: 0.670200\n",
      "Epoch 478, CIFAR-10 Batch 5:  Loss:     0.5488 Validation Accuracy: 0.660200\n",
      "Epoch 479, CIFAR-10 Batch 1:  Loss:     0.5638 Validation Accuracy: 0.669800\n",
      "Epoch 479, CIFAR-10 Batch 2:  Loss:     0.5711 Validation Accuracy: 0.666400\n",
      "Epoch 479, CIFAR-10 Batch 3:  Loss:     0.5430 Validation Accuracy: 0.674200\n",
      "Epoch 479, CIFAR-10 Batch 4:  Loss:     0.5507 Validation Accuracy: 0.674000\n",
      "Epoch 479, CIFAR-10 Batch 5:  Loss:     0.5521 Validation Accuracy: 0.664400\n",
      "Epoch 480, CIFAR-10 Batch 1:  Loss:     0.5721 Validation Accuracy: 0.668800\n",
      "Epoch 480, CIFAR-10 Batch 2:  Loss:     0.5679 Validation Accuracy: 0.668200\n",
      "Epoch 480, CIFAR-10 Batch 3:  Loss:     0.5464 Validation Accuracy: 0.673600\n",
      "Epoch 480, CIFAR-10 Batch 4:  Loss:     0.5672 Validation Accuracy: 0.658000\n",
      "Epoch 480, CIFAR-10 Batch 5:  Loss:     0.5467 Validation Accuracy: 0.665600\n",
      "Epoch 481, CIFAR-10 Batch 1:  Loss:     0.5868 Validation Accuracy: 0.666200\n",
      "Epoch 481, CIFAR-10 Batch 2:  Loss:     0.5775 Validation Accuracy: 0.665000\n",
      "Epoch 481, CIFAR-10 Batch 3:  Loss:     0.5502 Validation Accuracy: 0.675600\n",
      "Epoch 481, CIFAR-10 Batch 4:  Loss:     0.5409 Validation Accuracy: 0.672600\n",
      "Epoch 481, CIFAR-10 Batch 5:  Loss:     0.5398 Validation Accuracy: 0.664600\n",
      "Epoch 482, CIFAR-10 Batch 1:  Loss:     0.5680 Validation Accuracy: 0.674200\n",
      "Epoch 482, CIFAR-10 Batch 2:  Loss:     0.5873 Validation Accuracy: 0.659800\n",
      "Epoch 482, CIFAR-10 Batch 3:  Loss:     0.5362 Validation Accuracy: 0.678000\n",
      "Epoch 482, CIFAR-10 Batch 4:  Loss:     0.5323 Validation Accuracy: 0.674000\n",
      "Epoch 482, CIFAR-10 Batch 5:  Loss:     0.5459 Validation Accuracy: 0.665200\n",
      "Epoch 483, CIFAR-10 Batch 1:  Loss:     0.5851 Validation Accuracy: 0.666800\n",
      "Epoch 483, CIFAR-10 Batch 2:  Loss:     0.5698 Validation Accuracy: 0.668000\n",
      "Epoch 483, CIFAR-10 Batch 3:  Loss:     0.5377 Validation Accuracy: 0.676800\n",
      "Epoch 483, CIFAR-10 Batch 4:  Loss:     0.5735 Validation Accuracy: 0.664000\n",
      "Epoch 483, CIFAR-10 Batch 5:  Loss:     0.5417 Validation Accuracy: 0.668000\n",
      "Epoch 484, CIFAR-10 Batch 1:  Loss:     0.5719 Validation Accuracy: 0.670800\n",
      "Epoch 484, CIFAR-10 Batch 2:  Loss:     0.5507 Validation Accuracy: 0.673400\n",
      "Epoch 484, CIFAR-10 Batch 3:  Loss:     0.5451 Validation Accuracy: 0.674200\n",
      "Epoch 484, CIFAR-10 Batch 4:  Loss:     0.5337 Validation Accuracy: 0.674600\n",
      "Epoch 484, CIFAR-10 Batch 5:  Loss:     0.5348 Validation Accuracy: 0.672200\n",
      "Epoch 485, CIFAR-10 Batch 1:  Loss:     0.5784 Validation Accuracy: 0.671400\n",
      "Epoch 485, CIFAR-10 Batch 2:  Loss:     0.5657 Validation Accuracy: 0.677800\n",
      "Epoch 485, CIFAR-10 Batch 3:  Loss:     0.5497 Validation Accuracy: 0.672000\n",
      "Epoch 485, CIFAR-10 Batch 4:  Loss:     0.5405 Validation Accuracy: 0.672400\n",
      "Epoch 485, CIFAR-10 Batch 5:  Loss:     0.5530 Validation Accuracy: 0.670800\n",
      "Epoch 486, CIFAR-10 Batch 1:  Loss:     0.5697 Validation Accuracy: 0.676800\n",
      "Epoch 486, CIFAR-10 Batch 2:  Loss:     0.5789 Validation Accuracy: 0.665200\n",
      "Epoch 486, CIFAR-10 Batch 3:  Loss:     0.5466 Validation Accuracy: 0.675200\n",
      "Epoch 486, CIFAR-10 Batch 4:  Loss:     0.5406 Validation Accuracy: 0.672800\n",
      "Epoch 486, CIFAR-10 Batch 5:  Loss:     0.5546 Validation Accuracy: 0.664600\n",
      "Epoch 487, CIFAR-10 Batch 1:  Loss:     0.5897 Validation Accuracy: 0.668000\n",
      "Epoch 487, CIFAR-10 Batch 2:  Loss:     0.5603 Validation Accuracy: 0.672400\n",
      "Epoch 487, CIFAR-10 Batch 3:  Loss:     0.5480 Validation Accuracy: 0.669000\n",
      "Epoch 487, CIFAR-10 Batch 4:  Loss:     0.5486 Validation Accuracy: 0.667000\n",
      "Epoch 487, CIFAR-10 Batch 5:  Loss:     0.5398 Validation Accuracy: 0.662000\n",
      "Epoch 488, CIFAR-10 Batch 1:  Loss:     0.5873 Validation Accuracy: 0.663800\n",
      "Epoch 488, CIFAR-10 Batch 2:  Loss:     0.5553 Validation Accuracy: 0.670000\n",
      "Epoch 488, CIFAR-10 Batch 3:  Loss:     0.5415 Validation Accuracy: 0.676400\n",
      "Epoch 488, CIFAR-10 Batch 4:  Loss:     0.5435 Validation Accuracy: 0.672000\n",
      "Epoch 488, CIFAR-10 Batch 5:  Loss:     0.5473 Validation Accuracy: 0.667400\n",
      "Epoch 489, CIFAR-10 Batch 1:  Loss:     0.5861 Validation Accuracy: 0.665800\n",
      "Epoch 489, CIFAR-10 Batch 2:  Loss:     0.5665 Validation Accuracy: 0.671000\n",
      "Epoch 489, CIFAR-10 Batch 3:  Loss:     0.5399 Validation Accuracy: 0.674400\n",
      "Epoch 489, CIFAR-10 Batch 4:  Loss:     0.5471 Validation Accuracy: 0.670000\n",
      "Epoch 489, CIFAR-10 Batch 5:  Loss:     0.5472 Validation Accuracy: 0.662200\n",
      "Epoch 490, CIFAR-10 Batch 1:  Loss:     0.5904 Validation Accuracy: 0.661400\n",
      "Epoch 490, CIFAR-10 Batch 2:  Loss:     0.5663 Validation Accuracy: 0.670000\n",
      "Epoch 490, CIFAR-10 Batch 3:  Loss:     0.5398 Validation Accuracy: 0.674800\n",
      "Epoch 490, CIFAR-10 Batch 4:  Loss:     0.5197 Validation Accuracy: 0.672200\n",
      "Epoch 490, CIFAR-10 Batch 5:  Loss:     0.5456 Validation Accuracy: 0.670600\n",
      "Epoch 491, CIFAR-10 Batch 1:  Loss:     0.5605 Validation Accuracy: 0.675200\n",
      "Epoch 491, CIFAR-10 Batch 2:  Loss:     0.5678 Validation Accuracy: 0.669600\n",
      "Epoch 491, CIFAR-10 Batch 3:  Loss:     0.5325 Validation Accuracy: 0.667600\n",
      "Epoch 491, CIFAR-10 Batch 4:  Loss:     0.5327 Validation Accuracy: 0.668400\n",
      "Epoch 491, CIFAR-10 Batch 5:  Loss:     0.5468 Validation Accuracy: 0.662400\n",
      "Epoch 492, CIFAR-10 Batch 1:  Loss:     0.5633 Validation Accuracy: 0.676600\n",
      "Epoch 492, CIFAR-10 Batch 2:  Loss:     0.5603 Validation Accuracy: 0.674800\n",
      "Epoch 492, CIFAR-10 Batch 3:  Loss:     0.5365 Validation Accuracy: 0.675200\n",
      "Epoch 492, CIFAR-10 Batch 4:  Loss:     0.5469 Validation Accuracy: 0.664000\n",
      "Epoch 492, CIFAR-10 Batch 5:  Loss:     0.5422 Validation Accuracy: 0.663200\n",
      "Epoch 493, CIFAR-10 Batch 1:  Loss:     0.5740 Validation Accuracy: 0.670000\n",
      "Epoch 493, CIFAR-10 Batch 2:  Loss:     0.5620 Validation Accuracy: 0.673600\n",
      "Epoch 493, CIFAR-10 Batch 3:  Loss:     0.5247 Validation Accuracy: 0.675600\n",
      "Epoch 493, CIFAR-10 Batch 4:  Loss:     0.5389 Validation Accuracy: 0.672400\n",
      "Epoch 493, CIFAR-10 Batch 5:  Loss:     0.5417 Validation Accuracy: 0.669400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494, CIFAR-10 Batch 1:  Loss:     0.5573 Validation Accuracy: 0.671400\n",
      "Epoch 494, CIFAR-10 Batch 2:  Loss:     0.5444 Validation Accuracy: 0.672800\n",
      "Epoch 494, CIFAR-10 Batch 3:  Loss:     0.5398 Validation Accuracy: 0.677200\n",
      "Epoch 494, CIFAR-10 Batch 4:  Loss:     0.5314 Validation Accuracy: 0.672200\n",
      "Epoch 494, CIFAR-10 Batch 5:  Loss:     0.5333 Validation Accuracy: 0.675200\n",
      "Epoch 495, CIFAR-10 Batch 1:  Loss:     0.5767 Validation Accuracy: 0.670200\n",
      "Epoch 495, CIFAR-10 Batch 2:  Loss:     0.5574 Validation Accuracy: 0.670600\n",
      "Epoch 495, CIFAR-10 Batch 3:  Loss:     0.5474 Validation Accuracy: 0.673800\n",
      "Epoch 495, CIFAR-10 Batch 4:  Loss:     0.5570 Validation Accuracy: 0.664200\n",
      "Epoch 495, CIFAR-10 Batch 5:  Loss:     0.5464 Validation Accuracy: 0.664800\n",
      "Epoch 496, CIFAR-10 Batch 1:  Loss:     0.5631 Validation Accuracy: 0.669200\n",
      "Epoch 496, CIFAR-10 Batch 2:  Loss:     0.5735 Validation Accuracy: 0.665600\n",
      "Epoch 496, CIFAR-10 Batch 3:  Loss:     0.5159 Validation Accuracy: 0.677800\n",
      "Epoch 496, CIFAR-10 Batch 4:  Loss:     0.5308 Validation Accuracy: 0.672600\n",
      "Epoch 496, CIFAR-10 Batch 5:  Loss:     0.5392 Validation Accuracy: 0.668200\n",
      "Epoch 497, CIFAR-10 Batch 1:  Loss:     0.5756 Validation Accuracy: 0.665400\n",
      "Epoch 497, CIFAR-10 Batch 2:  Loss:     0.5627 Validation Accuracy: 0.668200\n",
      "Epoch 497, CIFAR-10 Batch 3:  Loss:     0.5552 Validation Accuracy: 0.672600\n",
      "Epoch 497, CIFAR-10 Batch 4:  Loss:     0.5249 Validation Accuracy: 0.673600\n",
      "Epoch 497, CIFAR-10 Batch 5:  Loss:     0.5375 Validation Accuracy: 0.668000\n",
      "Epoch 498, CIFAR-10 Batch 1:  Loss:     0.5641 Validation Accuracy: 0.669800\n",
      "Epoch 498, CIFAR-10 Batch 2:  Loss:     0.5481 Validation Accuracy: 0.674400\n",
      "Epoch 498, CIFAR-10 Batch 3:  Loss:     0.5320 Validation Accuracy: 0.674600\n",
      "Epoch 498, CIFAR-10 Batch 4:  Loss:     0.5234 Validation Accuracy: 0.672000\n",
      "Epoch 498, CIFAR-10 Batch 5:  Loss:     0.5315 Validation Accuracy: 0.667200\n",
      "Epoch 499, CIFAR-10 Batch 1:  Loss:     0.5639 Validation Accuracy: 0.675600\n",
      "Epoch 499, CIFAR-10 Batch 2:  Loss:     0.5424 Validation Accuracy: 0.677600\n",
      "Epoch 499, CIFAR-10 Batch 3:  Loss:     0.5160 Validation Accuracy: 0.677800\n",
      "Epoch 499, CIFAR-10 Batch 4:  Loss:     0.5415 Validation Accuracy: 0.663000\n",
      "Epoch 499, CIFAR-10 Batch 5:  Loss:     0.5503 Validation Accuracy: 0.663600\n",
      "Epoch 500, CIFAR-10 Batch 1:  Loss:     0.5679 Validation Accuracy: 0.666400\n",
      "Epoch 500, CIFAR-10 Batch 2:  Loss:     0.5633 Validation Accuracy: 0.672200\n",
      "Epoch 500, CIFAR-10 Batch 3:  Loss:     0.5228 Validation Accuracy: 0.677400\n",
      "Epoch 500, CIFAR-10 Batch 4:  Loss:     0.5181 Validation Accuracy: 0.667200\n",
      "Epoch 500, CIFAR-10 Batch 5:  Loss:     0.5380 Validation Accuracy: 0.664200\n",
      "Epoch 501, CIFAR-10 Batch 1:  Loss:     0.5658 Validation Accuracy: 0.673000\n",
      "Epoch 501, CIFAR-10 Batch 2:  Loss:     0.5418 Validation Accuracy: 0.670200\n",
      "Epoch 501, CIFAR-10 Batch 3:  Loss:     0.5274 Validation Accuracy: 0.677200\n",
      "Epoch 501, CIFAR-10 Batch 4:  Loss:     0.5399 Validation Accuracy: 0.668600\n",
      "Epoch 501, CIFAR-10 Batch 5:  Loss:     0.5540 Validation Accuracy: 0.660400\n",
      "Epoch 502, CIFAR-10 Batch 1:  Loss:     0.5948 Validation Accuracy: 0.661000\n",
      "Epoch 502, CIFAR-10 Batch 2:  Loss:     0.5482 Validation Accuracy: 0.671400\n",
      "Epoch 502, CIFAR-10 Batch 3:  Loss:     0.5491 Validation Accuracy: 0.671400\n",
      "Epoch 502, CIFAR-10 Batch 4:  Loss:     0.5540 Validation Accuracy: 0.662400\n",
      "Epoch 502, CIFAR-10 Batch 5:  Loss:     0.5413 Validation Accuracy: 0.662200\n",
      "Epoch 503, CIFAR-10 Batch 1:  Loss:     0.5471 Validation Accuracy: 0.671200\n",
      "Epoch 503, CIFAR-10 Batch 2:  Loss:     0.5444 Validation Accuracy: 0.668800\n",
      "Epoch 503, CIFAR-10 Batch 3:  Loss:     0.5431 Validation Accuracy: 0.675600\n",
      "Epoch 503, CIFAR-10 Batch 4:  Loss:     0.5473 Validation Accuracy: 0.671200\n",
      "Epoch 503, CIFAR-10 Batch 5:  Loss:     0.5451 Validation Accuracy: 0.661400\n",
      "Epoch 504, CIFAR-10 Batch 1:  Loss:     0.5483 Validation Accuracy: 0.668800\n",
      "Epoch 504, CIFAR-10 Batch 2:  Loss:     0.5460 Validation Accuracy: 0.663600\n",
      "Epoch 504, CIFAR-10 Batch 3:  Loss:     0.5508 Validation Accuracy: 0.671600\n",
      "Epoch 504, CIFAR-10 Batch 4:  Loss:     0.5451 Validation Accuracy: 0.671400\n",
      "Epoch 504, CIFAR-10 Batch 5:  Loss:     0.5329 Validation Accuracy: 0.666400\n",
      "Epoch 505, CIFAR-10 Batch 1:  Loss:     0.5679 Validation Accuracy: 0.667400\n",
      "Epoch 505, CIFAR-10 Batch 2:  Loss:     0.5537 Validation Accuracy: 0.668800\n",
      "Epoch 505, CIFAR-10 Batch 3:  Loss:     0.5365 Validation Accuracy: 0.672000\n",
      "Epoch 505, CIFAR-10 Batch 4:  Loss:     0.5517 Validation Accuracy: 0.663800\n",
      "Epoch 505, CIFAR-10 Batch 5:  Loss:     0.5296 Validation Accuracy: 0.669200\n",
      "Epoch 506, CIFAR-10 Batch 1:  Loss:     0.5637 Validation Accuracy: 0.669400\n",
      "Epoch 506, CIFAR-10 Batch 2:  Loss:     0.5445 Validation Accuracy: 0.669600\n",
      "Epoch 506, CIFAR-10 Batch 3:  Loss:     0.5273 Validation Accuracy: 0.669800\n",
      "Epoch 506, CIFAR-10 Batch 4:  Loss:     0.5353 Validation Accuracy: 0.673200\n",
      "Epoch 506, CIFAR-10 Batch 5:  Loss:     0.5190 Validation Accuracy: 0.670400\n",
      "Epoch 507, CIFAR-10 Batch 1:  Loss:     0.5626 Validation Accuracy: 0.667400\n",
      "Epoch 507, CIFAR-10 Batch 2:  Loss:     0.5651 Validation Accuracy: 0.667000\n",
      "Epoch 507, CIFAR-10 Batch 3:  Loss:     0.5296 Validation Accuracy: 0.674200\n",
      "Epoch 507, CIFAR-10 Batch 4:  Loss:     0.5228 Validation Accuracy: 0.666400\n",
      "Epoch 507, CIFAR-10 Batch 5:  Loss:     0.5305 Validation Accuracy: 0.667000\n",
      "Epoch 508, CIFAR-10 Batch 1:  Loss:     0.5731 Validation Accuracy: 0.667000\n",
      "Epoch 508, CIFAR-10 Batch 2:  Loss:     0.5515 Validation Accuracy: 0.665600\n",
      "Epoch 508, CIFAR-10 Batch 3:  Loss:     0.5541 Validation Accuracy: 0.668800\n",
      "Epoch 508, CIFAR-10 Batch 4:  Loss:     0.5287 Validation Accuracy: 0.666400\n",
      "Epoch 508, CIFAR-10 Batch 5:  Loss:     0.5335 Validation Accuracy: 0.671000\n",
      "Epoch 509, CIFAR-10 Batch 1:  Loss:     0.5627 Validation Accuracy: 0.663200\n",
      "Epoch 509, CIFAR-10 Batch 2:  Loss:     0.5384 Validation Accuracy: 0.673200\n",
      "Epoch 509, CIFAR-10 Batch 3:  Loss:     0.5493 Validation Accuracy: 0.672800\n",
      "Epoch 509, CIFAR-10 Batch 4:  Loss:     0.5478 Validation Accuracy: 0.665000\n",
      "Epoch 509, CIFAR-10 Batch 5:  Loss:     0.5208 Validation Accuracy: 0.672200\n",
      "Epoch 510, CIFAR-10 Batch 1:  Loss:     0.5460 Validation Accuracy: 0.671000\n",
      "Epoch 510, CIFAR-10 Batch 2:  Loss:     0.5559 Validation Accuracy: 0.666400\n",
      "Epoch 510, CIFAR-10 Batch 3:  Loss:     0.5494 Validation Accuracy: 0.669400\n",
      "Epoch 510, CIFAR-10 Batch 4:  Loss:     0.5206 Validation Accuracy: 0.670800\n",
      "Epoch 510, CIFAR-10 Batch 5:  Loss:     0.5341 Validation Accuracy: 0.665800\n",
      "Epoch 511, CIFAR-10 Batch 1:  Loss:     0.5661 Validation Accuracy: 0.671400\n",
      "Epoch 511, CIFAR-10 Batch 2:  Loss:     0.5491 Validation Accuracy: 0.666600\n",
      "Epoch 511, CIFAR-10 Batch 3:  Loss:     0.5440 Validation Accuracy: 0.671000\n",
      "Epoch 511, CIFAR-10 Batch 4:  Loss:     0.5454 Validation Accuracy: 0.665200\n",
      "Epoch 511, CIFAR-10 Batch 5:  Loss:     0.5225 Validation Accuracy: 0.665800\n",
      "Epoch 512, CIFAR-10 Batch 1:  Loss:     0.5503 Validation Accuracy: 0.669400\n",
      "Epoch 512, CIFAR-10 Batch 2:  Loss:     0.5480 Validation Accuracy: 0.668400\n",
      "Epoch 512, CIFAR-10 Batch 3:  Loss:     0.5375 Validation Accuracy: 0.675400\n",
      "Epoch 512, CIFAR-10 Batch 4:  Loss:     0.5251 Validation Accuracy: 0.672800\n",
      "Epoch 512, CIFAR-10 Batch 5:  Loss:     0.5103 Validation Accuracy: 0.673400\n",
      "Epoch 513, CIFAR-10 Batch 1:  Loss:     0.5556 Validation Accuracy: 0.672400\n",
      "Epoch 513, CIFAR-10 Batch 2:  Loss:     0.5717 Validation Accuracy: 0.661600\n",
      "Epoch 513, CIFAR-10 Batch 3:  Loss:     0.5271 Validation Accuracy: 0.674000\n",
      "Epoch 513, CIFAR-10 Batch 4:  Loss:     0.5210 Validation Accuracy: 0.673400\n",
      "Epoch 513, CIFAR-10 Batch 5:  Loss:     0.5336 Validation Accuracy: 0.670200\n",
      "Epoch 514, CIFAR-10 Batch 1:  Loss:     0.5397 Validation Accuracy: 0.674600\n",
      "Epoch 514, CIFAR-10 Batch 2:  Loss:     0.5447 Validation Accuracy: 0.668800\n",
      "Epoch 514, CIFAR-10 Batch 3:  Loss:     0.5358 Validation Accuracy: 0.674200\n",
      "Epoch 514, CIFAR-10 Batch 4:  Loss:     0.5346 Validation Accuracy: 0.663400\n",
      "Epoch 514, CIFAR-10 Batch 5:  Loss:     0.5316 Validation Accuracy: 0.663400\n",
      "Epoch 515, CIFAR-10 Batch 1:  Loss:     0.5615 Validation Accuracy: 0.664800\n",
      "Epoch 515, CIFAR-10 Batch 2:  Loss:     0.5588 Validation Accuracy: 0.663200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 515, CIFAR-10 Batch 3:  Loss:     0.5456 Validation Accuracy: 0.671800\n",
      "Epoch 515, CIFAR-10 Batch 4:  Loss:     0.5176 Validation Accuracy: 0.678200\n",
      "Epoch 515, CIFAR-10 Batch 5:  Loss:     0.5421 Validation Accuracy: 0.666600\n",
      "Epoch 516, CIFAR-10 Batch 1:  Loss:     0.5418 Validation Accuracy: 0.673600\n",
      "Epoch 516, CIFAR-10 Batch 2:  Loss:     0.5453 Validation Accuracy: 0.666800\n",
      "Epoch 516, CIFAR-10 Batch 3:  Loss:     0.5477 Validation Accuracy: 0.674600\n",
      "Epoch 516, CIFAR-10 Batch 4:  Loss:     0.5149 Validation Accuracy: 0.672600\n",
      "Epoch 516, CIFAR-10 Batch 5:  Loss:     0.5348 Validation Accuracy: 0.670600\n",
      "Epoch 517, CIFAR-10 Batch 1:  Loss:     0.5700 Validation Accuracy: 0.667000\n",
      "Epoch 517, CIFAR-10 Batch 2:  Loss:     0.5207 Validation Accuracy: 0.670000\n",
      "Epoch 517, CIFAR-10 Batch 3:  Loss:     0.5381 Validation Accuracy: 0.675800\n",
      "Epoch 517, CIFAR-10 Batch 4:  Loss:     0.5385 Validation Accuracy: 0.669600\n",
      "Epoch 517, CIFAR-10 Batch 5:  Loss:     0.5245 Validation Accuracy: 0.665600\n",
      "Epoch 518, CIFAR-10 Batch 1:  Loss:     0.5387 Validation Accuracy: 0.674800\n",
      "Epoch 518, CIFAR-10 Batch 2:  Loss:     0.5406 Validation Accuracy: 0.671000\n",
      "Epoch 518, CIFAR-10 Batch 3:  Loss:     0.5357 Validation Accuracy: 0.671000\n",
      "Epoch 518, CIFAR-10 Batch 4:  Loss:     0.5272 Validation Accuracy: 0.676200\n",
      "Epoch 518, CIFAR-10 Batch 5:  Loss:     0.5246 Validation Accuracy: 0.671800\n",
      "Epoch 519, CIFAR-10 Batch 1:  Loss:     0.5554 Validation Accuracy: 0.674200\n",
      "Epoch 519, CIFAR-10 Batch 2:  Loss:     0.5397 Validation Accuracy: 0.672000\n",
      "Epoch 519, CIFAR-10 Batch 3:  Loss:     0.5434 Validation Accuracy: 0.671200\n",
      "Epoch 519, CIFAR-10 Batch 4:  Loss:     0.5236 Validation Accuracy: 0.673200\n",
      "Epoch 519, CIFAR-10 Batch 5:  Loss:     0.5320 Validation Accuracy: 0.663800\n",
      "Epoch 520, CIFAR-10 Batch 1:  Loss:     0.5621 Validation Accuracy: 0.666000\n",
      "Epoch 520, CIFAR-10 Batch 2:  Loss:     0.5462 Validation Accuracy: 0.669600\n",
      "Epoch 520, CIFAR-10 Batch 3:  Loss:     0.5362 Validation Accuracy: 0.668200\n",
      "Epoch 520, CIFAR-10 Batch 4:  Loss:     0.5466 Validation Accuracy: 0.670400\n",
      "Epoch 520, CIFAR-10 Batch 5:  Loss:     0.5291 Validation Accuracy: 0.667600\n",
      "Epoch 521, CIFAR-10 Batch 1:  Loss:     0.5505 Validation Accuracy: 0.671200\n",
      "Epoch 521, CIFAR-10 Batch 2:  Loss:     0.5550 Validation Accuracy: 0.662200\n",
      "Epoch 521, CIFAR-10 Batch 3:  Loss:     0.5554 Validation Accuracy: 0.671800\n",
      "Epoch 521, CIFAR-10 Batch 4:  Loss:     0.5263 Validation Accuracy: 0.665600\n",
      "Epoch 521, CIFAR-10 Batch 5:  Loss:     0.5118 Validation Accuracy: 0.668200\n",
      "Epoch 522, CIFAR-10 Batch 1:  Loss:     0.5649 Validation Accuracy: 0.662600\n",
      "Epoch 522, CIFAR-10 Batch 2:  Loss:     0.5658 Validation Accuracy: 0.659600\n",
      "Epoch 522, CIFAR-10 Batch 3:  Loss:     0.5366 Validation Accuracy: 0.666600\n",
      "Epoch 522, CIFAR-10 Batch 4:  Loss:     0.5321 Validation Accuracy: 0.669200\n",
      "Epoch 522, CIFAR-10 Batch 5:  Loss:     0.5341 Validation Accuracy: 0.666400\n",
      "Epoch 523, CIFAR-10 Batch 1:  Loss:     0.5398 Validation Accuracy: 0.671600\n",
      "Epoch 523, CIFAR-10 Batch 2:  Loss:     0.5312 Validation Accuracy: 0.668800\n",
      "Epoch 523, CIFAR-10 Batch 3:  Loss:     0.5414 Validation Accuracy: 0.671800\n",
      "Epoch 523, CIFAR-10 Batch 4:  Loss:     0.5110 Validation Accuracy: 0.671800\n",
      "Epoch 523, CIFAR-10 Batch 5:  Loss:     0.5234 Validation Accuracy: 0.677400\n",
      "Epoch 524, CIFAR-10 Batch 1:  Loss:     0.5325 Validation Accuracy: 0.677200\n",
      "Epoch 524, CIFAR-10 Batch 2:  Loss:     0.5587 Validation Accuracy: 0.669800\n",
      "Epoch 524, CIFAR-10 Batch 3:  Loss:     0.5278 Validation Accuracy: 0.673400\n",
      "Epoch 524, CIFAR-10 Batch 4:  Loss:     0.5143 Validation Accuracy: 0.673400\n",
      "Epoch 524, CIFAR-10 Batch 5:  Loss:     0.5104 Validation Accuracy: 0.669400\n",
      "Epoch 525, CIFAR-10 Batch 1:  Loss:     0.5496 Validation Accuracy: 0.669800\n",
      "Epoch 525, CIFAR-10 Batch 2:  Loss:     0.5317 Validation Accuracy: 0.674200\n",
      "Epoch 525, CIFAR-10 Batch 3:  Loss:     0.5219 Validation Accuracy: 0.674200\n",
      "Epoch 525, CIFAR-10 Batch 4:  Loss:     0.5204 Validation Accuracy: 0.673600\n",
      "Epoch 525, CIFAR-10 Batch 5:  Loss:     0.5361 Validation Accuracy: 0.669400\n",
      "Epoch 526, CIFAR-10 Batch 1:  Loss:     0.5419 Validation Accuracy: 0.675800\n",
      "Epoch 526, CIFAR-10 Batch 2:  Loss:     0.5394 Validation Accuracy: 0.674800\n",
      "Epoch 526, CIFAR-10 Batch 3:  Loss:     0.5465 Validation Accuracy: 0.670200\n",
      "Epoch 526, CIFAR-10 Batch 4:  Loss:     0.5244 Validation Accuracy: 0.670400\n",
      "Epoch 526, CIFAR-10 Batch 5:  Loss:     0.5223 Validation Accuracy: 0.667400\n",
      "Epoch 527, CIFAR-10 Batch 1:  Loss:     0.5396 Validation Accuracy: 0.675200\n",
      "Epoch 527, CIFAR-10 Batch 2:  Loss:     0.5588 Validation Accuracy: 0.671000\n",
      "Epoch 527, CIFAR-10 Batch 3:  Loss:     0.5474 Validation Accuracy: 0.674400\n",
      "Epoch 527, CIFAR-10 Batch 4:  Loss:     0.5186 Validation Accuracy: 0.673200\n",
      "Epoch 527, CIFAR-10 Batch 5:  Loss:     0.5192 Validation Accuracy: 0.673400\n",
      "Epoch 528, CIFAR-10 Batch 1:  Loss:     0.5397 Validation Accuracy: 0.675600\n",
      "Epoch 528, CIFAR-10 Batch 2:  Loss:     0.5325 Validation Accuracy: 0.674800\n",
      "Epoch 528, CIFAR-10 Batch 3:  Loss:     0.5370 Validation Accuracy: 0.669000\n",
      "Epoch 528, CIFAR-10 Batch 4:  Loss:     0.5112 Validation Accuracy: 0.672800\n",
      "Epoch 528, CIFAR-10 Batch 5:  Loss:     0.5185 Validation Accuracy: 0.676600\n",
      "Epoch 529, CIFAR-10 Batch 1:  Loss:     0.5644 Validation Accuracy: 0.669400\n",
      "Epoch 529, CIFAR-10 Batch 2:  Loss:     0.5241 Validation Accuracy: 0.674400\n",
      "Epoch 529, CIFAR-10 Batch 3:  Loss:     0.5484 Validation Accuracy: 0.668400\n",
      "Epoch 529, CIFAR-10 Batch 4:  Loss:     0.5137 Validation Accuracy: 0.676400\n",
      "Epoch 529, CIFAR-10 Batch 5:  Loss:     0.5325 Validation Accuracy: 0.670400\n",
      "Epoch 530, CIFAR-10 Batch 1:  Loss:     0.5245 Validation Accuracy: 0.673600\n",
      "Epoch 530, CIFAR-10 Batch 2:  Loss:     0.5240 Validation Accuracy: 0.671800\n",
      "Epoch 530, CIFAR-10 Batch 3:  Loss:     0.5527 Validation Accuracy: 0.669800\n",
      "Epoch 530, CIFAR-10 Batch 4:  Loss:     0.5146 Validation Accuracy: 0.671400\n",
      "Epoch 530, CIFAR-10 Batch 5:  Loss:     0.5152 Validation Accuracy: 0.677400\n",
      "Epoch 531, CIFAR-10 Batch 1:  Loss:     0.5406 Validation Accuracy: 0.676400\n",
      "Epoch 531, CIFAR-10 Batch 2:  Loss:     0.5370 Validation Accuracy: 0.669800\n",
      "Epoch 531, CIFAR-10 Batch 3:  Loss:     0.5438 Validation Accuracy: 0.666600\n",
      "Epoch 531, CIFAR-10 Batch 4:  Loss:     0.5162 Validation Accuracy: 0.675200\n",
      "Epoch 531, CIFAR-10 Batch 5:  Loss:     0.5312 Validation Accuracy: 0.667400\n",
      "Epoch 532, CIFAR-10 Batch 1:  Loss:     0.5421 Validation Accuracy: 0.673200\n",
      "Epoch 532, CIFAR-10 Batch 2:  Loss:     0.5362 Validation Accuracy: 0.664400\n",
      "Epoch 532, CIFAR-10 Batch 3:  Loss:     0.5297 Validation Accuracy: 0.669800\n",
      "Epoch 532, CIFAR-10 Batch 4:  Loss:     0.5088 Validation Accuracy: 0.674200\n",
      "Epoch 532, CIFAR-10 Batch 5:  Loss:     0.5338 Validation Accuracy: 0.667000\n",
      "Epoch 533, CIFAR-10 Batch 1:  Loss:     0.5401 Validation Accuracy: 0.678400\n",
      "Epoch 533, CIFAR-10 Batch 2:  Loss:     0.5360 Validation Accuracy: 0.675200\n",
      "Epoch 533, CIFAR-10 Batch 3:  Loss:     0.5215 Validation Accuracy: 0.675200\n",
      "Epoch 533, CIFAR-10 Batch 4:  Loss:     0.5117 Validation Accuracy: 0.668200\n",
      "Epoch 533, CIFAR-10 Batch 5:  Loss:     0.5081 Validation Accuracy: 0.673600\n",
      "Epoch 534, CIFAR-10 Batch 1:  Loss:     0.5323 Validation Accuracy: 0.679200\n",
      "Epoch 534, CIFAR-10 Batch 2:  Loss:     0.5264 Validation Accuracy: 0.675000\n",
      "Epoch 534, CIFAR-10 Batch 3:  Loss:     0.5256 Validation Accuracy: 0.675400\n",
      "Epoch 534, CIFAR-10 Batch 4:  Loss:     0.5153 Validation Accuracy: 0.668400\n",
      "Epoch 534, CIFAR-10 Batch 5:  Loss:     0.5313 Validation Accuracy: 0.668400\n",
      "Epoch 535, CIFAR-10 Batch 1:  Loss:     0.5504 Validation Accuracy: 0.675800\n",
      "Epoch 535, CIFAR-10 Batch 2:  Loss:     0.5479 Validation Accuracy: 0.673200\n",
      "Epoch 535, CIFAR-10 Batch 3:  Loss:     0.5360 Validation Accuracy: 0.673400\n",
      "Epoch 535, CIFAR-10 Batch 4:  Loss:     0.4941 Validation Accuracy: 0.676400\n",
      "Epoch 535, CIFAR-10 Batch 5:  Loss:     0.5162 Validation Accuracy: 0.674000\n",
      "Epoch 536, CIFAR-10 Batch 1:  Loss:     0.5358 Validation Accuracy: 0.675400\n",
      "Epoch 536, CIFAR-10 Batch 2:  Loss:     0.5271 Validation Accuracy: 0.668400\n",
      "Epoch 536, CIFAR-10 Batch 3:  Loss:     0.5555 Validation Accuracy: 0.667200\n",
      "Epoch 536, CIFAR-10 Batch 4:  Loss:     0.5096 Validation Accuracy: 0.674400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 536, CIFAR-10 Batch 5:  Loss:     0.5101 Validation Accuracy: 0.673800\n",
      "Epoch 537, CIFAR-10 Batch 1:  Loss:     0.5349 Validation Accuracy: 0.672600\n",
      "Epoch 537, CIFAR-10 Batch 2:  Loss:     0.5304 Validation Accuracy: 0.674200\n",
      "Epoch 537, CIFAR-10 Batch 3:  Loss:     0.5147 Validation Accuracy: 0.673400\n",
      "Epoch 537, CIFAR-10 Batch 4:  Loss:     0.5341 Validation Accuracy: 0.666400\n",
      "Epoch 537, CIFAR-10 Batch 5:  Loss:     0.5333 Validation Accuracy: 0.670600\n",
      "Epoch 538, CIFAR-10 Batch 1:  Loss:     0.5458 Validation Accuracy: 0.670400\n",
      "Epoch 538, CIFAR-10 Batch 2:  Loss:     0.5327 Validation Accuracy: 0.670200\n",
      "Epoch 538, CIFAR-10 Batch 3:  Loss:     0.5251 Validation Accuracy: 0.675200\n",
      "Epoch 538, CIFAR-10 Batch 4:  Loss:     0.5096 Validation Accuracy: 0.674600\n",
      "Epoch 538, CIFAR-10 Batch 5:  Loss:     0.5144 Validation Accuracy: 0.666800\n",
      "Epoch 539, CIFAR-10 Batch 1:  Loss:     0.5518 Validation Accuracy: 0.669800\n",
      "Epoch 539, CIFAR-10 Batch 2:  Loss:     0.5099 Validation Accuracy: 0.678800\n",
      "Epoch 539, CIFAR-10 Batch 3:  Loss:     0.5215 Validation Accuracy: 0.676800\n",
      "Epoch 539, CIFAR-10 Batch 4:  Loss:     0.5031 Validation Accuracy: 0.672800\n",
      "Epoch 539, CIFAR-10 Batch 5:  Loss:     0.5075 Validation Accuracy: 0.670200\n",
      "Epoch 540, CIFAR-10 Batch 1:  Loss:     0.5526 Validation Accuracy: 0.671400\n",
      "Epoch 540, CIFAR-10 Batch 2:  Loss:     0.5453 Validation Accuracy: 0.668000\n",
      "Epoch 540, CIFAR-10 Batch 3:  Loss:     0.5508 Validation Accuracy: 0.668400\n",
      "Epoch 540, CIFAR-10 Batch 4:  Loss:     0.5302 Validation Accuracy: 0.668000\n",
      "Epoch 540, CIFAR-10 Batch 5:  Loss:     0.5249 Validation Accuracy: 0.670800\n",
      "Epoch 541, CIFAR-10 Batch 1:  Loss:     0.5366 Validation Accuracy: 0.674400\n",
      "Epoch 541, CIFAR-10 Batch 2:  Loss:     0.5339 Validation Accuracy: 0.676800\n",
      "Epoch 541, CIFAR-10 Batch 3:  Loss:     0.5266 Validation Accuracy: 0.664800\n",
      "Epoch 541, CIFAR-10 Batch 4:  Loss:     0.5046 Validation Accuracy: 0.671800\n",
      "Epoch 541, CIFAR-10 Batch 5:  Loss:     0.5175 Validation Accuracy: 0.669400\n",
      "Epoch 542, CIFAR-10 Batch 1:  Loss:     0.5496 Validation Accuracy: 0.671200\n",
      "Epoch 542, CIFAR-10 Batch 2:  Loss:     0.5524 Validation Accuracy: 0.670200\n",
      "Epoch 542, CIFAR-10 Batch 3:  Loss:     0.5384 Validation Accuracy: 0.668800\n",
      "Epoch 542, CIFAR-10 Batch 4:  Loss:     0.5214 Validation Accuracy: 0.667200\n",
      "Epoch 542, CIFAR-10 Batch 5:  Loss:     0.5192 Validation Accuracy: 0.671600\n",
      "Epoch 543, CIFAR-10 Batch 1:  Loss:     0.5493 Validation Accuracy: 0.671600\n",
      "Epoch 543, CIFAR-10 Batch 2:  Loss:     0.5202 Validation Accuracy: 0.673800\n",
      "Epoch 543, CIFAR-10 Batch 3:  Loss:     0.5097 Validation Accuracy: 0.672800\n",
      "Epoch 543, CIFAR-10 Batch 4:  Loss:     0.5068 Validation Accuracy: 0.672000\n",
      "Epoch 543, CIFAR-10 Batch 5:  Loss:     0.5198 Validation Accuracy: 0.668800\n",
      "Epoch 544, CIFAR-10 Batch 1:  Loss:     0.5279 Validation Accuracy: 0.673800\n",
      "Epoch 544, CIFAR-10 Batch 2:  Loss:     0.5379 Validation Accuracy: 0.670800\n",
      "Epoch 544, CIFAR-10 Batch 3:  Loss:     0.5494 Validation Accuracy: 0.675200\n",
      "Epoch 544, CIFAR-10 Batch 4:  Loss:     0.5224 Validation Accuracy: 0.671800\n",
      "Epoch 544, CIFAR-10 Batch 5:  Loss:     0.5113 Validation Accuracy: 0.671600\n",
      "Epoch 545, CIFAR-10 Batch 1:  Loss:     0.5432 Validation Accuracy: 0.674600\n",
      "Epoch 545, CIFAR-10 Batch 2:  Loss:     0.5229 Validation Accuracy: 0.674400\n",
      "Epoch 545, CIFAR-10 Batch 3:  Loss:     0.5221 Validation Accuracy: 0.674600\n",
      "Epoch 545, CIFAR-10 Batch 4:  Loss:     0.5083 Validation Accuracy: 0.673000\n",
      "Epoch 545, CIFAR-10 Batch 5:  Loss:     0.5017 Validation Accuracy: 0.676000\n",
      "Epoch 546, CIFAR-10 Batch 1:  Loss:     0.5264 Validation Accuracy: 0.675800\n",
      "Epoch 546, CIFAR-10 Batch 2:  Loss:     0.5429 Validation Accuracy: 0.667600\n",
      "Epoch 546, CIFAR-10 Batch 3:  Loss:     0.5201 Validation Accuracy: 0.674200\n",
      "Epoch 546, CIFAR-10 Batch 4:  Loss:     0.5029 Validation Accuracy: 0.668800\n",
      "Epoch 546, CIFAR-10 Batch 5:  Loss:     0.5193 Validation Accuracy: 0.672400\n",
      "Epoch 547, CIFAR-10 Batch 1:  Loss:     0.5428 Validation Accuracy: 0.673800\n",
      "Epoch 547, CIFAR-10 Batch 2:  Loss:     0.5362 Validation Accuracy: 0.672800\n",
      "Epoch 547, CIFAR-10 Batch 3:  Loss:     0.5400 Validation Accuracy: 0.668600\n",
      "Epoch 547, CIFAR-10 Batch 4:  Loss:     0.5006 Validation Accuracy: 0.677800\n",
      "Epoch 547, CIFAR-10 Batch 5:  Loss:     0.5073 Validation Accuracy: 0.678600\n",
      "Epoch 548, CIFAR-10 Batch 1:  Loss:     0.5304 Validation Accuracy: 0.674800\n",
      "Epoch 548, CIFAR-10 Batch 2:  Loss:     0.5668 Validation Accuracy: 0.659200\n",
      "Epoch 548, CIFAR-10 Batch 3:  Loss:     0.5239 Validation Accuracy: 0.677800\n",
      "Epoch 548, CIFAR-10 Batch 4:  Loss:     0.5049 Validation Accuracy: 0.676600\n",
      "Epoch 548, CIFAR-10 Batch 5:  Loss:     0.5047 Validation Accuracy: 0.673200\n",
      "Epoch 549, CIFAR-10 Batch 1:  Loss:     0.5602 Validation Accuracy: 0.671800\n",
      "Epoch 549, CIFAR-10 Batch 2:  Loss:     0.5234 Validation Accuracy: 0.672000\n",
      "Epoch 549, CIFAR-10 Batch 3:  Loss:     0.5231 Validation Accuracy: 0.673200\n",
      "Epoch 549, CIFAR-10 Batch 4:  Loss:     0.5004 Validation Accuracy: 0.669800\n",
      "Epoch 549, CIFAR-10 Batch 5:  Loss:     0.5012 Validation Accuracy: 0.675000\n",
      "Epoch 550, CIFAR-10 Batch 1:  Loss:     0.5376 Validation Accuracy: 0.669000\n",
      "Epoch 550, CIFAR-10 Batch 2:  Loss:     0.5299 Validation Accuracy: 0.673000\n",
      "Epoch 550, CIFAR-10 Batch 3:  Loss:     0.5299 Validation Accuracy: 0.670800\n",
      "Epoch 550, CIFAR-10 Batch 4:  Loss:     0.5015 Validation Accuracy: 0.674200\n",
      "Epoch 550, CIFAR-10 Batch 5:  Loss:     0.5128 Validation Accuracy: 0.675000\n",
      "Epoch 551, CIFAR-10 Batch 1:  Loss:     0.5356 Validation Accuracy: 0.670800\n",
      "Epoch 551, CIFAR-10 Batch 2:  Loss:     0.5411 Validation Accuracy: 0.665000\n",
      "Epoch 551, CIFAR-10 Batch 3:  Loss:     0.5258 Validation Accuracy: 0.671800\n",
      "Epoch 551, CIFAR-10 Batch 4:  Loss:     0.5185 Validation Accuracy: 0.664800\n",
      "Epoch 551, CIFAR-10 Batch 5:  Loss:     0.5076 Validation Accuracy: 0.674000\n",
      "Epoch 552, CIFAR-10 Batch 1:  Loss:     0.5264 Validation Accuracy: 0.671400\n",
      "Epoch 552, CIFAR-10 Batch 2:  Loss:     0.5238 Validation Accuracy: 0.673200\n",
      "Epoch 552, CIFAR-10 Batch 3:  Loss:     0.5228 Validation Accuracy: 0.672600\n",
      "Epoch 552, CIFAR-10 Batch 4:  Loss:     0.5219 Validation Accuracy: 0.674600\n",
      "Epoch 552, CIFAR-10 Batch 5:  Loss:     0.5035 Validation Accuracy: 0.678600\n",
      "Epoch 553, CIFAR-10 Batch 1:  Loss:     0.5369 Validation Accuracy: 0.677000\n",
      "Epoch 553, CIFAR-10 Batch 2:  Loss:     0.5379 Validation Accuracy: 0.671800\n",
      "Epoch 553, CIFAR-10 Batch 3:  Loss:     0.5290 Validation Accuracy: 0.669400\n",
      "Epoch 553, CIFAR-10 Batch 4:  Loss:     0.4958 Validation Accuracy: 0.674000\n",
      "Epoch 553, CIFAR-10 Batch 5:  Loss:     0.5181 Validation Accuracy: 0.671400\n",
      "Epoch 554, CIFAR-10 Batch 1:  Loss:     0.5264 Validation Accuracy: 0.677800\n",
      "Epoch 554, CIFAR-10 Batch 2:  Loss:     0.5336 Validation Accuracy: 0.667000\n",
      "Epoch 554, CIFAR-10 Batch 3:  Loss:     0.5335 Validation Accuracy: 0.670400\n",
      "Epoch 554, CIFAR-10 Batch 4:  Loss:     0.5160 Validation Accuracy: 0.668800\n",
      "Epoch 554, CIFAR-10 Batch 5:  Loss:     0.5063 Validation Accuracy: 0.666000\n",
      "Epoch 555, CIFAR-10 Batch 1:  Loss:     0.5347 Validation Accuracy: 0.672400\n",
      "Epoch 555, CIFAR-10 Batch 2:  Loss:     0.5369 Validation Accuracy: 0.672600\n",
      "Epoch 555, CIFAR-10 Batch 3:  Loss:     0.5352 Validation Accuracy: 0.664400\n",
      "Epoch 555, CIFAR-10 Batch 4:  Loss:     0.4975 Validation Accuracy: 0.669400\n",
      "Epoch 555, CIFAR-10 Batch 5:  Loss:     0.4964 Validation Accuracy: 0.666200\n",
      "Epoch 556, CIFAR-10 Batch 1:  Loss:     0.5354 Validation Accuracy: 0.670600\n",
      "Epoch 556, CIFAR-10 Batch 2:  Loss:     0.5301 Validation Accuracy: 0.667400\n",
      "Epoch 556, CIFAR-10 Batch 3:  Loss:     0.5093 Validation Accuracy: 0.675600\n",
      "Epoch 556, CIFAR-10 Batch 4:  Loss:     0.4871 Validation Accuracy: 0.673200\n",
      "Epoch 556, CIFAR-10 Batch 5:  Loss:     0.5121 Validation Accuracy: 0.669800\n",
      "Epoch 557, CIFAR-10 Batch 1:  Loss:     0.5174 Validation Accuracy: 0.675400\n",
      "Epoch 557, CIFAR-10 Batch 2:  Loss:     0.5397 Validation Accuracy: 0.668200\n",
      "Epoch 557, CIFAR-10 Batch 3:  Loss:     0.5514 Validation Accuracy: 0.665200\n",
      "Epoch 557, CIFAR-10 Batch 4:  Loss:     0.5132 Validation Accuracy: 0.671800\n",
      "Epoch 557, CIFAR-10 Batch 5:  Loss:     0.5241 Validation Accuracy: 0.661800\n",
      "Epoch 558, CIFAR-10 Batch 1:  Loss:     0.5435 Validation Accuracy: 0.671600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 558, CIFAR-10 Batch 2:  Loss:     0.5521 Validation Accuracy: 0.668000\n",
      "Epoch 558, CIFAR-10 Batch 3:  Loss:     0.5098 Validation Accuracy: 0.671000\n",
      "Epoch 558, CIFAR-10 Batch 4:  Loss:     0.4826 Validation Accuracy: 0.675800\n",
      "Epoch 558, CIFAR-10 Batch 5:  Loss:     0.4850 Validation Accuracy: 0.677000\n",
      "Epoch 559, CIFAR-10 Batch 1:  Loss:     0.5385 Validation Accuracy: 0.673200\n",
      "Epoch 559, CIFAR-10 Batch 2:  Loss:     0.5201 Validation Accuracy: 0.669800\n",
      "Epoch 559, CIFAR-10 Batch 3:  Loss:     0.5162 Validation Accuracy: 0.676200\n",
      "Epoch 559, CIFAR-10 Batch 4:  Loss:     0.5019 Validation Accuracy: 0.671800\n",
      "Epoch 559, CIFAR-10 Batch 5:  Loss:     0.5037 Validation Accuracy: 0.667400\n",
      "Epoch 560, CIFAR-10 Batch 1:  Loss:     0.5570 Validation Accuracy: 0.667600\n",
      "Epoch 560, CIFAR-10 Batch 2:  Loss:     0.5529 Validation Accuracy: 0.667600\n",
      "Epoch 560, CIFAR-10 Batch 3:  Loss:     0.5379 Validation Accuracy: 0.669000\n",
      "Epoch 560, CIFAR-10 Batch 4:  Loss:     0.4992 Validation Accuracy: 0.668400\n",
      "Epoch 560, CIFAR-10 Batch 5:  Loss:     0.5071 Validation Accuracy: 0.666200\n",
      "Epoch 561, CIFAR-10 Batch 1:  Loss:     0.5454 Validation Accuracy: 0.673400\n",
      "Epoch 561, CIFAR-10 Batch 2:  Loss:     0.5443 Validation Accuracy: 0.670000\n",
      "Epoch 561, CIFAR-10 Batch 3:  Loss:     0.5378 Validation Accuracy: 0.662400\n",
      "Epoch 561, CIFAR-10 Batch 4:  Loss:     0.5038 Validation Accuracy: 0.668800\n",
      "Epoch 561, CIFAR-10 Batch 5:  Loss:     0.5089 Validation Accuracy: 0.671600\n",
      "Epoch 562, CIFAR-10 Batch 1:  Loss:     0.5523 Validation Accuracy: 0.671400\n",
      "Epoch 562, CIFAR-10 Batch 2:  Loss:     0.5246 Validation Accuracy: 0.669200\n",
      "Epoch 562, CIFAR-10 Batch 3:  Loss:     0.5163 Validation Accuracy: 0.673200\n",
      "Epoch 562, CIFAR-10 Batch 4:  Loss:     0.5067 Validation Accuracy: 0.664600\n",
      "Epoch 562, CIFAR-10 Batch 5:  Loss:     0.5170 Validation Accuracy: 0.661000\n",
      "Epoch 563, CIFAR-10 Batch 1:  Loss:     0.5389 Validation Accuracy: 0.674200\n",
      "Epoch 563, CIFAR-10 Batch 2:  Loss:     0.5171 Validation Accuracy: 0.670400\n",
      "Epoch 563, CIFAR-10 Batch 3:  Loss:     0.5125 Validation Accuracy: 0.674600\n",
      "Epoch 563, CIFAR-10 Batch 4:  Loss:     0.5100 Validation Accuracy: 0.669200\n",
      "Epoch 563, CIFAR-10 Batch 5:  Loss:     0.4960 Validation Accuracy: 0.671200\n",
      "Epoch 564, CIFAR-10 Batch 1:  Loss:     0.5316 Validation Accuracy: 0.671200\n",
      "Epoch 564, CIFAR-10 Batch 2:  Loss:     0.5393 Validation Accuracy: 0.670400\n",
      "Epoch 564, CIFAR-10 Batch 3:  Loss:     0.5327 Validation Accuracy: 0.666800\n",
      "Epoch 564, CIFAR-10 Batch 4:  Loss:     0.4998 Validation Accuracy: 0.669000\n",
      "Epoch 564, CIFAR-10 Batch 5:  Loss:     0.5185 Validation Accuracy: 0.658200\n",
      "Epoch 565, CIFAR-10 Batch 1:  Loss:     0.5322 Validation Accuracy: 0.669600\n",
      "Epoch 565, CIFAR-10 Batch 2:  Loss:     0.5440 Validation Accuracy: 0.666200\n",
      "Epoch 565, CIFAR-10 Batch 3:  Loss:     0.5119 Validation Accuracy: 0.675800\n",
      "Epoch 565, CIFAR-10 Batch 4:  Loss:     0.4926 Validation Accuracy: 0.673400\n",
      "Epoch 565, CIFAR-10 Batch 5:  Loss:     0.5077 Validation Accuracy: 0.664600\n",
      "Epoch 566, CIFAR-10 Batch 1:  Loss:     0.5688 Validation Accuracy: 0.668200\n",
      "Epoch 566, CIFAR-10 Batch 2:  Loss:     0.5432 Validation Accuracy: 0.672400\n",
      "Epoch 566, CIFAR-10 Batch 3:  Loss:     0.5128 Validation Accuracy: 0.675800\n",
      "Epoch 566, CIFAR-10 Batch 4:  Loss:     0.4934 Validation Accuracy: 0.673200\n",
      "Epoch 566, CIFAR-10 Batch 5:  Loss:     0.4935 Validation Accuracy: 0.669600\n",
      "Epoch 567, CIFAR-10 Batch 1:  Loss:     0.5346 Validation Accuracy: 0.674400\n",
      "Epoch 567, CIFAR-10 Batch 2:  Loss:     0.5344 Validation Accuracy: 0.666800\n",
      "Epoch 567, CIFAR-10 Batch 3:  Loss:     0.5274 Validation Accuracy: 0.664800\n",
      "Epoch 567, CIFAR-10 Batch 4:  Loss:     0.5184 Validation Accuracy: 0.663200\n",
      "Epoch 567, CIFAR-10 Batch 5:  Loss:     0.5150 Validation Accuracy: 0.660600\n",
      "Epoch 568, CIFAR-10 Batch 1:  Loss:     0.5364 Validation Accuracy: 0.674800\n",
      "Epoch 568, CIFAR-10 Batch 2:  Loss:     0.5307 Validation Accuracy: 0.667000\n",
      "Epoch 568, CIFAR-10 Batch 3:  Loss:     0.5220 Validation Accuracy: 0.672000\n",
      "Epoch 568, CIFAR-10 Batch 4:  Loss:     0.5041 Validation Accuracy: 0.664800\n",
      "Epoch 568, CIFAR-10 Batch 5:  Loss:     0.5154 Validation Accuracy: 0.661000\n",
      "Epoch 569, CIFAR-10 Batch 1:  Loss:     0.5532 Validation Accuracy: 0.667000\n",
      "Epoch 569, CIFAR-10 Batch 2:  Loss:     0.5468 Validation Accuracy: 0.666800\n",
      "Epoch 569, CIFAR-10 Batch 3:  Loss:     0.5336 Validation Accuracy: 0.670600\n",
      "Epoch 569, CIFAR-10 Batch 4:  Loss:     0.5115 Validation Accuracy: 0.665800\n",
      "Epoch 569, CIFAR-10 Batch 5:  Loss:     0.4997 Validation Accuracy: 0.668200\n",
      "Epoch 570, CIFAR-10 Batch 1:  Loss:     0.5517 Validation Accuracy: 0.672400\n",
      "Epoch 570, CIFAR-10 Batch 2:  Loss:     0.5451 Validation Accuracy: 0.663800\n",
      "Epoch 570, CIFAR-10 Batch 3:  Loss:     0.5259 Validation Accuracy: 0.674000\n",
      "Epoch 570, CIFAR-10 Batch 4:  Loss:     0.4872 Validation Accuracy: 0.671400\n",
      "Epoch 570, CIFAR-10 Batch 5:  Loss:     0.5329 Validation Accuracy: 0.658800\n",
      "Epoch 571, CIFAR-10 Batch 1:  Loss:     0.5248 Validation Accuracy: 0.671600\n",
      "Epoch 571, CIFAR-10 Batch 2:  Loss:     0.5557 Validation Accuracy: 0.667400\n",
      "Epoch 571, CIFAR-10 Batch 3:  Loss:     0.5394 Validation Accuracy: 0.663800\n",
      "Epoch 571, CIFAR-10 Batch 4:  Loss:     0.5092 Validation Accuracy: 0.664600\n",
      "Epoch 571, CIFAR-10 Batch 5:  Loss:     0.5697 Validation Accuracy: 0.649200\n",
      "Epoch 572, CIFAR-10 Batch 1:  Loss:     0.5715 Validation Accuracy: 0.662200\n",
      "Epoch 572, CIFAR-10 Batch 2:  Loss:     0.5375 Validation Accuracy: 0.667000\n",
      "Epoch 572, CIFAR-10 Batch 3:  Loss:     0.5121 Validation Accuracy: 0.673400\n",
      "Epoch 572, CIFAR-10 Batch 4:  Loss:     0.4839 Validation Accuracy: 0.671400\n",
      "Epoch 572, CIFAR-10 Batch 5:  Loss:     0.5317 Validation Accuracy: 0.660000\n",
      "Epoch 573, CIFAR-10 Batch 1:  Loss:     0.5517 Validation Accuracy: 0.660200\n",
      "Epoch 573, CIFAR-10 Batch 2:  Loss:     0.5246 Validation Accuracy: 0.672400\n",
      "Epoch 573, CIFAR-10 Batch 3:  Loss:     0.5100 Validation Accuracy: 0.673400\n",
      "Epoch 573, CIFAR-10 Batch 4:  Loss:     0.4966 Validation Accuracy: 0.673800\n",
      "Epoch 573, CIFAR-10 Batch 5:  Loss:     0.4982 Validation Accuracy: 0.670200\n",
      "Epoch 574, CIFAR-10 Batch 1:  Loss:     0.5316 Validation Accuracy: 0.667000\n",
      "Epoch 574, CIFAR-10 Batch 2:  Loss:     0.5537 Validation Accuracy: 0.659800\n",
      "Epoch 574, CIFAR-10 Batch 3:  Loss:     0.5203 Validation Accuracy: 0.666400\n",
      "Epoch 574, CIFAR-10 Batch 4:  Loss:     0.5224 Validation Accuracy: 0.667000\n",
      "Epoch 574, CIFAR-10 Batch 5:  Loss:     0.5098 Validation Accuracy: 0.663000\n",
      "Epoch 575, CIFAR-10 Batch 1:  Loss:     0.5426 Validation Accuracy: 0.670200\n",
      "Epoch 575, CIFAR-10 Batch 2:  Loss:     0.5298 Validation Accuracy: 0.670600\n",
      "Epoch 575, CIFAR-10 Batch 3:  Loss:     0.5265 Validation Accuracy: 0.670600\n",
      "Epoch 575, CIFAR-10 Batch 4:  Loss:     0.4767 Validation Accuracy: 0.674000\n",
      "Epoch 575, CIFAR-10 Batch 5:  Loss:     0.5297 Validation Accuracy: 0.664800\n",
      "Epoch 576, CIFAR-10 Batch 1:  Loss:     0.5272 Validation Accuracy: 0.670400\n",
      "Epoch 576, CIFAR-10 Batch 2:  Loss:     0.5463 Validation Accuracy: 0.665400\n",
      "Epoch 576, CIFAR-10 Batch 3:  Loss:     0.5312 Validation Accuracy: 0.666000\n",
      "Epoch 576, CIFAR-10 Batch 4:  Loss:     0.4879 Validation Accuracy: 0.671800\n",
      "Epoch 576, CIFAR-10 Batch 5:  Loss:     0.5128 Validation Accuracy: 0.666000\n",
      "Epoch 577, CIFAR-10 Batch 1:  Loss:     0.5214 Validation Accuracy: 0.671800\n",
      "Epoch 577, CIFAR-10 Batch 2:  Loss:     0.5299 Validation Accuracy: 0.664200\n",
      "Epoch 577, CIFAR-10 Batch 3:  Loss:     0.5257 Validation Accuracy: 0.668800\n",
      "Epoch 577, CIFAR-10 Batch 4:  Loss:     0.5138 Validation Accuracy: 0.663000\n",
      "Epoch 577, CIFAR-10 Batch 5:  Loss:     0.5249 Validation Accuracy: 0.666000\n",
      "Epoch 578, CIFAR-10 Batch 1:  Loss:     0.5343 Validation Accuracy: 0.667800\n",
      "Epoch 578, CIFAR-10 Batch 2:  Loss:     0.5603 Validation Accuracy: 0.662800\n",
      "Epoch 578, CIFAR-10 Batch 3:  Loss:     0.5420 Validation Accuracy: 0.666400\n",
      "Epoch 578, CIFAR-10 Batch 4:  Loss:     0.4764 Validation Accuracy: 0.674600\n",
      "Epoch 578, CIFAR-10 Batch 5:  Loss:     0.5187 Validation Accuracy: 0.664600\n",
      "Epoch 579, CIFAR-10 Batch 1:  Loss:     0.5432 Validation Accuracy: 0.662400\n",
      "Epoch 579, CIFAR-10 Batch 2:  Loss:     0.5553 Validation Accuracy: 0.659200\n",
      "Epoch 579, CIFAR-10 Batch 3:  Loss:     0.5313 Validation Accuracy: 0.666400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 579, CIFAR-10 Batch 4:  Loss:     0.5012 Validation Accuracy: 0.668000\n",
      "Epoch 579, CIFAR-10 Batch 5:  Loss:     0.5157 Validation Accuracy: 0.665200\n",
      "Epoch 580, CIFAR-10 Batch 1:  Loss:     0.5427 Validation Accuracy: 0.669200\n",
      "Epoch 580, CIFAR-10 Batch 2:  Loss:     0.5344 Validation Accuracy: 0.666800\n",
      "Epoch 580, CIFAR-10 Batch 3:  Loss:     0.5310 Validation Accuracy: 0.664200\n",
      "Epoch 580, CIFAR-10 Batch 4:  Loss:     0.5153 Validation Accuracy: 0.660400\n",
      "Epoch 580, CIFAR-10 Batch 5:  Loss:     0.5130 Validation Accuracy: 0.660600\n",
      "Epoch 581, CIFAR-10 Batch 1:  Loss:     0.5273 Validation Accuracy: 0.670600\n",
      "Epoch 581, CIFAR-10 Batch 2:  Loss:     0.5512 Validation Accuracy: 0.668600\n",
      "Epoch 581, CIFAR-10 Batch 3:  Loss:     0.5309 Validation Accuracy: 0.660600\n",
      "Epoch 581, CIFAR-10 Batch 4:  Loss:     0.5262 Validation Accuracy: 0.661000\n",
      "Epoch 581, CIFAR-10 Batch 5:  Loss:     0.5222 Validation Accuracy: 0.661400\n",
      "Epoch 582, CIFAR-10 Batch 1:  Loss:     0.5570 Validation Accuracy: 0.666600\n",
      "Epoch 582, CIFAR-10 Batch 2:  Loss:     0.5320 Validation Accuracy: 0.668800\n",
      "Epoch 582, CIFAR-10 Batch 3:  Loss:     0.5156 Validation Accuracy: 0.668200\n",
      "Epoch 582, CIFAR-10 Batch 4:  Loss:     0.4894 Validation Accuracy: 0.667000\n",
      "Epoch 582, CIFAR-10 Batch 5:  Loss:     0.5206 Validation Accuracy: 0.668400\n",
      "Epoch 583, CIFAR-10 Batch 1:  Loss:     0.5326 Validation Accuracy: 0.674000\n",
      "Epoch 583, CIFAR-10 Batch 2:  Loss:     0.5294 Validation Accuracy: 0.666200\n",
      "Epoch 583, CIFAR-10 Batch 3:  Loss:     0.4974 Validation Accuracy: 0.672400\n",
      "Epoch 583, CIFAR-10 Batch 4:  Loss:     0.5129 Validation Accuracy: 0.662800\n",
      "Epoch 583, CIFAR-10 Batch 5:  Loss:     0.5066 Validation Accuracy: 0.665600\n",
      "Epoch 584, CIFAR-10 Batch 1:  Loss:     0.5408 Validation Accuracy: 0.661800\n",
      "Epoch 584, CIFAR-10 Batch 2:  Loss:     0.5383 Validation Accuracy: 0.662200\n",
      "Epoch 584, CIFAR-10 Batch 3:  Loss:     0.5030 Validation Accuracy: 0.676000\n",
      "Epoch 584, CIFAR-10 Batch 4:  Loss:     0.4826 Validation Accuracy: 0.670600\n",
      "Epoch 584, CIFAR-10 Batch 5:  Loss:     0.4899 Validation Accuracy: 0.670400\n",
      "Epoch 585, CIFAR-10 Batch 1:  Loss:     0.5226 Validation Accuracy: 0.670600\n",
      "Epoch 585, CIFAR-10 Batch 2:  Loss:     0.5197 Validation Accuracy: 0.668000\n",
      "Epoch 585, CIFAR-10 Batch 3:  Loss:     0.5222 Validation Accuracy: 0.665800\n",
      "Epoch 585, CIFAR-10 Batch 4:  Loss:     0.4907 Validation Accuracy: 0.668600\n",
      "Epoch 585, CIFAR-10 Batch 5:  Loss:     0.5062 Validation Accuracy: 0.665600\n",
      "Epoch 586, CIFAR-10 Batch 1:  Loss:     0.5633 Validation Accuracy: 0.669600\n",
      "Epoch 586, CIFAR-10 Batch 2:  Loss:     0.5546 Validation Accuracy: 0.670200\n",
      "Epoch 586, CIFAR-10 Batch 3:  Loss:     0.4999 Validation Accuracy: 0.673600\n",
      "Epoch 586, CIFAR-10 Batch 4:  Loss:     0.5264 Validation Accuracy: 0.664000\n",
      "Epoch 586, CIFAR-10 Batch 5:  Loss:     0.5267 Validation Accuracy: 0.660200\n",
      "Epoch 587, CIFAR-10 Batch 1:  Loss:     0.5511 Validation Accuracy: 0.664000\n",
      "Epoch 587, CIFAR-10 Batch 2:  Loss:     0.5134 Validation Accuracy: 0.669400\n",
      "Epoch 587, CIFAR-10 Batch 3:  Loss:     0.5148 Validation Accuracy: 0.669600\n",
      "Epoch 587, CIFAR-10 Batch 4:  Loss:     0.4905 Validation Accuracy: 0.675600\n",
      "Epoch 587, CIFAR-10 Batch 5:  Loss:     0.5009 Validation Accuracy: 0.668400\n",
      "Epoch 588, CIFAR-10 Batch 1:  Loss:     0.5290 Validation Accuracy: 0.671000\n",
      "Epoch 588, CIFAR-10 Batch 2:  Loss:     0.5369 Validation Accuracy: 0.672800\n",
      "Epoch 588, CIFAR-10 Batch 3:  Loss:     0.5036 Validation Accuracy: 0.674600\n",
      "Epoch 588, CIFAR-10 Batch 4:  Loss:     0.5144 Validation Accuracy: 0.666400\n",
      "Epoch 588, CIFAR-10 Batch 5:  Loss:     0.5320 Validation Accuracy: 0.661600\n",
      "Epoch 589, CIFAR-10 Batch 1:  Loss:     0.5281 Validation Accuracy: 0.671400\n",
      "Epoch 589, CIFAR-10 Batch 2:  Loss:     0.5308 Validation Accuracy: 0.673200\n",
      "Epoch 589, CIFAR-10 Batch 3:  Loss:     0.5023 Validation Accuracy: 0.672400\n",
      "Epoch 589, CIFAR-10 Batch 4:  Loss:     0.4883 Validation Accuracy: 0.674800\n",
      "Epoch 589, CIFAR-10 Batch 5:  Loss:     0.5022 Validation Accuracy: 0.666200\n",
      "Epoch 590, CIFAR-10 Batch 1:  Loss:     0.5271 Validation Accuracy: 0.672200\n",
      "Epoch 590, CIFAR-10 Batch 2:  Loss:     0.5470 Validation Accuracy: 0.665400\n",
      "Epoch 590, CIFAR-10 Batch 3:  Loss:     0.5089 Validation Accuracy: 0.671800\n",
      "Epoch 590, CIFAR-10 Batch 4:  Loss:     0.5184 Validation Accuracy: 0.664800\n",
      "Epoch 590, CIFAR-10 Batch 5:  Loss:     0.5167 Validation Accuracy: 0.658400\n",
      "Epoch 591, CIFAR-10 Batch 1:  Loss:     0.5443 Validation Accuracy: 0.665600\n",
      "Epoch 591, CIFAR-10 Batch 2:  Loss:     0.5413 Validation Accuracy: 0.666200\n",
      "Epoch 591, CIFAR-10 Batch 3:  Loss:     0.4923 Validation Accuracy: 0.677800\n",
      "Epoch 591, CIFAR-10 Batch 4:  Loss:     0.4856 Validation Accuracy: 0.675200\n",
      "Epoch 591, CIFAR-10 Batch 5:  Loss:     0.5117 Validation Accuracy: 0.667800\n",
      "Epoch 592, CIFAR-10 Batch 1:  Loss:     0.5461 Validation Accuracy: 0.666800\n",
      "Epoch 592, CIFAR-10 Batch 2:  Loss:     0.5247 Validation Accuracy: 0.667800\n",
      "Epoch 592, CIFAR-10 Batch 3:  Loss:     0.5051 Validation Accuracy: 0.674200\n",
      "Epoch 592, CIFAR-10 Batch 4:  Loss:     0.4830 Validation Accuracy: 0.669000\n",
      "Epoch 592, CIFAR-10 Batch 5:  Loss:     0.5123 Validation Accuracy: 0.667600\n",
      "Epoch 593, CIFAR-10 Batch 1:  Loss:     0.5449 Validation Accuracy: 0.672000\n",
      "Epoch 593, CIFAR-10 Batch 2:  Loss:     0.5254 Validation Accuracy: 0.674000\n",
      "Epoch 593, CIFAR-10 Batch 3:  Loss:     0.5036 Validation Accuracy: 0.673800\n",
      "Epoch 593, CIFAR-10 Batch 4:  Loss:     0.5091 Validation Accuracy: 0.660200\n",
      "Epoch 593, CIFAR-10 Batch 5:  Loss:     0.5051 Validation Accuracy: 0.667400\n",
      "Epoch 594, CIFAR-10 Batch 1:  Loss:     0.5228 Validation Accuracy: 0.667000\n",
      "Epoch 594, CIFAR-10 Batch 2:  Loss:     0.5373 Validation Accuracy: 0.674000\n",
      "Epoch 594, CIFAR-10 Batch 3:  Loss:     0.4995 Validation Accuracy: 0.676200\n",
      "Epoch 594, CIFAR-10 Batch 4:  Loss:     0.4757 Validation Accuracy: 0.672800\n",
      "Epoch 594, CIFAR-10 Batch 5:  Loss:     0.5094 Validation Accuracy: 0.662000\n",
      "Epoch 595, CIFAR-10 Batch 1:  Loss:     0.5650 Validation Accuracy: 0.663000\n",
      "Epoch 595, CIFAR-10 Batch 2:  Loss:     0.5202 Validation Accuracy: 0.672800\n",
      "Epoch 595, CIFAR-10 Batch 3:  Loss:     0.4903 Validation Accuracy: 0.673200\n",
      "Epoch 595, CIFAR-10 Batch 4:  Loss:     0.4972 Validation Accuracy: 0.670200\n",
      "Epoch 595, CIFAR-10 Batch 5:  Loss:     0.5113 Validation Accuracy: 0.668600\n",
      "Epoch 596, CIFAR-10 Batch 1:  Loss:     0.5315 Validation Accuracy: 0.672600\n",
      "Epoch 596, CIFAR-10 Batch 2:  Loss:     0.5196 Validation Accuracy: 0.671000\n",
      "Epoch 596, CIFAR-10 Batch 3:  Loss:     0.5024 Validation Accuracy: 0.672200\n",
      "Epoch 596, CIFAR-10 Batch 4:  Loss:     0.5012 Validation Accuracy: 0.665200\n",
      "Epoch 596, CIFAR-10 Batch 5:  Loss:     0.4973 Validation Accuracy: 0.667800\n",
      "Epoch 597, CIFAR-10 Batch 1:  Loss:     0.5190 Validation Accuracy: 0.668400\n",
      "Epoch 597, CIFAR-10 Batch 2:  Loss:     0.5315 Validation Accuracy: 0.667000\n",
      "Epoch 597, CIFAR-10 Batch 3:  Loss:     0.5244 Validation Accuracy: 0.669200\n",
      "Epoch 597, CIFAR-10 Batch 4:  Loss:     0.4923 Validation Accuracy: 0.668600\n",
      "Epoch 597, CIFAR-10 Batch 5:  Loss:     0.5081 Validation Accuracy: 0.664600\n",
      "Epoch 598, CIFAR-10 Batch 1:  Loss:     0.5429 Validation Accuracy: 0.667800\n",
      "Epoch 598, CIFAR-10 Batch 2:  Loss:     0.5061 Validation Accuracy: 0.677800\n",
      "Epoch 598, CIFAR-10 Batch 3:  Loss:     0.5010 Validation Accuracy: 0.675400\n",
      "Epoch 598, CIFAR-10 Batch 4:  Loss:     0.4963 Validation Accuracy: 0.661800\n",
      "Epoch 598, CIFAR-10 Batch 5:  Loss:     0.5103 Validation Accuracy: 0.664600\n",
      "Epoch 599, CIFAR-10 Batch 1:  Loss:     0.5252 Validation Accuracy: 0.670200\n",
      "Epoch 599, CIFAR-10 Batch 2:  Loss:     0.5048 Validation Accuracy: 0.675200\n",
      "Epoch 599, CIFAR-10 Batch 3:  Loss:     0.4927 Validation Accuracy: 0.673000\n",
      "Epoch 599, CIFAR-10 Batch 4:  Loss:     0.5466 Validation Accuracy: 0.653800\n",
      "Epoch 599, CIFAR-10 Batch 5:  Loss:     0.5205 Validation Accuracy: 0.664400\n",
      "Epoch 600, CIFAR-10 Batch 1:  Loss:     0.5268 Validation Accuracy: 0.666800\n",
      "Epoch 600, CIFAR-10 Batch 2:  Loss:     0.5134 Validation Accuracy: 0.669000\n",
      "Epoch 600, CIFAR-10 Batch 3:  Loss:     0.5007 Validation Accuracy: 0.675200\n",
      "Epoch 600, CIFAR-10 Batch 4:  Loss:     0.4892 Validation Accuracy: 0.672800\n",
      "Epoch 600, CIFAR-10 Batch 5:  Loss:     0.5249 Validation Accuracy: 0.666000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.6566685259342193\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fad642ec320>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. That's because there are many more techniques that can be applied to your model and we recemmond that once you are done with this project, you explore!\n",
    "\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
